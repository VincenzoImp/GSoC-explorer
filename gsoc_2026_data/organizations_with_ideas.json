[
  {
    "name": "Apache Software Foundation",
    "slug": "apache-software-foundation",
    "tagline": "Open source software to the public free of charge",
    "description": "The Foundation provides an established framework for intellectual property and financial contributions that simultaneously limits contributors potential legal exposure. Through a collaborative and meritocratic development process, Apache projects deliver enterprise-grade, freely available software products that attract large communities of users. The pragmatic Apache License makes it easy for all users, commercial and individual, to deploy Apache products.",
    "ideas_url": "https://s.apache.org/gsoc2026ideas",
    "website_url": "https://apache.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "java",
      "c++"
    ],
    "topic_tags": [
      "big data",
      "cloud",
      "libraries",
      "other"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/apache-software-foundation",
    "ideas_content": "DUE TO SPAM, SIGN-UP IS DISABLED. Goto [Selfserve wiki signup](https://selfserve.apache.org/confluence-account.html) and request an account.\n\nThis page is auto-generated! Please do NOT edit it, all changes will be lost on next update\n\nContents\n\n# APISIX\n\n[JSON Schema to Form UI for APISIX Dashboard](https://issues.apache.org/jira/browse/APISIX-39)\n\nAPISIX plugins ship JSON Schema definitions for their configuration. If APISIX Dashboard can render plugin configuration forms directly from JSON Schema, developer experience improves significantly and reduces manual UI maintenance.\n\nGoals (Deliverables)\n\nMust-have:\n\n- A reusable SchemaForm (or equivalent) that renders basic types: string/number/integer/boolean/object/array.\n- enum support (Select/Radio etc), defaults, required fields, basic constraints (min/max, pattern, etc) where feasible.\n- Support at least the key complex patterns used by APISIX plugin schemas:\n- oneOf (select one option and render corresponding fields)\n- dependencies / conditional fields\n- (Stretch) anyOf if present in target schemas\n\n- Validation pipeline: validate form values against schema (AJV) and show errors in UI consistently.\n- Documentation + developer guide: how to add/extend schema-to-widget mapping.\n- Tests (unit + minimal integration) to prevent regressions for schema parsing and conditional rendering.\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Yuan Bao*, mail: baoyuan (at) apache.org\n\n*Project Devs*, mail: dev (at) apisix.apache.org\n\n# Apache AsterixDB\n\n[NL2SQL++ assistant ](https://issues.apache.org/jira/browse/ASTERIXDB-3696)\n\nThis project aims to develop a modular, extensible NL2SQL component for AsterixDB that translates natural language prompts into executable SQL++ queries. The system will leverage recent advances in Large Language Models (LLMs) to enable users to express complex analytical questions without writing formal queries. It will follow best practices by exposing an OpenAPI-based interface that connects to external LLMs through frameworks such as LangChain4j while remaining model-agnostic. The component will also support locally-hosted LLMs to reduce operating costs and maintain privacy.\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Suryaa Charan*, mail: suryaacharan (at) apache.org\n\n*Project Devs*, mail:\n\n[LLM Agent Protocols/Memory](https://issues.apache.org/jira/browse/ASTERIXDB-3695)\n\nThis feature adds agent compatibility to AsterixDB by implementing standard agent protocols and agentic memory capabilities. It involves implementing two emerging standards: the Model Context Protocol (MCP) for tool exposure and structured capability discovery, and the Agent-to-Agent (A2A) protocol for multi-agent coordination. MCP will allow AsterixDB to describe its capabilities, datasets, functions, and safe operations to AI agents. The project also utilizes AsterixDB to provide persistent agentic memory that tracks an agent's query sessions, enabling agents to recall and build on previous interactions.\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Suryaa Charan*, mail: suryaacharan (at) apache.org\n\n*Project Devs*, mail:\n\n[Backup/restore utility for AsterixDB](https://issues.apache.org/jira/browse/ASTERIXDB-3697)\n\nIn order to backup and restore a database, one common pattern is to use a tool that takes the current state of the database and generates a set of DDL statements which, when executed, will create the existing state of the database. Currently this is not possible in AsterixDB for DDL statements- you would have to remember which ones you issued to create Types, Datasets, and so on. Therefore having a tool that can take the current state of the Metadata dataverse and craft a set of DDL statements that would create that state, and then for each dataset dump its contents into an INSERT statement, would be a great addition.\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Ian Maxon*, mail: imaxon (at) apache.org\n\n*Project Devs*, mail:\n\n[In-browser packaging of AsterixDB](https://issues.apache.org/jira/browse/ASTERIXDB-3698)\n\nAsterixDB since its inception has always been a distributed system. This has historically led to some friction for new users who simply want to try out the system to get a sense of the language and features. It simply isn't necessary for them to deploy the system as it would be for handling large amounts of data, however the deployment and packaging has to assume someone wants to do this. Therefore it has always been a balance between configurability and simplicity.\n\nWith the advancement of WASM and Javascript in general, there now exist versions of other databases, which were previously only run locally, which are adapted and targeted to a WASM or JS environment. This lets the user simply open a browser and get a fully-functioning instance of a real database like they would if it was installed locally or on a server somewhere. Given that AsterixDB is written purely in Java, it should in principle be possible to run AsterixDB on a JVM which can target WASM as an architecture, with WASI or some other platform. Having something similar for AsterixDB would be an amazing tool to help further the adoption of AsterixDB, and SQL++ in general.\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Ian Maxon*, mail: imaxon (at) apache.org\n\n*Project Devs*, mail:\n\n[Dynamic Memory Management ](https://issues.apache.org/jira/browse/ASTERIXDB-3703)\n\nAsterixDB currently uses a static approach for memory allocation in memory-intensive operators, where each operator is assigned a fixed memory budget, either user-provided or derived from defaults. Static budgeting can lead to several issues. Long-running queries may hold large memory allocations for extended periods, reducing concurrency and blocking other queries. In addition, memory estimation errors can result in over-allocation that wastes resources or under-allocation that causes spills and performance degradation.\n\nThis project will make key memory-intensive operators dynamically adaptive to memory reallocation requests from a resource broker. The broker will adjust operator memory budgets at runtime based on system conditions and workload objectives, such as improving fairness across concurrent queries, increasing overall throughput, and maintaining predictable performance under contention. The expected outcome is a coordinated memory management loop where operators expose safe resizing hooks and the broker uses feedback signals to rebalance memory across running queries.\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Shiva Jahangiri*, mail: shivajah (at) apache.org\n\n*Project Devs*, mail:\n\n[Top K Nearest Queries Support ](https://issues.apache.org/jira/browse/ASTERIXDB-3699)\n\nAsterixDB currently lacks native support for Top-K-Nearest queries, which return the K tuples whose attribute values are closest to a given reference value or point. Examples include: the five employees whose salaries are closest to the CEO's salary or the five buildings closest to the White House. This project involves designing and implementing efficient Top-K-Nearest query processing within AsterixDB's execution engine (Hyracks), including optimizer support to avoid full scans and to leverage existing indexes where possible. The implementation should integrate cleanly with SQL++.\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Suryaa Charan*, mail: suryaacharan (at) apache.org\n\n*Project Devs*, mail:\n\n# Apache Fineract\n\n[Loan Origination POC](https://issues.apache.org/jira/browse/FINERACT-2442)\n\n**Note: GSOC applicants - this is a \"draft concept\". Do not work on your proposal until we kick off the process at Fineract for evaluating. We may significantly edit this concept or create new ones to replace it.**\n\n**No one should work on this specific ticket unless assigned - the GSOC candidate we choose will be assigned this ticket.**\n\n**For more information, you should be reviewing emails on this subject and following the Wiki pages.** [https://lists.apache.org/list.html?dev@fineract.apache.org](https://lists.apache.org/list.html?dev@fineract.apache.org)[https://cwiki.apache.org/confluence/display/FINERACT/GSOC+Program+at+Fineract](https://cwiki.apache.org/confluence/display/FINERACT/GSOC+Program+at+Fineract)\n\n**LOAN ORIGINATION CONTEXT**\n\nFineract has some loan origination functionality but it is not robust enough for many operations. Several vendors, working with Fineract have created new Loan Origination plug ins.\n\nThere is also a major enhancement underway that would build out a full Loan Origination flow by supporting the backend needs of data storage for such LOS. See ticket [https://issues.apache.org/jira/browse/FINERACT-2418](https://issues.apache.org/jira/browse/FINERACT-2418) .\n\nThe GSOC student would be expected to propose something as a POC (proof of concept) that would either - use the developed Fienract backend solution, or build a new component outside of Fineract to create the flows that would demonstrate the LOS functionality.\n\nThat is, this is a moving target, and we would need different proposals from prospective candidates to explore the area of Loan Origination. This may require expertise in risk assessment, loan origination models and business acumen. There will not be much more explanation that this available. The student would be expected to be a self starter.\n\nThe mentor for this would need to be an expert at risk modeling, understand Loan Origination, and support a conceptual basis that may involve some things internal to Fineract and some processing elements outside of Fineract. Please comment below if you are an existing Fineract contributor with this expertise.\n\nTo try to illustrate: one possible GSOC Proposal archtype we could accept would be a survey of Loan Origination Models, their strengths and weaknesses and to identify commonalities for the community to focus on. This would thus be a Requirements exercise and may help identify future roadmap concepts. In this case, the code to be developed may just expose a few APIs into different screen flows. Thus, perhaps FIGMA flows (or similar) connecting to a set of APIs on the backend.\n\nIf those new LOS APIs are existing in June 2026 (ticket 2418 resolved), then those APIs are to be used. if they are NOT there in Fineract, then the student would be requested to create a fork and to implement the POC outside of the main Dev branch.\n\nI welcome additions to this write up. [jdailey](https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jdailey)\n\n**Difficulty:**Minor\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*James Dailey*, mail: jdailey (at) apache.org\n\n*Project Devs*, mail: dev (at) fineract.apache.org\n\n[Front end application MVP (POC)](https://issues.apache.org/jira/browse/FINERACT-2440)\n\n**Note: GSOC applicants - this is a \"draft concept\". Do not work on your proposal until we kick off the process at Fineract for evaluating. We may significantly edit this concept or create new ones to replace it.**\n\n**No one should work on this specific ticket unless assigned - the GSOC candidate we choose will be assigned this ticket.**\n\n**For more information, you should be reviewing emails on this subject and following the Wiki pages.** [https://lists.apache.org/list.html?dev@fineract.apache.org](https://lists.apache.org/list.html?dev@fineract.apache.org)[https://cwiki.apache.org/confluence/display/FINERACT/GSOC+Program+at+Fineract](https://cwiki.apache.org/confluence/display/FINERACT/GSOC+Program+at+Fineract)\n\n**Build a simple self-service front end that talks to the Self-Service API**\n\nWe need a new, user-friendly front end app that connects to our Backend for Front end (**Self-Service API component)** This will be the “customer portal” experience where users can log in, see their accounts, and check recent activity. It should be straightforward, easy to use, and a good reference example for others to build on.\n\nFunctionality needed would include:\n\n- Login\n- Check balances\n- Transfer between accounts owned by the same customer.\n- Submit application for a new loan\n\nTesting end to end required.\n\nSolid UI design\n\nModern app framework\n\nDocumentation\n\n**Difficulty:**Minor\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*James Dailey*, mail: jdailey (at) apache.org\n\n*Project Devs*, mail: dev (at) fineract.apache.org\n\n[Create a new backend for front end component POC](https://issues.apache.org/jira/browse/FINERACT-2439)\n\n**Note: GSOC applicants - this is a \"draft concept\". Do not work on your proposal until we kick off the process at Fineract for evaluating. We may significantly edit this concept or create new ones to replace it.**\n\n**No one should work on this specific ticket unless assigned - the GSOC candidate we choose will be assigned this ticket.**\n\n**For more information, you should be reviewing emails on this subject and following the Wiki pages.** [https://lists.apache.org/list.html?dev@fineract.apache.org](https://lists.apache.org/list.html?dev@fineract.apache.org)[https://cwiki.apache.org/confluence/display/FINERACT/GSOC+Program+at+Fineract](https://cwiki.apache.org/confluence/display/FINERACT/GSOC+Program+at+Fineract)\n\n**Build a Self-Service API Component that Connects to Apache Fineract**\n\nWhen the project removed self-service APIs in 2025, it did so understanding that we would need an outside component to make that connection as part of an overall solution.\n\nThis project is to create - as a Proof of Concept (POC) - a new dedicated Self-Service API component or service that integration with Fineract backend. It will need to expose APIs to consumer facing applications for typical activities like viewing account balances, transaction initiation, loan application, etc.\n\nThe idea is for GSOC candidates to propose a design and build the POC.\n\nMinimal criteria include testing, authentication methodology, documentation.\n\nNot included in this GSOC would be the end consumer APP, although that may be undertaken by another project and coordination would be needed.\n\n**Difficulty:**Minor\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*James Dailey*, mail: jdailey (at) apache.org\n\n*Project Devs*, mail: dev (at) fineract.apache.org\n\n[BI connector and demonstration](https://issues.apache.org/jira/browse/FINERACT-2441)\n\n**Note: GSOC applicants - this is a \"draft concept\". Do not work on your proposal until we kick off the process at Fineract for evaluating. We may significantly edit this concept or create new ones to replace it.**\n\n**No one should work on this specific ticket unless assigned - the GSOC candidate we choose will be assigned this ticket.**\n\n**For more information, you should be reviewing emails on this subject and following the Wiki pages.** [https://lists.apache.org/list.html?dev@fineract.apache.org](https://lists.apache.org/list.html?dev@fineract.apache.org)[https://cwiki.apache.org/confluence/display/FINERACT/GSOC+Program+at+Fineract](https://cwiki.apache.org/confluence/display/FINERACT/GSOC+Program+at+Fineract)\n\nThe idea is to create a connector and a demonstration of analytics that would consume and organize data from Fineract.\n\nFor example, create a way to pull data out of Fineract and make it easy to use in common analytics such as Power BI or Tableau or, better yet, an open source variant. The data should probably go to a Data Warehouse.\n\nStart by proposing and exploring different options and write up the pros and cons.\n\nCreate a demonstration project that takes into account security, levels of access, and security of PII data if it exists.\n\n**Difficulty:**Minor\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*James Dailey*, mail: jdailey (at) apache.org\n\n*Project Devs*, mail: dev (at) fineract.apache.org\n\n[fineract-client-feign usage for integration tests](https://issues.apache.org/jira/browse/FINERACT-2454)\n\n**Note: GSOC applicants - this is a \"draft concept\". Do not work on your proposal until we kick off the process at Fineract for evaluating. We may significantly edit this concept or create new ones to replace it.**\n\n**No one should work on this specific ticket unless assigned - the GSOC candidate we choose will be assigned this ticket.**\n\n**For more information, you should be reviewing emails on this subject and following the Wiki pages.** [https://lists.apache.org/list.html?dev@fineract.apache.org](https://lists.apache.org/list.html?dev@fineract.apache.org)[https://cwiki.apache.org/confluence/display/FINERACT/GSOC+Program+at+Fineract](https://cwiki.apache.org/confluence/display/FINERACT/GSOC+Program+at+Fineract)\n\n\"Moving away from RestAssured (low-level) API calls in integration tests and rather use fineract-client-feign would be a great improvement\"\n\n**Summary (with some assist from chatgpt for clarity)**\n\nApache Fineract has a large set of REST APIs and many integration tests currently call those APIs using **RestAssured**(low-level HTTP requests). This ticket is to help modernize the tests by switching them to use **fineract-client-feign**, which is Fineract’s higher-level API client.\n\n#### Goal\n\nCreate a simple migration approach and then migrate a small set of integration tests from RestAssured to fineract-client-feign.\n\n#### Why we’re doing this\n\n- Makes tests easier to read and maintain (less raw HTTP code).\n\n- Encourages consistent API usage across tests.\n\n- Reduces duplicated request-building logic (headers, base URLs, auth, etc.).\n\n## Scope of Work\n\n### 1) Create a short migration plan\n\nWrite a short note (in the Jira ticket comments or a small doc) that answers:\n\n- Where are the current RestAssured-based integration tests located?\n\n- What’s the recommended pattern for using fineract-client-feign in tests?\n\n- What should be migrated first (start small)?\n\n### 2) Pick a small “starter set” of tests\n\nIdentify **2–5 integration tests** that:\n\n- Are simple (e.g., create/read/update a resource)\n\n- Don’t involve complicated multi-step workflows\n\n- Run reliably in CI\n\n### 3) Implement the migration for the starter set\n\nFor each selected test:\n\n- Replace RestAssured calls with fineract-client-feign client calls\n\n- Keep the same assertions (same expected behavior)\n\n- Ensure the tests still pass locally and in CI\n\n### 4) Document the new pattern\n\nAdd a short README note or comments in the test code showing:\n\n- How to initialize/configure the Feign client for tests\n\n- How auth/session is handled\n\n- A small “before vs after” explanation (1 paragraph is enough)\n\n## Acceptance Criteria\n\n- A brief migration plan is written and linked in the ticket.\n\n- At least\n**2 integration tests**have been converted to use fineract-client-feign.\n\n- All tests pass (locally and/or in CI).\n\n- A short note exists explaining how to write future integration tests using fineract-client-feign.\n\n## Notes / Hints for a beginner\n\n- Start by converting just one very small test to learn the pattern.\n\n- Keep changes small and easy to review (one test per commit is ideal).\n\n- If something is unclear (e.g., how auth is set up), add a comment in the ticket describing what you found.\n\n## Out of Scope (for this ticket)\n\n- Migrating\n*all*integration tests across the repo\n\n- Refactoring production API code\n\n- Changing API behavior—this is only a test client swap\n\n**Difficulty:**Minor\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*James Dailey*, mail: jdailey (at) apache.org\n\n*Project Devs*, mail: dev (at) fineract.apache.org\n\n[[GSoC 2026] [POC] Standardize and Harden Transaction Idempotency for Savings and Loans](https://issues.apache.org/jira/browse/FINERACT-2485)\n\n**Goal:** Standardize idempotency enforcement to prevent replay attacks in core financial modules. **Implementation Strategy (Addressing James Dailey's feedback):**\n\n**Opt-In Architecture:**New logic will be behind a Global Configuration flag. Default remains legacy behavior to ensure 100% backward compatibility.\n\n**Phased Approach:**Audit existing m_portfolio_command_source usage and bridge gaps in the Savings module first.\n\n**Testing:**Implementation of integration tests simulating network failures/retries.\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*saifulhuq*, mail: saifulhuq (at) apache.org\n\n*Project Devs*, mail: dev (at) fineract.apache.org\n\n[[Testing] Add unit tests for ApiParameterHelper in fineract-core](https://issues.apache.org/jira/browse/FINERACT-2494)\n\nThere is currently no unit test coverage for the ApiParameterHelper utility class. I have implemented a new test suite using JUnit 5 to cover core methods like extractFieldsForResponseIfProvided.\n\nVerification: Successfully ran locally with 1/1 tests passed (100% success rate)\n\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Ambika*, mail: ambikasony (at) apache.org\n\n*Project Devs*, mail: dev (at) fineract.apache.org\n\n[New command processing infrastructure](https://issues.apache.org/jira/browse/FINERACT-2169)\n\n## Background and Motivation\n\nFineract accumulated some technical debt over the years. One area that is implicated is type-safety of internal and external facing APIs, the most prominent of which is Fineract's REST API. In general the package layout of the project reflects a more or less classic layered architecture (REST API, data transfer/value objects, business logic services, storage/repositories). The project predates some of the more modern frameworks and best practices that are available today and on occasions the data structures that are exchanged offer some challenges (e.g. generic types). Fineract's code base reflects that, especially where JSON de-/serialization is involved. Nowadays, this task would be simply delegated to the Jackson framework, but when Fineract (Mifos) started the decision was made to use Google's GSON library and create handcrafted helper classes to deal with JSON parsing. While this provided a lot of flexibility this approach had some downsides:\n\n- the lowest common denominator is the string type (aka JSON blob); this is where we lose the type information\n- the strings are transformed into JSONObjects; a little bit better than raw strings, but barely more than a hash map\n- a ton of \"magic\" strings are needed to get/set values\n- this approach makes refactoring unnecessarily more difficult\n- to be able to serve an OpenAPI descriptor (as JSON and YAML) we had to re-introduce the type information at the REST API level with dummy classes that contain only the specified attributes; those classes are only used with the Swagger annotations and no were else\n- some developers skipped the layered architecture and found it too tedious to maintain DTOs and JSON helper classes, and as a result just passed JSONObjects right to the business logic layer\n- now the business logic is unnecessarily aware of how Fineract communicates to the outside world and makes replacing/enhancing the communication protocol (e.g. with GRPC) pretty much impossible\n\nThe list doesn't end here, but in the end things boil down to two main points:\n\n- poor developer experience: boilerplate code and missing type safety cost more time\n- bugs: the more code the more likely errors get introduced, especially when type safety is missing and we have to rely on runtime errors (vs. compile time).\n\nThere has been already some preparatory work done concerning type safety, but until now we avoided dealing with the real source of this issue. Fineract's architectures devises read from write requests (\"CQRS\", [https://martinfowler.com/bliki/CQRS.html](https://martinfowler.com/bliki/CQRS.html)) for improved scalability.\n\nThe read requests are not that problematic, but all write requests pass through a component/service that is called \"SynchronousCommandProcessingService. As the name suggests the execution of business logic is synchronous (mostly) due to this part of the architecture. This is not necessarily a problem (not immediately at least), but it's nevertheless a central bottleneck in the system. Even more important: this service is responsible to route incoming commands to their respective handler classes which in turn execute functions on one or more business logic services. The payload of these commands are obviously not always the same... which is the main reason why we decided to use the lowest common denominator to be able to handle these various types and rendered all payloads as strings. This compromise bubbles now up in the REST API and the business logic layers (and actually everything in between).\n\nOver the years we've also added additional features (e.g. idempotency guarantees for incoming write requests) that make it now very hard to reason about the execution flow. Testing the performance impact of such additions to the critical execution path even can't be properly measured. Note: the current implementation of idempotency relies on database lookups (quite often, for each incoming request) and none of those queries are cached. If we wanted to store already processed requests (IDs) in a faster system (let's Redis) then this can't be done without major refactoring.\n\nIn conclusion, if we really want to fix those issues that are not only cosmetic and affect the performance and the developer experience equally then we urgently need to fix the way how we process write requests aka commands.\n\n## Target Personas\n\n- developers\n- integrators\n- end users\n- BaaS\n\n## Goals\n\n- new command processing will run independently next to the legacy mechanics\n- self contained\n- fully tested\n- ensure that the REST API is 100% backward compatible\n- try to contain the migration and make it as easy as possible for the community to integrate those changes\n- introduce types where needed and migrate the (old) JAX-RS REST resource classes to Spring Web MVC (better performance and better testability)\n- introduce DTOs if not already available and make sure if they exist that they are not outdated\n- assemble one DTO as command payload from all incoming REST API parameters (headers, query/path paramters, request bodies)\n- annotate attributes in the DTOs with Jakarta Validation annotations to enforce constraints on their values\n- wired REST API to the new command processing, one service at a time/pull request\n- take a non-critical service (like document management) and migrate it to the new command processing mechanics from top (REST API) to bottom (business logic service)\n- refactor command handlers to new internal API\n- make sure that the business service logic classes/functions take only one DTO request input parameter (aka don't let a function have 12 input parameters of type string...)\n- when all integration tests run successfully then remove all legacy boilerplate code that is not used anymore\n- make an ordered list of modules/features (easiest, lowest hanging fruit first)\n- maintain at least the same performance as the current implementation\n- optional: improve performance if it can be done in a reasonable time frame\n- optional: improve resilience if it can be done in a reasonable time frame\n\n## Non-Goals\n\n- current command processing will stay untouched, will run independently of new infrastructure\n- don't try cleaning up the storage layer; that's a separate effort for later (type safe queries, query peformance, clean entity classes)\n- maker-checker is tightly coupled in the current command processing implementation upstream; this is a separate concern for a separate proposal (domains: security, workflow)\n- doesn't need to be optimized for speed immediately\n- no changes in the integration tests\n\n## Proposed API Changes\n\n### Command Wrapper\n\nClass contains some generic attributes like:\n\n- username\n- tenant ID\n- timestamp\n\nThe actual payload (aka command input parameters) are defined as a generic parameter \"payload\". It is expected that the modules implement classes that introduce the payload types and inherit from the abstract command class.\n\n### Command Processing Service\n\nThree performance levels are configurable via application.properties\n\n- synchronously (required): this is pretty much as we do right now (use virtual threads optionally)\n- asynchronously (optional): with executor service and completable futures (use virtual threads optionally)\n- non-blocking (optional): high performance LMAX Disruptor non-blocking implementation\n\nThese different performance level implementations need to be absolute drop-in replacements (for each other). It is expected that more performant implementations need more testing due to increased complexity and possible unforeseen side effects (thread local variables, transactions). In case any problems show up we can always roll back to the required default implementation (synchronous).\n\nNOTE: we should consider providing a command processing implementation based on Apache Camel once this concept is approved and we migrated already a couple of services. They are specialized for exactly this kind of use cases and have more dedicated people working on it's implementation. Could give more flexibility without us needing to maintain code.\n\n### Middlewares\n\nTBD\n\n### Command Handlers\n\nTBD\n\n### References to users (aka AppUser)\n\nKeep things lightweight and only reference users by their user names.f\n\n## Risks\n\nTBD\n\n- feature creep\n\n## ETA\n\nA first prototype of the a new command processing component is ready for evaluation. There is also an initial smoke test (JMH) available.\n\nYou can try it out with the following instructions (it's still in a private repository, but will be published soon as an official PR):\n\ngit clone git@github.com:vidakovic/fineract.git\n\ncd fineract\n\ngit checkout feature/[FINERACT-2169](https://issues.apache.org/jira/browse/FINERACT-2169)\n\n./gradlew :fineract-command:build\n\n./gradlew :fineract-command:jmh\n\n## Diagrams\n\nTBD\n\n## Related Jira Tickets\n\n**Difficulty:**Critical\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Aleksandar Vidakovic*, mail: aleks (at) apache.org\n\n*Project Devs*, mail: dev (at) fineract.apache.org\n\n# Apache NuttX\n\n[Add support to ESP Hosted on NuttX](https://issues.apache.org/jira/browse/NUTTX-25)\n\nESP Hosted is a firmware that allows ESP32xx modules shared WiFi and BLE with the host OS, like Linux, RTOS or even some baremetal MCU.\n\nAdd ESP Hosted support on NuttX will allow any platform supported by NuttX to WiFi and/or BLE from ESP32xx modules.\n\nMore info: [https://github.com/espressif/esp-hosted](https://github.com/espressif/esp-hosted)\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Alan Carvalho de Assis*, mail: acassis (at) apache.org\n\n*Project Devs*, mail: dev (at) nuttx.apache.org\n\n[Dropbear port (or other SSH Server/Client) to NuttX](https://issues.apache.org/jira/browse/NUTTX-21)\n\nNuttX doesn't have a SSH Client/Server support yet.\n\nSupporting a SSH server will open doors to let NuttX boards in the fields to be access remotely for maintenance\n\nAdding support to SSH client will let low cost boards powered by NuttX and LVGL to become a remote console control for more advanced Linux server.\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Alan Carvalho de Assis*, mail: acassis (at) apache.org\n\n*Project Devs*, mail: dev (at) nuttx.apache.org\n\n[Create a NuttX Distribution with Dynamic Binary (ELF) Loading](https://issues.apache.org/jira/browse/NUTTX-20)\n\nNuttX is very Unix/Linux-like RTOS for microcontrollers and it supports dynamic loading of binaries and libraries. It makes perfect sense to have the possibilities to create a NuttX Distros similar to what exists for Linux.\n\nIn fact there is already a proposal here: [https://github.com/apache/nuttx/issues/17351](https://github.com/apache/nuttx/issues/17351)\n\nGoals:\n\n1) Test ELF Loading in the current NuttX mainline\n\n2) Create an application that will be downloaded and updated the existing version on the board\n\n3) Add Library support on NuttX/NuttX-Apps (use Android Makefile Library building as reference)\n\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Alan Carvalho de Assis*, mail: acassis (at) apache.org\n\n*Project Devs*, mail: dev (at) nuttx.apache.org\n\n[Micro-ROS integration on NuttX](https://issues.apache.org/jira/browse/NUTTX-14)\n\nMicro-ROS ([https://micro.ros.org)](https://micro.ros.org)/) is a ROS2 support to Microcontrollers. Initially the project was developed over NuttX by Bosch and other EU organizations. Later on they added support to FreeRTOS and Zephyr. After that NuttX support started ageing and we didn't get anyone working to fix it (with few exceptions like Roberto Bucher work to test it with pysimCoder).\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Alan Carvalho de Assis*, mail: acassis (at) apache.org\n\n*Project Devs*, mail: dev (at) nuttx.apache.org\n\n[Add X11 graphic support on NuttX using NanoX](https://issues.apache.org/jira/browse/NUTTX-16)\n\nNanoX/Microwindows is a small graphic library what allow Unix/Linux X11 application to run on embedded systems that cannot support X-Server because it is too big. Add it to NuttX will allow many applications to be ported to NuttX. More importantly: it will allow FLTK 1.3 run on NuttX and that could big Dillo web browser.\n\n**Difficulty:**Major\n\n**Project size:**~175 hour (medium)\n\n**Potential mentors:**\n\n*Alan Carvalho de Assis*, mail: acassis (at) apache.org\n\n*Project Devs*, mail: dev (at) nuttx.apache.org\n\n[Wireguard port to NuttX](https://issues.apache.org/jira/browse/NUTTX-22)\n\nWireguard is a light VPN solution for Linux and microcontrollers.\n\nPorting wireguard for NuttX will allow remote and secure access to NuttX devices.\n\nProjects to be used as reference:\n\n**Difficulty:**Major\n\n**Project size:**~175 hour (medium)\n\n**Potential mentors:**\n\n*Alan Carvalho de Assis*, mail: acassis (at) apache.org\n\n*Project Devs*, mail: dev (at) nuttx.apache.org\n\n[TinyGL support on NuttX](https://issues.apache.org/jira/browse/NUTTX-15)\n\nTinyGL is a small 3D graphical library created by Fabrice Bellard (same creator of QEMU) designed for embedded system. Currently NuttX RTOS doesn´t have a 3D library and this could enable people to add more 3D programs on NuttX.\n\n**Difficulty:**Major\n\n**Project size:**~175 hour (medium)\n\n**Potential mentors:**\n\n*Alan Carvalho de Assis*, mail: acassis (at) apache.org\n\n*Project Devs*, mail: dev (at) nuttx.apache.org\n\n[Add multi-user support for NuttX](https://issues.apache.org/jira/browse/NUTTX-8)\n\nCurrently NuttX only support a single user. Also there is no file mode and file owner support.\n\nIn fact file mode is already defined in some places in the fs/ but it is not used.\n\nThis feature will make NuttX even yet more Unix/Linux-like.\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Alan Carvalho de Assis*, mail: acassis (at) apache.org\n\n*Project Devs*, mail: dev (at) nuttx.apache.org\n\n[NXBoot algorithm extension for two partitions](https://issues.apache.org/jira/browse/NUTTX-23)\n\nCurrently NuttX bootloader NXBoot requires three partitions to function properly. This is a trade of between better update speed and higher external memory capacity requirements.\n\nThe algorithm isn't suited for devices with small or even none external memory. A different algorithm that uses just two partitions (primary which runs the image) and update (where the update is uploaded) could be used for devices that use only internal memory. It would result in slower update process, but save memory space.\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Michal Lenc*, mail: michallenc (at) apache.org\n\n*Project Devs*, mail: dev (at) nuttx.apache.org\n\n[Analog (ADC/DAC) interfaces unification and better API](https://issues.apache.org/jira/browse/NUTTX-24)\n\nThe issue was discussed and is tracked in a GitHub issue [https://github.com/apache/nuttx/issues/16916](https://github.com/apache/nuttx/issues/16916)\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Michal Lenc*, mail: michallenc (at) apache.org\n\n*Project Devs*, mail: dev (at) nuttx.apache.org\n\n# Apache Wayang\n\n[Make Wayang more datalake-friendly](https://issues.apache.org/jira/browse/WAYANG-54)\n\n**Background**\n\nApache Wayang is a cross-platform data processing framework that allows users to execute analytics pipelines across multiple heterogeneous execution engines such as Apache Spark, Apache Flink, and relational database systems. Wayang’s optimizer automatically selects where to execute a pipeline and enables hybrid pipelines where part of it can be executed in one platform and part of it in another.\n\nWayang’s architecture is built around a pluggable backend model. Each execution engine is integrated via a dedicated backend implementation that translates Wayang’s logical operators into engine-specific physical operators.\n\nCurrent execution engines (platforms) that Wayang supports include: JDBC-based databases, Spark, Flink, Tensorflow, Giraph.\n\n**Project Goal**\n\nDesign and implement one or more **new execution engine backends** to enable Apache Wayang to work in data lake environments.\n\nPotential target engines include (depending on feasibility and community discussion):\n\n- Apache Datafusion\n\n- Trino / Presto\n\n- Dremio\n- BigQuery\n\nThe project includes:\n\n- Implementing the backend abstraction layer,\n\n- Mapping Wayang logical operators to the new engine’s execution model,\n\n- Integrating cost estimation for the optimizer.\n\n**Difficulty:** Medium**Project size:** Depends on the number of platforms. It can be 175 (medium) or ~350 hours (large)**Potential mentors:**\n\n- Zoi Kaoudi — zkaoudi (at) apache.org\n\n- Juri Petersen — juri (at) apache.org\n- Community — dev (at) wayang.apache.org\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Zoi Kaoudi*, mail: zkaoudi (at) apache.org\n\n*Project Devs*, mail: dev (at) wayang.apache.org\n\n[Implement a JDBC driver for Wayang](https://issues.apache.org/jira/browse/WAYANG-55)\n\n**Background**\n\nApache Wayang is a cross-platform data processing framework that enables users to write data analytics tasks once and execute them across multiple heterogeneous execution engines (e.g., Spark, Flink, Java Streams, and others). In addition, Wayang optimizes execution plans across platforms and can split pipelines to be executed among multiple backends to optimize performance.\n\nCurrently, Wayang provides programmatic APIs (Java/Scala) and SQL support. However, it does not expose a standard **JDBC interface** that would allow external tools to connect to Wayang as if it were a relational database.\n\nMany analytics tools rely on JDBC to communicate with query engines. Implementing a JDBC driver for Wayang would allow users to issue SQL queries to Wayang using standard database tooling.\n\n**Project Goal**\n\nDesign and implement a **JDBC driver for Apache Wayang** that allows users to:\n\n- Establish a JDBC connection to a Wayang instance,\n\n- Submit SQL queries via standard JDBC interfaces,\n\n- Retrieve results using ResultSet,\n\n- Access metadata through DatabaseMetaData,\n\n- Integrate Wayang with existing SQL-based tools and BI platforms.\n\nThe driver should delegate incoming SQL queries to the SQL api provided by Wayang.\n\n**Difficulty:** Minor**Project size:** ~90 hours (small)**Potential mentors:**\n\n- Zoi Kaoudi — zoka (at) apache.org\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Zoi Kaoudi*, mail: zkaoudi (at) apache.org\n\n*Project Devs*, mail: dev (at) wayang.apache.org\n\n[Support for a Dataframes API ](https://issues.apache.org/jira/browse/WAYANG-53)\n\n**Background**\n\nApache Wayang is a cross-platform data processing framework that lets users write data analytics tasks once and execute them efficiently across diverse execution engines such as Apache Spark, Apache Flink, relational databases, and others. It abstracts heterogeneous backends and can enable efficient hybrid execution across different execution engines.\n\nCurrently, Wayang supports dataflow-style APIs in Java, Scala, and Python and an SQL API. However, there is **no high-level DataFrame API** — a programmatic abstraction widely used in modern data processing ecosystems (e.g., Spark DataFrames, Pandas, R DataFrames) — that lets users express relational transformations over structured datasets in a fluent, tabular style.\n\nA DataFrame API for Wayang would dramatically improve usability for data engineers and scientists, making Wayang accessible to users familiar with DataFrame programming paradigms while preserving its powerful cross-platform optimization capabilities.\n\n**Project Goal**\n\nImplement a **DataFrame API for Apache Wayang** that:\n\n- Represents structured data in a tabular abstraction (rows & columns),\n\n- Supports common relational and analytical operations (select, filter, join, groupBy, aggregate, etc.),\n\n- Can compile DataFrame operations into Wayang plans executed across backends transparently,\n\n- Includes comprehensive documentation and examples.\n\n**Outcomes & Impact**\n\nBy the end of GSoC, Wayang will have its first robust DataFrame API — a major usability milestone that bridges structured analytics with cross-platform execution. This will enhance adoption, unlock new classes of applications, and position Wayang as a friendly high-level programming environment in addition to its optimizer backend strengths.\n\n**Difficulty:** Medium**Project size:** ~350 hours (Large)**Potential mentors:**\n\n- Zoi Kaoudi — zkaoudi (at) apache.org\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Zoi Kaoudi*, mail: zkaoudi (at) apache.org\n\n*Project Devs*, mail: dev (at) wayang.apache.org\n\n# Apache Fory\n\n[Apache Fory Implement Fory Python gRPC Integration](https://issues.apache.org/jira/browse/GSOC-319)\n\n**Description**:\n\nApache Fory can generate high-performance Python model code from IDL, but Python gRPC stubs are not generated yet.\n\nThis project will implement Python gRPC integration in the Fory compiler by generating *_service.py and *_grpc.py\n\nartifacts, using Fory serialization only (without protobuf runtime payload types).\n\nThe implementation should align with Fory’s compiler conventions and keep runtime overhead low.**Potential Outcomes:**\n\n- Generate *_service.py base interfaces and *_grpc.py gRPC binding files from service definitions.\n- Generate servicer base classes and stub classes using gRPC unary/stream APIs.\n- Wire request/response serialization via generated Fory serializer/deserializer callables.\n- Implement zero-copy deserialization buffer support for inbound gRPC payloads, with a safe fallback path when zero-copy cannot be applied.\n- Add golden codegen tests for output file names and key signatures.\n- Provide a runnable Python server/client example with generated stubs and Fory codec.\n- Update compiler documentation for Python gRPC code generation usage and constraints.\n\n**Skills:**\n\nPython, gRPC (grpcio), compiler/code generation, serialization internals, testing, performance optimization.**Difficulty:** Medium**Project size:** 175 hours**Potential mentors:** Chaokun Yang, Weipeng Wang\n\n**Source links:**\n\n[https://github.com/apache/fory/issues/3273](https://github.com/apache/fory/issues/3273)[https://fory.apache.org/docs/next/compiler/compiler_guide](https://fory.apache.org/docs/next/compiler/compiler_guide)[https://github.com/apache/fory/tree/main/compiler](https://github.com/apache/fory/tree/main/compiler)[https://github.com/apache/fory/tree/main/python](https://github.com/apache/fory/tree/main/python)[https://fory.apache.org/docs/guide/python/](https://fory.apache.org/docs/guide/python/)\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Chaokun Yang*, mail: chaokunyang (at) apache.org\n\n*Project Devs*, mail: dev (at) fory.apache.org\n\n[Apache Fory Implement Fory Java gRPC Integration](https://issues.apache.org/jira/browse/GSOC-318)\n\n**Description**\n\nApache Fory can already generate high-performance Java model code from IDL, but Java gRPC stubs are not generated\n\nyet.\n\nThis project will implement Java gRPC integration in the Fory compiler by generating *Service.java and *Grpc.java artifacts, using Fory serialization only (no protobuf runtime types for payload encoding).\n\ncompiler conventions, and avoid adding gRPC runtime dependencies into Fory core.\n\n- Generate *Service.java interfaces and *Grpc.java binding classes from service definitions.\n- Generate gRPC MethodDescriptors, server binders, and client stubs (including unary/streaming modes supported by\n\nIR). - Implement generated Fory-based Marshaller logic for request/response types.\n- Add golden codegen tests for output file names and key method signatures.\n- Provide a runnable Java server/client example using generated stubs and Fory codec.\n- Update compiler documentation for Java gRPC code generation usage and limits.\n\n**Skills**\n\nJava, gRPC Java, compiler/code generation, serialization internals, testing.\n\n**Difficulty**:Medium**Project size:**175 hours\n\n**Potential mentors**: Chaokun Yang, Weipeng Wang\n\n**Source links:**\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Chaokun Yang*, mail: chaokunyang (at) apache.org\n\n*Project Devs*, mail: dev (at) fory.apache.org\n\n[Apache Fory Implement Fory C++ gRPC integration](https://issues.apache.org/jira/browse/GSOC-321)\n\n**Description:**\n\nApache Fory can generate high-performance C++ model code from IDL, but it does not yet generate C++ gRPC service\n\nbindings.\n\nThis project will add C++ gRPC code generation to the Fory compiler. For each service definition, the compiler should\n\ngenerate service.h (service API), service.grpc.h (gRPC declarations), and service.grpc.cc (gRPC implementations),\n\nusing a Fory codec instead of protobuf runtime payload types.\n\nThe implementation should follow Fory compiler conventions and prioritize low-overhead, performance-first behavior.\n\n**Potential Outcomes:**\n\n- Parse service IR and generate C++ gRPC outputs for unary and streaming methods.\n- Generate service.h, service.grpc.h, and service.grpc.cc with clear separation between API abstractions and transport\n\nbindings. - Generate abstract service interfaces and client stub classes compatible with gRPC C++.\n- Implement Fory-based request/response serialization hooks for gRPC marshalling.\n- Implement zero-copy deserialization buffer support for inbound gRPC payloads, with a safe fallback path when zero-\n\ncopy cannot be applied. - Add golden codegen tests for generated file names and key signatures.\n- Provide a runnable C++ server/client example using generated bindings and Fory codec.\n- Update compiler documentation for C++ gRPC code generation usage and constraints.\n\n**Skills:**\n\nC++ 17, gRPC, compiler/code generation, serialization internals, testing, performance optimization.\n\n**Difficulty**: Medium**Project size:** 175 hours**Potential mentors:** Chaokun Yang, Weipeng Wang\n\n**Source links:** * [https://github.com/apache/fory/issues/3276](https://github.com/apache/fory/issues/3276)\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Chaokun Yang*, mail: chaokunyang (at) apache.org\n\n*Project Devs*, mail: dev (at) fory.apache.org\n\n[Apache Fory Implement Fory Rust gRPC Integration](https://issues.apache.org/jira/browse/GSOC-320)\n\n**Description:**\n\nApache Fory can generate high-performance Rust model code from IDL, but it does not yet generate Rust gRPC service bindings.\n\nThis project will add Rust gRPC code generation to the Fory compiler using tonic. For each service definition, the compiler should generate service.rs (service API traits/modules) and service_grpc.rs (tonic server/client transport\n\nThe implementation should follow Fory compiler conventions and prioritize low-overhead, allocation-conscious runtime behavior.\n\n**Potential Outcomes:**\n\n- Generate service.rs and service_grpc.rs from service definitions, with clear separation between API traits and\n\ntransport bindings. - Generate tonic-compatible async server/client wrappers.\n- Implement a custom tonic codec backed by Fory serialization/deserialization.\n- Implement zero-copy deserialization buffer support for inbound gRPC payloads, with a safe fallback path when zero-\n\ncopy cannot be applied. - Add golden codegen tests for generated file names and key signatures.\n- Provide a runnable Rust server/client example using tonic + generated Fory codec bindings.\n- Update compiler documentation for Rust gRPC code generation usage and constraints.\n\n**Skills:**\n\nRust, gRPC (tonic), compiler/code generation, serialization internals, async Rust, testing, performance optimization.**Difficulty:** Medium**Project size:** 175 hours**Potential mentors:** Chaokun Yang, Weipeng Wang**Source links:**\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Chaokun Yang*, mail: chaokunyang (at) apache.org\n\n*Project Devs*, mail: dev (at) fory.apache.org\n\n[Apache Fory Implement Fory Go gRPC integration](https://issues.apache.org/jira/browse/GSOC-322)\n\n**Description:**\n\nApache Fory can generate high-performance Go model code from IDL, but it does not yet generate Go gRPC service\n\nThis project will add Go gRPC code generation to the Fory compiler. For each service definition, the compiler should\n\ngenerate *_service.go (service interfaces) and *_grpc.go (gRPC transport bindings), using a Fory codec instead of\n\nThe implementation should follow Fory compiler conventions and prioritize low-overhead, performance-first behavior.\n\n**Potential Outcomes:**\n\n- Parse service IR and generate Go gRPC outputs for unary and streaming methods.\n- Generate ServiceDesc, server interfaces, and client wrappers compatible with grpc-go.\n- Register and use a custom Fory codec through grpc.CallOption for request/response serialization.\n- Implement zero-copy deserialization buffer support for inbound gRPC payloads, with a safe fallback path when zero-copy cannot be applied.\n- Add golden codegen tests for generated file names and key signatures.\n- Provide a runnable Go server/client example using generated bindings and Fory codec.\n- Update compiler documentation for Go gRPC code generation usage and constraints.\n\n**Skills:**\n\nGo, gRPC (grpc-go), compiler/code generation, serialization internals, testing, performance optimization.\n\n**Difficulty:** Medium**Project size:** 175 hours**Potential mentors:** Chaokun Yang, Weipeng Wang\n\n**Source links:**\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Chaokun Yang*, mail: chaokunyang (at) apache.org\n\n*Project Devs*, mail: dev (at) fory.apache.org\n\n[Apache Fory Implement Fory JavaScript gRPC integration](https://issues.apache.org/jira/browse/GSOC-323)\n\n**Description:**\n\nApache Fory currently lacks JavaScript/TypeScript gRPC service binding generation.\n\nThe generated service interface and gRPC binding outputs should follow existing JS/TS generator naming and layout conventions, stay dependency-light in Fory runtime, and keep runtime overhead low.**Potential Outcomes:**\n\n- Generate JS/TS service interface and gRPC binding outputs from service definitions, aligned with existing generator\n\nlayout conventions. - Wire request/response payload handling through generated Fory serializer/deserializer functions.\n\ncopy cannot be applied. - Coordinate with JS/TS type generation so emitted message/enum/union types are directly usable by generated gRPC\n\nstubs. - Add golden codegen tests for generated file names and key signatures.\n- Provide a runnable JS/TS server-client example using generated bindings and Fory codec.\n- Update compiler documentation for JS/TS gRPC code generation usage and constraints.\n\n**Skills:**\n\nJavaScript/TypeScript, Node.js, gRPC (@grpc/grpc-js), compiler/code generation, serialization internals, testing, performance optimization.\n\n**Difficulty:** Medium**Project size:** 175 hours**Potential mentors:** Chaokun Yang, Weipeng Wang\n\n**Source links:**\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Chaokun Yang*, mail: chaokunyang (at) apache.org\n\n*Project Devs*, mail: dev (at) fory.apache.org\n\n[Apache Fory Implement Fory Dart gRPC integration](https://issues.apache.org/jira/browse/GSOC-324)\n\n**Description**\n\nApache Fory does not yet generate Dart gRPC service bindings.\n\nThis project will add Dart gRPC code generation to the Fory compiler. For each service definition, the compiler should generate Dart service interfaces and gRPC transport bindings that follow the existing Dart generator layout and use a Fory codec instead of protobuf runtime payload types.\n\nThe implementation must keep the Fory runtime free of gRPC dependencies. Any required gRPC glue should be emitted as generated helper code. Runtime behavior should remain low-overhead and allocation-conscious.\n\n**Potential Outcomes**\n\n- Generate Dart service interface and gRPC binding outputs from service definitions, aligned with current Dart generator conventions.\n- Generate Dart gRPC server and client stubs for unary and streaming RPCs using Dart gRPC APIs.\n- Wire request/response handling through generated Fory serializer and deserializer functions.\n- Implement zero-copy deserialization buffer support for inbound gRPC payloads, with a safe fallback path when zero-copy cannot be applied.\n- Coordinate with Dart type generation so emitted message, enum, and union types are directly usable by generated gRPC stubs.\n- Add golden codegen tests for generated file names and key signatures.\n- Provide a runnable Dart server/client example using generated bindings and the Fory codec.\n- Update compiler documentation for Dart gRPC code generation usage and constraints.\n\n**Skills：**Dart, gRPC (`grpc`), compiler/code generation, serialization internals, async programming, testing, performance optimization.\n\n**Difficulty：** Medium**Project size：**175 hours**Potential mentors：**Chaokun Yang, Weipeng Wang**Source links：**\n\n[https://github.com/apache/fory/issues/3279](https://github.com/apache/fory/issues/3279)[https://github.com/apache/fory/issues/3281](https://github.com/apache/fory/issues/3281)[https://fory.apache.org/docs/next/compiler/compiler_guide](https://fory.apache.org/docs/next/compiler/compiler_guide)[https://github.com/apache/fory/tree/main/compiler](https://github.com/apache/fory/tree/main/compiler)[https://github.com/apache/fory/tree/main/dart](https://github.com/apache/fory/tree/main/dart)[https://github.com/apache/fory/blob/main/dart/README.md](https://github.com/apache/fory/blob/main/dart/README.md)[https://github.com/apache/fory/tree/main/dart/packages/fory](https://github.com/apache/fory/tree/main/dart/packages/fory)\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Chaokun Yang*, mail: chaokunyang (at) apache.org\n\n*Project Devs*, mail: dev (at) fory.apache.org\n\n[Apache Fory - Schema IDL Codegen and gRPC Integration for Apache Fory Swift](https://issues.apache.org/jira/browse/GSOC-326)\n\nApache Fory has a mature compiler pipeline for FDL, Protocol Buffers, and FlatBuffers frontends, plus code generators for Java, Python, Go, Rust, and C++. The compiler also already includes service IR parsing and a `--grpc` generation path, but Swift code generation is not yet supported.\n\nThis project adds end-to-end Swift support in two layers:\n\n1. Swift schema and model code generation from Fory IR.\n\n2. Swift gRPC generation from service definitions, including transport bindings and a Fory-backed codec.\n\nThe implementation should follow existing compiler conventions and prioritize low-overhead, allocation-conscious runtime behavior.\n\n**Problem Statement**\n\nThe repository already contains a Swift runtime (`swift/Sources/Fory`) but lacks compiler-generated Swift model code and Swift gRPC bindings from IDL files. This creates a gap:\n\n- Swift users cannot use `foryc` to generate model types from `.fdl`, `.proto`, or `.fbs`.\n- Service definitions parsed into compiler IR cannot yet target Swift transport code.\n- There is no official Fory codec integration for grpc-swift.\n\n**Why This Project Matters**\n\n- Completes the Swift developer workflow: IDL -> generated models -> generated service APIs -> runnable gRPC client and server.\n- Reuses existing multi-frontend service parsing support in compiler IR.\n- Aligns Swift with other language targets and improves cross-language consistency.\n- Enables high-performance Swift service communication using Fory serialization semantics.\n\n**Expected Outcomes**\n\n- Add Swift as a first-class compiler target (`\n~~{~~}lang swift`, `{-}-swift_out`). - Generate Swift model code from schema definitions (messages, enums, unions, nested types).\n- Generate `service_grpc.swift` from service definitions.\n- Generate grpc-swift compatible async server and client wrappers.\n- Implement a custom grpc-swift codec backed by Fory serialization and deserialization.\n- Implement inbound zero-copy decode support with a safe copy fallback path.\n- Add golden-style codegen tests for filenames and key generated signatures.\n- Add cross-frontend parity tests for FDL, proto, and fbs service definitions.\n- Provide runnable Swift server and client example(s) using generated code and codec.\n- Document compiler usage, constraints, and integration steps.\n\n**Detailed Scope**\n\n1) Compiler and CLI Integration\n\n- Add `SwiftGenerator` under `compiler/fory_compiler/generators/`.\n- Register generator in `compiler/fory_compiler/generators/\n*{*}init{*}*.py`. - Extend CLI output mapping and options to support `--swift_out`.\n- Ensure `--lang swift` works with existing recursive import compilation flow.\n\n2) Swift Model Code Generation\n\nGenerate Swift for:\n\n- Enums\n- Messages\n- Unions\n- Nested types\n- Type registration helper APIs\n\n**Requirements:**\n\n- Follow Fory type ID behavior (explicit IDs, auto IDs, namespace/name registration fallback).\n- Match existing cross-language semantics where applicable.\n- Integrate with existing Swift runtime abstractions (`Serializer`, type resolver, registration APIs).\n\n3) Swift Service and gRPC Code Generation\n\nFor each schema service:\n\n- Generate `service.swift` containing service protocol and method shape declarations.\n- Generate `service_grpc.swift` containing grpc-swift server and client transport bindings.\n\nRequired RPC support:\n\n- Unary\n- Client streaming\n- Server streaming\n- Bidirectional streaming\n\n4) Fory Codec for grpc-swift\n\n- Implement codec encode and decode using Fory Swift runtime.\n- Ensure request and response types map correctly to generated Swift types.\n- Provide clear error mapping for decode and type mismatch failures.\n\n5) Zero-Copy Decode and Fallback\n\n- Add a zero-copy-friendly decode path for inbound payload handling when safe ownership and lifecycle constraints are satisfied.\n- Add a fallback path that copies payload bytes when zero-copy cannot be safely applied.\n- Ensure behavior is deterministic and memory-safe.\n\n6) Tests\n\nCompiler tests:\n\n- Add codegen tests validating generated Swift file names and key signatures.\n- Add service generation tests for all RPC modes.\n- Add cross-frontend equivalence tests for FDL/proto/fbs service definitions.\n\nSwift runtime and integration tests:\n\n- Codec round-trip tests.\n- Error-path tests (invalid payload, type mismatch, unsupported mode).\n- Zero-copy path and fallback path coverage.\n\n7) Examples and Documentation\n\n- Add runnable Swift gRPC server/client example using generated files.\n- Update `docs/compiler/compiler-guide.md` for Swift codegen options and usage.\n- Update `docs/compiler/generated-code.md` with Swift output layout and generated API shape.\n- Add concise Swift integration documentation for grpc-swift + Fory codec.\n\n**Performance and Quality Requirements**\n\n- Keep allocation count low on encode and decode paths.\n- Avoid unnecessary data copies in transport integration.\n- Keep generated code predictable and stable for golden-style testing.\n- Preserve compiler behavior for existing languages and frontends.\n\n**Milestones (Recommended)**\n\n1. Community Bonding\n\n- Finalize generated API naming and file layout.\n- Confirm Swift option strategy and dependency constraints.\n- Agree on test matrix and acceptance checklist.\n\n2. Phase 1\n\n- Implement Swift generator base and CLI wiring.\n- Generate core model types and registration helpers.\n- Add baseline model codegen tests.\n\n3. Phase 2\n\n- Implement service generation (`service.swift`, `service_grpc.swift`).\n- Support unary and all streaming RPC method shapes.\n- Add service signature and transport generation tests.\n\n4. Phase 3\n\n- Implement and validate Fory grpc-swift codec.\n- Implement zero-copy decode path and fallback path.\n- Add integration example and end-to-end tests.\n\n**Finalization**\n\n- Documentation updates.\n- Stability pass and cleanup.\n- Final validation across compiler and Swift test suites.\n\n**Acceptance Criteria**\n\n1. `foryc` supports Swift generation through `~~{~~}lang swift` and `{-}-swift_out`.\n\n2. Swift model code compiles and integrates with Fory Swift runtime.\n\n3. Service generation outputs `service.swift` and `service_grpc.swift` with correct signatures.\n\n4. Unary, client-streaming, server-streaming, and bidi-streaming methods are correctly generated.\n\n5. Fory-backed grpc-swift codec works for request and response round-trip.\n\n6. Zero-copy decode path exists with tested fallback behavior.\n\n7. Added tests pass and no regressions are introduced in existing compiler suites.\n\n8. Documentation and runnable Swift example are complete and usable.\n\n**Skills Required**\n\n- Swift\n- grpc-swift\n- Compiler and code generation\n- Serialization internals\n- Async and streaming APIs\n- Testing and performance profiling\n\n**Difficulty**\n\nHard\n\n**Project Size**\n\n350 hours\n\n**Potential Mentors**\n\n- Chaokun Yang\n- Weipeng Wang\n\n**Source Links**\n\n[https://github.com/apache/fory/issues/3370](https://github.com/apache/fory/issues/3370)[https://fory.apache.org/docs/next/compiler/compiler_guide](https://fory.apache.org/docs/next/compiler/compiler_guide)[https://github.com/apache/fory/tree/main/compiler](https://github.com/apache/fory/tree/main/compiler)[https://github.com/apache/fory/tree/main/compiler/fory_compiler](https://github.com/apache/fory/tree/main/compiler/fory_compiler)[https://github.com/apache/fory/tree/main/compiler/fory_compiler/tests](https://github.com/apache/fory/tree/main/compiler/fory_compiler/tests)[https://github.com/apache/fory/tree/main/swift](https://github.com/apache/fory/tree/main/swift)[https://fory.apache.org/docs/guide/rust/](https://fory.apache.org/docs/guide/rust/)[https://github.com/grpc/grpc-swift](https://github.com/grpc/grpc-swift)\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Chaokun Yang*, mail: chaokunyang (at) apache.org\n\n*Project Devs*, mail: dev (at) fory.apache.org\n\n# Mahout\n\n[Add ZZFeatureMap Encoding for QDP](https://issues.apache.org/jira/browse/GSOC-312)\n\n**Backgroud**\n\nZZFeatureMap is the most widely-used data encoding in quantum machine learning. It's the default in Qiskit and PennyLane for quantum kernel methods and variational classifiers.\n\nQDP currently supports amplitude, angle, basis, and IQP encodings. Adding ZZFeatureMap completes our QML encoding suite.\n\n**What is ZZFeatureMap?**\n\nMaps classical features to quantum states using:\n\n1. Hadamard gates (superposition)\n\n2. RZ gates (single-qubit rotations)\n\n3. ZZ interactions (two-qubit entanglement)\n\n4. Repetition layers for expressivity\n\n**Tracked github issue**\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Ryan Huang*, mail: hcr (at) apache.org\n\n*Project Devs*, mail: dev (at) mahout.apache.org\n\n[Apache Mahout Automated API Documentation Pipeline for Qumat & QDP](https://issues.apache.org/jira/browse/GSOC-313)\n\n**Summary**\n\nImplement an automated API documentation pipeline that generates and publishes API reference documentation from the Python (Qumat, QDP) and Rust (qdp-core) codebases, integrated into the project's Docusaurus website and CI.\n\n**Background**\n\n- Apache Mahout exposes\n**two main API surfaces**:**Qumat**: Python library for quantum circuits (backends: Qiskit, Cirq, Amazon Braket).**QDP (Quantum Data Plane)**: GPU-accelerated encoding (Rust core + PyO3 Python bindings, qumat.qdp / _qdp).\n\n- Manual doc updates are error-prone and don’t scale. Automating from source keeps docs accurate and reduces maintainer burden.\n\n**Current state**\n\n- QuMat API is maintained by hand and can drift from code.\n- QDP API is waiting for new website migration to be finished.\n- Rust (qdp-core) has extensive doc comments but no published rustdoc in the website.\n\n**Goals**\n\n1. Generate API reference from source for Python (Qumat).\n\n2. Integrate generated docs into the existing Docusaurus site.\n\n3. Automate the pipeline in CI so doc builds run on changes.\n\n4. Define conventions (docstrings, public API) for future contributors.\n\n**Deliverables**\n\n- Python API doc pipeline for qumat and QDP.\n- QuMat API reference either generated or explicitly linked.\n- Rust (qdp-core) rustdoc built and linked from the website.\n- CI job(s) that build Python API docs and rustdoc and fail on errors.\n- Short contribution guide on docstring style and how to update API docs.\n\n**Tracked github issue**\n\n[https://github.com/apache/mahout/issues/1012](https://github.com/apache/mahout/issues/1012)\n\n**Note**\n\nPlease email me(jiekaichang@apache.org) your proposal first and show me different types of approaches you considered and why you decided to do it this way.\n\n**Difficulty:**Major\n\n**Project size:**~175 hour (medium)\n\n**Potential mentors:**\n\n*Jie-Kai Chang*, mail: jiekaichang (at) apache.org\n\n*Project Devs*, mail: dev (at) mahout.apache.org\n\n# Beam\n\n[Apache Beam Add Kafka Streams Runner](https://issues.apache.org/jira/browse/GSOC-305)\n\nSketch a working skeleton of portable Kafka Streams Runner for Apache Beam. The runner should be able to run basic portable pipelines and be a baseline implementation for further development, feature additions and performance optimization.\n\nA more detailed design document shall be attached to the [github tracking issue](https://github.com/apache/beam/issues/18479).\n\n**Difficulty:**Major\n\n**Project size:**~175 hour (medium)\n\n**Potential mentors:**\n\n*Jan Lukavský*, mail: janl (at) apache.org\n\n*Project Devs*, mail: dev (at) beam.apache.org\n\n[A learning path to using accelerators with Beam](https://issues.apache.org/jira/browse/GSOC-311)\n\nThe Beam project has a few examples where hardware accelerators can be used to run models. See [https://github.com/apache/beam/blob/master/examples/notebooks/beam-ml/dataflow_tpu_examples.ipynb](https://github.com/apache/beam/blob/master/examples/notebooks/beam-ml/dataflow_tpu_examples.ipynb)\n\nThis project is to improve on the available set of examples by building starter examples that allow a user to write code that slowly builds up to using these hardware accelerators. The idea would be:\n\n- A simple python script that runs slowly without HW accelerators\n- A script that shows improvements when using them\n- A training job that uses accelerators\n- A Beam pipeline that can train multiple models in parallel using accelerators\n- A blog post that can serve as a guide for anyone learning to use hardware accelerators\n\nThese would run continuously to ensure their freshness.\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Pablo Estrada*, mail: pabloem (at) apache.org\n\n*Project Devs*, mail: dev (at) beam.apache.org\n\n[Simplify management of Beam infrastructure, access control and permissions via Platform features](https://issues.apache.org/jira/browse/GSOC-273)\n\nThis project consists in a series of tasks that build a sort of 'infra platform' for Beam. Some tasks include:\n\n- Automated cleaning of infrastructure:\n[[Task]: Build a cleaner for assets in the GCP test environment #33644](https://github.com/apache/beam/issues/33644) - Implement Infra-as-code for Beam infrastructure\n- Implement access permissions using IaC:\n[[Task]: Build a cleaner for assets in the GCP test environment #33644](https://github.com/apache/beam/issues/33644) - Implement drift detection for IaC resources for Beam\n- Implement 'best-practice' key management for Beam (i.e. force key rotation for service account keys, and store in secret manager secrets)\n\n- Implement access permissions using IaC:\n\nA quality proposal will include a series of features beyond the ones listed above. Some ideas:\n\n- Detection of policy breakages, and nagging to fix\n- Security detections based on cloud logging\n- others?\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Pablo Estrada*, mail: pabloem (at) apache.org\n\n*Project Devs*, mail: dev (at) beam.apache.org\n\n[Apache Beam Python SDK native streaming transforms](https://issues.apache.org/jira/browse/GSOC-315)\n\n## Background\n\nApache Beam is a unified programming model for user developing data processing pipelines capable running in distributed systems. Apache Beam SDK officially supports Java, Python, and Go. While Java SDK was historically dominant, Python SDK is increasingly popular thanks to Beam ML. Python APIs are crucial for developers. We plan to port highly anticipated basic streaming transforms made convenient for Beam Python developers.\n\n## Tasks\n\n1. Python UnboundedSource ([https://github.com/apache/beam/issues/19137)](https://github.com/apache/beam/issues/19137))\n\nWhile Splittable DoFn has been introduced as a Beam primitive transform handling IO sources, UnboundedSource arguably remains an easier API for users to author their own IOs. In the Java SDK, UnboundedSource/UnboundedReader has been (re)implemented as a wrapper of Splittable DoFn, we can follow the Java implementation and add it to Python.\n\nStretch goal: implement a native Python streaming IO based on UnboundedSource.\n\n2. Python Watch Transform ([https://github.com/apache/beam/issues/21521)](https://github.com/apache/beam/issues/21521))\n\nCurrently we have a Watch transform in the Java SDK that is very useful when periodically polling for new input to a pipeline. We would like a parallel transform in Python.\n\nStretch goal: Update Python FileIO.readContinuously to use watch transform\n\n## Deliverables\n\n- Implementation of Python UnboundedSource: A functional wrapper API for UnboundedSource and UnboundedReader built on Splittable DoFn (a merged pull request to the Apache Beam repo).\n- Implementation of Python Watch Transform: A parallel transform to the Java Watch API for periodic polling (a merged pull request to the Apache Beam repo).\n- Unit and Integration Tests: tests for both features, specifically covering watermarks, checkpointing, and polling termination conditions.\n- User Documentation: Updated SDK guides and Docstrings explaining how to author custom IOs using UnboundedSource and how to use the Watch transform in pipelines.\n- Refactored FileIO.readContinuously (Stretch Goal): A pull request updating FileIO.read_continuously to utilize the new Watch transform logic.\n\n## Recommended Skills\n\n- Proficiency in Python, experience with pytest\n- Java-to-Python Porting: Ability to read and interpret Java source code\n- Version control: Git, development with GitHub\n- nice to have: exposure to streaming data processing tools (e.g. Apache Beam/Flink/Spark, etc)\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Yi Hu*, mail: yhu (at) apache.org\n\n*Project Devs*, mail: dev (at) beam.apache.org\n\n# DolphinScheduler\n\n[Apache DolphinScheduler Embedding the AlertServer into the API Server](https://issues.apache.org/jira/browse/GSOC-306)\n\n**Apache DolphinScheduler**\n\nApache DolphinScheduler is a distributed and extensible workflow scheduler platform with powerful DAG visual interfaces, dedicated to solving complex job dependencies in the data pipeline and providing various types of jobs available out of box.\n\nWebsite: [https://dolphinscheduler.apache.org/en-us/index.html](https://dolphinscheduler.apache.org/en-us/index.html)\n\nGitHub: [https://github.com/apache/dolphinscheduler](https://github.com/apache/dolphinscheduler)\n\nLinked GitHub Issue: [https://github.com/apache/dolphinscheduler/issues/8975](https://github.com/apache/dolphinscheduler/issues/8975)\n\n**Background**\n\nCurrently, DolphinScheduler requires a separate alert-server to handle workflow and task alerts. Although the alert-server is lightweight, maintaining and deploying it separately adds operational complexity.\n\nWe aim to remove the standalone alert-server and embed its alerting functionality directly into the API server.\n\n**Task**\n\nIntegrate the alert-server functionality into the API server so that it can handle workflow and task alerts natively.\n\n**Deliverables**\n\n- Remove the standalone alert-server.\n\n- Enable the API server to handle all alerting tasks.\n- Add Integration test case.\n\n**Recommended Skills**\n\n- Proficiency in Java.\n- Familiarity with microservice, e.g. spring-boot.\n\n- Familiarity with DolphinScheduler’s architecture and alerting mechanisms is a plus.\n\n**Mentors**\n\n- Wenjun Ruan(Apache DolphinScheduler PMC member),\n[wenjun@apache.org](mailto:wenjun@apache.org) - Zihao Xiang(Apache DolphinScheduler PMC member),\n[zihaoxiang@apache.org](mailto:zihaoxiang@apache.org)\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Wenjun Ruan*, mail: wenjun (at) apache.org\n\n*Project Devs*, mail: dev (at) dolphinscheduler.apache.org\n\n# SkyWalking\n\n[Apache SkyWalking BanyanDB Native Data Export/Import Utility](https://issues.apache.org/jira/browse/GSOC-310)\n\n**Background**\n\n**BanyanDB** is the native storage engine for Apache SkyWalking, designed specifically for observability data (Traces, Metrics, and Logs). As BanyanDB matures into a production-ready storage backend, data portability becomes critical. Users need the ability to move datasets between environments (e.g., from production to staging for debugging) or export data for external analysis in tools like Python/Pandas, Spark, or specialized AI training pipelines.\n\nCurrently, BanyanDB supports disaster recovery backups and simple CSV dumps for specific models. This project aims to build a high-performance, comprehensive **Export/Import Utility** that supports multiple formats and ensures data integrity.\n\n**Tasks**\n\n**Multi-Format Support:**Implement export/import functionality for:\n\n**Native Binary:**High-performance format for BanyanDB-to-BanyanDB migration.\n\n\n**Plain Text/Standard:**Support for**Parquet**(optimized for metrics/measures) and**JSON/CSV**(for human readability).\n\n\n**Batch & Stream Processing:**Ensure the tool can handle massive datasets by implementing chunked data reading and writing to avoid memory bottlenecks.\n\n**Schema Evolution Handling:**Implement logic to handle cases where the schema in the exported file differs slightly from the target server's schema.\n\n**Integration with bydbctl:**Expose these capabilities through a user-friendly CLI command suite (e.g., bydbctl data export --group=user_logs --format=parquet).\n\n**Requirements**\n\n- Strong knowledge of\n**Go**and concurrency patterns.\n\n- Experience with data serialization formats (Protobuf, Parquet, Apache Arrow).\n\n- Familiarity with gRPC-based API communication.\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Hongtao Gao*, mail: hanahmily (at) apache.org\n\n*Project Devs*, mail: dev (at) skywalking.apache.org\n\n[Apache SkyWalking Natural Language to BydbQL](https://issues.apache.org/jira/browse/GSOC-309)\n\n**Background**\n\n**BanyanDB** is the native storage engine for Apache SkyWalking, designed specifically for observability data (Traces, Metrics, and Logs). It utilizes its own query language, **BydbQL**, which is SQL-like but optimized for time-series and observability schemas. While BydbQL is powerful, non-expert users or SREs in high-pressure situations may find it difficult to construct complex queries for specific traces or aggregated metrics.\n\nThe goal of this project is to build an **Intelligent Query Agent** that leverages **Large Language Models (LLMs)** to translate Natural Language (NL) into valid BydbQL.\n\n**Tasks**\n\n**Schema-Aware Prompting:**Develop a mechanism to extract BanyanDB metadata (Groups, Streams, Measures, Tag Families) and feed it into the LLM context (RAG - Retrieval-Augmented Generation).\n\n**N2SQL Implementation:**Adapt state-of-the-art \"Natural Language to SQL\" (NL2SQL) techniques to the specific syntax and constraints of BydbQL.\n\n**Verification Loop:**Integrate the agent with the existing BydbQL parser to validate generated queries before execution.\n\n**CLI/UI Integration:**Implement a \"chat\" interface or an --ask flag in bydbctl (the BanyanDB CLI tool) to allow users to query data via plain English (e.g.,*\"Show me the top 5 slowest services in the last hour\"*).\n\n**Requirements**\n\n- Proficiency in\n**Go**(BanyanDB's primary language).\n\n- Experience with\n**LLM APIs**(OpenAI, Gemini, or local models via Ollama) and orchestration frameworks (LangChain, LangGraph).\n\n- Understanding of\n**Compiler Front-ends**(Lexing, Parsing, AST).\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Hongtao Gao*, mail: hanahmily (at) apache.org\n\n*Project Devs*, mail: dev (at) skywalking.apache.org\n\n# IoTDB\n\n[Compatible with TPU & integrate SOTA time series foundation models for IoTDB-AINode](https://issues.apache.org/jira/browse/GSOC-307)\n\n**Background**\n\n**Apache** **IoTDB** is a high-performance, IoT-native time-series database designed to manage massive volumes of time-series data generated by industrial IoT devices. It addresses challenges including high ingestion rates, complex out-of-order data handling, and real-time analytical requirements. **IoTDB-AINode** represents an endogenous node type in the IoTDB ecosystem, extending the database with native machine learning capabilities. IoTDB-AINode enables seamless integration of time series machine learning algorithms directly within the database engine, allowing users to register, manage, and execute inference tasks using simple SQL statements (e.g., *CREATE MODEL ..., SELECT * FROM FORECAST (...)*). This architecture eliminates costly data migration to external ML platforms, accelerates processing pipelines, and enhances data security by keeping computations close to the data. Currently, AINode includes built-in time series foundation models such as the Timer and Chronos for time series forecasting task.**Tensor Processing Units (TPUs)** are Google-developed AI accelerators specifically designed for neural network computations. Offering high-throughput matrix operations and energy efficiency, TPUs provide a compelling alternative to GPUs for deploying large foundation models. PyTorch/XLA enables PyTorch models to leverage TPU hardware through the XLA (Accelerated Linear Algebra) compiler, supporting both single-device and distributed training scenarios.**Time Series Foundation Models** have emerged as powerful tools for temporal analysis. These models demonstrate superior performance across diverse domains—from industrial sensor data to financial forecasting—making them ideal candidates for integration into IoTDB's analytical pipeline.\n\n**Goal**\n\nThis project aims to enhance IoTDB-AINode with TPU hardware acceleration capabilities and integrate cutting-edge time series foundation models into the database's model inference pipeline. Specifically, the project will:\n\n- Enable IoTDB-AINode to recognize and leverage Google TPU devices for model deployment and inference.\n- Adapt the AINode packaging and compilation workflow (Maven/Java and Poetry/Python) to support TPU-specific releases.\n- Survey and integrate 1-2 SOTA time series foundation models (e.g., TimesFM) into AINode's SQL-accessible model registry.\n- Establish comprehensive CI pipelines for TPU environments to ensure long-term maintainability.\n\nThe ultimate outcome will empower IoTDB users to execute high-performance time series analysis on TPU hardware using state-of-the-art foundation models through simple SQL interfaces, significantly enhancing the database's analytical capabilities for industrial AI applications.\n\n**Core Tasks（Mandatory）**\n\n**TPU****Adaptation.**Implement TPU device recognition and tensor management within the AINode Python runtime. This involves:- Integrating PyTorch/XLA (torch_xla) to detect available TPU devices during AINode initialization.\n- Implementing device abstraction layers to handle model loading and tensor operations on TPU hardware.\n- Ensuring automatic fallback mechanisms to CPU/GPU when TPU is unavailable.\n\n**Packaging for TPU Version.**Extend the existing build infrastructure to support TPU-enabled distributions:- Update Poetry configuration to manage PyTorch/XLA and TPU-specific Python dependencies.\n- Create automated packaging scripts that bundle XLA compilers and TPU runtime libraries.\n- Ensure the TPU version can be deployed directly in Google Cloud TPU environments and on-premise TPU pods without manual dependency resolution.\n\n**Model Survey.**Conduct a comprehensive technical survey of SOTA time series foundation models available at project commencement. The deliverable will be a technical document analyzing each model's architecture, input requirements, computational complexity, zero-shot capabilities, and suitability for IoTDB's SQL-based inference pipeline. The survey will conclude with a justified selection of 1–2 models for integration based on deployability, inference latency, licensing, and compatibility with IoTDB’s SQL-based workflow.**Model Integration.**Integrate 1-2 selected foundation models into IoTDB-AINode's model inference framework:- Implement model wrappers conforming to AINode's model registration interface.\n- Adapt models to process IoTDB's time series data format.\n- Ensure compatibility with AINode's inference pipeline, supporting SQL syntax such as\n*SELECT * FROM FORECAST (...)*. - Support both built-in model usage and custom model registration for integrated architectures.\n\n**Integration Testing & CI.**Establish robust testing infrastructure for TPU functionality:- Design and implement integration tests covering device detection, model loading, tensor operations, and end-to-end inference workflows.\n- Build TPU-specific CI environments using Google Cloud TPUs or TPU simulators.\n\n\n**Advanced Tasks (Optional)**\n\n**Distributed Large Model Deployment.**As an optional stretch goal, this task explores distributed deployment of large time series foundation models across multiple TPU devices. This involves:- Enabling distributed inference where large models are partitioned across TPU pods.\n- Developing SQL extensions to specify distributed compute resources (e.g.,\n*LOAD MODEL ... TO DEVICES ...*). - Optimizing communication patterns between DataNodes and AINode for high-throughput industrial scenarios involving thousands of time series streams.\n\n\n**Deliverables**\n\n**Fully Functional****Source Code****.**- Pull requests to Apache IoTDB repository containing TPU adaptation modules.\n- Integration code for SOTA time series foundation models.\n- Extended build configurations (Maven/Poetry/PyInstaller) supporting TPU distributions.\n\n**Comprehensive Integration Tests.**- Automated test suites for TPU device detection and model execution.\n- CI pipeline configurations for TPU environments.\n\n**User Documentation.**- Deployment guide for TPU-enabled AINode (e.g. Google Cloud TPU).\n- SQL reference extensions for new model types and TPU-specific configuration options.\n- Tutorial documentation demonstrating time series analysis workflows using the integrated foundation models.\n\n\n**Recommended Skills**\n\n**Python >= 3.11.**Including asynchronous programming and ML pipeline development.\n\n**Poetry & PyInstaller.**Experience with Python dependency management and executable packaging.\n\n**PyTorch.**Known about the PyTorch/XLA integration for TPU support.\n\n**Java & Maven.**Knowledge of multi-module Java projects, build profiles, and dependency management**.**\n\n# Learning Material\n\n**Apache****IoTDB.**[https://iotdb.apache.org/](https://iotdb.apache.org/)\n\n**Time series forecasting models in HuggingFace.**[https://huggingface.co/models?pipeline_tag=time-series-forecasting&sort=trending](https://huggingface.co/models?pipeline_tag=time-series-forecasting&sort=trending)\n\n**PyTorch****TPU****support.**[https://docs.pytorch.org/xla/master/accelerators/tpu.html](https://docs.pytorch.org/xla/master/accelerators/tpu.html)\n\n**Difficulty:** medium**Mentor:** Yongzao Dan (Apache IoTDB PMC Member) *(yongzao@apache.org)*\n\n**Difficulty:**Major\n\n**Project size:**~175 hour (medium)\n\n**Potential mentors:**\n\n*Yongzao Dan*, mail: yongzao (at) apache.org\n\n*Project Devs*, mail: dev (at) iotdb.apache.org\n\n[Enhancing ThingsBoard Integration with IoTDB 2.X Table Mode](https://issues.apache.org/jira/browse/GSOC-304)\n\n# Background\n\n**Apache** **IoTDB** is a high-performance, open-source time-series database optimized for data management and analysis in Internet of Things (IoT) scenarios, while ThingsBoard is an open-source IoT platform for device management, data visualization, and rule-based automation.\n\nWith the release of IoTDB 2.X introducing a **dual-mode** **architecture** (tree and table), significant opportunities arise to enhance this integration. The table mode supports standard SQL syntax, JOIN operations, and user-defined functions, enabling more complex queries and analytics. This project proposes to develop an enhanced storage backend for ThingsBoard based on IoTDB's 2.X table mode, providing improved flexibility and performance for IoT data storage and analysis.\n\n# Goal\n\nThe primary goal of this project is to design and implement a new, enhanced storage backend for ThingsBoard that strategically leverages key features of Apache IoTDB 2.X’s table mode to improve flexibility, query expressiveness, and performance for core IoT telemetry workloads. This enhancement aims to provide ThingsBoard users with more powerful SQL querying capabilities (including complex multi-device joins and time-window aggregations) and improved performance for specific workloads. Furthermore, the project seeks to strengthen the open-source ecosystem by providing a deeper, more capable integration between ThingsBoard and the Apache IoTDB project, resulting in a more robust end-to-end IoT solution for the community.\n\n\n# Core Tasks (Mandatory)\n\n**In-depth Analysis and Design**: Conduct a thorough analysis of the existing ThingsBoard-IoTDB integration architecture and ThingsBoard's storage backend interfaces (e.g., TimeseriesDao). Then, design an optimal strategy for mapping the ThingsBoard data model (devices, assets, telemetry, attributes, labels) to the IoTDB 2.X table mode. A key focus will be utilizing IoTDB's TAGS column to efficiently store and manage static device attributes (e.g., location, device type), enabling flexible device filtering and grouping based on these tags .**Implementation of Storage Backend Connector**:**Data Access Layer**: Based on the design, implement the relevant ThingsBoard storage backend interfaces to connect with IoTDB.**Write Path**: Develop efficient data writing logic that transforms device telemetry data received by ThingsBoard and performs batch writes to the corresponding tables in IoTDB.**Read/****Query****Path**: Implement query interfaces that translate data requests from ThingsBoard dashboards or the rule engine into efficient SQL queries that take full advantage of IoTDB 2.X table mode features.\n\n**Performance Benchmarking and Comparison**: Design and execute standardized performance test cases (e.g., high-concurrency data ingestion, complex conditional queries, large-scale range queries). Produce a detailed performance comparison report between the new IoTDB 2.X table mode-based backend and ThingsBoard's existing data storage options, This report should quantify improvements in metrics like write throughput and query latency.**Testing and Documentation**: Write comprehensive integration tests to ensure the correctness and stability of the new functionality. Create detailed user documentation, including installation/configuration instructions, data model explanations, API usage guidelines, and best practices.**Community Collaboration and Upstream Contribution**: Actively communicate with the ThingsBoard open-source community at key project milestones to discuss designs and gather feedback. Submit high-quality Pull Requests (PRs) to the official ThingsBoard repository, adhering to its coding standards, with the goal of getting the implementation merged.\n\n# Advanced Tasks (Optional)\n\n**Leverage IoTDB UDFs**: Explore the integration of IoTDB's User-Defined Functions (UDFs) within ThingsBoard's rule engine. This could allow for performing more complex data processing and analysis (e.g., anomaly detection) directly within the database before data is pulled into ThingsBoard.\n\n**Enhanced Data Modeling for Assets**: Extend the data mapping design to optimally support ThingsBoard's assets and the relations between entities (devices, assets, customers), exploiting the relational capabilities of the IoTDB table mode for more complex queries.\n\n**Comprehensive Dashboard Demo**: Build a detailed ThingsBoard dashboard that showcases the advanced querying capabilities made possible by the new integration, such as visualizations based on multi-device joins or complex aggregations.\n\n# Deliverables\n\n- A fully functional storage backend plugin/implementation, including source code, build scripts, and configuration examples.\n- A detailed design document explaining the data mapping and integration architecture between ThingsBoard and the IoTDB 2.X table mode.\n- A comprehensive performance benchmark report comparing the new solution with existing options.\n- Complete user and developer documentation.\n- A Pull Request submitted to the ThingsBoard community containing the implementation, tests, and relevant documentation.\n- A final project report summarizing work, technical challenges, learnings, and future possibilities.\n\n# Recommended Skills\n\n**Programming Language**: Proficiency in Java, as both ThingsBoard and IoTDB are primarily Java-based projects.\n\n**Database Knowledge**: Understanding of SQL and fundamental database concepts. Knowledge of time-series data is a plus.\n\n**System Integration**: Interest or experience in connecting different systems and understanding data flows.\n\n**Learning and Communication**: Ability to quickly understand the codebases of two open-source projects and willingness to actively collaborate with community mentors and members.\n\n# Learning Material\n\n- Apache IoTDB Official Website:\n[https://iotdb.apache.org/](https://iotdb.apache.org/) - ThingsBoard Official Documentation:\n[https://thingsboard.io/docs/](https://thingsboard.io/docs/) - Integrated Reference:\n[https://github.com/thingsboard/thingsboard/pull/11476](https://github.com/thingsboard/thingsboard/pull/11476) - IoTDB Table Mode Concepts:\n[https://iotdb.apache.org/UserGuide/latest/Background-knowledge/Data-Model-and-Terminology_apache.html](https://iotdb.apache.org/UserGuide/latest/Background-knowledge/Data-Model-and-Terminology_apache.html) - IoTDB Table Mode Query Syntax:\n[https://iotdb.apache.org/UserGuide/latest-Table/SQL-Manual/overview_apache.html](https://iotdb.apache.org/UserGuide/latest-Table/SQL-Manual/overview_apache.html)\n\n**Difficulty:** medium**Mentor:** Xuan Wang (Apache IoTDB Committer) *(*[critas@apache.org](mailto:critas@apache.org)\n\n*)*\n\n**Difficulty:**Major\n\n**Project size:**~175 hour (medium)\n\n**Potential mentors:**\n\n*Xuan Wang*, mail: critas (at) apache.org\n\n*Project Devs*, mail: dev (at) iotdb.apache.org\n\n[[GSoC] Flink connector for IoTDB 2.X Table Mode](https://issues.apache.org/jira/browse/GSOC-308)\n\n# Background\n\n**Apache** **IoTDB** is an open-source IoT-native time-series database designed for high-performance storage, ingestion, and analysis of massive time-series data from IoT devices. It supports deep integration with big data ecosystems like Apache Hadoop, Spark, and Flink, enabling seamless data processing workflows. IoTDB traditionally uses a tree-based data model for organizing time-series data hierarchically (e.g., root.group.device.sensor), which is efficient for device-centric IoT scenarios.\n\nStarting with IoTDB 2.0, a dual-mode SQL architecture was introduced, adding a table mode alongside the tree mode. The table mode allows users to manage time-series data using SQL-like table structures, where each table represents a device type, with columns for timestamps, tags, and fields (e.g., measurements like temperature or humidity). This mode enhances flexibility for data analysis, supports standard SQL queries, and improves interoperability with relational tools. It is particularly useful for scenarios involving heterogeneous devices or advanced analytics, as it supports table-level schema management and retention-related configurations (e.g., TTL).**Apache** **Flink** is a powerful stream and batch processing framework for real-time data analytics. IoTDB already provides a Flink connector (flink-iotdb-connector) for reading from and writing to IoTDB using the tree mode, including IoTDBSource for data ingestion and IoTDBSink for output. There is also a Flink SQL connector (flink-sql-iotdb-connector) for SQL-based interactions and change data capture (CDC). However, these connectors primarily target the tree mode and lack full support for the table mode's features, such as table-specific metadata handling, SQL table mappings in Flink Table API, and optimized read/write operations for table-structured data. As a result, Flink users cannot natively treat IoTDB table-mode data as first-class tables in Flink SQL or the Table API. This gap limits the ability to leverage Flink's processing capabilities with IoTDB's modern table mode, especially in real-time IoT applications like predictive maintenance or anomaly detection.\n\nThis project aims to bridge this gap by developing a dedicated Flink connector for IoTDB's 2.X table mode, enabling efficient, real-time integration between Flink and IoTDB tables.\n\n# Goal\n\nThe primary goal is to create a robust, production-ready Flink connector that supports reading from and writing to IoTDB tables using the 2.X table mode. This will allow Flink users to process IoT time-series data stored in table format, perform transformations, aggregations, and joins in real-time, and sink results back into IoTDB tables. The connector should align with Flink's DataStream and Table APIs, support fault tolerance, and handle table-specific features like tags, fields, and TTL. Ultimately, this will enhance IoTDB's ecosystem integration, making it easier for developers to build scalable IoT data pipelines.\n\n\n# Core Tasks (Mandatory)\n\n**Research and Design**: Analyze the existing flink-iotdb-connector and flink-sql-iotdb-connector to identify limitations with the table mode. Design the connector architecture, including schema and type mappings between Flink Table/RowData and IoTDB table-mode concepts (e.g., time column, tags, and fields). Define APIs for source and sink functions compatible with Flink 1.18+.\n\n**Implement IoTDB Table Source**: Develop a Flink source connector (e.g., IoTDBTableSource) that reads data from IoTDB tables. Support filtering by time ranges, tags, and fields using IoTDB's SQL interface. Ensure it handles schema inference and dynamic table changes.\n\n**Implement IoTDB Table Sink**: Create a Flink sink connector (e.g., IoTDBTableSink) for writing processed data back to IoTDB tables. Support batch and streaming modes, automatic schema creation (if enabled in IoTDB), and error handling for constraints like TTL or data types.\n\n**Testing and Documentation**: Write unit and integration tests using Flink's testing utilities and IoTDB test clusters. Document usage examples, configuration options, and deployment guides in the IoTDB repository.\n\n**Community Contributions**: Submit pull requests to upstream repositories for any required changes, and create example Flink jobs demonstrating the use cases.\n\n# Advanced Tasks (Optional)\n\n**Performance Optimization**: Implement optimizations like parallel reading/writing.\n\n**Benchmarking and Comparison**: Develop benchmarks comparing the new connector's performance with the existing tree-mode connector, focusing on throughput, latency, and resource usage in IoT scenarios.\n\n# Deliverables\n\n\nSource code for the Flink connector for IoTDB table mode, including Maven artifacts (e.g., flink-iotdb-table-connector).\n\nComprehensive documentation, including API references, setup guides, and usage examples integrated into the IoTDB website.\n\nTest suites covering core functionality, edge cases, and integration with Flink.\n\nA demo application showcasing a complete Flink pipeline reading from/writing to IoTDB tables.\n\nOptimization reports, benchmarks, and any upstream PRs.\n\n# Recommended Skills\n\n**Programming Language**: Proficiency in Java, as both Flink and IoTDB are primarily Java-based projects.\n\n**Database Knowledge**: Understanding of SQL and fundamental database concepts. Knowledge of time-series data is a plus.\n\n**System Integration**: Interest or experience in connecting different systems and understanding data flows.\n\n**Learning and Communication**: Ability to quickly understand the codebases of two open-source projects and willingness to actively collaborate with community mentors and members.\n\n# Learning Material\n\n\nApache IoTDB Official Website:[https://iotdb.apache.org/](https://iotdb.apache.org/)\n\nApache Flink Official Documentation:[https://flink.apache.org/](https://flink.apache.org/)\n\nIntegrated Reference:[https://github.com/apache/iotdb-extras/tree/master/connectors/flink-iotdb-connector](https://github.com/apache/iotdb-extras/tree/master/connectors/flink-iotdb-connector)\n\nIoTDB Table Mode Concepts:[https://iotdb.apache.org/UserGuide/latest/Background-knowledge/Data-Model-and-Terminology_apache.html](https://iotdb.apache.org/UserGuide/latest/Background-knowledge/Data-Model-and-Terminology_apache.html)\n\nIoTDB Table Mode Query Syntax:[https://iotdb.apache.org/UserGuide/latest-Table/SQL-Manual/overview_apache.html](https://iotdb.apache.org/UserGuide/latest-Table/SQL-Manual/overview_apache.html)\n\n**Difficulty:** medium**Mentor:** Haonan Hou (Apache IoTDB PMC member) *(haonan@apache.org)*\n\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Haonan Hou*, mail: haonan (at) apache.org\n\n*Project Devs*, mail: dev (at) iotdb.apache.org\n\n[Implement Trino-IoTDB Plugin to enable OLAP on time-series data](https://issues.apache.org/jira/browse/GSOC-303)\n\n**Background**\n\nApache IoTDB (Internet of Things Database) is a high-performance, open-source time-series database optimized for data management and analysis in IoT scenarios. Trino (formerly PrestoSQL) is a fast distributed SQL query engine designed for running interactive analytic queries against data sources of all sizes.\n\nCurrently, while IoTDB provides strong capabilities for writing and querying time-series data, integrating it with the broader big data ecosystem for complex OLAP (Online Analytical Processing) remains a demand. A dedicated Trino connector for IoTDB will allow users to query IoTDB data using standard SQL via Trino and perform federated queries with other data sources (like Hive, MySQL, or Iceberg).\n\n**Goal**\n\nThe goal of this project is to implement a trino-iotdb connector plugin based on the Trino SPI (Service Provider Interface). This connector will enable Trino to read data directly from IoTDB, supporting schema mapping, data projection, and predicate pushdown or maybe aggregate pushdown.\n\n\n**Core Tasks（Mandatory）**\n\n**Project Scaffolding:**Set up the Maven project structure for the trino-iotdb plugin and integrate the IoTDB JDBC API.**Metadata Implementation:**Implement ConnectorMetadata to map IoTDB’s Table Mode (relational view) to Trino’s relational metadata model:\n\nMap IoTDB databases to Trino Schemas.\n\nMap IoTDB Tables to Trino Tables.\n\nMap IoTDB Data Type to Trino Data Type.\n\n**Column Pruning (Projection Pushdown):**Ensure the connector strictly fetches only the requested columns (measurements) from IoTDB, avoiding SELECT * overhead.**Predicate Pushdown:**Implement optimization rules to push down SQL filters (especially time range filters and value filters) to the IoTDB engine to minimize data transfer.**Limit & Offset Pushdown:**Map Trino’s LIMIT and OFFSET clauses to IoTDB’s native query pagination to prevent fetching excessive data during preview or pagination queries.**Integration Testing:**Provide Docker-based integration tests to verify correctness using Trino's testing framework.\n\n**Advanced Tasks (Optional)**\n\n**Aggregation Pushdown:**Implement the applyAggregation method in the connector SPI.\n\nGoal: Map Trino’s aggregate functions (e.g., COUNT, AVG, SUM, MIN, MAX) directly to IoTDB’s native aggregation queries.\n\nBenefit: Instead of fetching raw data to Trino for calculation, the connector leverages IoTDB's pre-calculated statistics or downsampling capabilities, significantly reducing network overhead and latency.\n\n\n**Deliverables**\n\n\nA fully functional trino-iotdb connector source code.(a pull request to Trino Repo)\n\nComprehensive integration tests covering data types and query patterns.\n\nUser documentation explaining how to configure and use the connector.\n\n**Recommended Skills**\n\n**Java:**Proficiency in Java programming (Trino and IoTDB are both Java-based).**Database Internals:**Basic understanding of SQL execution, schema design, and database connectors.**Maven:**Experience with Java build systems.**Nice to have:**Familiarity with Trino SPI or IoTDB Session API.\n\n# Learning Material\n\n\nApache IoTDB:[https://iotdb.apache.org/](https://iotdb.apache.org/)\n\nTrino Connector Developer Guide:[https://trino.io/docs/current/develop/connectors.html](https://trino.io/docs/current/develop/connectors.html)\n\nTrino PG Plugin:[https://github.com/trinodb/trino/tree/master/plugin/trino-postgresql/src/main/java/io/trino/plugin/postgresql](https://github.com/trinodb/trino/tree/master/plugin/trino-postgresql/src/main/java/io/trino/plugin/postgresql)\n\nIoTDB Java JDBC API:[https://iotdb.apache.org/UserGuide/latest/API/Programming-JDBC_apache.html](https://iotdb.apache.org/UserGuide/latest/API/Programming-JDBC_apache.html)\n\nIoTDB Table Model Concepts:[https://iotdb.apache.org/UserGuide/latest/Background-knowledge/Data-Model-and-Terminology_apache.html](https://iotdb.apache.org/UserGuide/latest/Background-knowledge/Data-Model-and-Terminology_apache.html)\n\nIoTDB Table Model Query Syntax:[https://iotdb.apache.org/UserGuide/latest-Table/SQL-Manual/overview_apache.html](https://iotdb.apache.org/UserGuide/latest-Table/SQL-Manual/overview_apache.html)\n\n**Difficulty:** medium**Mentor:** Yuan Tian (Apache IoTDB PMC Member) *(jackietien@apache.org)*\n\n\n**Difficulty:**Major\n\n**Project size:**~175 hour (medium)\n\n**Potential mentors:**\n\n*Yuan Tian*, mail: jackietien (at) apache.org\n\n*Project Devs*, mail: dev (at) iotdb.apache.org\n\n# Seata\n\n[GSoC 2026 - Apache Seata(Incubating)Enhance the Seata framework Golang SDK’s support for multiple databases](https://issues.apache.org/jira/browse/GSOC-314)\n\n**Project Overview**\n\n**Title**\n\nEnhance the Seata framework Golang SDK’s support for multiple databases\n\n**Abstract**\n\nApache Seata(incubating) is a popular distributed transaction solution, providing solutions like AT, TCC, and XA for ensuring data consistency in microservice architectures.\n\nThe AT mode (Automatic Transaction) provides applications with non-intrusive distributed transaction capabilities by proxying SQL statements and parsing protocols. Although Seata-go currently supports MySQL and has initial compatibility with PostgreSQL, it still falls short in covering commonly used production databases, and precise compatibility with Oracle and MariaDB is an urgent need.\n\nThis project aims to align with the mature ecosystem of Seata Java and introduce AT mode support for Oracle and MariaDB in Seata-go. This not only involves parsing and adapting SQL dialects, but also includes metadata management, handling differences in Undo Log serialization, and integrating with the specific locking mechanisms of each database. It is a critical step in expanding the capability boundaries of Seata-go.\n\n**Detailed Description** **Objectives**\n\n- Console Metrics Visualization: Develop functionality to view various metrics related to the connection pool in the Seata console. The metrics should be displayed based on IP/connection pool granularity, helping users easily identify resource allocation and utilization.\n\n- Metrics Control via Console: Allow users to control various aspects of the connection pools directly from the Seata console. This includes the ability to adjust minimum and maximum connection counts, configure connection acquisition timeout, and manage connection pool keep-alive settings.\n\n**Deliverables**\n\n**Complete MariaDB AT Mode Support (Priority P0)**- Implement MariaDB driver adapter layer (seata-at-mariadb Driver)\n- Implement MariaDB TableMetaCache and Trigger\n- Implement MariaDB UndoLogManager\n- Handle dialect differences between MariaDB and MySQL (e.g., RETURNING clause, system variables)\n\n**Complete Oracle AT Mode Support (Priority P1)**- Implement Oracle driver adapter layer (seata-at-oracle Driver)\n- Implement Oracle metadata query adaptation (based on ALL_TAB_COLUMNS, ALL_INDEXES system views)\n- Implement Oracle data type to JDBC type mapping (NUMBER, VARCHAR2, CLOB, DATE, etc.)\n- Implement Oracle UndoLogManager with Undo Log serialization differences\n- Adapt Oracle SQL dialect (ROWNUM pagination, Sequence retrieval, DUAL table, etc.)\n\n**Integration Testing and Validation (Priority P1)**- Write comprehensive unit tests and integration tests covering single-table CRUD, multi-table join operations, and transaction rollback scenarios\n- Validate accuracy of Before/After Image generation\n- Validate correctness of global locks and Undo Log\n\n**Samples and Documentation (Priority P2)**- Add Oracle and MariaDB usage demos in seata-go-samples\n- Write a technical blog \"Seata-Go Multi-Database Adaptation Design\" explaining design concepts and implementation details\n\n\n**Implementation Plan**\n\nPhase 1: Requirement Analysis and Design\n\n- Align scope and acceptance criteria with mentors/community: prioritize MariaDB (P0) and Oracle (confirm final priority as per topic), and define the must-cover SQL/transaction scenarios (CRUD, rollback, lock conflict, batch ops, joins where applicable).\n\n- Study and benchmark Seata Java AT implementation: produce a gap list for Dialect, TableMeta, UndoLog, Before/After Image, and global lock integration, and decide what to port vs. re-design for Go.\n\n- Design a pluggable multi-database architecture for Seata-Go: define clear interfaces (Dialect, MetaQuery, TypeMapper, UndoLogManager, DriverAdapter) and module boundaries for MariaDB/Oracle implementations; write a short design spec.\n\n- Prepare baseline environments and regression safety: stand up MariaDB/Oracle test environments (local and/or CI) and create baseline test cases to ensure existing MySQL AT behavior does not regress.\n\nPhase 2: MariaDB AT Mode Support (P0)\n\n- Implement seata-at-mariadb driver adapter: integrate with database/sql, hook into key execution points, and ensure Seata AT context is correctly propagated.\n\n- MariaDB dialect adaptation: handle MariaDB vs. MySQL differences (syntax/behaviors such as RETURNING-related cases, system variables, and any MariaDB-specific edge cases affecting parsing and image SQL).\n\n- Metadata and caching: implement MariaDB TableMetaCache and metadata queries (columns, primary keys, indexes) with robust caching/invalidations as needed.\n\n- MariaDB UndoLogManager: implement undo log write/read/delete and serialization strategy consistent with Seata-Go conventions; ensure rollback works for common and edge data types.\n\n- Scenario-driven hardening: validate with integration tests covering single-table DML, unique key updates, batch updates, idempotent rollback, and lock conflict/retry behaviors.\n\nPhase 3: Oracle AT Mode Support (P0/P1)\n\n- Implement seata-at-oracle driver adapter: adapt to the chosen Oracle driver (godror / go-ora, per community decision), addressing bind variables, result set handling, and transaction boundary behaviors.\n\n- Oracle metadata adaptation: implement metadata queries using Oracle system views (e.g., ALL_TAB_COLUMNS, ALL_INDEXES) and cache results effectively.\n\n- Oracle type mapping: map Oracle types to Seata-Go internal types (NUMBER, VARCHAR2, CLOB, DATE, TIMESTAMP, etc.) to ensure image capture and undo serialization are consistent.\n\n- Oracle dialect adaptation: support Oracle-specific SQL behaviors (ROWNUM pagination patterns, sequences, DUAL table usage, locking semantics where relevant).\n\n- Oracle UndoLogManager: implement Oracle-compatible undo log persistence and serialization differences; validate large objects and time types in rollback.\n\nPhase 4: Testing, Samples, and Documentation\n\n- Testing: add unit tests (Dialect/TypeMapper/MetaQuery/UndoLog) and integration tests (real DB) to verify:\n- Before/After Image correctness\n- Global lock correctness (conflicts, concurrency, retries)\n- Rollback correctness and idempotency\n- No regressions for existing MySQL AT\n\n- CI enablement (if feasible): make MariaDB/Oracle tests repeatable in CI or provide a documented script-based workflow for contributors.\n\n- Samples: add full MariaDB and Oracle examples to incubator-seata-go-samples (config, schema, demo transactions, rollback demos).\n\n- Documentation/blog: write “Seata-Go Multi-Database Adaptation Design” and user/developer docs covering configuration, driver selection, supported SQL patterns, and known limitations.\n\n**Required Skills**\n\n- Have Go language development experience, familiar with database/sql standard library and common database drivers (e.g., go-sql-driver/mysql, godror, go-ora)\n\n- Proficient in SQL syntax, deep understanding of relational database principles, familiar with transaction isolation levels and row/table locking mechanisms\n\n- Understand the core principles of Seata AT mode (Before/After Image, Undo Log, Global Lock)\n\n- Have experience with Oracle or MariaDB databases, understand their dialect differences from MySQL\n\n- Possess good documentation habits and code standards awareness, able to read Seata Java source code for reference\n\n**Benefits to Apache Seata**\n\n- Broader database coverage for Seata-Go AT mode: enables production adoption in enterprises that rely on MariaDB and Oracle.\n\n- Lower migration and adoption cost: users can extend distributed transaction capability beyond MySQL with minimal application changes.\n\n- Better maintainability and extensibility: a clean, interface-driven design (Dialect/Meta/UndoLog/TypeMapping) reduces future effort to add more databases.\n\n- Higher reliability through verification: comprehensive integration tests and samples make correctness measurable and reduce regressions.\n\n- Stronger community value: aligning with Seata Java’s proven approach and producing clear docs/design guidance improves contributor productivity and ecosystem confidence.\n\n**Conclusion**\n\nThis project strengthens Seata-Go AT mode by adding robust MariaDB and Oracle support aligned with Seata Java’s mature implementation. By delivering dialect adaptation, metadata management, undo log handling, type mapping, and thorough testing plus samples and documentation, it significantly expands Seata-Go’s multi-database capabilities and improves its production readiness for real-world enterprise environments.\n\n**Useful Link**\n\n[https://github.com/apache/incubator-seata-go](https://github.com/apache/incubator-seata-go)\n\n[https://github.com/apache/incubator-seata-go-samples](https://github.com/apache/incubator-seata-go-samples)\n\n**Contact Information**\n\n- Mentor Name: FengZhang [zfeng@apache.org], Apache Seata(incubating) PPMC member\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Feng Zhang*, mail: zfeng (at) apache.org\n\n*Project Devs*, mail: dev (at) seata.apache.org\n\n[GSoC 2026 - Apache Seata(Incubating)Enhance the Seata framework Golang SDK’s multi-registry support and seata-ctl capability](https://issues.apache.org/jira/browse/GSOC-316)\n\n# Project Overview\n\n## Title\n\nEnhance Seata-Go Multi-Registry Support and seata-ctl Diagnostic Tool Capability\n\n## Abstract\n\nApache Seata (incubating) is a popular distributed transaction solution for ensuring data consistency in microservice architectures. Seata-Go, as its Go language SDK, is responsible for implementing core TM/RM functionalities in the Go ecosystem.\n\nCurrently, Seata-Go lags behind the Java version in terms of registry support richness at the infrastructure layer, and its production-level transaction troubleshooting and operational toolchain (seata-ctl) is still in its early stages. This results in limited options for users in non-Etcd/Raft scenarios and high troubleshooting costs when transaction anomalies occur.\n\nThis project aims to align with Seata's infrastructure ecosystem by introducing support for four mainstream registries: **Nacos, ZooKeeper, Consul, and Redis** to Seata-Go. Additionally, it will significantly enhance seata-ctl's diagnostic capabilities through full-chain environment checks, transaction state insights, and an interactive terminal interface, reducing the operational threshold for distributed transactions.\n\n## Detailed Description / Objectives\n\n**Infrastructure Alignment**: Ensure Seata-Go can seamlessly integrate into existing enterprise-level microservice governance systems by implementing adapters for various mainstream registries.**Operational Efficiency Improvement**: Build a complete diagnostic command set enabling developers to quickly locate network, database, and transaction state anomalies, and simplify operation workflows through an interactive interface.**Community Ecosystem Contribution**: Produce high-quality design documents and technical blogs to help community users understand Seata-Go's underlying governance logic and operational best practices.\n\n## Deliverables\n\n### 1. Multi-Registry Cluster Support (Priority P0)\n\n**Mainstream Registry Adapter Implementation**:\n\n- Implement\n**Nacos**and**ZooKeeper**registry adapters with support for service instance subscription, real-time listening, and multi-tenant isolation configuration. - Implement\n**Consul**and**Redis**adapters with support for service registration/discovery and heartbeat monitoring mechanisms. - Bug fixes for Seata NamingServer Golang SDK.\n- Ensure service registration path formats for all registries are fully compatible with Java version Seata.\n\n- Implement\n**Configuration and Initialization System Integration**:\n\n- Extend configuration structure to standardize registry-specific configuration parameters.\n- Optimize factory initialization logic to support smooth registry type switching via configuration files.\n\n\n### 2. seata-ctl Diagnostic Tool Enhancement (Priority P1)\n\n**Full-Chain Self-Check Functionality**:\n\n- Implement automated environment checks covering network connectivity verification with the server.\n- Implement database-level health checks including connection availability and validation of transaction core system table structures.\n- Implement configuration file format and required field legality validation.\n\n**Transaction State Insight Capability**:\n\n- Implement real-time query functionality for active transaction lists.\n- Implement query functionality for resource lock records corresponding to specific transaction identifiers (XID).\n- Support structured output formats (e.g., table, JSON, YAML).\n\n**Interactive Terminal Interface (TUI)**:\n\n- Introduce a visual interactive mode for the tool, simplifying complex command input through interface guidance to enhance operational experience.\n\n\n### 3. Testing, Samples, and Community Output (Priority P2)\n\n**Testing and Validation**:\n\n- Write unit tests and integration tests for each registry adapter to verify node change awareness capabilities.\n- Validate diagnostic tool accuracy across different database dialects.\n\n**Samples and Documentation**:\n\n- Add complete multi-registry integration examples in seata-go-samples.\n- Write technical articles:\n**\"Seata-Go Registry Extension Design and Practice Guide\"**and**\"Distributed Transaction Troubleshooting in Practice: Quickly Locating Anomalies with Diagnostic Tools\"**.\n\n\n## Implementation Plan\n\n**Phase 1: Research and Architecture Design**\n\n- Research existing Seata-Go registry implementations and study Seata NamingServer implementation logic.\n- Design diagnostic tool's interaction logic and command set architecture, ensuring tool extensibility.\n\n**Phase 2: Registry Adapter Development (P0)**\n\n- Prioritize completion of core functionality implementation and compatibility testing for Nacos and ZooKeeper.\n- Perform bug fixes for Seata NamingServer to optimize its stability in the Go SDK.\n- Integrate Consul and Redis support and unify configuration initialization entry points.\n\n**Phase 3: Diagnostic Tool and Interactive Interface Development (P1)**\n\n- Develop core logic for environment checks and transaction state queries.\n- Build interactive terminal interface (TUI), encapsulating underlying commands into intuitive visual operations.\n\n**Phase 4: Testing Validation and Community Promotion (P2)**\n\n- Improve test cases to ensure stability across different registry environments.\n- Complete community technical article output and submit related sample code.\n\n\n## Required Skills\n\n- Have Go language development experience, familiar with concurrent programming and network communication.\n- Understand service discovery principles, familiar with mainstream registries (e.g., Nacos, ZooKeeper).\n- Understand basic distributed transaction principles, familiar with Seata's interaction architecture (TM/RM/TC).\n- Familiar with command-line tool development, possess good code standards awareness and documentation writing skills.\n\n## Benefits to Apache Seata\n\n**Expand Infrastructure Boundaries**: Enable Seata-Go to adapt to more diverse enterprise production environments, eliminating selection barriers.**Improve Operational Convenience**: Fill the gap in operational diagnostic tools for the Go version, significantly reducing user learning and maintenance costs.**Enhance Ecosystem Interoperability**: Ensure consistency in governance between Go and Java versions, supporting Seata's unified multi-language ecosystem.\n\n## Conclusion\n\nThis project addresses Seata-Go's shortcomings in infrastructure adaptation and operational troubleshooting by enhancing multi-registry support and diagnostic tool capabilities. This not only improves Seata-Go's production readiness but also strengthens the Apache Seata community ecosystem through user-friendly interactive tools and comprehensive technical documentation.\n\n## Useful Link\n\n[https://seata.apache.org/](https://seata.apache.org/)[https://github.com/apache/incubator-seata-go](https://github.com/apache/incubator-seata-go)[https://github.com/apache/incubator-seata-go-samples](https://github.com/apache/incubator-seata-go-samples)[https://github.com/apache/incubator-seata-ctl](https://github.com/apache/incubator-seata-ctl)\n\n## Contact Information\n\n- Mentor Name: TunGuo [tew@apache.org], Apache Seata(incubating) Committer\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*FinnTew*, mail: tew (at) apache.org\n\n*Project Devs*, mail: dev (at) seata.apache.org\n\n# HugeGraph\n\n[[GSoC][HugeGraph] HugeGraph Query Engine Upgrade & Adaptation](https://issues.apache.org/jira/browse/GSOC-317)\n\n**Description**\n\nCurrently, the HugeGraph core query engine is built on **Java 11 + TinkerPop 3.5.x + Groovy 3**. While this stack provides fundamental graph query capabilities, it lags behind in security, performance optimization, and support for modern features. Specifically, the built-in Groovy engine relies on complex, high-maintenance black/whitelist mechanisms for script security, which poses potential bypass risks.\n\nThe goal of this task is to comprehensively upgrade HugeGraph's underlying dependencies to **Java 17 + TinkerPop 3.7/3.8 + Groovy 4**. This is not just a version iteration, but a modern architectural transformation:\n\n**Groovy 4 & TinkerPop 3.7/3.8**: Introduce improved syntax features and security designs. We aim to refactor HugeGraphSecurity using native, efficient sandboxing mechanisms to replace the legacy blacklist logic.**Java 17/21 Support**: Adapt to the new JDK to fully leverage features like ZGC/Shenandoah GC, Records, and Virtual Threads, significantly improving throughput and reducing long-tail latency in large-scale graph queries.\n\nApplicants are expected to handle the full lifecycle, from dependency upgrades and code refactoring to unit test fixes and final performance benchmarking.\n\n**Recommended Skills**\n\n**Java Core**: Proficiency in Java development with a solid understanding of Java 17+ new features.**HugeGraph Architecture**: Basic understanding of HugeGraph's storage structure (KV Store), Schema design, and specifically the Gremlin query execution flow.**Graph Computing & Compilers**: Familiarity with the TinkerPop Gremlin framework architecture; knowledge of AST (Abstract Syntax Tree) parsing or Functional Programming (FP) mindset is a plus.**AI Coding**:**Proficiency in using AI Coding tools (e.g., Codex, Claude Code, Copilot) to assist in code refactoring, test case optimization, and source code interpretation is highly preferred.****Security Awareness**: Awareness of code security, understanding of how to prevent Script Injection, and experience designing secure sandbox environments.\n\n### 💡 **Important Notes for Applicants**\n\n**Authenticity Matters**: While we encourage the use of AI for coding efficiency, please**strictly control and reasonably limit**the use of LLMs when writing your project**proposal**/**emails**. We value genuine communication and mutual respect.**Proactive Engagement**: We highly recommend participating in community**Mini Tasks**early. Demonstrating your hands-on ability within the community will significantly increase your chances of selection and help build trust with mentors.\n\n**Task List**\n\n**Dependency Analysis & Upgrade**:- Analyze\n**Breaking Changes**from TinkerPop 3.5 to 3.7/3.8. - Complete core dependency version upgrades and API adaptations following mentor confirmation.\n\n- Analyze\n\n**Java 17 Environment Adaptation**:- Resolve compile-time and runtime compatibility issues (e.g., reflection restrictions, module access) to ensure the Server module runs correctly on Java 17 (Java 21 is even better).\n- Update Docker configurations to migrate the default runtime to Java 17 (while exploring backward compatibility with Java 11).\n\n\n**PD & Store Module Upgrade (New)**:- Extend the upgrade scope to the\n**PD (Placement Driver)**and**Store**modules after completing the core Server upgrade. - Ensure these modules are adapted to Java 17 to unify the runtime environment across the HugeGraph ecosystem.\n\n- Extend the upgrade scope to the\n\n**Security Module Refactoring**:- Refactor the HugeGraphSecurity component based on Groovy 4 features.\n- Design a lightweight, secure script execution strategy and remove the performance-heavy legacy blacklist logic.\n\n\n**Testing & Fixes**:- Fix Unit Test (UT) failures caused by the upgrade.\n- Ensure all core functions (CRUD, complex Gremlin queries) pass verification.\n\n\n**Performance Benchmarking**:- Produce a performance comparison report:\n**Java 11 (Old)**vs.**Java 17 (New)**using the Twitter-14B public dataset. - Quantify improvements in\n**Latency**reduction and**Throughput**increases.\n\n- Produce a performance comparison report:\n\n**References**\n\n**New Contributor Guide**:[HugeGraph Contribution Guide (Issue #2212)](https://www.google.com/url?sa=E&q=https%3A%2F%2Fgithub.com%2Fapache%2Fhugegraph%2Fissues%2F2212)- Environment setup & basics.\n\n**Upgrade Docs**:[TinkerPop Upgrade Documentation](https://www.google.com/url?sa=E&q=https%3A%2F%2Ftinkerpop.apache.org%2Fdocs%2Fcurrent%2Fupgrade%2F)\n\n**Reference Implementation**:[JanusGraph Upgrade PR (For reference only)](https://www.google.com/url?sa=E&q=https%3A%2F%2Fgithub.com%2FJanusGraph%2Fjanusgraph%2Fpull%2F3914)\n\n**Gremlin Learning**:[Practical Gremlin Guide](https://www.google.com/url?sa=E&q=https%3A%2F%2Fkelvinlawrence.net%2Fbook%2FGremlin-Graph-Guide.html)\n\n**Project Wiki**:[HugeGraph Deepwiki](https://www.google.com/url?sa=E&q=https%3A%2F%2Fdeepwiki.com%2Fapache%2Fhugegraph%2F)\n\n**Project Size**\n\n**Difficulty**: Medium (Similar references available)\n\n**Estimated Time**: ~250 Hours (~15 Weeks)\n\n**Mentors**\n\n- Yan Zhang:\n[vaughn@apache.org](https://www.google.com/url?sa=E&q=mailto%3Avaughn%40apache.org)(Apache HugeGraph PMC)\n\n- Imba Jin:\n[jin@apache.org](https://www.google.com/url?sa=E&q=mailto%3Ajin%40apache.org)(Apache HugeGraph PMC)\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Imba Jin*, mail: jin (at) apache.org\n\n*Project Devs*, mail:\n\n# CloudStack\n\n[[GSoC] [CloudStack] Improve CloudMonkey user experience by enhancing autocompletion](https://issues.apache.org/jira/browse/GSOC-295)\n\n## Summary\n\nCurrently a lot of API parameters do not get auto-completed as cloudmonkey isn't able to deduce the probable values for those parameters based on the list APIs heuristics. A lot of these parameters are enums on CloudStack end and by finding a way to expose these and consume them on cloudmonkey side, we could improve the usability of the CLI greatly.\n\n## Benefits to CloudStack\n\n- Improved end user experience when using CLI\n- Reduce incorrect inputs\n\n## Deliverables\n\n- Expose enums and all other relevant information that can be used to enhance auto-completion of parameters on CloudStack end -\n- May require framework level changes and changes to APIs\n\n- Consume these exposed details on Cloudmonkey end\n\n## Dependent projects\n\n[https://github.com/apache/cloudstack-cloudmonkey/](https://github.com/apache/cloudstack-cloudmonkey/)\n\nRef CloudStack Issue: [https://github.com/apache/cloudstack/issues/10442](https://github.com/apache/cloudstack/issues/10442)\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*Pearl Dsilva*, mail: pearl11594 (at) apache.org\n\n*Project Devs*, mail: dev (at) cloudstack.apache.org\n\n# Apache Grails\n\n[Author and Publish New Practical Guides for Apache Grails](https://issues.apache.org/jira/browse/GSOC-325)\n\nAuthor and Publish New Practical Guides for Apache Grails on [https://guides.grails.org](https://guides.grails.org/) (will be moved to grails.apache.org soon)\n\n## Background\n\nThe Grails Guides provide step-by-step, hands-on tutorials with accompanying GitHub repositories containing initial and complete project states. They cover core topics GORM, testing, security, frontend integrations (Vue.js, React, Angular), Micronaut features, deployment (AWS, Google Cloud, GitHub Actions), and more.\n\nExisting guides are strong in foundational and some advanced areas but have gaps in:\n\n- Modern frontend setups\n- Broader cloud deployment\n- Current DevOps practices\n- Popular plugins/ecosystem updates\n\nCreating 5-10 high-quality, up-to-date guides would directly enhance this key learning resource, making Grails more approachable and demonstrating current best practices without requiring core framework changes.\n\n## Project Goals\n\n**Research & Plan Topics:**Select 5-10 high-impact guide topics based on community needs (user list discussions, Slack feedback, gaps identified).**Develop Guides:**For each:- Build a complete, runnable Grails application example.\n- Create initial and complete GitHub repos following the standard template.\n- Write a clear, step-by-step Markdown guide with code snippets, explanations, and best-practice rationale.\n\n**Test & Polish:**Ensure guides work with the latest stable Grails (e.g., 7.x or 8.x series), include tests where relevant, and follow accessibility/Asciidoc formatting standards.**Submit & Integrate:**Open PRs to publish guides update any related docs or grails.org links.**Optional Stretch Goals:**Add video walkthroughs (if comfortable), create a \"What's New in Recent Guides\" summary blog post, or contribute minor improvements to existing guides.\n\n**Suggested Guide Topics (prioritize with mentor input):**\n\n- Building Modern Full-Stack Apps with Grails + React/Vite (or Vue/Vite) – Update/extend older profiles with current tooling.\n- Securing Grails APIs with JWT + OAuth2 (modern patterns, perhaps using Micronaut Security).\n- Deploying Grails Apps to the cloud\n- Advanced CI/CD\n- Performance Tuning\n- Using HTMX + Grails for Interactive UIs without Heavy Frontend Frameworks.\n\n## Deliverables\n\n- 5-10 new published guides on\n[https://guides.grails.org](https://guides.grails.org/)(each with its own GitHub repo under grails-guides). - Corresponding initial and complete source code repositories.\n- Well-structured Markdown/Asciidoc content with clear sections, screenshots/code blocks, and \"Try it Yourself\" instructions.\n- PRs reviewed and merged by mentors/community.\n- A short summary report or blog draft for the Grails blog announcing the new guides.\n- Documentation updates if needed (e.g., category additions on the guides index page).\n\n**Quantifiable Results for the Apache Community:**\n\n- Fresh, relevant content that attracts and retains new developers.\n- Reduced support burden on mailing lists/Slack by pointing users to modern tutorials.\n- Evergreen educational assets maintained by the community.\n\n## Proposed Timeline (12-week program)\n\n**Community Bonding (May 2026):**Join Grails Slack/mailing list, review existing guides, discuss topic priorities with mentors, fork/clone template repo, set up local build.**Weeks 1–2:**Finalize 3–5 topics, create initial repos, outline guide structures.**Weeks 3–6:**Implement and document first 2–3 guides (focus on core features, testing).**Weeks 7–9:**Complete remaining guides, add polish (screenshots, edge-case notes), self-review for clarity.**Weeks 10–11:**Submit PRs for review, incorporate feedback, test on latest Grails version.**Week 12:**Final merges, any last tweaks, prepare announcement draft, evaluations.\n\n## Required Skills\n\n- Solid understanding of Grails (create-app, domains, controllers, services, GSP/JSON views).\n- Experience with Groovy/Java and web basics (REST, security concepts).\n- Good technical writing (clear, concise explanations).\n- Git/GitHub proficiency (branching, PRs).\n- Nice-to-have: Familiarity with Asciidoc/Markdown, frontend tools (Vite, npm), or deployment platforms.\n\n## Why This Project?\n\nThis is a high-reward contribution that directly improves one of Grails' most visible learning resources. It's flexible, scope can adjust based on progress, and allows the student to master Grails while helping others. Similar documentation-focused GSoC projects have succeeded in many Apache projects.\n\nIf Grails is accepted for GSoC 2026, this would be an excellent intermediate project. Interested students should contact the Grails dev mailing list or Slack early to discuss topics and secure a mentor. The community welcomes fresh guides to keep the framework vibrant!\n\n**Difficulty:** Medium**Project size:** ~350 hour (large)**Potential mentors:***James Fredley*\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*James Fredley*, mail: jamesfredley (at) apache.org\n\n*Project Devs*, mail: dev (at) grails.apache.org\n\n# Spark\n\n[SPIP Client-Side Metadata Caching for Spark Connect](https://issues.apache.org/jira/browse/SPARK-55163)\n\n**This SPIP proposes adding a client-side schema cache for Spark Connect DataFrames.**\n\nCurrently, every call to df.columns or df.schema triggers a synchronous gRPC analysis request to the server. While these are local and near-instant in Spark Classic, in Connect they average 277 ms on standard cloud setups (like AWS t3.medium). This makes iterative work extremely slow; we've measured a 13-second lag for 50 metadata calls in a typical ETL pipeline.\n\nThis delay is forcing developers to use a \"Shadow Schema\" pattern, where they manually track column names in local lists to avoid the RPC overhead. Since Spark DataFrames are immutable, we can fix this by caching the resolved schema on the client after the first request. Our POC shows this reduces the 13-second lag to about 250 ms (a 51× speedup) without breaking the core Spark Connect model.\n\n\nI have followed the official SPIP template for the detailed breakdown below.\n\n**SIP**\n\n[ https://docs.google.com/document/d/1xTvL5YWnHu1jfXvjlKk2KeSv8JJC08dsD7mdbjjo9YE/edit?tab=t.0](https://docs.google.com/document/d/1xTvL5YWnHu1jfXvjlKk2KeSv8JJC08dsD7mdbjjo9YE/edit?tab=t.0)\n\n**Benchmark** - [https://docs.google.com/document/d/1ebX8CtTHN3Yf3AWxg7uttzaylxBLhEv-T94svhZg_uE/edit?tab=t.0](https://docs.google.com/document/d/1ebX8CtTHN3Yf3AWxg7uttzaylxBLhEv-T94svhZg_uE/edit?tab=t.0)\n\n**Difficulty:**Major\n\n**Project size:**~350 hour (large)\n\n**Potential mentors:**\n\n*vaquar khan*, mail: vaquar.khan@gmail.com (at) apache.org\n\n*Project Devs*, mail:"
  },
  {
    "name": "EROFS filesystem",
    "slug": "erofs-filesystem",
    "tagline": "Modern image-based kernel filesystem for everyone",
    "description": "EROFS [1] is a modern, high-performance block-based immutable Linux filesystem with highly-optimized on-disk format and runtime implementation. Since it's landed upstream, it has been widely deployed to billions of devices, and addresses various target scenarios. Nowadays, almost all Linux mainstream distributions support EROFS.\n\nEROFS has become a recommended filesystem [2] for Android system partitions and has already been adopted by the majority of Android vendors. It has also become popular in the Linux container world. For example, Composefs [3] uses the EROFS format for its metadata tree. Containerd 2.1 [4] also officially includes a built-in EROFS support to boost container launch performance. gVisor now supports EROFS as well [5].\n\n[1] https://erofs.docs.kernel.org\n[2] https://source.android.com/docs/core/architecture/kernel/erofs\n[3] https://github.com/containers/composefs\n[4] https://github.com/containerd/containerd/releases/tag/v2.1.0\n[5] https://github.com/google/gvisor/pull/9486",
    "ideas_url": "https://erofs.docs.kernel.org/en/latest/roadmap.html",
    "website_url": "https://erofs.docs.kernel.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "android",
      "linux kernel",
      "Containerd",
      "gVisor"
    ],
    "topic_tags": [
      "operating system",
      "containers",
      "android",
      "filesystems",
      "agent sandbox"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/erofs-filesystem",
    "ideas_content": "# 🗺 Roadmap[#](https://erofs.docs.kernel.org#roadmap)\n\nNote that items marked with **[SoC]** are also intended for Summer of Code projects.\n\n## Linux Kernel[#](https://erofs.docs.kernel.org#linux-kernel)\n\n## Userspace tools (erofs-utils)[#](https://erofs.docs.kernel.org#userspace-tools-erofs-utils)\n\nStabilize liberofs APIs;\n\n**[SOC]**[Multi-threaded decompression](https://github.com/erofs/erofs-utils/issues/33);Fanotify on-demand loading support (using fanotify pre-content hooks);\n\nRebuild improvements (including incremental updates\n\n[[1]](https://git.kernel.org/xiang/erofs-utils/c/7550a30c332c)).\n\n## Containers[#](https://erofs.docs.kernel.org#containers)\n\n## Miscellaneous items[#](https://erofs.docs.kernel.org#miscellaneous-items)\n\n**[SOC]**[Porting EROFS to BSD Kernels](https://github.com/erofs/freebsd-freebsd-src/issues/1)."
  },
  {
    "name": "Zulip",
    "slug": "zulip",
    "tagline": "Organized chat for distributed teams",
    "description": "Zulip is the only modern team chat app that is ideal for both live and asynchronous conversations. Zulip has a web app, a cross-platform mobile app for iOS and Android, cross-platform desktop and terminal apps, and over 100 native integrations. The entire Zulip codebase is 100% open source.\n\nZulip has been gaining in popularity since it was released as open source software in late 2015, with code contributions from over 1000 people from all around the world. Thousands of people use Zulip every day, and your work on Zulip will have meaningful impact on their experience.\n\nAs an organization, we value engaged, responsive mentorship and making sure our product quality is extremely high. You can expect to receive disciplined code reviews by highly experienced engineers. Since Zulip is a team chat product, your GSoC experience with the Zulip project will be highly interactive.\n\nAs part of our commitment to mentorship, Zulip has over 160,000 words of documentation for developers, much of it designed to explain not just how Zulip works, but why Zulip works the way that it does.\n\nTo learn more about the experience of doing GSoC with Zulip, check out our blog post: https://blog.zulip.com/2025/12/02/google-summer-of-code-2025/",
    "ideas_url": "https://zulip.readthedocs.io/en/latest/outreach/gsoc.html",
    "website_url": "https://zulip.com/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "django",
      "flutter",
      "css",
      "typescript"
    ],
    "topic_tags": [
      "great developer tooling",
      "visual design",
      "teaching quality codebase",
      "team chat",
      "integrations"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/zulip",
    "ideas_content": "# GSoC project ideas[](https://zulip.readthedocs.io#gsoc-project-ideas)\n\nThis page describes ideas you can use as a starting point for your project\nproposal. If you have not done so yet, you should **start by reading our guide on\nhow to apply** to a Zulip outreach program. As noted in the guide:\n\nYour first priority during the contribution period should be figuring out how to become an effective Zulip contributor. Start developing your project proposal only once you have experience with iterating on your PRs to get them ready for integration. That way, you’ll have a much better idea of what you want to work on and how much you can accomplish.\n\n\n## Project size[](https://zulip.readthedocs.io#project-size)\n\nWe have designed all our projects to have incremental milestones that can be completed throughout the program. Consequently, Zulip projects described below are generally compatible with both large-sized (350 hours) and medium-sized (175 hours) projects. Of course, the amount of progress you will be expected to make depends on whether you are doing a 175-hour or 350-hour project. Because it takes significant time investment to learn how to contribute complex features to Zulip’s codebase, we are not planning to offer small-size projects.\n\nContributors who master the art of consistently packaging their work\ninto correct, [reviewable pull\nrequests](https://zulip.readthedocs.io/contributing/reviewable-prs.html) are able to make major\nimprovements to the Zulip app. If you pay attention to the contributor\nguidelines, carefully review your own work before asking anyone else\nfor review, take the time to clearly communicate your changes, and\napply the feedback you receive to your next contribution, you’ll be\namazed at what you can accomplish.\n\n## Focus areas[](https://zulip.readthedocs.io#focus-areas)\n\nFor 2026, we are particularly interested in GSoC contributors who have strong skills at full-stack feature development, Typescript, visual design, HTML/CSS, Flutter, or performance optimization. So if you’re an applicant with those skills and are looking for an organization to join, we’d love to talk to you!\n\nThe Zulip project has a huge surface area, so even when we’re focused on something, a large amount of essential work goes into other parts of the project. Every area of Zulip could benefit from the work of a contributor with strong programming skills, so don’t feel discouraged if the areas mentioned above are not your main strength.\n\n## Project ideas by area[](https://zulip.readthedocs.io#project-ideas-by-area)\n\nThis section contains the seeds of project ideas; you will need to do research\non the Zulip codebase, read issues on GitHub, read documentation, and talk with\ndevelopers to put together a complete project proposal. It’s also fine to come\nup with your own project ideas. As you’ll see below, you can put together a\ngreat project around one of the [area\nlabels](https://github.com/zulip/zulip/labels) on GitHub; each has a cluster of\nproblems in one part of the Zulip project that we’d love to improve.\n\n### Full stack and web frontend focused projects[](https://zulip.readthedocs.io#full-stack-and-web-frontend-focused-projects)\n\nCode: [github.com/zulip/zulip](https://github.com/zulip/zulip/) – Python,\nDjango, TypeScript/JavaScript, and CSS.\n\n**Cluster of priority features**. Implement a cluster of new full stack features for Zulip. The[high priority label](https://github.com/zulip/zulip/issues?q=is%3Aissue+is%3Aopen+label%3A%22priority%3A+high%22)documents hundreds of issues that we’ve identified as important to the project. A great project can be 3-5 significant features around a theme (often, but not necessarily, an[area label](https://github.com/zulip/zulip/labels)); the goal will be to implement and get fully merged a cluster of features with a meaningful impact on the project. Zulip has a lot of half-finished PRs, so some features might be completed by reading, understanding, rebasing, and reviving an existing pull request. 175 or 350 hours; difficulty will vary.**Skills required**: Depends on the features; Tim Abbott will help you select an appropriate cluster once we’ve gotten to know you and your strengths through your getting involved in the project.Experts: Tim Abbott and various others depending on project area\n\n**Complete some unfinished projects**. This is a variant of the previous project idea category, but focused on projects with significant existing work to start from and polish, rather than projects that have not been seriously attempted previously.We maintain a\n\n[completion candidate label](https://github.com/zulip/zulip/pulls?q=is%3Aopen+is%3Apr+label%3A%22completion+candidate%22)for pull requests where a previous contributor (sometimes via GSoC!) did significant work towards something valuable, and there’s significant feedback from maintainers, but the project was never finished, and requires significant further effort from a new contributor in order to progress. One of our goals for this summer’s GSoC is to complete many of these issues. Start by picking something that’s interesting to you, and you feel you have the skills required to complete. Read the code and the feedback, and then create your own PR for the issue. See the[guide on continuing unfinished work](https://zulip.readthedocs.io/contributing/continuing-unfinished-work.html)for details. 175 or 350 hours; difficulty will vary.**Skills required**: Varies with project; a common skill will be good reading comprehension and organization/communication skills, to walk maintainers through how you resolved problems, addressed any pending feedback on the previous PR, and your understanding of the outstanding questions for a given project. Taking the time to get really good at resolving merge conflicts is likely to be valuable here as well.Experts: Tim Abbott and various others depending on project area\n\n\nAdd the core infrastructure for\n\n**topic-based permissions and settings**like[pinned topics](https://github.com/zulip/zulip/issues/19483)and[read-only topics](https://github.com/zulip/zulip/issues/26944), and then build some of those settings. This project will be a mixture of Python 3/PostgreSQL work, including thinking about database transactions and races, writing database migrations intended to be run live at scale, and complex logic to handle moving messages correctly in the context of these settings, including significant changes to the Zulip API and API documentation. 175 or 350 hours; fairly difficult.**Skills required**: A high level of fluency with writing readable Python 3 and thinking about corner cases.Experts: Tim Abbott, Prakhar Pratyush\n\nZulip’s\n\n, which is an important resource for any organization integrating with Zulip, as well as the developers of our API clients. Zulip has a**REST API documentation**[nice framework](https://zulip.readthedocs.io/documentation/api.html)for writing API documentation built by past GSoC students based on the OpenAPI standard with built-in automated tests of the data both the Python and curl examples. However, the documentation isn’t yet what we’re hoping for: there are a few dozen endpoints that are missing, several of which are quite important, the visual design isn’t perfect (especially for, e.g.,`GET /events`\n\n), many templates could be deleted with a bit of framework effort, etc. See the[API docs area label](https://github.com/zulip/zulip/issues?q=is%3Aopen+is%3Aissue+label%3A%22area%3A+documentation+%28api+and+integrations%29%22)for some specific projects in the area; and`git grep pending_endpoints`\n\nto find the list of endpoints that need documentation and their priorities. Our goal for the summer is for 1-2 students to resolve all open issues related to the REST API documentation. 175 or 350 hours; difficulty easy or medium.**Skills required**: Python programming. Expertise with reading documentation and English writing are valuable, and product thinking about the experience of using third-party APIs is very helpful.Expert: Lauryn Menard\n\n\n**Improve the UI and visual design**of the Zulip web app. We are working on a major redesign for the core surfaces of the Zulip web app – see the[redesign label](https://github.com/zulip/zulip/issues?q=is%3Aopen+is%3Aissue+label%3Aredesign)for specced out work, with more to come. We’re particularly excited about students who are interested in making our CSS clean and readable as part of working on the UI. 175 or 350 hours; medium to difficult.**Skills required**: Design, HTML and CSS skills; most important is the ability to carefully verify that one’s changes are correct and will not break other parts of the app; design changes are very rewarding since they are highly user-facing, but that also means there is a higher bar for correctness and reviewability for one’s work. A great application would include PRs making small, clean improvements to the Zulip UI (whether logged-in or logged-out pages).Experts: Aman Agrawal, Karl Stolley, Alya Abbott\n\n\n**Improve type safety of node tests**. Rework Zulip’s[automated node tests](https://zulip.readthedocs.io/testing/testing-with-node.html)to use objects that consistently have the correct type. Currently, many tests use fake message, user, or channel objects with only a handful of fields relevant to the test. We’ve been working towards`web/tests/lib/example_*`\n\n. A good starter project would be to try to convert a small test module that currently does not use the`make_user`\n\ntype functions to do so. The[main TypeScript migration thread](https://chat.zulip.org/#narrow/channel/6-frontend/topic/typescript.20migration/with/2085240)is useful background reading, and[#frontend](https://chat.zulip.org/#narrow/channel/6-frontend)channel is a good place to start new topics while working on this project. 175 or 350 hours; medium difficulty.**Skills required**: TypeScript fluency, and the discipline to write easily reviewed pull requests that often will include a series of changes to clean up an individual test while you’re working on it.Experts: Afeefuddin, Lalit\n\n**Replace hundreds of**. While functionally efficient,`dict[str, Any]`\n\ntypes with modern dataclasses`dataclasses`\n\nare more readable, safe against typos, and have nice support for optimizing them further using`__slots__`\n\n. A lot of Zulip server code was written before dataclasses existed, and while a lot has been converted naturally as part of other projects, we’d like to make a focused push to replace the remaining ones. This project will involve making dozens of small commits and PRs, each a clean refactor converting a single type. Use[this conversation](https://chat.zulip.org/#narrow/channel/3-backend/topic/migrating.20to.20dataclasses/near/2085283)for discussion and coordination.**Skills required**. Solid understanding of statically typed Python, and the discipline to learn to write refactoring commits that are easy to integrate, following our standard guidelines, because they convincingly don’t change any product behavior while improving type-safety.Experts: Tim Abbott, Anders Kaseorg\n\n**Optimize performance and scalability**, either for the web frontend or the server. Zulip is already one of the faster web apps out there, but we have a number of ideas for how to make it substantially faster yet. This is likely a particularly challenging project to do well, since there are a lot of subtle interactions to understand. 175 or 350 hours; difficult.**Skill recommended**: Strong debugging, communication, and code reading skills are most important here. JavaScript experience; some Python/Django experience, some skill with CSS, ideally experience using the Chrome Performance profiling tools (but you can pick this up as you go) can be useful depending on what profiling shows. Our[backend scalability design doc](https://zulip.readthedocs.io/subsystems/performance.html)and the[performance label](https://github.com/zulip/zulip/labels/area%3A%20performance)may be helpful reading for the backend part of this.Experts: Tim Abbott\n\n\nFill in gaps, fix bugs, and improve the framework for Zulip’s\n\n**library of native integrations**. We have about 120 native integrations, but there are a number of others we would like to add. Also, several extensions to the framework that would dramatically improve the user experience of using integrations, e.g., being able to do callbacks to third-party services like Stripe to display more user-friendly notifications. The[the integrations label on GitHub](https://github.com/zulip/zulip/labels/area%3A%20integrations)lists some of the priorities here (many of which are great preparatory projects). 175 or 350 hours; medium difficulty with various possible difficult extensions.**Skills required**: Strong Python experience, will to install and do careful manual testing of third-party products. Fluent English, usability sense and/or technical writing skills are all pluses.Experts: Niloth, Lauryn Menard\n\n**Make Zulip integrations easier for nontechnical users to set up**. This includes adding a backend permissions system for managing bot permissions (and implementing the enforcement logic), adding an OAuth system for presenting those controls to users, as well as making the`/integrations`\n\npage UI have buttons to create a bot, rather than sending users to the administration page. 175 or 350 hours; easy to difficult depending on scope.**Skills recommended**: Strong Python/Django; JavaScript, CSS, and design sense helpful. Understanding of implementing OAuth providers, e.g., having built a prototype with[the Django OAuth toolkit](https://django-oauth-toolkit.readthedocs.io/en/latest/)would be great to demonstrate as part of an application. The[Zulip integration writing guide](https://zulip.readthedocs.io/documentation/integrations.html)and[integration documentation](https://zulip.com/integrations/)are useful materials for learning about how things currently work, and[the integrations label on GitHub](https://github.com/zulip/zulip/labels/area%3A%20integrations)has a bunch of good starter issues to demonstrate your skills if you’re interested in this area.Experts: Niloth, Lauryn Menard\n\nWork on Zulip’s\n\n**development and testing infrastructure**. Zulip is a project that takes great pride in building great tools for development, but there’s always more to do to make the experience delightful. Significantly, about 10% of Zulip’s open issues are ideas for how to improve the project’s contributor experience, and are[in](https://github.com/zulip/zulip/labels/area%3A%20tooling)[these](https://github.com/zulip/zulip/labels/area%3A%20testing-coverage)[four](https://github.com/zulip/zulip/labels/area%3A%20testing-infrastructure)[labels](https://github.com/zulip/zulip/labels/area%3A%20provision)for tooling improvements.This is a somewhat unusual project, in that it would likely consist of dozens of small improvements to the overall codebase, but this sort of work has a huge impact on the experience of other Zulip developers and thus the community as a whole (project leader Tim Abbott spends more time on the development experience than any other single area). 175 or 350 hours; difficult.\n\n**Skills required**: Python, some DevOps, and a passion for checking your work carefully. A strong applicant for this will have completed several projects in these areas.Expert: Tim Abbott\n\n\n### Terminal app[](https://zulip.readthedocs.io#terminal-app)\n\nCode: [The official multi-platform terminal app, written in\nPython](https://github.com/zulip/zulip-terminal).\n\nExperts: Neil Pilgrim, Aman Agrawal\n\n**Contribute to Zulip Terminal, our terminal user interface (TUI) client**. Zulip Terminal is out in beta, but there’s still a lot to do for it to approach parity with the web app - and Zulip keeps coming out with new features too!Previous contributors have themed their projects according to a\n\n**cluster of features**or**completing unfinished projects**, or some combination, much like the first two bullets in the Full-stack project list. Project complexity and potential scope can vary substantially, since the required changes can involve touching different parts of the application stack. For example, these may be purely improving multiple elements of the UI, platform/terminal, or client-side model of the data available to a user - or multiple of these in a full-stack style.We would be happy to accept multiple strong students to work on this project. 175 or 350 hours; medium difficulty.\n\n**Skills required**: Python 3 development skills, good communication and project management skills. Reading and understanding complex code and tests, and taking the initiative to propose clean refactoring and other solutions, will be highly valuable.\n\n### Desktop app[](https://zulip.readthedocs.io#desktop-app)\n\nCode:\n[Our cross-platform desktop app, written in JavaScript on\nElectron](https://github.com/zulip/zulip-desktop).\n\nExpert: Anders Kaseorg\n\n**Contribute to our**. There’s plenty of feature/UI work to do, but focus areas for us include things to (1) improve the release process for the app, using automated testing, TypeScript, etc., and (2) polishing the UI. Browse the open issues and get involved! 175 or 350 hours. This is a difficult project because it is important user-facing code without good automated testing, so the bar for writing high quality, reviewable PRs that convince others your work is correct is high.[Electron-based desktop client application](https://github.com/zulip/zulip-desktop)**Skills required**: JavaScript, Electron; you can learn Electron as part of your application.**Prototype a next generation Zulip desktop app implemented using the Tauri Rust-based framework**. Tauri is a promising new project that we believe is likely a better technical direction for client applications than Electron for desktop apps, for security and resource consumption reasons. The goal of this project would be to build a working prototype to evaluate to what extent Tauri is a viable platform for us to migrate the Zulip desktop app to. 350 hours only; difficult.**Skills required**: Ability to learn quickly. Experience with Rust and secure software design may be helpful.\n\n### Mobile app[](https://zulip.readthedocs.io#mobile-app)\n\nCode: [Zulip’s mobile app for Android and iOS, written in\nFlutter](https://github.com/zulip/zulip-flutter)\n\nExperts: Greg Price, Chris Bobbe, Rajesh Malviya\n\nWork on the\n\n**Flutter-based Zulip client**. Zulip’s brand new Futter-based mobile app was[released last summer](https://blog.zulip.com/2025/06/17/flutter-mobile-app-launched/).This project will involve building features for the mobile app, including code for UI, data structures, and interacting with the Zulip server and the Android and/or iOS platforms. For a sense of the features we’re working on, see our\n\n[project board](https://github.com/orgs/zulip/projects/5/views/4); the tasks we’ll be working on during GSoC will come mostly from the[M9: 2026 Q2](https://github.com/zulip/zulip-flutter/milestone/14)and[MXA: Later](https://github.com/zulip/zulip-flutter/milestone/4)milestones. For some features, we[may find](https://chat.zulip.org/#narrow/channel/2-general/topic/Flutter/near/1524757)ourselves[contributing changes](https://github.com/flutter/flutter/pull/129802)upstream to the Flutter project itself. 175 or 350 hours; difficult.**Skills required**: Ability to learn quickly, check your work carefully, and communicate clearly and accurately. The code for this project will be written primarily in Dart atop Flutter; previous experience may be helpful, but you can learn both during the contributions leading up to your application. Previous experience with Android or iOS may also be helpful but is not necessary."
  },
  {
    "name": "Gambit: The package for computation in game theory",
    "slug": "gambit-the-package-for-computation-in-game-theory",
    "tagline": "The package for computation in game theory",
    "description": "Gambit is a set of software tools for doing computation on finite, noncooperative games in extensive or strategy form and a set of file formats for storing and communicating games to external tools.\n\nThe Gambit Project was founded in the mid-1980s at the California Institute of Technology and to this day is actively developed by a community of contributors, with core development led by The Alan Turing Institute as part of its project: Automated analysis of strategic interactions.",
    "ideas_url": "https://www.gambit-project.org/gsoc_2026/",
    "website_url": "https://www.gambit-project.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "c++",
      "wxwidgets",
      "visualization"
    ],
    "topic_tags": [
      "algorithms",
      "game theory",
      "mathematical optimizaton"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/gambit-the-package-for-computation-in-game-theory",
    "ideas_content": "The Gambit project is sumbitting projects as an organization for [Google Summer of Code 2026](https://summerofcode.withgoogle.com/).\nProspective contributors interested in working with the Gambit team should read the “Contributor Guidance” and “Project Ideas” sections below.\n\nGoogle Summer of Code is a global, online program focused on bringing new contributors into open source software development. GSoC Contributors work with an open source organization on a 12+ week programming project under the guidance of mentors.\n\n\nPlease provide a CV and short cover letter. On your CV, include any relevant domain experience in game theory, and technical skills and experience in software engineering. We recommend to read through the Project Ideas below before submitting an application.\n\nIn your cover letter please include answers to the following questions:\n\n- What interests you most about the Gambit project?\n- Which specific project idea(s) are you most interested in and why? Note: While we do not rule out contributors proposing their own ideas, projects need to align with Gambit’s overall goals and must be feasible given the time available and your skills. Please cover how these aspects are met if you propose your own idea.\n- Please provide us with details of the times of day and days of the week you intend to work on the project, to help us in scheduling regular catch ups.\n- Is there anything that you’ll be studying or working on whilst working alongside us?\n\nProspective contributors should read through the project ideas listed below before submitting an application, following the Contributor Guidance above. Select a project based on your research interests and the technical experience you have, or would like to develop.\n\nFor each project we have listed at least two possible mentors, with the first mentioned mentor like\nto be the primary one and the other one able to act as a secondary additional mentor.\nOur core team of mentors for 2026 are: [Ted Turocy](mailto:ted.turocy@gmail.com), [Rahul Savani](mailto:rahul.savani@gmail.com),\nand [Ed Chalstrey](mailto:echalstrey@turing.ac.uk).\nBernhard von Stengel can act as an additional mentor for ideas 3 and 6; Bernhard authored the\n`draw_tree`\n\nand `lemke`\n\npackages that underpin these two projects, respectively.\n\nThe following table summarises our ideas, and includes links to detailed descriptions below.\n\n| Idea/link | Title | Difficulty | Keywords |\n|---|---|---|---|\n|\n\nGambit’s graphical interface is the oldest part of the package. It traces its origins to a MS-DOS based tool written in C++ using the Borland Graphics Interface (BGI) in the early 1990s. It was ported to wxWindows (now wxWidgets) in the mid-1990s, in the early days of that package. Growing emphasis on scriptability and calculation at scale has meant the GUI has received less attention in recent years. Nevertheless, it remains important to the package and the community as it is the point of entry for many users, either through use in teaching or in manually inputting small games for exploratory analysis.\n\nIn this project, we will modernise the implementation of the graphical interface. This will involve a combination of several inter-related strands:\n\nThe history of development and maintenance of the GUI means it has not been modernised to use wxWidgets 3.x features, retaining a lot of history of 2.x (and in some places possibly even 1.x) style. We will update the implementation to use modern wxWidgets and C++17 idioms.\n\nThe interaction design of the canvas used to display game trees, and the tables used to display games in normal form, is less than ideal, with features like drag-and-drop, scrolling, and so forth being sometimes unreliable. These are due in part to legacy, in some cases dating back to the BGI implementation. We will clean up the dated parts of the interface to an application that gives a more modern appearance.\n\nWhen the GUI was invented it was not possible to do meaningful analysis of games much larger than could be drawn by hand. Today Gambit supports the analysis of huge (by comparison) games. We will improve the scalability of the GUI to use the concepts we have developed for working with large games, including the ability to load and work with “standard” games from the extensive catalog of examples and benchmarks we have developed.\n\n\nThe key expected outcome of this project is a modernised version of the Gambit GUI.\n\nExperience with C++ is essential; experience with wxWidgets is desirable but not essential.\n\nWe consider this a 350 hours project, especially if a student fully takes forward all 3 inter-related strands mentioned in the description. There is scope for a scaled down 175 hour project, but 90 hours does not appear enough to make enough progress to make this worthwhile.\n\nMedium. Strands 1 and 2 should be relatively easy for someone with suitable C++ experience. The 3rd strand is more open-ended and challenging.\n\nWe have developed tools that leverage Large Language Models (LLMs) to translate natural language descriptions of games into formal game-theoretic models within Gambit. See, e.g.,\n\nShilong Deng, Yongzhao Wang, Rahul Savani:\n*From Natural Language to Extensive-Form Game Representations*. **AAMAS 2025**: 593-601.\n\nThe method in that paper was called GameInterpreter v1; we are actively developing newer versions. In this project, a student would develop a front end that would allow users to explore the different versions of GameInterpreter.\n\nFor a blog post describing the work above see: [https://www.turing.ac.uk/blog/introducing-gambit-tool-doing-computation-game-theory](https://www.turing.ac.uk/blog/introducing-gambit-tool-doing-computation-game-theory).\n\nA basic version of this project would provide a front end to allow users to run different translators\nand compare and contrast the outputs.\nAn extended version would also incorporate our new methods for *automatically evaluating* the\ncorrectness of translations.\n\nThe key expected outcome of this project is a browser-based front end that lets user explore our tools that translate natural language descriptions of game to formal game-theoretic models within Gambit.\n\nExperience with browser-based front-end development is essential.\n\n90 hours for the basic version; 175 hours if the extension is done too.\n\nEasy/Medium.\n\nExtensive form game trees differ from other kinds of trees in graph theory due to the presence of information sets, which make drawing such trees a unique challenge not addressed by other software packages. In Game Theory, in any game with “imperfect information”, where some players are not fully informed about the state of the world, information sets group decision nodes based on the information available to players.\n\nThe Gambit project team have developed `draw_tree`\n\n, a Python package which works in tandem with `pygambit`\n\n(Gambit’s Python implementation) to draw extensive form game trees. The package is already used in Gambit’s Python tutorial documentation, but is also intended to be used for other purposes, in particular generating publication-ready images of game trees for research papers.\n\nThe best current layout algorithm used in `draw_tree`\n\nis based on code originally developed for Gambit’s GUI software, which doesn’t nicely render all the examples in Gambit’s catalog of games, especially large ones with many information sets. The aim of the GSoC project would be to develop a new layout algorithm that can sensibly draw games of various sizes and complexity, including many information sets.\n\nThis project would suit someone who has a particular interest in visualisation challenges. For reference, check out the [“Stripped-down poker”](https://gambitproject.readthedocs.io/en/stable/tutorials/03_stripped_down_poker.html) tutorial from the `pygambit`\n\ndocumentation, which demonstrates how `pygambit`\n\nis used to construct, and `draw_tree`\n\nis used to visualise, a small extensive form game, including an explanation of the information sets present in the game.\n\nThe key expected outcome of this project is an implemented and tested new visualiztion algorithm for `draw_tree`\n\n.\n\nExperience with Python is essential; experience with “graph drawing” algorithms is desirable but not essential. Keen interest in visualization and aesthetics is essential.\n\n[Ed Chalstrey](mailto:echalstrey@turing.ac.uk); [Ted Turocy](mailto:ted.turocy@gmail.com). Bernhard von Stengel, who designed and authored the original `draw_tree`\n\nimplementation can act as an additional supporting mentor.\n\n350 hours.\n\nHard. Developing a suitable layout algorithm that works across a wide range of games and then implementing it and testing constitutes a significant project that we expect to take up a full 350-hour project and to be challenging.\n\nSageMath is a prominent open source mathematical software system. SageMath has some existing support for Game Theory, including some interoperability with Gambit version 15. There is a desire on both the Gambit and SageMath sides to improve interoperability and to get SageMath working fully with Gambit version 16.5 and later – see the following PR: [https://github.com/sagemath/sage/pull/37809](https://github.com/sagemath/sage/pull/37809). In this project, a student would work to update that PR with a view to getting it merged by SageMath. In addition, a student could develop tutorials to demonstrate existing and new interoperability between Gambit and SageMath (see the following issue from Gambit’s repo: [#627](https://github.com/gambitproject/gambit/issues/627).\n\nThe key expected outcome of this project is a merged SageMath pull request that would see the latest versions of Gambit integragted into SageMath. Ideally the integration will also be demonstrated with tutorials and docs.\n\nExperience with Python is essential; experience with SageMath is desirable but not essential.\n\n90 or 175 hours. While it might be possible in 90 hours to implement the basic SageMath integration needed to get a PR merged, we would have a strong preference for a student to also produce rich materials (such as tutorials and examples) that show off the new integration, for which a 175 hour project seems more reasonable.\n\nEasy.\n\nMany mathematical problems that arise in game theory can be expressed in standard formulations. For example, there are many problems which can be expressed as linear programs, or the solutions to a system of polynomial equations and inequalities. Gambit has routines for solving these problems; for example, Gambit has an internal LP solver, in part because it was not straightforward to call or link with external packages circa 1994! In the modern scientific computing ecosystem, there are packages specialised to classes of mathematical programming or optimisation problems which will be far more performant.\n\nGambit currently has some very limited support for interfacing with some selected external tools via formulating the relevant problem in the file format required by that tool, running the tool, and then mapping the output back into game-theoretic objects. This support is ad-hoc, and limited to certain tools - for example, at the moment Gambit does not have any support to use external LP solvers.\n\nIn this project, we will develop a better framework for this process of generating the problem instance and mapping the result back into Gambit objects, that will be more extensible to different project types and different external solvers. In particular, as an important use case, we will develop the formulation of the linear programs that arise in several different places in game theory, and provide interfaces to different user-selectable LP solvers.\n\nWe are already aware from ad-hoc testing that in many cases the use of external solvers leads to huge performance gains, so success on this project would lead to a substantial increase in the size of game which is feasible to analyse.\n\nThe expected outcome of this project is an improved framework for working with external solvers in Gambit. At a minimum requirement, the existing external solvers (e.g. lrc and PHCpack) should use the new framework. As a stretch goal, an extended project could see several new external solvers integrated with Gambit via the new framework.\n\nExperience with Python is essential; experience with mathematical optimization/programming is highly desirable.\n\nThe core outcome of an improved framework for dealing with solvers could conceivably be done in 90 hours. Integration of new external solvers within the new framework could take the project to 175 hours, or even 350 depending on the number and complexity of the new external solvers.\n\nMedium/Hard.\n\nLemke’s algorithm is an important method in mathematical optimization for solving “Linear Complementarity Problems” (LCPs). Two player games, either in extensive or strategic form, the two primary game formats in Gambit, can be cast as LCPs solved using Lemke’s algorithm and variants of it. While Gambit has an in-built implementation of Lemke’s algorithm in C++, we would like to integrate a python implementation of Lemke’s algorithm by Benrhard von Stengel.\n\nThe project would have two main parts:\n\nImprove the “lemke” package, see\n\n[https://github.com/gambitproject/lemke](https://github.com/gambitproject/lemke), and release it as a standalone LCP solver package. That package should support both standalone tools and be a callable library, for example with work needed on argument parsing (e.g. using the “click” package). There is also scope for also improving the code to be more pythonic. In addition, a test suite should be written for the package.Integrate the new “lemke” package with core Gambit (\n\n[https://github.com/gambitproject/gambit/)](https://github.com/gambitproject/gambit/)), as an optional dependency, and alternative to the in-built Lemke solver.\n\nThe key expected outcomes of this project are:\n\n- A modernised standalone “lemke” package;\n- Integration of the modernised package with Gambit.\n\nExperience with Python is essential; relevant background in complementary pivoting, or at least mathematical programming methods like the Simplex method ([https://en.wikipedia.org/wiki/Simplex_algorithm](https://en.wikipedia.org/wiki/Simplex_algorithm)) are highly desirable.\n\n[Rahul Savani](mailto:rahul.savani@gmail.com); [Ted Turocy](mailto:ted.turocy@gmail.com); the author of the Lemke package ([https://github.com/gambitproject/lemke)](https://github.com/gambitproject/lemke)), Bernhard von Stengel is also available to act as an part-time mentor on this project (in addition to having a primary and secondary mentor from the core Gambit team).\n\n175 to 350 hours.\n\nMedium/Hard.\n\nThere are several methods for computing Nash equilibrium which are based on numerical continuation, i.e. following a smooth (differentiable) path defined by a system of equations. Gambit has implementations of a few of these methods, but there are a number of others which have been published which Gambit does not yet include.\n\nTwo examples which are currently in Gambit’s issue list are:\n\n*A differentiable homotopy to compute Nash equilibria of n-person games*. Herings, P. & Peeters, R. Econ Theory (2001) 18: 159. doi:10.1007/PL00004129 ([http://link.springer.com/article/10.1007%2FPL00004129](http://link.springer.com/article/10.1007%2FPL00004129) (See Gambit issue [https://github.com/gambitproject/gambit/issues/193](https://github.com/gambitproject/gambit/issues/193))\n\n*A variant of Harsanyi’s tracing procedures to select a perfect equilibrium in normal form games*. Cao, Y. and Dang, C. (2022) 134: 127-150. [https://www.sciencedirect.com/science/article/abs/pii/S0899825622000719](https://www.sciencedirect.com/science/article/abs/pii/S0899825622000719) (See Gambit issue [https://github.com/gambitproject/gambit/issues/304](https://github.com/gambitproject/gambit/issues/304))\n\nWhile ultimately we would like to have C++ implementations of these methods, it would also be useful to create Python-based prototypes (using numpy for the numerical heavy lifting), which would aid in the production of test and benchmarking suites for these methods.\n\n(There are many other methods for computing Nash equilibria and other solution concepts; we are interested in proposals to implement any of these within Gambit.)\n\nThe expected outcome of this project is implementations of one or more new equilibrium computiation methods, with these implementaitons integrated into Gambit.\n\nAs mentioned the implementations can be in either Python or C++, so experience in one or both of those is essential.\n\nExperience with the background in mathemetical optimization/programming behind equilibrium computation algorithms is highly desirable.\n\n\nAll three sizes of project are possible with this idea, depending on how many and how complex the implemented algorithms are.\n\nMedium/Hard.\n\nWhile some algorithms themselves can be quite involved, there are also potentially easier algorithms a student might choose to implement. Also, this project idea is only minimally constrained by the existing Gambit code base, and thus the challenge is really on picking, understanding, and then implementing an equilibrium computation method or methods, which can give rise to easy or hard projects, depending on the methods chosen.\n\nOn this page"
  },
  {
    "name": "Alaska",
    "slug": "alaska",
    "tagline": "Many Traditions, One Alaska",
    "description": "Alaska Project Ideas are mentored by the researchers and collaborators of the University of Alaska and supported by other open-source entities in Alaska, such as Alaska Dev Alliance.\n\nWe aim to represent the open-source ecosystem of the 49th state, Alaska. Anchorage, the largest city in Alaska, has a vibrant open-source community. Through this GSoC initiative, industrial experts who are part of the Alaska Developer Alliance and faculty and researchers from the University of Alaska Anchorage (UAA) and the University of Alaska Fairbanks (UAF) join hands to provide a perfect mentoring experience for interested contributors globally. We offer a glimpse of this northern state and its tech landscape to the Lower 48 and the outside world through this open-source remote summer coding program organized and funded by Google. Our projects focus on healthcare, climate science, polar science, and other research fields critical to the Circumpolar North and the rest of the world.",
    "ideas_url": "https://github.com/uaanchorage/GSoC",
    "website_url": "https://www.uaa.alaska.edu/research",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "mysql",
      "java",
      "matlab",
      "dicom"
    ],
    "topic_tags": [
      "deep learning",
      "neuroscience",
      "radiology",
      "heathcare",
      "Polar Science"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/alaska",
    "ideas_content": "[ 2026 will be our third time participating in the Google Summer of Code (GSoC) as a mentoring organization, and we are already excited about the potential and opportunities. We had four enthusiastic contributors as a ](https://raw.githubusercontent.com/uaanchorage/GSoC/main/figures/Alaska.png)[first-time organization in 2024](https://github.com/uaanchorage/GSoC/tree/GSoC-2024) and we doubled in 2025 with our excellent 8 contributors. We consist of stable open-source projects in production use in research and relatively young projects. We also have mentors who have participated in several GSoC instances over the past several years and have been active in open-source software development for decades.\n\nWe represent the 49th state, Alaska. Anchorage, the largest city in Alaska, has a vibrant open-source community. Through this GSoC initiative, researchers from the [University of Alaska Anchorage (UAA)](https://www.uaa.alaska.edu/) and [University of Alaska Fairbanks (UAF)](https://www.uaf.edu/) join hands with the Alaska-based software experts that are part of open-source entities such as [Healthy](https://github.com/healthyinc/) and [Alaska Developer Alliance](https://www.akdevalliance.com/) to provide a perfect mentoring experience for interested contributors globally. We provide a glimpse of this northern state and its tech landscape to the Lower 48 and the outside world through this open-source remote summer coding program organized and funded by Google. Our projects focus on healthcare, climate science, polar science, and other research fields critical to the Circumpolar North and the rest of the world.\n\n**Please first refer to the contributor guidelines to get started!** It puts you on the right track with application details and a standard template.\n\n**Please also refer to our**A\n\n[Acceptable and Ethical AI Use Policy](https://github.com/uaanchorage/GSoC/blob/main/Acceptable-and-Ethical-AI-Use-Policy.md)to make sure your use of AI/ML/LLM tools such as ChatGPT falls under the acceptable use.[rubrics](https://github.com/uaanchorage/GSoC/blob/main/Rubrics.md)is provided as reference material on being a competitive applicant for Alaska in GSoC.\n\n**Please avoid sending individual private emails (or social media messages!!) to mentors.** However, the mentors' emails with each project idea are listed below in case the mentor initiates or recommends an email communication later. If you are proposing your own idea, make sure that idea is relevant to Alaska and has a potential mentor from the list of mentors below.\n\nMany of the ideas proposed here have a research component. Contributors who work on these ideas have the potential to author a research paper (as the first author, working with the researchers from the University of Alaska) or become co-authors in our ongoing research papers. We strongly encourage those interested in higher studies or research careers to apply for their GSoC with us.\n\n**[1] Automated coastline extraction for erosion modeling in Alaska.**\n\n**Mentors:** Frank Witmer (fwitmer -at- alaska.edu) and Ritika Kumari (rkjane333 -at- gmail.com)\n\n**Overview:** The rapidly warming Arctic is leading to increased rates of coastal erosion, placing hundreds of Alaska communities at the frontline of climate change. Understanding current rates of coastline change and accurately forecasting future changes is critical for communities to mitigate and adapt to these changes. Current modeling approaches typically use a simple linear model based solely on historical coastline positions to measure rates of change and extrapolate them into the future. In doing so, these models fail to capture the dynamic effects associated with decreasing sea ice, increasing annual wave energy, and increasing temperatures. To improve the quality of these coastal models, we need to increase the quantity of digitized coastlines, but manual photointerpretation is slow and laborious.\n\n**Current Status:** An initial model and pipeline have been developed to automatically extract coastlines from [PlanetLabs imagery](https://www.planet.com/). An auto-download script is available to retrieve PlanetLabs imagery (3-5m spatial resolution) by specifying any timeframe, cloud coverage percentage, and geometry. Additionally, [NDWI](https://en.wikipedia.org/wiki/Normalized_difference_water_index) with a majority sliding window has been introduced, allowing a specific threshold for each window to improve water detection accuracy. The [DeepWaterMap](https://github.com/isikdogan/deepwatermap) algorithm was originally trained with the [Global Surface Water (GSW)](https://developers.google.com/earth-engine/datasets/catalog/JRC_GSW1_4_GlobalSurfaceWater) dataset at 30 m resolution from [Landsat](https://landsat.gsfc.nasa.gov/) imagery, but the model did not not work well applied to PlanetLabs imagery. We are working to re-train the model using PlanetLabs imagery automatically labeled using the NDWI thresholding method. This project extends and expands on the progress made in 2024 and 2025.\n\n*Potential areas of improvement:*\n\n- Improve training data by incorporating the PlanetLabs Usable Data Mask (UDM) data.\n- Data Expansion (Deering 2017–2019 and Beyond): Currently using data from 2017 to 2019 for Deering; we plan to include more recent data to extend the time series.\n- Improved Cliff Area Segmentation: Enhance segmentation performance specifically in steep or cliff-like coastal areas.\n- Handling Challenging Conditions: Improve segmentation in regions with water shadows, buildings, satellite artifacts, and other data quality issues.\n- SWIR and Elevation Data Integration: Investigate combining short-wave infrared (SWIR) data and elevation data (e.g., DEMs) to further refine segmentation accuracy.\n\n**Expected Outcomes:** A finished model with high accuracy that automatically extracts a vectorized coastline representation from PlanetLabs satellite imagery. Then, the model can be applied to large amounts of imagery to model coastline changes over time.\n\n**Required Skills:** Python\n\n**Code Challenge:** Experience with multi-band satellite imagery, geospatial data processing, and machine learning.\n\n**Source Code:** [https://github.com/fwitmer/CoastlineExtraction](https://github.com/fwitmer/CoastlineExtraction)\n\n**Discussion Forum:** [https://github.com/fwitmer/CoastlineExtraction/discussions](https://github.com/fwitmer/CoastlineExtraction/discussions)\n\n**Effort:** 350 Hours\n\n**Difficulty Level:** Intermediate\n\n**[2] BHV: Behavioral Health Vault.**\n\n**Mentors:** Mohamed Abdullah F (abdullahfakrudeen2020 -at- gmail.com) and Pradeeban Kathiravelu (pkathiravelu -at- alaska.edu)\n\n**Overview:** The goal of this project is to provide a digitization approach to record the journey of recovery of people with serious mental illnesses, substance-use disorders, and other social determinants affecting well-being. BHV (Behavioral Health Vault) aims to complement traditional Electronic Health Records (EHRs) by storing patient provided images such as photographs, sketches, and scanned drawings along with associated textual narratives, which may be provided directly by patients or recorded by social workers during interviews. BHV is a minimal, Python-based application that enables healthcare networks to store and retrieve patient-provided images. BHV aims to provide them access to upload, view, and edit their own images and narratives. It will provide admin-level access to system administrators, allowing them to view the entire ecosystem, upload images on behalf of users, along with the narrative, edit images on behalf of users, and delete images or narrations on behalf of users or as a moderation action. Importantly, BHV will also include an optional research module integrating a fuzzy logic–based color-emotion association model (inspired by [Color-Emotion Associations in Art: Fuzzy Approach](https://ieeexplore.ieee.org/document/10464290)). This enables researchers to explore correlations between color palettes in user-submitted images and self-reported emotions supporting studies on emotional recovery, addiction patterns, and social determinants of mental health. This user-driven data (images + emotional self-reports) helps researchers study how environmental factors, social contexts, and personal narratives affect mental health. The system is built for participatory behavioral health research, emphasizing accessibility, transparency, and ethical data handling.\n\n**Current Status:** Currently, we have [Beehive](https://github.com/kathiravelulab/beehive) project. However, it has a complex architecture, which has made it a difficult installation for community health clinics that lack the technical expertise. The goal of BHV is to provide the same functionality while minimizing the complex tech stack of Beehive. The eventual goal of BHV is to replace Beehive and be the \"Beehive-2.0.\"\n\n**Expected Outcomes:** The Behavioral Health Vault (BHV) will deliver a secure yet minimal system designed for ease of use and installation in healthcare and research environments. The signup and login process will be intentionally simple, allowing users to register using a basic email and password combination or Using [Google OAuth](https://support.google.com/googleapi/answer/6158849?hl=en) would be nice, without unnecessary authentication complexity. The platform will prioritize a lightweight, modular architecture that avoids bloat, ensuring that community clinics and behavioral health researchers can deploy the system effortlessly, even with limited technical expertise. To achieve this, BHV will be installable and runnable from a single command, without the need to start separate services for the frontend, backend, and database. Images will be stored efficiently within the local file system, accompanied by a database index that enables fast search and retrieval of user submissions and narratives. The design will follow a privacy by default approach, incorporating appropriate security measures for sensitive data. Documentation will be concise and easy to follow, supported by the system’s inherently minimal design. Additionally, the platform will integrate an optional fuzzy color emotion analysis module to assist researchers in examining user provided images for emotional patterns, thereby expanding the application’s value beyond data storage toward behavioral health research and recovery studies.\n\nBHV will support the option to create a private GitHub repository for each user, where their uploaded images and related metadata will be securely stored in the cloud. Each repository will contain an `img/`\n\ndirectory for images and a global JSON file maintaining essential metadata such as title, description, and image path. Administrators will be added programmatically as collaborators, ensuring they can view, edit, and moderate submissions, while other users repositories remain private and isolated. In addition to GitHub storage, BHV will continue to support a local storage mode as a secondary option for installations preferring offline or self-hosted operation. To maintain data integrity and performance, each uploaded image will be restricted by a configurable file size limit.\n\nThose Private repo will create under the users account.\n\nWe encourage that BHV will be in Minimal Design Structure like [Google Arts and Culture](https://artsandculture.google.com/category/art-movement) and contributors can come up with your minimal design too.\n\n**Required Skills:** Python, a datastore such as MySQL, Postgresql, SQLite, or MongoDB, and a minimal front-end.\n\n**Code Challenge:** Prior experience with Python and database systems through established project experience, ideally through previous GitHub repositories.\n\n**Source Code:** [https://github.com/KathiraveluLab/BHV](https://github.com/KathiraveluLab/BHV) (New Project).\n\n**Discussion Forum:** [https://github.com/KathiraveluLab/BHV/discussions](https://github.com/KathiraveluLab/BHV/discussions)\n\n**Effort:** 350 Hours\n\n**Difficulty Level:** Intermediate\n\n**[3] Alaska Wildfire Prediction Using Satellite Imagery.**\n\n**Mentors:** Yali Wang (ywang35 -at- alaska.edu) and Arghya Kusum Das (akdas -at- alaska.edu)\n\n**Overview:** Given Alaska’s unique wildfire patterns, where large-scale fires occur annually in boreal forests, tundra, and remote wilderness, predicting fire-prone areas can help mitigate disasters and optimize resource allocation. The presence of vegetation (fuel) is necessary for a fire, but the determining factors are weather conditions (humidity, wind speed, temperature) and an ignition source (lightning, human activity, etc.).\nThis project aims to develop a hybrid deep learning model to predict wildfire risk in Alaska by integrating optical, thermal, and synthetic aperture radar (SAR) satellite imagery with ground-based weather data.\nTraditional wildfire prediction relies on weather data, historical fire records, and human observations, which can be delayed or inaccurate in remote areas like Alaska. In contrast, satellite imagery provides real-time, high-resolution insights into vegetation health, thermal anomalies, burn severity mapping, soil moisture, fuel dryness, and even cloud-penetrating fire detection.\n\nSatellite choices:\n\n| Satellite | Resolution | Revisit Frequency | Why Use It? |\n|---|---|---|---|\n| Landsat 8 & 9 (NASA/USGS) | 30m (multispectral), 100m (thermal) | 16 days | Tracks pre/post-fire vegetation and burn severity with great detail. |\n| Sentinel-2 (ESA) | 10m (RGB, NIR), 20m (SWIR) | 5 days | High-resolution images for fire risk classification and early warnings. |\n| MODIS (Terra/Aqua, NASA) | 250m (fire detection), 1km (thermal) | Daily | Provides historical fire perimeters and active fire locations. |\n| VIIRS (Suomi NPP & NOAA-20) | 375m (fire detection), 750m (thermal) | Daily | Real-time fire monitoring, capturing active hotspots. |\n| Sentinel-1 (ESA) | 5m - 20m | 6-12 days | SAR imaging for vegetation moisture & burned area mapping. |\n| ALOS-2 (JAXA) | 10m - 100m | 14 days | L-band SAR for detecting dry fuel and terrain changes. |\n\nAdditional ground data sources:\n\n1). ERA5 Climate Reanalysis (ECMWF): Provides historical & real-time temperature, wind, and humidity data.\n\n2). NOAA NWS Weather Data: Near real-time humidity, wind, and temperature.\n\n3). Alaska Fire Service (AFS) Wildfire Data: Historical ignition source data (lightning, human activity).\n\n**Current Status:** This project is currently in the research stage.\n\n**Expected Outcomes:**\nThis project aims to develop a deep-learning model that predicts wildfire risk in Alaska using a combination of satellite and ground-based weather data. The expected outcome of this project would involve both the dataset preprocessing pipeline and the performance of the developed model. Especially, the dataset preprocessing would include how to process the pre-fire and post-fire images efficiently and integrate the ground-based data with satellite imagery. Expected outcomes include:\n\nMinimum viable product (MVP):\n\nFire risk classification: Given pre-fire satellite images, the model predicts the probability of a fire occurring within a defined time frame like 1 month, 3 months, or 6 months. The classifications should be \"High Fire Risk,\" \"Moderate Risk,\" or \"No Risk.\"\n\n- Data pipeline development:\n\nPreprocessing satellite images: Band selection, geospatial cropping, cloud removal (For this step, we are mostly interested in analyzing [Sentinel-2 data](https://dataspace.copernicus.eu/explore-data/data-collections/sentinel-data/sentinel-2));\n\nSynthetic Aperture Radar (SAR) analysis: Extracting fuel moisture & terrain features (For this step, we are mostly interested in extracting information like vegetation density and soil moisture from [Sentinel-1 SAR data](https://dataspace.copernicus.eu/explore-data/data-collections/sentinel-data/sentinel-1));\n\nTime-series weather data integration: Incorporating temperature, wind, and humidity. We have access to past decades of weather data for almost the past 30 years for multiple different places in Alaska.\n\n- Model training and prediction:\n\nA hybrid model such as CNN-LSTM that analyzes satellite data and time-series weather trends (CNN-LSTM is just an example. We are open to multiple different types of analysis methodology);\n\nA web-based GIS dashboard to visualize fire-prone regions in Alaska;\n\nA report on model performance and fire risk metrics.\n\n**Required Skills:** Python. Experience with deep learning and machine learning.\n\n**Code Challenge:** Experience with multi-band satellite imagery, geospatial data processing (like ArcGIS Pro), and remote sensing.\n\n**Source Code:** [https://github.com/YaliWang2019/AK-Satellite-Imagery-Wildfire-Prediction](https://github.com/YaliWang2019/AK-Satellite-Imagery-Wildfire-Prediction) (New Project)\n\n**Discussion Forum:** [https://github.com/YaliWang2019/AK-Satellite-Imagery-Wildfire-Prediction/discussions](https://github.com/YaliWang2019/AK-Satellite-Imagery-Wildfire-Prediction/discussions)\n\n**Effort:** 350 Hours\n\n**Difficulty Level:** Intermediate/Hard\n\n**[4] Understanding proximity in locations and emotions through digitized memories.**\n\n**Mentors:** Jihye Kwon (jkwon2 -at- alaska.edu) and Pradeeban Kathiravelu (pkathiravelu -at- alaska.edu).\n\n**Overview:** The project [DREAMS](https://github.com/KathiraveluLab/DREAMS) looks into how emotions evolve with time and uses the photos as a contributing factor towards the journey of recovery in marginalized folks, such as those battling drug use, alcohol use, or those with serious mental illnesses. This project extends our scope further, to understand how even seemingly unrelated places could be connected. While proximity is usually considered based on geo-coordinates, there can be other factors in determining how two locations are proximate in their digital representation. Taking two photos at the same spot will result in duplicate location or, more likely (due to minor changes in positioning), a near-duplicate location. However, sometimes, these are not the exact locations - rather, similar ones. Perhaps, 1) two different churches, two different police stations, ... 2) same language (two different Portuguese restaurants, ...) 3) same/similar cultures... This project aims to formalize such proximity in DREAMS and how they contribute to the evolving emotions.\n\n**Current Status:** The current DREAMS prototype does not take such elaborate measures of proximity. However, proximity (not just geographically, but based on the multiple dimensions that compose the data) needs to be formalized in DREAMS to understand the emotions attached to a particular place (e.g., this particular church) vs. a specific class of places (e.g., any churches).\n\n**Expected Outcomes:** Complexities of time and ordering in the use of behavioral patterns and narratives, formalizing the representation of proximity in location beyond the geo-coordinates. This project contains a research portion. Several studies have been done on the topic. We should use the existing outcomes to expand our understanding further, while also implementing our findings.\n\n**Required Skills:** Python, digital image processing, and data mining.\n\n**Code Challenge:** Prior digital image processing or data mining experience is beneficial. Establish the experience through prior projects or related code samples.\n\n**Source Code:** [https://github.com/KathiraveluLab/DREAMS](https://github.com/KathiraveluLab/DREAMS)\n\n**Discussion Forum**: [https://github.com/KathiraveluLab/DREAMS/discussions](https://github.com/KathiraveluLab/DREAMS/discussions)\n\n**Effort:** 350 Hours\n\n**Difficulty Level:** Intermediate\n\n**[5] Building a Decentralized Application (dApp) for Data Analysis in Bio-Block.**\n\n**Mentors:** Chalinda Weerasinghe (chalindaweerasinghe -at- gmail.com), Karthik Sathish (karthiksathishjeemain -at- gmail.com), Albin Bajramovic (albin -at- cptolabs.com), and Erik Zvaigzne (erik.zvaigzne -at- gmail.com)\n\n**Overview:** The open-source Bio-Block data and payment portal could theoretically admit health and medical information, subject to proper compliance and regulatory protocols. Can we build a dApp that takes this information and performs various levels of analytics: graphical, descriptive, inferential and possibly predictive? What blockchain architectures would permit such a dApp to reside on Bio-Block, and how can we make such a dApp scalable and open? Would the dApp connect through an API, and if so, what would that look like? This project explores and constructs a dApp that meets at least minimal architectural requirements, such as being decentralized, scalable and open, and implements at least two levels of analysis.\n\n**Current Status:**. Bio-Block Healthy App was built as part of the GSoC 2025. This project expands on it to build a decentralized app for data analysis.\n\n**Expected Outcomes:** A dApp that provides data analysis features to Bio-Block.\n\n**Required Skills:** Python is proposed as the programming language. However, students can also propose their preferred alternative programming language and frameworks. Prior experience developing on Ethereum is a plus.\n\n**Code Challenge:** Prior experience in Python (or the proposed alternative language) and, preferably, Ethereum blockchain through established coding examples. Students are expected to establish their experience with Blockchain technologies in architecting and programming them through previous projects - ideally through their respective GitHub repository (or similar code repositories).\n\n**Source Code:** [https://github.com/healthyinc/bio-block](https://github.com/healthyinc/bio-block)\n\n**Discussion Forum:** [https://github.com/healthyinc/bio-block/discussions](https://github.com/healthyinc/bio-block/discussions)\n\n**Effort:** 350 hours\n\n**Difficulty Level:** Intermediate\n\n**[6] Anonymization of Personal Health Information (PHI) Submitted to Bio-Block and Improving Data Retrieval.**\n\n**Mentors:** Karthik Sathish (karthiksathishjeemain -at- gmail.com), Ashutosh Ingole (ashingole -at- gmail.com), and Forrester Kane Manis (Forrester -at- headword.co).\n\n**Overview:** This is a two-part project. Bio-Block is meant to admit all types of bio-medical information. Some of these data types were explored and tackled in GSoC 2025. The personal health and identification information must be stripped from this data completely so that anonymization is achieved. The first part of the project explores algorithms and processes to completely anonymize the data while maintaining the ability to sort, query and analyze. After anonymization is achieved, there needs to be sufficient ability to query the data so that potential data retrieval is easy and meaningful. The second part of the project entails creating retrieval algorithms and processes to achieve this objective.\n\n**Current Status:** Bio-Block Healthy App was built as part of the GSoC 2025. This project expands on it to build the PHI anonymization pipelines.\n\n**Expected Outcomes:** Data anonymization pipelines built and integrated into bio-block, to remove PHI from data uploads prior to storing those in bio-block.\n\n**Required Skills:** Python is proposed as the programming language. However, students can also propose their preferred alternative programming language and frameworks. Prior experience developing on Ethereum is a plus.\n\n**Code Challenge:** Prior experience in Python (or the proposed alternative language) and, preferably, Ethereum blockchain through established coding examples. Students are expected to establish their experience with Blockchain technologies in architecting and programming them through previous projects - ideally through their respective GitHub repository (or similar code repositories).\n\n**Source Code:** [https://github.com/healthyinc/bio-block](https://github.com/healthyinc/bio-block)\n\n**Discussion Forum:** [https://github.com/healthyinc/bio-block/discussions](https://github.com/healthyinc/bio-block/discussions)\n\n**Effort:** 350 hours\n\n**Difficulty Level:** Intermediate\n\n**[7] DICOM Image Retrieval and Processing in MATLAB.**\n\n**Mentors:** Pradeeban Kathiravelu (pkathiravelu -at- alaska.edu) and Ananth Reddy (bananthreddy30 -at- gmail.com)\n\n**Overview:** DICOM (Digital Imaging and Communications in Medicine) is a radiographic imaging standard for how various modalities of scanners, PACS (Picture archiving and communication system), and other imaging systems communicate. As a storage protocol, it defines how images are stored in a standard way. It also functions as a messaging protocol, an extension to TCP. Many DICOM processing tools exist. They support receiving images from the scanners and PACS to a research cluster in real-time as an imaging stream or on-demand, selectively. They also provide means to anonymize the DICOM images to preserve patient privacy, export the DICOM images into a format such as PNG or JPEG, and extract the textual metadata from DICOM files to store it in a CSV file format or a database. Machine learning pipelines cannot be executed in clinical systems such as scanners and PACS. Therefore, the DICOM images and their metadata in the research clusters can be used to run machine learning pipelines.\n\nMATLAB [Medical Imaging Toolbox](https://www.mathworks.com/products/medical-imaging.html) provides comprehensive support for DICOM using the [DICOM Toolkit (DCMTK)](https://dicom.offis.de/dcmtk.php.en). The MATLAB [Image Processing Toolbox](https://www.mathworks.com/products/image-processing.html) also supports [directly processing DICOM](https://www.mathworks.com/help/images/dicom-support-in-the-image-processing-toolbox.html). Similarly, MATLAB supports [reading, processing, and writing 3-D Medical Images with Spatial Referencing](https://www.mathworks.com/help/medical-imaging/ug/read-process-and-write-3-d-medical-image-with-spatial-referencing.html). In addition, [Python programs can be integrated with MATLAB](https://www.mathworks.com/products/matlab/matlab-and-python.html), which makes it easy to port existing Python workflows into MATLAB incrementally or let them execute interoperably. The out-of-the-box support for DICOM provided by MATLAB could make our job easy in certain projects. This facilitates [processing the files from the file system](https://www.mathworks.com/help/images/dicom-support-in-the-image-processing-toolbox.html). MATLAB natively supports [finding Region-of-Interest for DICOM-RT files](https://www.mathworks.com/help/images/ref/dicomcontours.html). It also supports [deep learning on DICOM and NifTi files](https://www.mathworks.com/help/deeplearning/ug/preprocess-volumes-for-deep-learning.html).\n\n**Current Status:** This project is currently in the research stage.\n\n**Expected Outcomes:** This project aims to create a MATLAB alternative to the [Niffler](https://github.com/Emory-HITI/Niffler) framework built in Python. Niffler allows real-time and on-demand batch retrieval of DICOM images from the scanners and PACS. It also provides additional features such as metadata extraction, conversion to PNG format, and anonymization. Sample workflows, such as scanner usage computation and IVC filter detection workflows, are included in Niffler. This project is an effort towards building a similar framework, but in MATLAB, using the existing extensive DICOM features provided by MATLAB. We will use MATLAB R2025a for this project. Since this is a research project, we should study the existing projects first to avoid re-inventing the wheel. From Google Scholar, we see many processing and pipelines (ROI, deep learning, ...) on DICOM/DICOM-RT have been implemented using MATLAB. Regardless of the scientific novelty, we can get an open-source solution to help with further ML stuff using MATLAB on the DICOM files. However, we should also observe how this could be a scientific contribution and its merits beyond what is already available. We can use readily available public DICOM data sources to test our implementations, such as [the Cancer Imaging Archive (TCIA)](https://www.cancerimagingarchive.net/), thereby avoiding the handling of sensitive patient data with PHI. We propose using [Orthanc](https://www.orthanc-server.com/), with anonymized DICOM images retrieved from TCIA stored in it, in place of a PACS.\n\n**Required Skills:** MATLAB\n\n**Code Challenge:** Prior experience with MATLAB should be established through previous projects or code samples. Experience working with DICOM images will be a plus.\n\n**Source Code:** [https://github.com/KathiraveluLab/DWiM](https://github.com/KathiraveluLab/DWiM) (New Project).\n\n**Discussion Forum**: [https://github.com/KathiraveluLab/DWiM/discussions](https://github.com/KathiraveluLab/DWiM/discussions)\n\n**Effort:** 350 Hours\n\n**Difficulty Level:** Intermediate\n\n**[8] Support for Logarithmic Number Systems in Large Language Models.**\n\n**Mentors:** Mark Arnold (markgarnold -at- yahoo.com), Alex Krentz (alexkrentz2 -at- gmail.com), and Ed Chester (ed.chester -at- gmail.com)\n\n**Overview:** The Logarithmic Number System (LNS) is an alternative to built-in Floating Point (FP), which makes multiplication and division easy at the expense of more difficult addition. Using overloaded operators, xlnscpp provides an open-source C++ library for both 16- and 32-bit LNS arithmetic. Interest in fabricating LNS hardware has grown since it may reduce power consumption for applications that tolerate approximate results, such as deep learning (see [1]-[5]). Although LNS has been studied extensively for feed-forward networks, only recently [6] has LNS been considered for Large Language Models (LLMs).\n\nLLMs consist of two main computations: a) feed-forward neural networks for which LNS has been shown to be useful, and b) an operation known as attention. The training of an LLM produces weights for both of these computations, which are often quantized to reduce data storage requirements. These quantized weights are reconstructed (usually in either 16- or 32-bit FP) and operated on by vectors of tokens (usually in similar FP format).\n\nExisting LLM engines, such as the open-source [llama.cpp](https://github.com/ggerganov/llama.cpp), perform vector/matrix/tensor operations (mostly matrix multiply)\nbetween the FP tokens and the weights (in a variety of formats, not including LNS).\n\nllama.cpp uses a library called [ggml](https://github.com/ggml-org) to do the actual math. The design of ggml supports a variety of FP hardware, such as CPUs and GPUs.\n\n**Current Status:** xlnscpp is not supported by llama.cpp or ggml. Weights can be stored in a variety of built-in int or FP formats instead of LNS. Matrix operations are carried out in FP.\n\n**Expected Outcomes:** The goal of this project is to provide support for xlnscpp instead of FP in ggml (and indirectly) llama.com.\nAt a minimum, this involves modifying ggml to support a \"virtual\" LNS \"machine\" using xlnscpp to perform the actual LNS computation,\nbut which appears to the calling llama.cpp like another hardware platform, like a GPU. The storage format of the quantized weights would still be the same, but they would be converted to LNS for computations like attention on LNS-format tokens. It is not expected that the speed would be as fast as if hardware FP were used, although a design that minimizes the slowdown is desirable (for instance, converting to LNS once, and reusing LNS many times, much as data is transferred to GPU memory and reused many times there). The purpose is a proof of concept that LNS yields valid output from an LLM. The design needs to implement enough ggml features to support an actual LLM, like Deepseek.\n\n**Required Skills:** C++ and some familarity with LLMs\n\n**Code Challenge:**\n\n-\nRun the xlns16test.cpp and xlns32test.cpp examples.\n\n-\nGo through the ggml example for 32-bit FP matrix multiplication on CPU (\n\n[https://huggingface.co/blog/introduction-to-ggml](https://huggingface.co/blog/introduction-to-ggml)) which illustrates concepts like: ggml_backend (the code that does the computation on a GPU or CPU), ggml_context (a \"container\" that holds data), ggml_cgraph: (what computation the backend performs), ggml_backend_buffer: (hold the data of multiple tensors), and ggml_backend_buffer_type: (a \"memory allocator\" connected to each ggml_backend). This is quite involved because of the ggml_backend concept. Such experience will help you design a new ggml_backend for LNS (which your design proposal will describe as running on CPU using xlnscpp). -\nWrite a standalone C++ program that has a function to do 32-bit FP matrix multiply with a main program that prints the FP result. Test it with the same matrix data as the previous ggml example. (Hint: use nested for loops to compute the sum of products that form the matrix product).\n\n-\nModify this program to include xlns32.cpp (define xlns_ideal first) and perform the internal computation in LNS format. The main program and the signature of the function it calls remain the same (32-bit FP), which requires that the function convert to/from LNS before and after the matrix multiply. (Hint: if you do it properly, the overloaded xlnscpp assignment operator takes care of this automatically.) The sum of products should be computed entirely in LNS (not FP). Notice the numeric results are close to what FP produces.\n\n-\nModify the program to include xlns16.cpp instead. Notice the numeric results are slightly less accurate (the 16-bit LNS product is stored in the 32-bit FP result). This illustrates the tradeoff of using reduced precision LNS, which is what we want to experiment with in this project.\n\n\nThese code challenges provide possible insight as to how the LNS-CPU backend your design proposal will describe can \"look like\" an FP backend to llama.cpp. When data would be transferred to the backend, it is converted to LNS. When data is transfered back to llama.cpp, it is converted back to 32-bit FP. This is one idea for this project. You may incorporate improvements to this concept in your design proposal that considers the features of ggml.\n\n**References:**\n\n[1] G. Alsuhli, et al., “Number Systems for Deep Neural Network Architectures: A Survey,” [https://arxiv.org/abs/2307.05035](https://arxiv.org/abs/2307.05035), 2023.\n\n[2] M. Arnold, E. Chester, et al., “Training neural nets using only an approximate tableless LNS ALU”. 31st International Conference on Application-specific Systems, Architectures and Processors. IEEE. 2020, pp. 69–72. [https://doi.org/10.1109/ASAP49362.2020.00020](https://doi.org/10.1109/ASAP49362.2020.00020)\n\n[3] O. Kosheleva, et al., “Logarithmic Number System Is Optimal for AI Computations: Theoretical Explanation of Empirical Success”, [https://www.cs.utep.edu/vladik/2024/tr24-55.pdf](https://www.cs.utep.edu/vladik/2024/tr24-55.pdf)\n\n[4] D. Miyashita, et al., “Convolutional Neural Networks using Logarithmic Data Representation,” [https://arxiv.org/abs/1603.01025](https://arxiv.org/abs/1603.01025), Mar 2016.\n\n[5] J. Zhao et al., “LNS-Madam: Low-Precision Training in Logarithmic Number System Using Multiplicative Weight Update,” IEEE Trans. Computers, vol. 71, no. 12, pp.3179–3190, Dec. 2022, [https://doi.org/10.1109/TC.2022.3202747](https://doi.org/10.1109/TC.2022.3202747)\n\n[6] P. Haghi, C. Wu, Z. Azad, Y. Li, A. Gui, Y. Hao, A. Li, and T. T. Geng, “Bridging the Gap Between LLMs and LNS with Dynamic Data Format and Architecture Codesign ,” in 2024 57th IEEE/ACM International Symposium on Microarchitecture (MICRO). Los Alamitos, CA, USA: IEEE Computer Society, Nov. 2024, pp. 1617–1631. [https://doi.ieeecomputersociety.org/10.1109/MICRO61859.2024.00118](https://doi.ieeecomputersociety.org/10.1109/MICRO61859.2024.00118)\n\n**Source Code:** [https://github.com/xlnsresearch/xlnscpp](https://github.com/xlnsresearch/xlnscpp)\n\n**Discussion Forum:** [https://github.com/xlnsresearch/xlnscpp/discussions](https://github.com/xlnsresearch/xlnscpp/discussions)\n\n**Effort:** 350 Hours\n\n**Difficulty Level:** Hard\n\n**[9] Telehealth Effectiveness and Necessity Tracker for Alaska.**\n\n**Mentors:** Pradeeban Kathiravelu (pkathiravelu -at- alaska.edu) and David Moxley (dpmoxley -at- alaska.edu).\n\n**Overview:** This project uses public health site data and Internet performance data to find the regions with limited healthcare access (known as the healthcare deserts) but with stable Internet access. The outcome is a web application with a dashboard that can shed light on the necessity and feasibility of telehealth across Alaskan cities and villages.\n\nA compound metric should be defined to identify healthcare deserts, incorporating information such as the number of health sites in the region, the availability of specialist access, the distance to the nearest clinic for any resident, and the presence of a transportation network. Health site data may be retrieved from public sources (such as [https://healthsites.io/map](https://healthsites.io/map)), but should be supplemented with local sources for accuracy. Internet access and performance can be identified through measurement networks (such as [https://broadbandmapping.com](https://broadbandmapping.com)) and Internet Service Provider (ISP) data.\n\nA mashup of healthcare access (or the lack of it) combined with Internet access and performance should be visualized as an overlay on the map of Alaska using map platforms such as OpenStreetMap, with interactive visualizations.\n\n**Current Status:** This project is currently in the research stage.\n\n**Expected Outcomes:** A web application that is specific to highlight the telehealth feasibility and necessity in Alaska. The application should be generalizable to different locations. However, it should focus on Alaska, and as such, the map of Alaska (rather than the whole world) should load when a map-based interface is used.\n\n**Required Skills:** Python or a similar high-level language, and experience in necessary front-end frameworks.\n\n**Code Challenge:** Prior experience working with similar frameworks and projects in the language of choice.\n\n**Source Code:** [https://github.com/KathiraveluLab/TENeT](https://github.com/KathiraveluLab/TENeT) (New Project)\n\n**Discussion Forum**: [https://github.com/KathiraveluLab/TENeT/discussions/](https://github.com/KathiraveluLab/TENeT/discussions/)\n\n**Effort:** 350 Hours\n\n**Difficulty Level:** Intermediate\n\n**[10] AAA for Beehive: Authentication, Authorization, and Access Control.**\n\n**Mentors:** David Moxley (dpmoxley -at- alaska.edu) and Pradeeban Kathiravelu (pkathiravelu -at- alaska.edu)\n\n**Overview:** The goal of this project is to test and improve on the data privacy and security aspects of Beehive. Currently, we are hosting Beehive locally and it is used in a controlled environment within the organizational firewalls. However, if we open up Beehive with a public URL, data privacy aspects will play a critical role. Current Beehive implementation did not consider these data privacy and security matters sufficiently. Furthermore, the Clark APIs are likely not fully utilized, as currently they are used in authentication - but many features and functionalities are run without checking for authorization. This project aims to address these critical security and data privacy shortcomings in Beehive.\n\n**Current Status:** The Beehive project is functionally complete. However, it has severe limitations in authentication, authorization, and access control. While several measures are taken for authorization and authentication, the approaches were largely untested for various cases. Also, some of the design choices might be questionable. Rather than having an external API key provider, such as Google Cloud and Clerk, we might have used an API gateway such as Kong, Tyk, or API Umbrella, and used their authentication, authorization, and access control mechanisms. There are some security flaws, in terms of authorization and access control, as can be observed from the issue tracker.\n\n**Expected Outcomes:** The system should be secure. But the signup process should be fairly easy. Email-based signups are ok. Log-ins should be straightforward. A simple username and password should be sufficient. The system should avoid unnecessary bloat and complex installation steps, to enable easy installation in healthcare networks. Consider using a locally deployed API Gateway and its API key-based features to protect access to Beehive front-end. This could complement or replace the current Clerk and Google cloud-based authentication.\n\n**Required Skills:** Python, Computer and Network Security, and API Gateways.\n\n**Code Challenge:** Prior experience working with Python and knowledge in security testing are essential. Experience with API Gateways is a plus. Pull requests are welcome.\n\n**Source Code:** [https://github.com/KathiraveluLab/Beehive](https://github.com/KathiraveluLab/Beehive)\n\n**Discussion Forum:** [https://github.com/KathiraveluLab/Beehive/discussions](https://github.com/KathiraveluLab/Beehive/discussions)\n\n**Effort:** 350 Hours\n\n**Difficulty Level:** Hard\n\n**[11] A Reference Implementation for concore Library in Julia.**\n\n**Mentors:** Mayuresh Kothare (mvk2 -at- lehigh.edu), Rahul Jagwani (rahuljagwani1012 -at- gmail.com), and Pradeeban Kathiravelu (pkathiravelu -at- alaska.edu)\n\n**Overview:** [concore](https://github.com/ControlCore-Project/concore) is a lightweight framework for closed-loop peripheral neuromodulation control systems. Currently, it supports implementations of programs in Python, C++, Matlab, Octave, and Verilog. In this project, the contributor will develop a reference implementation of the concore library in Julia.\n\n**Current Status:** We developed the concore library initially in Python and then implemented support for other languages. The contributor will work towards a reference implementation in Julia in this project. The successful completion of this project will expand the user base of concore to include Julia developers.\n\n**Expected Outcomes:** A complete reference implementation of the concore Library in Julia.\n\n**Required Skills:** Julia and Python\n\n**Code Challenge:** Demonstration of previous expertise in Julia and Python can be beneficial.\n\n**Source Code:** [https://github.com/ControlCore-Project/concore](https://github.com/ControlCore-Project/concore)\n\n**Discussion Forum**: [https://github.com/ControlCore-Project/concore/discussions](https://github.com/ControlCore-Project/concore/discussions)\n\n**Effort:** 350 Hours\n\n**Difficulty Level:** Medium\n\nYou are welcome to propose new open-source project ideas, especially those that serve the state of Alaska and its people. Please use the below template to create new project ideas. However, if you are proposing a new project idea as a contributor, make sure they are relevant to Alaska specifically and the circumpolar north in general. Also, contact potential mentors from the above-listed mentors and confirm their interest in your project idea before drafting an entire proposal based on your own idea.\n\n**[N] PROJECT TITLE.**\n\n**Mentors:** FIRSTNAME1 LASTNAME1 (email-address) and FIRSTNAME2 LASTNAME2 (email-address)\n\n**Overview:**\n\n**Current Status:**\n\n**Expected Outcomes:**\n\n**Required Skills:**\n\n**Code Challenge:**\n\n**Source Code:**\n\n**Discussion Forum**:\n\n**Effort:** 90/175/350 Hours\n\n**Difficulty Level:** Easy/Intermediate/Hard"
  },
  {
    "name": "MetaBrainz Foundation Inc",
    "slug": "metabrainz-foundation-inc",
    "tagline": "Open music / book metadata, music recommendations",
    "description": "The MetaBrainz Foundation is a non-profit that believes in free, open access to data. It has been set up to build community maintained databases and make them available in the public domain or under Creative Commons licenses.\n\nOur data is mostly gathered by volunteers and verified by peer review to ensure it is consistent and correct. All non-commercial use of this data is free, but commercial users are asked to support us in order to help fund the project. We encourage all data users to contribute to the data gathering process so that our data can be as comprehensive as possible.\n\nWith this data we are building a music social network and bias free music recommendations.",
    "ideas_url": "https://wiki.musicbrainz.org/Development/Summer_of_Code/2026",
    "website_url": "https://metabrainz.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "machine learning",
      "perl",
      "postgres",
      "spark"
    ],
    "topic_tags": [
      "machine learning",
      "open data",
      "music",
      "books",
      "music social network"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/metabrainz-foundation-inc",
    "ideas_content": "# Development/Summer of Code/2026\n\nAre you interested in working with MetaBrainz in Google Summer of Code 2026? You're in the right place!\n\n## Important Schedule Note\n\n**If you're arriving here after 23 March 2026, you've missed your chance to apply with us. We will not consider applications from applicants who have not discussed their idea during the application discussion phase which ends March 23rd. We will make no exceptions.**\n\n## Where to start\n\n- New to MetaBrainz?\n- The MetaBrainz Foundation has been set up to build community maintained databases and make them available in the public domain or under Creative Commons licenses.\n- New to MetaBrainz development and/or GSoC?\n[Getting started with GSoC](https://wiki.musicbrainz.org/Development/Summer_of_Code/Getting_started)\n\n## About AI/Large Language models\n\n**We discourage the use of AI tools in communications and contributions.**\n\nThe goal of GSoC is for you to learn and improve your skills, not just to finish your project at any cost.\n\nHowever, if you do use any AI or LLMs, you must disclose their use in your PRs and/or conversations with your mentor. Additionally, you must fully understand and be able to explain any AI-generated code you submit.\n\n**Any undisclosed use of AI** or Large Language Models, or inability to explain AI-generated contributions, **will be grounds for instant disqualification**.\n\n## Application template\n\nWhen you're ready to write your application, please use this\n[Development/Summer_of_Code/Application_Template](https://wiki.musicbrainz.org/Development/Summer_of_Code/Application_Template) as the basis of your application.\n\n## Projects\n\n|\n\nWe're interested in projects that help us reach our roadmap, and that add major functionalities to the website.\n\nPlease see our [ideas page](https://wiki.musicbrainz.org/Development/Summer_of_Code/2026/BookBrainz) for more details and information on getting started.\n\n**Top 3 Desired Skills**: Node.js, React, PostgreSQL[Ideas page](https://wiki.musicbrainz.org/Development/Summer_of_Code/2026/BookBrainz)|[Main page](https://bookbrainz.org/)|[Forums](https://community.metabrainz.org/c/bookbrainz)\n|\n\n**Languages/skills**: Python, Flask, PostgreSQL, Spark, React, Android[Ideas page](https://wiki.musicbrainz.org/Development/Summer_of_Code/2026/ListenBrainz)|[Main page](https://listenbrainz.org/)|[Forums](https://community.metabrainz.org/c/listenbrainz/)\n|\n\n**Languages/skills**: JavaScript (React), PostgreSQL, Rust"
  },
  {
    "name": "CGAL Project",
    "slug": "cgal-project",
    "tagline": "C++ library of computational geometry",
    "description": "CGAL is a software library that offers a number of reliable geometric data structures and algorithms. CGAL components operate in 2D and 3D, and sometime in arbitrary dimensions. Examples of components include convex hulls, convex decomposition, Delaunay triangulations, Voronoi diagrams, polygonal surface mesh data-structures, mesh generation, Boolean operations, envelope computations, intersection detection, surface reconstruction, and subdivision surfaces.\n\nCGAL is used in a variety of application domains such as CAD/CAM (computer aided design and modeling), GIS (geographic information systems), geophysics, image processing, molecular biology, robotics, motion planning, and graphics.\n\nCGAL is written in C++ and rigorously adheres to the generic-programming paradigm.\n\nCGAL became an Open Source project in 2003. Most of CGAL is under the GPL v3+ license, and some core parts are under the LGPL v3+. The semi-annual releases have currently about 10,000 downloads. CGAL is commercially supported by the spin-off company GeometryFactory.",
    "ideas_url": "https://github.com/CGAL/cgal/wiki/Project-Ideas",
    "website_url": "https://www.cgal.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c++",
      "qt"
    ],
    "topic_tags": [
      "geometry",
      "mesh processing",
      "computation geometry",
      "geometry processing"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/cgal-project",
    "ideas_content": "-\n[Notifications](https://github.com/login?return_to=%2FCGAL%2Fcgal)You must be signed in to change notification settings -\n[Fork 1.5k](https://github.com/login?return_to=%2FCGAL%2Fcgal)\n\n# Project Ideas\n\n[68 revisions](https://github.com/CGAL/cgal/wiki/Project-Ideas/_history)\n\n-\n[GSoC 2026 Projects](https://github.com#gsoc-2026-projects)[Topological Filtering of Features in Triangle Meshes](https://github.com#topological-filtering-of-features-in-triangle-meshes)[Adding Support for New File Formats for Meshes](https://github.com#adding-support-for-new-file-formats-for-meshes)[Efficient k-DOPs](https://github.com#efficient-k-dops)[Approximate Convex Decomposition of Meshes with Collision-Aware Concavity and Tree Search](https://github.com#approximate-convex-decomposition-of-meshes-with-collision-aware-concavity-and-tree-search)[Ray Marching for Mesh Generation](https://github.com#ray-marching-for-mesh-generation)[Optimizing Geometric Operations](https://github.com#optimizing-geometric-operations)[Enhancing the 2D Regularized Boolean Operation Demo](https://github.com#enhancing-the-2d-regularized-boolean-operation-demo)[Enhancing CGAL Python Bindings](https://github.com#enhancing-cgal-python-bindings)[Implementing a 3D Arrangement of Planes Data Structure](https://github.com#implementing-a-3d-arrangement-of-planes-data-structure)[Isotropic Remeshing of Surface Triangle Meshes](https://github.com#isotropic-remeshing-of-surface-triangle-meshes)[Intersection of a Cellular Complex with a Plane](https://github.com#intersection-of-a-cellular-complex-with-a-plane)[Robust Discrete Differential Operators for Wild Geometry](https://github.com#robust-discrete-differential-operators-for-wild-geometry)[Shaders for Basic Viewer](https://github.com#shaders-for-basic-viewer)[Spatial Searching on GPU](https://github.com#spatial-searching-on-gpu)\n\n[Information Candidates Should Supply](https://github.com#information-candidates-should-supply)[Previous Project Ideas and Successful Projects](https://github.com#previous-project-ideas-and-successful-projects)\n\nThe CGAL Project is a candidate mentoring organization of the [Google Summer of Code](https://summerofcode.withgoogle.com) 2026.\nOn this page we present some project ideas as well the [information](https://github.com#information-candidates-should-supply) applicants have to provide us.\n**GSoC applicants are welcome to propose other ideas and check if a mentor is interested in supervising it**. For new project\nproposals, contact us at [gsoc-cgal@inria.fr](mailto:gsoc-cgal@inria.fr).\n\n**Mentor**: Sebastien Loriot\n\n**Project description:**\n\nRemeshing algorithms in CGAL requires the proper extraction of sharp features so that they can be represented in the output mesh ([like here for example](https://doc.cgal.org/latest/Mesh_3/index.html#fig__figuretwo_spheres_mesh)).\nClassical method to detect sharp features are based on collecting edges with sharp dihedral surface angles. However, depending on\nthe quality of the input mesh, some noisy edges might be detected, or some edges might be detected.\nTo workaround these issues, it might be interesting to rely on tools from Topological Data Analysis, like for example persistence.\nIndeed, extra data or missing data are all related to a notion of scale at which the problem is looked at. The goal of this project is\nto implement such a strategy for provide curated feature edge graph to the meshing algorithm of CGAL. If time allows, extension to\ndetection of significant handles might also be looked at.\n\nResources:\n\n[A Practical Solver for Scalar Data Topological Simplification](https://arxiv.org/abs/2407.12399)[To cut or to fill: a global optimization approach to topological simplification](https://www.cse.wustl.edu/~taoju/research/cutfill.pdf)[Topological Simplification of Nested Shapes](https://www.cs.wustl.edu/~taoju/research/nested_self.pdf)[Gudhi library](https://gudhi.inria.fr/)\n\n**Required Skills:** C++17, Mesh Processing, Topological Data Analysis\n\n**Contact:** [sebastien.loriot@cgal.org](mailto:sebastien.loriot@cgal.org)\n\n**Duration:** 350h\n\n**Mentors**: Andreas Fabri and Mael Rouxel-Labbé\n\n**Project description:**\n\nThe CGAL library provides several functions to read and write meshes (surface and volume) in the [Stream Support package](https://doc.cgal.org/latest/Stream_support).\nThe list of currently supported file format is available [here](https://doc.cgal.org/latest/Stream_support/IOStreamSupportedFileFormats.html).\nThe goal of this project is to add support to more file formats. We could for example add support for glTF, gmsh format, 3mf v2, ...\nThe duration of the project will depend on the file format proposed for addition.\n\n**Required Skills:** C++17\n\n**Contact:** [sebastien.loriot@cgal.org](mailto:sebastien.loriot@cgal.org)\n\n**Duration:** 90h, 175h, or 350h\n\n**Mentors:** Gabriel Zachmann, Rene Weller, University of Bremen\n\n**Project description:**\n\nA nice generalization of AABBs are k-DOPs, which can bound geometry much tighter than AABBs by adjusting the parameter k. We have implemented algorithms that can create such kDOPs to bound a given set of polygons; also, our code can check two k-DOPs for overlap, even when they are rotated, i.e., no longer given over a common set of generating vectors. Finally, our code can make use of SSE/AVX instructions, which can give a good performance boost.\n\nThe task in this GSOC project will be to CGAL-ify our code. This means using the CGAL data structures (e.g., those for points, vectors, polygons, etc.). Also, an important part will be writing unit tests that can be run in an automated environment and test the correctness of the code. This can be a little challenge in the case where the pair of k-DOPs are rotated arbitrarily, but CGAL's convex hull algorithms should be helpful for that (the unit tests do not necessarily need to have optimal running times).\n\n**Resources:**\n\n[https://cgvr.cs.uni-bremen.de/papers/iros2019/iros2019_paper.pdf](https://cgvr.cs.uni-bremen.de/papers/iros2019/iros2019_paper.pdf)[https://cgvr.cs.uni-bremen.de/papers/vrais98/vrais98.pdf](https://cgvr.cs.uni-bremen.de/papers/vrais98/vrais98.pdf)- Section 3.5.9 in\n[https://cgvr.cs.uni-bremen.de/papers/zachmann_diss/zachmann_diss.pdf](https://cgvr.cs.uni-bremen.de/papers/zachmann_diss/zachmann_diss.pdf)\n\n**Required Skills:** C++17, experience with CGAL, Computational Geometry\n\n**Contact:** {zach, weller}@cs.uni-bremen.de\n\n**Duration:** 350h\n\n**Mentors**: Léo Valque and Sebastien Loriot\n\n**Project description:**\n\nApproximate convex decomposition aims to partition a 3D shape into a set of nearly convex components whose convex hulls approximate the input geometry. This representation enables efficient collision detection and physical simulation, as many geometry processing algorithms are optimized for convex shapes.\nThe project is to implement an existing method described [here](https://arxiv.org/pdf/2205.02961) within CGAL. The algorithm relies on a plane-based decomposition strategy combined with a concavity metric that measures deviation from convexity using approximate symmetric Hausdorff distance between the surface and its convex hull. The algorithm iteratively cuts the mesh by planes to minimize global concavity. The algorithm selects the cutting planes using a Monte-Carlo Tree Search startegy.\n\nResources:\n\n[The publication](https://arxiv.org/pdf/2205.02961)- [The implementation of the publication]((\n[https://github.com/SarahWeiii/CoACD](https://github.com/SarahWeiii/CoACD))\n\n**Required Skills:** C++17, Mesh Processing\n\n**Contact:** [sebastien.loriot@cgal.org](mailto:sebastien.loriot@cgal.org)\n\n**Duration:** 175h-350h\n\n**Mentors:** Sven Oesau and Mael Rouxel-Labbé\n\n**Project description:**\n\nSome packages in CGAL need to compute the intersections of segments, rays, or lines with an implicit function. This is generally done through naive bisection algorithms. For some configurations however, we know that the implicit function is a signed distance field (offset meshing, alpha wrapping, ...), or an harmonic function (Poisson reconstruction). In these configurations, we can do better than bisection algorithms. The goal of this project is to implement these marching algorithms for the 3D Mesh Generation, Poisson Surface Reconstruction, and Alpha Wrapping packages, and identify other relevant packages, and possible improvements on these algorithms.\n\n**Resources:**\n\n[https://en.wikipedia.org/wiki/Ray_marching](https://en.wikipedia.org/wiki/Ray_marching)[https://iquilezles.org/articles/](https://iquilezles.org/articles/)[https://markjgillespie.com/Research/harnack-tracing/HarnackTracing.pdf](https://markjgillespie.com/Research/harnack-tracing/HarnackTracing.pdf)\n\n**Required Skills:** C++17, Computer Graphics, Computational Geometry\n\n**Contact:** [mael.rouxel.labbe@geometryfactory.com](mailto:mael.rouxel.labbe@geometryfactory.com)\n\n**Duration:** 175h\n\n**Mentor**: Efi Fogel and Sébastien Loriot\n\n**Project Overview:**\nThis project focuses on the optimization of fundamental geometric operations, such as intersection detection for various families of curves in the 2D Arrangement package and perhaps also in the core of CGAL.\n\n**Technical Context:**\nThe 2D Arrangement package relies on a flexible design utilizing several geometry traits class templates to support various families of curves, e.g., linear segments, conic curves, and Bézier curves. Each traits class template consists of a set of functors that implement specific geometric operations for a given curve family. Most popular kernels of CGAL include implementations of various operations on linear objects, such as segments. This project aims to improve the efficiency and robustness of these underlying operations across different curve types.\n\n**Required Skills:** geometry, code development tools (e.g., git), and C++17 proficiency\n\n**Contact:** [efifogel@gmail.com](mailto:efifogel@gmail.com)\n\n**Duration:** 350h\n\n**Mentor**: Efi Fogel\n\n**Project description:**\nThe new demonstration program of the \"2D Regularized Boolean Operations\" package demonstrates various operations on polygons, such as union, intersection, and Minkowski sum. It also demonstrates the application of several operations in a pipeline fashion. The demo has not been published yet; it requires a few enhancements, such as the support of Boolean operations on general polygons bounded by non-linear curves.\n\n**Required Skills:** Qt6, geometry, code development tools (e.g., git), and C++17 proficiency\n\n**Contact:** [efifogel@gmail.com](mailto:efifogel@gmail.com)\n\n**Duration:** 350h\n\n**Mentor**: Efi Fogel\n\n**Project description:**\nRecently, we have developed a system that can generate Python bindings for several functions and class template instances in CGAL.\nThis project includes the following tasks:\n\n- Adding Python bindings that are currently missing.\n- Adding docstrings.\n- Porting of CGAL examples to Python.\n\n**Required Skills:** code development tools (e.g., git), C++17 proficiency, CMake, and Python\n\n**Contact:** [efifogel@gmail.com](mailto:efifogel@gmail.com)\n\n**Duration:** 350h\n\n**Mentor**: Efi Fogel and Sven Oesau\n\n**Project description:**\nThe goal of this project is to design and implement a data structure representing the subdivision of three-dimensional space induced by a set of planes. Unlike the 2D case, where the topology is maintained via a Halfedge Data Structure (HDS), this implementation will leverage CGAL's Combinatorial Maps package (specifically, 3-maps or Linear Cell Complexes) to handle the higher-dimensional topology (volumes, faces, edges, and vertices). The work will mainly consist of bridging the gap between the topological representation (Combinatorial Maps) and the geometric predicates required to construct, maintain, and operate on such an arrangement.\n\n**Required Skills:** code development tools (e.g., git), C++17 proficiency, Linear Algebra\n\n**Contact:** [efifogel@gmail.com](mailto:efifogel@gmail.com)\n\n**Duration:** 350h\n\n**Mentor**: Jane Tournois\n\n**Project description:**\n\nThis project focuses on improving the surface isotropic remeshing algorithm for triangle meshes within the CGAL library. The work will include benchmarking the existing implementation on the Thingi10K dataset, preventing the creation of self-intersections during remeshing, and enhancing the edge-flipping stage to improve mesh quality. The project starts from a functional CGAL implementation used as a baseline.\n\nResources:\n\n[CGAL::isotropic_remeshing()](https://doc.cgal.org/latest/Polygon_mesh_processing/group__PMP__meshing__grp.html#ga66cb01cf228ed22f0a2a474cfa2aeb3f)[A Remeshing Approach to Multiresolution Modeling - Botsch, Kobbelt](https://www.graphics.rwth-aachen.de/media/papers/remeshing1.pdf)[Thingi10K](https://ten-thousand-models.appspot.com/)\n\n**Required Skills:** C++17, Mesh Processing\n\n**Contact:** [jane.tournois@geometryfactory.com](mailto:jane.tournois@geometryfactory.com)\n\n**Duration:** 175h-350h\n\n**Mentor**: Sébastien Loriot and Simon Lopez\n\n**Project description:**\nThe goal of this project is to propose and implement a generic framework to slice a cellular complex (a 3D grid, a tetrahedron mesh, a hex-(dominant)-mesh, ...).\nThe cells of the complex are assumed to be convex. More precisely, we are interested in the intersection polygons of each cell with the plan.\nDepending on the requested output, the code will either generate a soup of polygons or a polygon mesh. A key functionality is to be able to transfer the cell id to each polygon.\nThe nature of the problem make it trivially parallel on CPU. If time allows, a GPU version can be made for real-time display.\n\n**Required Skills:** C++17, Mesh Processing\n\n**Contact:** [sebastien.loriot@cgal.org](mailto:sebastien.loriot@cgal.org)\n\n**Duration:** 175h-350h\n\n**Mentor**: Andreas Fabri and Mario Botsch\n\n**Project description:**\nThe goal of this project is to implement the [paper](https://cg.cs.tu-dortmund.de/publications/2025-robust.pdf) by Mario Botsch and Sven Wagner in CGAL,\nstarting from Sven's [code](https://github.com/sdwagner/wildDDG). This project is co-mentored by a core CGAL developer, and the author of the publication.\n\n**Required Skills:** C++17, Geometry Processing\n\n**Contact:** [andreas.fabri@geometryfactory.com](mailto:andreas.fabri@geometryfactory.com)\n\n**Duration:** 175h-350h\n\n**Mentor**: Guillaume Damiand an Jason Fong\n\n**Project description:**\nProject description: Since CGAL 4.13, it has been possible to visualize various CGAL data structures using a simple global draw() function. This visualization capability was further enhanced in CGAL 6.0 with the introduction of the Basic Viewer package, which allows users to develop their own visualization code. The rendering is performed using OpenGL shaders, with different shaders available for drawing vertices, edges, and faces in various modes. For example, one shader enables transparent rendering of parts of an object, making it possible to visualize the interior of a 3D model.\n\nHowever, the current version of these shaders has some limitations:\n\n- The initial size of the drawn object is sometimes incorrectly calculated, depending on whether the object is 2D or 3D and its overall dimensions.\n- The edges of meshes are rendered as rectangles, which can lead to visual artifacts.\n\nThe goal of this project is to improve the shaders used in the Basic Viewer and address these issues. We will also explore solutions implemented in major software tools like MeshLab or ParaView to determine if existing approaches can be directly applied to resolve these challenges.\n\n**Required Skills:** C++17, OpenGL Shaders\n\n**Contact:** [guillaume.damiand@cnrs.fr](mailto:guillaume.damiand@cnrs.fr)\n\n**Duration:** 175h\n\n**Mentor**: Mael Rouxel-Labbé, Sven Oesau, and Pierre Alliez\n\n**Project description:**\nCGAL, as of now, is entirely CPU-oriented. Both the advancements in software and hardware for GPUs make it an attractive target architecture to port and develop computation geometry algorithms. Internally, a few projects have already attempted to use GPU computing, with promising results.\n\nThe goal of this project is to continue work on a series of prototypes for axis-aligned bounding box (AABB) trees on GPUs, and more generally spatial searching structures on GPUs. The end goal is to adapt a typical AABB-heavy algorithm such as self-intersection detection to the new architecture.\n\nResources:\n\n**Required Skills:** C++17, GPU design proficiency\n\n**Contact:** [mael.rouxel.labbe@geometryfactory.com](mailto:mael.rouxel.labbe@geometryfactory.com)\n\n**Duration:** 350h\n\nThe application process has several steps. Before contacting anybody verify that you are eligible (Check section 7.1 of the official [rules](https://summerofcode.withgoogle.com/rules)). The next step is to contact the mentor\nof the project you are interested in. You have to convince him that you are the right person to get the job\ndone. The next step is to work out more details and to contact the mentoring organization by providing\nthe following information by email to [gsoc-cgal@inria.fr](mailto:gsoc-cgal@inria.fr):\n\n-\nProject:\n\n- Select a project in the list and provide your personal and detailed description. If you wish to work on another idea of your own, we are pretty open as long as this serves the goal of consolidating CGAL as a whole.\n- Provide a proposal of a technical solution with your envisioned methodology. The more detailed the better.\n- Explain how the solution will be available to the user, in which form. Do not forget the documentation, unitary tests and cross-platform aspects.\n- Provide a realistic schedule with objectives (one every two weeks for example) and deadlines. Focus on mid-term objectives as well as on the final evaluation.\n\n-\nPersonal data:\n\n- First name, last name, affiliation and geographical location.\n- A brief list of the main studies and programming courses attended, with ranking.\n- List of the most important software projects contributed and success.\n- Which are your best skills in terms of programming and scientific computing?\n- In general what is your taste in terms of programming? language, methodology, team work, etc.\n- Is there anything that prevents you from working full time on the project during the program period?\n- How do you see your involvement after the program ends? Do you see yourself pushing the project further, or do you see yourself contributing to other CGAL projects?\n- Are you more interested in the theory/scientific aspect of CGAL, or do you feel more like a hacker?\n- What are your long-term wishes in terms of job?\n\n\n\n**General Information**\n\n[Information for New Developers](https://github.com/Information-for-New-Developers)- Developing with Git\n- Structure of a CGAL Package\n- Building\n[Concurrency in CGAL](https://github.com/Concurrency-in-CGAL)[License](https://github.com/License)[Documentation Guidelines](https://github.com/Documentation-Guidelines)- Reviewing Process\n[Testing](https://github.com/Testing)- Miscellaneous\n\n[Tools](https://github.com/Tools)[Scripts](https://github.com/Scripts)[Libraries](https://github.com/Libraries)[Infrastructure](https://github.com/Infrastructure)- Releases\n- Miscellaneous"
  },
  {
    "name": "Invesalius",
    "slug": "invesalius",
    "tagline": "3D Medical visualization and neuronavigation tool",
    "description": "InVesalius is an Open Source organization that works developing free software for reconstruction of computed tomography and magnetic resonance images. The software is mainly used for rapid prototyping, teaching, forensics, and in the medical field. It is possible to use it on the Microsoft Windows, GNU/Linux and Apple Mac OS X platforms. \n\nInVesalius main software started began their development on 2001 by Centro de Tecnologia da Informação Renato Archer (CTI), in Brazil, later it was released under GNU license and more practitioners joins the organization to improve their development.\n\nAt that time, there was no medical image software in Portuguese that fulfilled the Brazilian hospitals and clinics needs. Therefore, InVesalius came as a proposal of development with the aim to be a medical software image analysis with null acquisition cost, capability of execution on low-cost personal computers and the\ncapability of execution on different operating systems and act as a platform to encourage the use and development of medical images in Brazil.",
    "ideas_url": "https://github.com/invesalius/gsoc/blob/main/gsoc_2026_ideas.md",
    "website_url": "https://invesalius.github.io/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "cython",
      "numpy",
      "dicom",
      "Vtk"
    ],
    "topic_tags": [
      "ehealth",
      "medical imaging",
      "3D Reconstruction",
      "3d printing",
      "Neuronavigation"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/invesalius",
    "ideas_content": "# GSoC 2026 Ideas for InVesalius\n\nSee also the instructions for applying [here](https://github.com/invesalius/gsoc/blob/main/gsoc_application.md).\n\nAll the current ideas for GSoC 2026 are listed bellow:\n\n---\n\n### Fixes in 3D mask editing and mask preview\n\nFix 1 - 3D edition tools: Polygons are not removed after using the tool. https://github.com/invesalius/invesalius3/issues/1078   \n\nFix 2 - 3D edition tools: The “Clean Polygons” button clears the edits even when “Edit in 3D” is disabled. https://github.com/invesalius/invesalius3/issues/1079   \n\nFix 3 - 3D edition tools: Incorrect volume selection when it occupies the entire viewport. https://github.com/invesalius/invesalius3/issues/1084   \n\nFix 4 - 3D edition tools: Empty volume screen when activating 3D editing after DICOM import. https://github.com/invesalius/invesalius3/issues/1085   \n\nFix 5 - 3D edition tools: Incorrectly edited volume after importing a DICOM study and enabling “Edit in 3D”. https://github.com/invesalius/invesalius3/issues/1086   \n\nFix 6 - Mask Preview:  Volume is not updated after selecting part of the mask. https://github.com/invesalius/invesalius3/issues/1080\n\nFix 7 - Mask Preview: Update the volume color (in red), as in the slices, when a region is selected with \"Tools -> Mask -> Select parts\". https://github.com/invesalius/invesalius3/issues/1081   \n\n**Requirements**: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies. Good background of computer graphics.\n\n**Deliverables**:\n- Bug fixes for the 3D mask editing and mask preview tools.\n\n**Programming Languages**: Python\n\n**Duration**:  175h (medium)\n\n**Difficulty level:** Medium\n\n**Mentor:**  \nThiago Franco de Moraes - totonixsame@gmail.com  \nPaulo Henrique Junqueira Amorim - paulojamorim@gmail.com\n\n**References**:\n- https://github.com/invesalius/invesalius3/issues/91 and https://en.wikipedia.org/wiki/3D_projection\n\n---\n\n### Surface texture\n\nAdd texture to a surface based on the image tissue.\n\n**Requirements**: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies. Good background of computer graphics.\n\n**Deliverables**:\n- Tool to set a texture to a surface.\n\n**Programming Languages**: Python\n\n**Duration**: 350h (large)\n\n**Difficulty level:** Hard\n\n**Mentor:**  \nThiago Franco de Moraes - totonixsame@gmail.com\n\n**References**: \n- https://en.wikipedia.org/wiki/Texture_mapping \n- https://doi.org/10.1080/21681163.2016.1254069\n\n---\n\n### Export and import using the .3MF format\n\nThe 3D Manufacturing Format (3MF) is a file format for 3D printing that allows design applications to exchange high-fidelity 3D models with other applications, platforms, services, and printers. Add support for exporting colored triangular meshes (surfaces) in .3MF format. The .3MF import functionality should also be added to the “3D Surfaces” tab, which currently supports STL, OBJ, and PLY imports.\n\n**Requirements**: Computer with Windows, Linux or Mac OS installed. A source code editor, Rust language (for performance reasons), Python and InVesalius libraries dependencies. Good background of computer graphics. If the lib3mf library is used, its performance should be tested. It is important that the generated file can be opened in slicers such as [Orca Slicer](https://orca-slicer.com/)\n\n**Deliverables**:\n- Tool to export and import 3MF file format.\n\n**Programming Languages**: Rust and Python\n\n**Duration**: 175h (medium)\n\n**Difficulty level:** Medium\n\n**Mentor:**  \nPaulo Henrique Junqueira Amorim - paulojamorim@gmail.com  \nThiago Franco de Moraes - totonixsame@gmail.com\n\n**References**: \n- https://3mf.io/spec/\n- https://pypi.org/project/lib3mf/\n  \n---\n\n\n### Extract surface using Dual contouring\n\nInVesalius uses Marching Cubes to extract surface from volumetric images. It's interesting to have other methods like Marching Tetrahedra and Dual Contouring.\n\n**Requirements**: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies. Good background of computer graphics.\n\n**Deliverables**:\n- Tool to generate surfaces using other methods than Marching Cubes.\n\n**Programming Languages**: Python and Cython\n\n**Duration**: 350h (large)\n\n**Difficulty level:** Hard\n\n**Mentor:**  \nThiago Franco de Moraes - totonixsame@gmail.com\n \n**References**: https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/ https://en.wikipedia.org/wiki/Marching_tetrahedra https://en.wikipedia.org/wiki/Isosurface\n\n\n---\n\n\n### Importing `.nii` masks into InVesalius\n\nImplementation of a basic feature to import segmentation masks in **NIfTI format (.nii / .nii.gz)** into InVesalius. This allows users to load externally created masks (e.g., regions of interest) and visualize them together with existing medical image data.\n\n**Requirements:**\nComputer with Windows, Linux, or Mac OS installed.\nPython programming language and InVesalius library dependencies.\nA source code editor.\n\n**Deliverables:**\n- Import of `.nii` / `.nii.gz` mask files into mask lisk \n- Basic documentation  \n\n**Programming Languages:** Python\n\n**Duration:** 90h (small)\n\n**Difficulty Level:** Medium \n\n**Mentor:**  \nRenan Matsuda - renan_hiroshi@hotmail.com  \nThais Marchetti - thaismarchetti123@gmail.com  \nLucas Betioli - lucasantoniobetioli@gmail.com  \nVictor Malheiro - victorhugomalheiro@gmail.com\n\n**References**:\n- Similar to import mesh: https://github.com/invesalius/invesalius3/pull/68\n\n\n---\n\n\n\n### Visualization of the selected marker on image slices\n\nImplementation of a feature to visualize the **selected marker** on axial, sagittal, and coronal slices. When a marker is selected in the marker list or 3D view, its position is highlighted on the corresponding image slices.\n\nThis improves spatial understanding during neuronavigation tasks.\n\n**Requirements:**  \nComputer with Windows, Linux, or Mac OS installed.  \nPython programming language and InVesalius library dependencies.  \nA source code editor.\n\n**Deliverables:**  \n- Highlight of the selected marker on 2D slices  \n- Synchronization between marker selection and slice views  \n- Basic documentation  \n\n**Programming Languages:** Python  \n\n**Duration:** 175h (medium)\n\n**Difficulty Level:** Medium  \n\n**Mentor:**  \nRenan Matsuda - renan_hiroshi@hotmail.com  \nThais Marchetti - thaismarchetti123@gmail.com  \nLucas Betioli - lucasantoniobetioli@gmail.com  \nVictor Malheiro - victorhugomalheiro@gmail.com  \n\n**References:**  \n- Existing neuronavigation and marker visualization modules in InVesalius  \n\n---\n\n\n### Saving timestamp for each created marker\n\nImplementation of a feature to automatically store a **timestamp (date and time)** when a marker is created. The timestamp is saved together with the marker data and can be used for later analysis and synchronization with external systems (e.g., EEG, EMG, TMS).\nBackward compatibility with older marker files is required.\n\n**Requirements:**  \nComputer with Windows, Linux, or Mac OS installed.  \nPython programming language and InVesalius library dependencies.  \nA source code editor.\n\n**Deliverables:**  \n- Timestamp stored for each created marker  \n- Timestamp saved in project and export files  \n- Basic documentation  \n\n**Programming Languages:** Python  \n\n**Duration:** 90h (small) \n\n**Difficulty Level:** Low  \n\n**Mentor:**  \nRenan Matsuda - renan_hiroshi@hotmail.com  \nThais Marchetti - thaismarchetti123@gmail.com  \nLucas Betioli - lucasantoniobetioli@gmail.com  \nVictor Malheiro - victorhugomalheiro@gmail.com  \n\n**References:**  \n- Existing marker save/export implementation in InVesalius  \n\n---\n\n### TMS-Evoked Potential (TEP) visualization integration in InVesalius\n\nImplementation of a visualization module for **TMS-evoked potentials (TEPs)** within InVesalius. Initially, EEG signals containing TEP data are loaded from files and visualized alongside neuronavigation data, enabling spatial and temporal correlation between cortical activity, stimulation sites, and navigation events (e.g., markers). The software architecture must be **flexible and extensible**, allowing future integration of **real-time TMS-EEG acquisition**.\n\nThe system should support visualization of **TEP-derived metrics** (e.g., amplitude, latency, or frequency-band power such as alpha power) mapped onto the cortical surface or regions of interest over time, enabling spatiotemporal representations of brain responses to TMS. Users must be able to interact with individual signals (e.g., zoom, scale, channel selection) and adjust visualization parameters.\n\nBasic signal processing tools should be included, such as noise filtering and moving average filters, serving as a foundation for future advanced processing.\n\n**Requirements:**  \nComputer with Windows, Linux, or Mac OS installed.  \nPython programming language and InVesalius library dependencies.  \nA source code editor.  \nBasic knowledge of EEG, TMS, and TEP analysis.\n\n**Deliverables:**  \n- Import of EEG files containing TEP data  \n- Interactive temporal visualization of EEG/TEP signals  \n- Spatiotemporal mapping of TEP features onto 3D brain surfaces or ROIs  \n- Basic signal processing tools (e.g., noise filters, moving average filters)  \n- Temporal alignment between TMS events, neuronavigation markers, and EEG data  \n- Modular and extensible codebase prepared for future real-time TMS-EEG integration  \n- Technical documentation  \n\n**Programming Languages:** Python  \n\n**Duration:** 350h (large) \n\n**Difficulty Level:** Very Hard  \n\n**Mentor:**  \nRenan Matsuda - renan_hiroshi@hotmail.com  \nMarcio Campos - marcio.campos6@gmail.com  \nLucas Betioli - lucasantoniobetioli@gmail.com  \n\n**References:**  \n- https://mne.tools/stable/_images/sphx_glr_30_ecog_003.png\n- https://www.fieldtriptoolbox.org/tutorial/tms/tms-eeg/\n- http://www.tmseeg.com/tutorials/\n\n---\n\n### Implement neuronavigation capability for transcranial focused ultrasound (tFUS)\n\nDevelopment and integration of the functionality for neuronavigation of transcranial focused ultrasound transducers (tFUS). InVesalius currently supports only neuronavigation for Transcranial Magnetic Stimulation (TMS) coils. We aim at extending the support to tFUS, which is becoming an important neuromodulation tool to study and and interact with brain function non-invasively. This new feature will significantly extend the user based on InVesalius to support accurate and reproducible neuroscience. \n\n**Requirements:**\nComputer with Windows, Linux, or Mac OS installed.\nPython programming language and InVesalius library dependencies.\nA source code editor.\n\n**Deliverables:**\n- Visualization interface for coregistration of tFUS transducers.\n- Targeting and guiding interface for tFUS.\n- Minor adjustment to UI/UX considering the tFUS user requirements.\n\n**Programming Languages:** Python\n\n**Duration:** 350h (large)\n\n**Difficulty Level:** Hard\n\n**Mentor:**  \nVictor H. Souza - vhosouza@gmail.com  \nRenan Matsuda - renan_hiroshi@hotmail.com  \nVictor Malheiro - victorhugomalheiro@gmail.com\n\n**References**:\n- Neuronavigation: [Track multiple coils simultaneously and show stylus/probe #827](https://github.com/invesalius/invesalius3/pull/827)\n- tFUS: [tFUS Basics](https://doi.org/10.3389/fnhum.2021.749162)\n  \n---\n\n### Adapt PACS implementation to current InVesalius\n\nThere is a pull request (https://github.com/invesalius/invesalius3/pull/644) for the PACS tool that requires updates in order to be merged. The tool also needs more testing on servers such as DCM4CHEE and Orthanc. This activity will focus on code fixes to enable the merge and on testing the interaction between InVesalius (client) and PACS servers for DICOM send, retrieve, and query operations.\n\n**Requirements:** \nComputer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies. A PACS server like Orthanc or DCM4CHE.\n\n**Deliverables:**\nA tool capable of sending, retrieving, and querying DICOM data on PACS servers.\n\n**Programming Languages:** Python\n\n**Duration:** 175h (medium)\n\n**Difficulty Level:** Medium\n\n**Mentor:**  \nPaulo Henrique Junqueira Amorim - paulojamorim@gmail.com  \nThiago Franco de Moraes - totonixsame@gmail.com\n\n---\n\n### SimNIBS TMS Electric Field Simulation and Head Modeling Integration in InVesalius\n\nImplementation of a direct integration between SimNIBS and InVesalius to enable subject-specific head model generation and TMS electric field (E-field) simulations within InVesalius.\n\nCurrently, head modeling and E-field simulations require external workflows and manual data handling. This project will integrate the full pipeline into InVesalius, allowing users to generate MRI-based head models, position and orient TMS coils using existing neuronavigation tools, configure simulation parameters, execute simulations internally, and visualize E-field magnitude (|E|) directly on 3D anatomical models.\n\nThe activity will focus on implementing a Python-based interface to SimNIBS, aligning coordinate systems, handling simulation inputs/outputs robustly, and integrating results into the InVesalius visualization environment.\n\n**Requirements:**  \nComputer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius library dependencies. SimNIBS installed and accessible via Python. Basic knowledge of MRI segmentation, TMS, and E-field modeling.\n\n**Deliverables:**  \n- Integrated MRI-based head modeling pipeline.  \n- Python interface module connecting InVesalius to SimNIBS.  \n- UI panel for head modeling and simulation configuration.  \n- Execution of TMS E-field simulations within InVesalius.  \n- 3D visualization of E-field magnitude (|E|).  \n- Technical documentation.\n\n**Programming Languages:** Python  \n\n**Duration:** 400h (large)  \n\n**Difficulty Level:** Very Hard  \n\n**Mentor:**  \nRenan Matsuda - renan_hiroshi@hotmail.com\nAna Soto - ana.sotodelacruz@aalto.fi\nVictor H. Souza - vhosouza@gmail.com  \n\n**References**:\nhttps://github.com/invesalius/invesalius3/pull/473\nhttps://github.com/invesalius/invesalius3/pull/1011\n[SimNIBS](https://simnibs.github.io/simnibs/build/html/tutorial/scripting.html#scripting-tutorial)\n<!--\n### Fix GUI inconsistencies\n\n**Programming Languages:** Python\n\n**Duration:** \n\n**Difficulty Level:** Easy\n\n--- \n\n### Convert GUI from WXPython to Qt\n\n\n**Programming Languages:** Python\n\n**Duration:** 350h\n\n**Difficulty Level:** Hard-->"
  },
  {
    "name": "JSON Schema",
    "slug": "json-schema",
    "tagline": "We enable the reliable use of JSON data format.",
    "description": "JSON Schema is a vocabulary that allows you to annotate and validate JSON documents \n\nWe are a community JSON Schema enthusiast dedicated to maintain, evolve and promote the JSON Schema specification. The Community consists of individuals, community members, tooling builders, schema designers, researchers, and representatives from companies and organizations who use or are considering using JSON Schema.",
    "ideas_url": "https://github.com/json-schema-org/community/blob/main/programs/mentoring/gsoc/gsoc-2026.md",
    "website_url": "https://json-schema.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "typescript",
      ".net",
      "JSON Schema"
    ],
    "topic_tags": [
      "web",
      "apis",
      "standards",
      "data validation",
      "developer tooling"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/json-schema",
    "ideas_content": "![gsoc-banner](https://github.com/json-schema-org/community/assets/40007659/7d7d3f1d-6f4a-4139-98fb-96aa3354b777)\n\n# Welcome to Google Summer of Code 2026 with JSON Schema!\n\nWe are thrilled to announce that JSON Schema will be applying as a mentoring organization for the 2026 Google Summer of Code (GSoC). If accepted, we look forward to collaborating with talented contributors from around the world to advance the field of JSON Schema and open-source technology.\n\n## Timeline\n\nThe timeline is forthcoming, kindly check back after the official accepted organizations announcement from Google.\n\n## [Project Ideas](https://github.com/json-schema-org/community/issues?q=is%3Aopen+label%3Agsoc+sort%3Acreated-desc)\nHere is the list of our 2026 project ideas:\n- [#991](https://github.com/json-schema-org/community/issues/991): **GSoC 2026: Replacement for vscode-json-languageservice**\n- [994](https://github.com/json-schema-org/community/issues/994): **GSoC 2026: Unify the test suite**\n- [965](https://github.com/json-schema-org/community/issues/965): **GSoC 2026: Comprehensive test suite for format validation** \n- [984](https://github.com/json-schema-org/community/issues/984): **GSoC 2026: JSON Schema Compatibility Checker — Detect Breaking Changes Between Schema Versions**\n- [980](https://github.com/json-schema-org/community/issues/980): **GSoC 2026: Ecosystem Observability**\n- [977](https://github.com/json-schema-org/community/issues/977): **GSOC 2026: Add Support for Reporting on the Annotation Test Suite**\n- [983](https://github.com/json-schema-org/community/issues/983): **GSOC 2026: Enhanced Interaction and Navigation in JSON Schema Studio**\n\n## Why Choose a JSON Schema Project?\n\nJSON Schema is a widely adopted and powerful tool in the developer ecosystem. Some of the most active members today joined because of their participation in past GSoC editions, which is a clear evidence of how positive the experience has been for them. Our mentors have extensive mentoring experience, you will have the best support before, during and after the program.\n\nContributing to a JSON Schema project offers:\n- Real-World Impact: Your work will influence the global developer community.\n- Skill Development: Gain hands-on experience with cutting-edge technology and improve your software development skills.\n- Collaborative Learning: Work closely with experienced mentors and a welcoming community.\n- Professional Growth: Build your network, receive guidance, and showcase your contributions at community events.\n- Financial Support: Participants receive a stipend from Google for their contributions.\n\n## How to Apply\nDetails about our projects, qualification tasks, and application guidelines will be shared soon. In the meantime, prepare by:\n\n- Familiarizing yourself with JSON Schema.\n- Engaging with the community via GitHub and Slack.\n- Exploring past GSoC projects to understand the process.\n\n## Getting in Contact\n\n- **GitHub:** Please use [Issues](https://github.com/json-schema-org/community/issues?q=is%3Aopen+label%3Agsoc+sort%3Acreated-desc) to comment on project ideas, ask questions and collaborate.\n- **Slack:** Please join us in our [slack workspace](https://json-schema.org/slack). All GSoC discussions are are hapenning in the [`#gsoc`](https://json-schema.slack.com/archives/C04MVQSRBRS) channel.\n\nPlease see our [Code of Conduct](https://github.com/json-schema-org/.github/blob/main/CODE_OF_CONDUCT.md)\n\n## Getting Help\n\nGot a problem? Reach out to mentors or the community for assistance. Remember, mentors are listed, but other community members can also lend a hand. When talking to non-mentors:\n\n- Introduce yourself.\n- Discuss tasks based on personal interest, not just the contest.\n- Explain technical decisions independently.\n- Consult mentors for guidance on task evaluation.\n\n## 🫶 How to get involved before GSoC?\n\nIf you join our organization before GSoC, we invite you to join us contributing to JSON Schema as a great way to start engaging with the Team, learn about the JSON Schema specification and get to know some of our projects.\n\nPlease check out our [Contribution guidelines](https://github.com/json-schema-org/.github/blob/main/CONTRIBUTING.md) to know more about how to contribute in each area.\n\n## 🏗 GSoC Contributor Guidance\n\nPlease, check-out the [GSoC Contributior Guidance](CONTRIBUTOR-GUIDANCE.md)"
  },
  {
    "name": "German Center for Open Source AI",
    "slug": "german-center-for-open-source-ai",
    "tagline": "Democratically governed AI for society",
    "description": "German Center for Open Source AI (GC.OS) builds open source AI software and a sovereign tech stack that is democratically run by its users. For a list of our supported projects, please visit: https://gcos.ai/projects.",
    "ideas_url": "https://github.com/gc-os-ai/mentoring-projects/blob/main/2026/ideas_list.md",
    "website_url": "https://gcos.ai/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "pytorch",
      "scikit-learn"
    ],
    "topic_tags": [
      "machine learning",
      "time-series",
      "Causal Inference"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/german-center-for-open-source-ai",
    "ideas_content": "The following is the list of projects (alphabetical order) that are confirmed to be participating under GC.OS umbrella\nin GSoC 2026. Please refer to the links for more details on each project and the application process.\n\n* [`pgmpy` project ideas 2026](https://github.com/pgmpy/pgmpy/wiki/GSoC-2026-Project-Ideas)\n* [`pyGAM` project ideas 2026](https://github.com/gc-os-ai/mentoring-projects/blob/main/2026/pyGAM.md)\n* [`pytorch-forecasting` project ideas 2026](https://github.com/sktime/mentoring/blob/main/internships/projects_2026.md#pytorch-forecasting-and-dsipts)\n* [`skpro` project ideas 2026](https://github.com/sktime/mentoring/blob/main/internships/projects_2026.md#skpro)\n* [`sktime` project ideas 2026](https://github.com/sktime/mentoring/blob/main/internships/projects_2026.md#sktime)"
  },
  {
    "name": "Fortran-lang",
    "slug": "fortran-lang",
    "tagline": "High-performance parallel programming language",
    "description": "Fortran-lang is an open-source community that develops tools and libraries for modern Fortran development. Our flagship projects include the standard library, Fortran build system and package manager, as well as the interactive compiler, LFortran. Fortran-lang also provides an inclusive and welcoming space for all Fortran enthusiasts around the world to collaborate.",
    "ideas_url": "https://github.com/fortran-lang/webpage/wiki/GSoC-2026-Project-ideas",
    "website_url": "https://fortran-lang.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "c++",
      "fortran"
    ],
    "topic_tags": [
      "compilers",
      "programming languages",
      "build systems",
      "libraries",
      "Fortran"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/fortran-lang",
    "ideas_content": "<!-- This comment is not visible to the final document.\n\nNOTE: Please update the Project Index if a project is added, removed or renamed.\n\n-->\n\nWelcome to the Fortran-Lang ideas page for contributors applying for Google Summer of Code (GSoC).\nIf you are interested in applying for GSoC, see the\n[Contributor Instructions](https://github.com/fortran-lang/webpage/wiki/GSoC‐2026‐Contributor‐Instructions)\nfor more information on how to apply.\n\nThe list here is based on priorities identified by Fortran-Lang contributors and should inform you\nabout the state and direction of each project. If you are interested in an idea on this page, please\ncontact us on our [Discourse](https://fortran-lang.discourse.group/t/google-summer-of-code-2026/10674/2)\nto ask any questions and get the latest information about the project idea.\nPlease read the existing discussion(s) in any linked issues.\n\nThe project ideas on this page are grouped by the repository.\nPlease familiarize yourself with each repository before exploring the ideas here.\n\nWe are not limited to the project ideas listed on this page.\nIf you have your own project idea that is not listed here, let us know.\n\nContacts for prospective mentors: [Mentors list](https://github.com/fortran-lang/webpage/wiki/GSoC-2026-Mentors)\n\n## Project Index\n\n- fpm - Fortran Package Manager\n  - [Version Constraint Resolution](#version-constraint-resolution-fpm)\n  - [Build Process Enhancements](#build-process-enhancements-fpm)\n  - [Extended Testing Support](#extended-testing-support-fpm)\n  - [Export build order and `compile_commands.json`](#export-build-order-and-compile_commandsjson-fpm)\n  - [Support of external third-party preprocessors](#support-of-external-third-party-preprocessors)\n- stdlib - Fortran Standard Library\n  - [File system library](#file-system-library-stdlib)\n  - [Library to work with OS processes](#library-to-work-with-os-processes-stdlib)\n  - [Linear algebra and sparse matrices](#linear-algebra-and-sparse-matrices-stdlib)\n  - [String to number conversion](#string-to-number-conversion-stdlib)\n- LFortran\n  - [Compile any Fortran code](#compile-any-fortran-code-LFortran)\n  - [Compile neural-fortran using LFortran](#compile-neural-fortran-using-LFortran)\n  - [Compile benchmarking code written in Fortran with LFortran and improving LFortran's performance on these benchmarks](#compile-benchmarking-code-written-in-fortran-with-lfortran-and-improving-lfortrans-performance-on-these-benchmarks-lfortran)\n  - [Allow running Fortran in the browser](#allow-running-fortran-in-the-browser-lfortran)\n  - [Implementation of features on the ASR and LLVM level](#Implementation-of-features-on-the-ASR-and-LLVM-level-lfortran)\n  - [Other LFortran ideas](#other-lfortran-ideas-lfortran)\n- fortls - Fortran Language Server\n  - [MPI support](#mpi-support-fortls)\n  - [Semantic highlighting and collapsable scopes](#semantic-highlighting-and-collapsable-scopes-fortls)\n  - [Replace explicit LSP interface with pygls](#replace-explicit-lsp-interface-with-pygls-fortls)\n- vscode-fortran-support - Modern Fortran for VS Code\n  - [Python environment manager](#python-environment-manager-vscode-fortran-support)\n  - [vscode integration with fpm](#vscode-integration-with-fpm-vscode-fortran-support)\n- Other\n  - [Standard Conformance Suite](#standard-conformance-suite)\n  - [Coarray Fortran Framework of Efficient Interfaces to Network Environments (Caffeine)](#coarray-fortran-framework-of-efficient-interfaces-to-network-environments-caffeine)\n  - [Get fortran-lang/minpack to be used in SciPy](#get-fortran-langminpack-to-be-used-in-scipy)\n  - [Improving fastGPT: Making it Faster, Easier to Use, and More General](#improving-fastgpt-making-it-faster-easier-to-use-and-more-general)\n  - [Fortran Graphics Library](#fortran-graphics-library)\n  - [Improved generation of Fortran interfaces for PETSc](#improved-generation-of-fortran-interfaces-for-petsc)\n\n-----\n\n## Version Constraint Resolution (fpm)\n\nThe current decentralized package system in fpm allows dependencies to be fetched via a git repository URL. As part of this, a git tag or commit can be given to require a specific version of a dependency. There is however no way of specifying version compatibility requirements (_e.g._ `>= 1.0.0, <2.0.0`) and no way to resolve such requirements across a dependency tree.\n\nThis project will involve:\n\n- Defining a manifest syntax for version compatibility matching\n- Implementing support in fpm for solving a set of version compatibility constraints\n\nA possible approach would be to interface with an existing satisfiability solver such as:\n\n- [libsolv](https://github.com/openSUSE/libsolv):\n  interface via `iso_c_binding` as a separate fpm package\n\n__See also:__ existing options for version matching syntax:\n\n- [conda](https://docs.conda.io/projects/conda-build/en/latest/resources/package-spec.html#package-match-specifications)\n- [npm](https://docs.npmjs.com/about-semantic-versioning/)\n- [cargo](https://doc.rust-lang.org/cargo/reference/specifying-dependencies.html)\n\n__Expected outcomes:__ Implemented a working version constraint mechanism in fpm\n\n__Skills preferred:__ Fortran programming, experience with one or more build systems\n\n__Difficulty:__ Intermediate, 350 hours\n\n__Mentors:__\nBrad Richardson ([@everythingfunctional](https://github.com/everythingfunctional)),\nSebastian Ehlert ([@awvwgk](https://github.com/awvwgk)), Umashankar Sivakumar ([@usivakum](https://github.com/usivakum))\n\n\n## Build Process Enhancements (fpm)\n\nFortran Package Manager (fpm) is pivotal for long-term Fortran success. This GSoC project aims to improve fpm’s build process by improving dependency detection, optimizing linking, implementing shared libraries, ensuring safe concurrent builds, and introducing external Makefile generation.\n\nThe project will address the following tasks:\n1. **Custom flags and configurations**\n     - Implement custom and compiler-dependent flags, and configurations \n2. **External build system Generation:**\n     - Enable generation of external Makefiles akin to `cmake -G` for advanced project configuration.\n3. **Linking Optimization:**\n     - Replace one-liner linking with static libraries to prevent line buffer overflow in Windows builds.\n4. **Shared Library Implementation:**\n     - Introduce support for shared library targets for project flexibility.\n5. **Dependency Detection**:\n     - Enhance fpm’s dependency detection to minimize rebuilds by parsing or hashing module/submodule files or parsing procedure interfaces in module files. fpm should not rebuild dependencies to a module whose public interface has not changed.\n\n__Expected Outcomes__:\n* Enhanced dependency tracking and reduced rebuild times.\n* Improved reliability in linking, particularly in Windows.\n* Increased project versatility with shared library support.\n* Safer concurrent builds through file locking.\n* Greater project configuration flexibility with external Makefile generation.\n\n**Difficulty:** Intermediate, 175 hours.\n\n**Skills preferred:** Fortran programming, experience with one or more build systems\n\n**Mentors:**\nFederico Perini ([@perazz](https://github.com/perazz)), José Alves ([@jalvesz](https://github.com/jalvesz)), Henil Panchal ([@henilp105](https://github.com/henilp105))\n\n## Extended Testing Support (fpm)\n\nThe aim of this project is to create a manifest specification to provide defaults to executable targets in fpm projects.\nInformation can be passed as environment variables, command-line arguments or as a runner.\nDesired features include:\n\n- Programs should have a way to find resources of which the relative position within the project source directory is known.\n- The current binary directory to access other targets within a project.\n- Default runners like `mpirun`/`cafrun` or scripts from test frameworks should be usable to launch programs.\n- A general syntax to define environment variables and command-line arguments should be defined.\n\nSome features should be implemented directly in fpm, while more elaborated functionality could be implemented in a separate fpm package as an official Fortran-lang fpm package.\n\n__Related issues:__\n- [fpm#179](https://github.com/fortran-lang/fpm/issues/179): Testing with fpm test\n\n__Related discussions:__\n- [fpm#328](https://github.com/fortran-lang/fpm/discussions/328): Example which requires external data\n\n__Expected outcomes:__ fpm has broader and deeper testing functionality\n\n__Skills preferred:__ Fortran programming and writing unit tests\n\n__Difficulty:__ Easy, 175 hours\n\n__Mentors:__\nSebastian Ehlert ([@awvwgk](https://github.com/awvwgk)),\nBrad Richardson ([@everythingfunctional](https://github.com/everythingfunctional))\n\n## Export build order and `compile_commands.json` (fpm)\n\n`fpm` has the ability to automatically determine the build order of a project's\nsource files. This information is valuable to third party tools such as\nlanguage servers and code analysis tools. The goal of this project is to\nexport the build order of a project's source files in the `compile_commands.json`.\n\nThe second leg of this project is to implement the full syntax of\n`compile_commands.json` as described in the [Clang documentation](https://clang.llvm.org/docs/JSONCompilationDatabase.html). This would bring `fpm` a step closer\nto being compatible with other build tools.\n\n**Expected outcomes:** `fpm` will export a complete `compile_commands.json` file.\n\n**Skills preferred:** Fortran programming, experience with one or more build systems\n\n**Difficulty:** Hard, 350 hours\n\n**Mentors**:\nGiannis Nikiteas ([@gnikit](https://github.com/gnikit))\n\n## Support of external third-party preprocessors\n\nAdding support for external third-party preprocessors is important for fpm due to the additional flexibility they provide when building complex packages.\nIn particular, the Fortran-lang [stdlib](https://github.com/fortran-lang/stdlib) project exploits the powerful [fypp](https://github.com/aradi/fypp) preprocessor for code generation and the support of fypp by fpm is required for stdlib to eventually be compatible as an fpm package.\n\nThis project will require to:\n\n- Modify fpm to optionally invoke a third-party preprocessor before compiling sources;\n- Extend the current manifest syntax of fpm for defining preprocessor variables in a preprocessor-independent manner, if necessary;\n- Extend the current manifest syntax of fpm for specifying a third-party preprocessor and the corresponding file suffixes, if necessary;\n- Passe defined preprocessor variables to built-in preprocessors if necessary;\n\nThird-party preprocessors should be specified on a per-project basis, _i.e._ multiple preprocessors might be required, and fpm should be able to report useful errors for missing third-party preprocessors.\n\n__Related issues:__\n- [fpm#78](https://github.com/fortran-lang/fpm/issues/78): support for third-party preprocessors (_e.g._ fypp)\n- [fpm#308](https://github.com/fortran-lang/fpm/issues/308): Fortran-based smart code generation in fpm\n- [fpm#469](https://github.com/fortran-lang/fpm/issues/469): Source pre-processing prior to determining dependencies\n\n__Expected outcomes:__ fpm has a working preprocessing capability\n\n__Skills preferred:__ Fortran, C, or Python programming, experience using one or more preprocessors\n\n__Difficulty:__ easy, 175 hours\n\n__Mentors:__ \nLaurence Kedward ([@lkedward](https://github.com/lkedward)),\nMilan Curcic ([@milancurcic](https://github.com/milancurcic)),\nFederico Perini ([@perazz](https://github.com/perazz)),\nJeremie Vandenplas ([@jvdp1](https://github.com/jvdp1))\n\n\n## File system library (stdlib)\n\nCurrently, file system operations such as listing contents of directories, traversing directories, and similar,\nare restricted to 3rd party libraries and compiler extensions that are platform-specific and not portable.\nThis project will entail designing and implementing a cross-platform solution for file system operations.\n\n__Related issues:__\n- [stdlib#201](https://github.com/fortran-lang/stdlib/issues/201): File system operations\n- [stdlib#220](https://github.com/fortran-lang/stdlib/issues/220): API for file system operations, directory manipulation\n\n__WIP implementation:__\n- [stdlib_os](https://github.com/MarDiehl/stdlib_os)\n\n__Expected outcomes:__ Implemented an stdlib module that provides cross-platform file-system utilities\n\n__Skills preferred:__ Fortran and C programming, experience using Linux, macOS, and Windows\n\n__Difficulty:__ Intermediate, 350 hours\n\n__Mentors__:\nArjen Markus ([@arjenmarkus](https://github.com/arjenmarkus)),\nMilan Curcic ([@milancurcic](https://github.com/milancurcic))\n\n## Library to work with OS processes (stdlib)\n\nCross-platform solution to abstract POSIX and Windows API for creating subprocesses.\n\n__Related issues:__\n- [stdlib#22](https://github.com/fortran-lang/stdlib/issues/22): Interface to POSIX I/O API\n- [stdlib#308](https://github.com/fortran-lang/stdlib/issues/308): Subprocesses and Multiprocessing\n\n__Discourse thread:__\n- [Ideas for command module](https://fortran-lang.discourse.group/t/ideas-for-command-module/439)\n\n__Skills preferred:__ Fortran and C programming, experience using Linux, macOS, and Windows\n\n__Difficulty:__ Intermediate, 350 hours\n\n__Mentors:__ Sebastian Ehlert ([@awvwgk](https://github.com/awvwgk))\n\n## Linear algebra and sparse matrices (stdlib)\n\nImprove dense and sparse linear algebra APIs in the Fortran Standard Library. \n\nThe API development should closely follow the developements on dense [linear algebra](https://stdlib.fortran-lang.org/page/specs/stdlib_linalg.html) in order to keep a coherent interface for sparse and dense matrices.\n\n__Related issue__: [#931](https://github.com/fortran-lang/stdlib/issues/931) [#930](https://github.com/fortran-lang/stdlib/issues/930) [#910](https://github.com/fortran-lang/stdlib/issues/910) [#898](https://github.com/fortran-lang/stdlib/issues/898) [#891](https://github.com/fortran-lang/stdlib/issues/891) [#763](https://github.com/fortran-lang/stdlib/issues/763) [#934](https://github.com/fortran-lang/stdlib/issues/934)\n\n__WIP implementations__: [#915](https://github.com/fortran-lang/stdlib/pull/915) [#844](https://github.com/fortran-lang/stdlib/pull/844) [FSPARSE](https://github.com/jalvesz/FSPARSE)\n\n__Expected outcomes:__ Improved linear algebra and sparse matrix functionality in the `stdlib_linalg` module\n\n__Skills preferred:__ Fortran programming, understanding of linear algebra\n\n__Difficulty:__ Hard, 350 hours\n\n__Mentors:__\nOndřej Čertík ([@certik](https://github.com/certik)),\nIvan Pribec ([@ivan-pi](https://github.com/ivan-pi/)),\nJeremie Vandenplas ([@jvdp1](https://github.com/jvdp1)),\nJose Alves ([@jalvesz](https://github.com/jalvesz)),\nFederico Perini ([@perazz](https://github.com/perazz))\n\n## String to number conversion (stdlib)\n\nThis project will enhance stdlib's string handling capabilities for fast number parsing in Fortran.\n\nRecently, a new module was added to stdlib called [`stdlib_str2num`](https://github.com/fortran-lang/stdlib/blob/master/src/stdlib_str2num.fypp) which implements fast routines for converting strings to numerical types. The participant would get familiar with these implementations and subsequently:\n\n* Create a full benchmark suite for the string to number conversion, across compiler vendors, operating systems, and CPU architectures.\n* Explore ways to improve robustness and efficiency, e.g. error handling.\n* Propose a shallow interface for the [string_type](https://github.com/fortran-lang/stdlib/blob/master/src/stdlib_string_type.fypp) facility in stdlib.\n* Propose an enhancement to the [loadtxt](https://github.com/fortran-lang/stdlib/blob/master/src/stdlib_io.fypp) facility function to speed-up file reading.\n* Depending on the advancement, the participant is also encouraged to include a roadmap for inclusion of the inverse conversion by following the intitiative in this thread [ryu-based to_string function](https://github.com/fortran-lang/stdlib/issues/627)\n\n__Relevant thread on Fortran Discrouse__: [Faster string to double](https://fortran-lang.discourse.group/t/faster-string-to-double/2208)\n\n__Expected outcomes:__ Enhancement of stdlib fast string to number conversion\n\n__Skills preferred:__ Fortran and C programming, understanding of floating-point arithmetic\n\n__Difficulty:__ Hard, 350 hours\n\n__Mentors:__\nJose Alves ([@jalvesz](https://github.com/jalvesz)),\nCarl Burkert ([@carltoffel](https://github.com/carltoffel))\nBrad Richardson ([@everythingfunctional](https://github.com/everythingfunctional)),\nIvan Pribec ([@ivan-pi](https://github.com/ivan-pi/))\n\n## Compile benchmarking code written in Fortran with LFortran and improving LFortran's performance on these benchmarks (LFortran)\n\nhttps://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/fortran.html contains all the benchmark codes written for various problems such as `n-body`, `sepctral norm`, `mandelbrot`. The workflow would involve first doing bug fixes to compile the code (modifying the input code would be okay) with LFortran and producing correct outputs. Then, improving LFortran to perform better or equivalent to other Fortran compilers such as GFortran.\n\n`n-body` already compiles with workarounds with LFortran main. See, https://github.com/lfortran/lfortran/pull/1213. More work needs to be done for other benchmark codes. \n\n\n__Expected outcomes:__ LFortran can compile as many benchmark codes as possible. Performing better than other compilers would be an additional plus.\n\n__Skills preferred:__ Fortran and C++ programming\n\n__Difficulty:__ intermediate/hard, 350 hours\n\n**Mentors** - Ondřej Čertík\n\n\n## Compile any Fortran code (LFortran)\n\nThe primary goal is to compile as many codes as possible. We have identified and listed those at [label:code-to-be-compiled](https://github.com/lfortran/lfortran/labels/Code%20to%20be%20Compiled). \n\nThis project aims to pick up a code and get it compiled to ASR, then to LLVM, binary and assure that values align with GFortran (or other Fortran compilers). We can have several of these projects at the same time.\n\n__Expected outcomes:__ LFortran can compile chosen code.\n\n__Skills preferred:__ Fortran and C++ programming\n\n__Difficulty:__ intermediate/hard, 350 hours\n\n**Mentors** - Pranav Goswami\n\n## Compile `neural-fortran` using LFortran\n\nCurrently LFortran compiles 14% of `neural-fortran`. It is a parallel framework for deep learning. \n\n__Expected outcomes:__ LFortran can compile `neural-fortran` code.\n\n__Skills preferred:__ Fortran and C++ programming\n\n__Difficulty:__ intermediate/hard, 350 hours\n\n**Mentors** - Pranav Goswami\n\n\n## Allow running Fortran in the browser (LFortran)\n\nWe have LFortran running in the browser using WASM here: https://dev.lfortran.org/, the goal of this project would be to improve the user interface. Here is a list of issues that the project can work on fixing: https://github.com/lfortran/lcompilers_frontend/issues\n\nThis project would entail working with LFortran, LLVM, Emscripten,\nand Webassembly to allow running Fortran in the browser.\n\n__Skills preferred:__ Fortran and C++ programming\n\n__Difficulty:__ intermediate, 350 hours\n\n**Mentors** - Ondřej Čertík\n\n\n## Implementation of features on the ASR and LLVM level (LFortran)\n\nThe roadmap https://gitlab.com/lfortran/lfortran/-/issues/272 issue contains a list of Fortran features that we want implemented. Each feature should be implemented at the ASR level and in the LLVM backend to be complete. If AST is missing for a given feature, then it has to be implemented also.\n\nHere you can pick a feature or a set of features from the list and propose it as a GSoC project. In other words, this project idea can accommodate multiple student projects.\n\nList of resources for more information and background:\n\n* [ASR.asdl](https://gitlab.com/lfortran/lfortran/-/blob/0391231553932e7df230c7c88bc05528d5348f85/grammar/ASR.asdl), the comment at the top explains the design motivation\n* [asr_to_llvm.cpp](https://gitlab.com/lfortran/lfortran/-/blob/0391231553932e7df230c7c88bc05528d5348f85/src/lfortran/codegen/asr_to_llvm.cpp) is the LLVM backend\n* [ast_to_asr.cpp](https://gitlab.com/lfortran/lfortran/-/blob/0391231553932e7df230c7c88bc05528d5348f85/src/lfortran/semantics/ast_to_asr.cpp) is the AST -> ASR conversion where all semantics checks are being done and compiler errors reported to the user\n* [Developer Tutorial](https://docs.lfortran.org/developer_tutorial)\n\nIf you have any questions, please do not hesitate to ask, we can discuss or provide more details.\n\n__Mentors:__\nOndrej Certik ([@certik](https://github.com/certik))\n\n## Other LFortran ideas (LFortran)\n\nMore LFortran project ideas for GSoC can be found at: <https://github.com/lfortran/lfortran/wiki/GSoC-2026-Ideas>\n\n## MPI support (fortls)\n\n`fortls` has support for Fortran intrinsics, Standard modules and OpenMP.\nIt does not however support MPI. The goal of this project is to add full support\nfor completions, hover and signature help for MPI variables, subroutines and functions.\n\nDue to the size of the MPI standard, the process of extracting the necessary\ninformation from the standard such as names, interfaces and documentation will\nbe automated. The student will be responsible for creating a scraper/parser\nto fetch the necessary information from the MPI standard and then create the\nserialised data (JSON) to be used by `fortls`.\n\n**Discourse thread:** [MPI documentation and interfaces](https://fortran-lang.discourse.group/t/mpi-documentation-and-interfaces/7252)\n\n**Expected outcomes:** `fortls` will have completion and hover support for MPI.\n\n**Skills preferred:** Python programming and understanding of Fortran\n\n**Difficulty:** Intermediate, 175 hours\n\n**Mentors**:\nGiannis Nikiteas ([@gnikit](https://github.com/gnikit))\n\n## Semantic highlighting and collapsable scopes (fortls)\n\nAs part of this project the student will add support to `fortls` for the\nSemantics Tokens request, which is used to provide improved syntax highlighting\nand the Folding Range request, which is used to provide collapsable scopes.\n\n**Related Issues:**\n\n- [fortls#56](https://github.com/fortran-lang/fortls/issues/56)\n\n**Expected outcomes:** `fortls` will serve for semantic highlighting and collapsable scopes requests.\n\n**Skills preferred:** Python programming and understanding of Fortran\n\n**Difficulty:** Intermediate, 175 hours\n\n**Mentors**:\nGiannis Nikiteas ([@gnikit](https://github.com/gnikit))\n\n## Replace explicit LSP interface with pygls (fortls)\n\n`fortls` uses explicit interfaces to the Language Server Protocol (LSP).\nTo decrease code duplication and increase maintainability, the work of\nmaintaining the explicit interfaces should be replaced with the use of\n`pygls`' module.\n\n**Related Issues:**\n\n- [fortls#96](https://github.com/fortran-lang/fortls/issues/96)\n\n**Expected outcomes:** `fortls` uses `pygls`' to define LSP interfaces, types and requests.\n\n**Skills preferred:** Python programming and understanding of the Language Server Protocol\n\n**Difficulty:** Hard, 350 hours\n\n**Mentors**:\nGiannis Nikiteas ([@gnikit](https://github.com/gnikit))\n\n## Python environment manager (vscode-fortran-support)\n\nIn the Modern Fortran for VS Code extension, the use of Python as a means to\ninstall third party tools is essential. The goal of this project is to\ncreate a robust Python environment manager for installing and running third\nparty tools such as `fortls`, `fpm`, `findent`, etc., taking into account\nthe user's setup (venv, conda, system Python, etc.).\n\n**Expected outcomes:** Modern Fortran for VS Code will have a robust Python environment manager for installing and running third party tools.\n\n**Skills preferred:** Typescript, Python programming\n\n**Difficulty:** Hard, 175 hours\n\n**Mentors**:\nGiannis Nikiteas ([@gnikit](https://github.com/gnikit))\n\n## vscode integration with fpm (vscode-fortran-support)\n\nThe goal of this project is to allow `fpm` integration with the Modern Fortran\nextension for Visual Studio Code, similar to how CMake and Meson are integrated\nin VS Code.\n\nUsing an Activity bar icon, the user will be able to build and run projects,\ntests and examples. The student will be responsible for creating the GUI\nintegration and the necessary backend to communicate with `fpm`.\n\n**Expected outcomes:** Modern Fortran for VS Code will have a GUI integration\nwith `fpm` to build and run projects, tests and examples.\n\n**Skills preferred:** Typescript, Fortran programming\n\n**Difficulty:** Hard, 350 hours\n\n**Mentors**:\nGiannis Nikiteas ([@gnikit](https://github.com/gnikit))\n\n## Standard Conformance Suite\n\nFortran compilers' support for ISO Fortran standards generally lag the publication of the standard by\nseveral years or longer.  Fortran consultants Ian Chivers and Jane Sleightholme periodically publish\na [paper](https://dl.acm.org/doi/10.1145/3432987.3432991) containing a table detailing the standard\nfeatures supported by 10 compilers.  Gathering the tabulated data requires a considerable amount of\neffort on the part of the authors and the compiler developers.  The chosen venue for publishing the \ntable also puts it behind a paywall: access requires a subscription to ACM SIGPLAN Fortran Forum.\nThe project will automate the generation of the table, make it more detailed and empower the community to contribute to\nby submitting small tests to an open-source conformance test suite.\n\n__Prior work:__\n- [fortran-compiler-tests](https://github.com/nncarlson/fortran-compiler-tests)\n- [flibs chkfeatures](https://sourceforge.net/p/flibs/svncode/HEAD/tree/trunk/chkfeatures/)\n- [Defunct](https://github.com/sourceryinstitute/Defunct)\n- [Fortran Testsuite Proposal](https://github.com/j3-fortran/fortran_proposals/issues/57)\n\n__Expected outcomes:__ A comprehensive test suite that generates a report of standard conformance for any Fortran compiler.\nThe suite is not expected to be 100% complete by the end of the project, but should be significant in terms of standard coverage.\n\n__Skills preferred:__ Fortran programming, experience reading and interpreting the Fortran Standard, and writing tests\n\n__Difficulty:__ Hard, 350 hours\n\n__Mentors:__\nDamian Rouson ([@rouson](https://github.com/rouson)),\nArjen Markus ([@arjenmarkus](https://github.com/arjenmarkus)),\nOndřej Čertík ([@certik](https://github.com/certik))\n\n## Coarray Fortran Framework of Efficient Interfaces to Network Environments ([Caffeine](https://github.com/berkeleylab/caffeine))\n\nThis project would add support for grouping images (parallel processes) into teams that allow submodes to execute independently.\nCaffeine 0.1.0 uses the [GASNet-EX](https://go.lbl.gov/gasnet) networking middleware software as a back end for supporting most of the non-coarray parallel features of Fortran 2018 except for the intrinsic derived `team_type` and related features.\nWork is underway to support the coarray features that most applications will need for expressing custom parallel algorithms.\nThe teams feature set is the one significant non-coarray parallel group of features not yet implemented in Caffeine.\n\n__Expected outcomes:__ Caffeine can be used to create images groups in execution parallel programs\n\n__Skills preferred:__ Fortran and C programming\n\n__Difficulty:__ Intermediate, 175 hours\n\n__Mentors:__ Damian Rouson ([@rouson](https://github.com/rouson))\n\n## Get fortran-lang/minpack to be used in SciPy\n\n[fortran-lang/minpack #14](https://github.com/fortran-lang/minpack/issues/14)\n\nThe participant would work with Fortran-lang and SciPy teams toward implementing\nfortran-lang/minpack in SciPy.\n\n__Expected outcomes:__ fortran-lang/minpack is incorporated into SciPy.\n\n__Skills preferred:__ Fortran-C interop, Python programming\n\n__Difficulty:__ Easy, 175 hours\n\n__Mentors:__ Sebastian Ehlert ([@awvwgk](https://github.com/awvwgk))\n\n## Improving fastGPT: Making it Faster, Easier to Use, and More General\n\nThe [fastGPT](https://github.com/certik/fastGPT) project is a Fortran implementation of GPT-2 that is comparable in speed to PyTorch. Although it is already very fast on CPUs, there is still room for improvement in terms of usability and performance on CPU and other architectures, such as GPUs.\n\nThis project aims to explore various aspects of fastGPT to improve its usability and performance. Some potential areas of exploration include:\n\n*   *Parallelism*: Investigate the use of parallelism in fastGPT, including MPI and coarrays, to potentially make it even faster. Given that GPT inference is dominated by large matrix-matrix multiplications over a few layers, we will carefully investigate which parallel approach is the best (whether MPI, coarrays, OpenMP or just parallel BLAS that we already have).\n\n*   *Reduced precision models*: Experiment with using reduced precision models (e.g., 16-bit or 8-bit floats) instead of the default 32-bit to potentially speed up inference.\n\n*   *GPU acceleration*: Explore how to optimize fastGPT for GPU architectures to potentially make it even faster.\n\n*   *UI improvements*: Add a chat mode (similar to chatGPT). Explore how to make it easier to use as a grammar checker, or creating summaries, or other areas where GPT-2 is strong. Make it a nice Fortran library, installable using fpm, usable in other projects. Investigate how to use it with the `neural-fortran` project.\n\n__Expected outcomes:__ Create an improved fastGPT implementation that is faster, easier to use, and more general.\n\n__Skills preferred:__ Fortran, linear algebra\n\n__Difficulty:__ Intermediate, 175 hours\n\n__Mentors:__\nOndřej Čertík ([@certik](https://github.com/certik)),\nMilan Curcic ([@milancurcic](https://github.com/milancurcic))\n\n## Fortran Graphics Library \n\nFortran does not have native graphics handling capabilities. While several bindings interfacing Fortran to graphics and plotting libraries are available (e.g., [f03gl](https://www-stone.ch.cam.ac.uk/pub/f03gl/index.xhtml), [sdl](https://github.com/interkosmos/fortran-sdl2), [pyplot](https://github.com/jacobwilliams/pyplot-fortran), [dislin](https://www.dislin.de/exa_f90.html#section_12d), [plplot](https://plplot.sourceforge.net) ), no up-to-date open-source graphics package with a pure, modern Fortran API is available. \n\nThe aim of this project is to lay out the basics of an object-oriented \"canvas\" representation in object-oriented Fortran. The contributor would implement, document, and test basic graphics classes (2d points, lines, brushes, etc.), an abstract graphics canvas API with backends to both file and graphics devices (i.e., bitmap, PNG, OpenGL, SVG, etc.) The outcome of this project would be a contribution to the development of a platform-agnostic graphics library for Fortran.  \n\n__Expected outcomes:__ Design and implement classes for 2d graphics primitives, a unified graphics canvas API, and several backend implementations.\n\n__Skills preferred:__ Fortran, C, 2D graphics basics \n\n__Difficulty:__ Intermediate, 350 hours\n\n__Mentors:__\nFederico Perini ([@perazz](https://github.com/perazz))*\n\n## Improved generation of Fortran interfaces for PETSc\n\n[PETSc](https://petsc.org), the Portable, Extensible Toolkit for Scientific Computation, pronounced PET-see, is for the scalable (parallel) solution of scientific applications modeled by partial differential equations (PDEs).\nIt has bindings for C, Fortran, and Python (via petsc4py). PETSc also contains TAO, the Toolkit for Advanced Optimization, software library. It supports MPI, and GPUs through CUDA, HIP, Kokkos, or OpenCL, as well as hybrid MPI-GPU parallelism; it also supports the NEC-SX Tsubasa Vector Engine.\n\nCurrently, only a part of the Fortran interfaces can be generated automatically using [bfort](http://wgropp.cs.illinois.edu/projects/software/sowing/bfort/bfort.htm).\nSince the manual generation of the remaining interfaces is tedious and error prone, this project is about an improved generation of Fortran interfaces from PETSc's C code.\n\nThe main tasks of this project are\n\n * Definition of a robust and future-proof structure for the Fortran interfaces\n * Selection and/or development of a tool that creates the interfaces automatically\n\n\nMore specifically, the first task is about finding a suitable structure of the C-to-Fortran interface that reduces the need of 'stubs' on the C and Fortran side making use of modern Fortran features where appropriate.\nThis task will involve evaluating different approaches found in other projects taking into account the object-oriented approach of PETSc.\nPrototypes will be implemented manually and evaluated with the help of the PETSc community.\nThe second task is then the automated generation of the Fortran interfaces using the approach selected in the first task.\nTo this end, it will be evaluated whether an extension of bfort, the use of another existing tool, or the development of a completely new tool (probably in Python) is the most suitable approach.\n\n**Links**:\n\n * [PETSc](https://petsc.org)\n * [bfort](http://wgropp.cs.illinois.edu/projects/software/sowing/bfort/bfort.htm)\n * [Fortran Wiki: Generating C Interfaces](https://fortranwiki.org/fortran/show/Generating+C+Interfaces)\n * [Fortran Discourse: ISO_C_binding](https://fortran-lang.discourse.group/t/iso-c-binding-looking-for-practical-example-of-how-it-helps-with-mangling/3393)\n\n**Expected outcomes**: Stable and robust autogeneration of Fortran interfaces for PETSc that works for almost all routines\n\n**Skills preferred**: Programming experience in multiple languages, ideally C and/or Fortran\n\n**Difficulty**: Intermediate, 350 hours\n\n**Mentors**: Martin Diehl ([@MarDiehl](https://github.com/MarDiehl)), Ivan Pribec ([@ivan-pi](https://github.com/ivan-pi))"
  },
  {
    "name": "BRL-CAD",
    "slug": "brl-cad",
    "tagline": "3D CAD & other computer-aided tech (CAx)",
    "description": "<p>This is the place to be if you love computer graphics.  We do 2D/3D modeling, 3D printing, solid geometry, design, and more.  Depending on the project, you have the opportunity to work with C/C++, Python, OpenGL, OpenCL, Qt, Javascript, and more...  Help us develop open source computer-aided technologies (CAx)!</p>\n<br>\n<p>We operates as an umbrella organization with several CAx communities including:</p>\n<br>\n<ul>\n<li> - OpenSCAD is a solid 3D modeler with a rich syntax for programmable geometry.\n<li> - LibreCAD is a 2D modeling system specializing in blueprint-style drawings and draftings.\n<li> - IfcOpenShell is a library for working with standard IFC building model data.\n<li> - BRL-CAD is a solid modeling suite with conversion and advanced solid ray tracing features.\n<li> - Manifold is a solid geometry mesh processing library.\n</ul>\n<br>\n<p>We want to select at least one student for each, so feel free to ask us where to start.</p>\n<br>\n<a href=\"https://opencax.github.io\"><img src=\"https://summerofcode.withgoogle.com/media/org/brl-cad/4ec07aqdfrvygfed-360.png\"></a>",
    "ideas_url": "https://github.com/opencax/GSoC/issues?q=is%3Aissue+is%3Aopen+label%3A%22GSoC+2026%22",
    "website_url": "https://opencax.github.io/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "c/c++",
      "opengl",
      "opencl",
      "scripting"
    ],
    "topic_tags": [
      "geometry",
      "2d/3d graphics",
      "ray tracing",
      "high-performance computing",
      "deep neural net rendering"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/brl-cad",
    "ideas_content": "We read every piece of feedback, and take your input very seriously.\n\nTo see all available qualifiers, see our documentation."
  },
  {
    "name": "JBoss Community",
    "slug": "jboss-community",
    "tagline": "Community of projects around JBoss Middleware",
    "description": "JBoss Community is a community of open source projects. The community hosts a diverse set of projects that are written in various programming languages. The primary language is Java, however there are also projects that are written in Go, Rust, Ruby, PHP, Node and other languages.\n\nProject categories range from application servers, microservices, IOT, cloud technologies, web frameworks et cetera",
    "ideas_url": "https://spaces.redhat.com/spaces/GSOC/pages/750884772/Google+Summer+of+Code+2026+Ideas",
    "website_url": "http://www.jboss.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "java",
      "react",
      "golang",
      "cloud"
    ],
    "topic_tags": [
      "artificial intelligence",
      "iot",
      "cloud",
      "microservices",
      "kubernetes"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/jboss-community",
    "ideas_content": "The JBoss Community is planning to participate in Google Summer of Code in 2026.\n\nAll contributors & developers are welcome to participate in the [https://summerofcode.withgoogle.com/](https://summerofcode.withgoogle.com/) program with the JBoss Community.\n\nIf you are a contributor looking forward to participating in the GSoC 2026 with the JBoss Community:\n\n- Feel free to browse the growing idea list below.\n- Please don't hesitate to contact the mentor(s) indicated in the proposal for any related clarification and to discuss proposals.\n- You can have a look at\n[ideas list of previous years](https://spaces.redhat.com/display/GSOC/GSOC+-+Google+Summer+Of+Code)for inspiration. - Please see our\n[contributor guide](https://spaces.redhat.com/display/GSOC/Google+Summer+of+Code+-+contributor+guide). - You may find a sample GSoC proposal document\n[here](https://spaces.redhat.com/display/GSOC/Google+Summer+of+Code+2021+Ideas?preview=/81428506/84871584/Sample%20GSoC%20proposal%20document.pdf)which was for[this](https://docs.jboss.org/display/GSOC/Google+Summer+of+Code+2020+ideas#GoogleSummerofCode2020ideas-Knative-AlternativeKnativeBrokerImplementationbasedonApacheKafka)idea.\n\nContributors: Please read the list above and also read our [contributor guide](https://spaces.redhat.com/display/GSOC/Google+Summer+of+Code+-+contributor+guide).\n\nA note to mentors\n\nMENTORS: Red Hat employees can change this page directly to add ideas. Please be extra careful to not get other mentors' edits discarded.\n\nRed Hatters should have linked their [jboss.org](http://jboss.org) account with Red Hat and can be checked on [https://sso.jboss.org/login](https://sso.jboss.org/login)\n\nNon-Red Hatters can add a comment to the page and admins will make sure the idea is added to the page.\n\n__Table of Contents__\n\n__Administrators and Mentors__\n\nWe will list the potential mentors in this place. For now, if you have any questions, please contact the GSoC administrators:\n\nGeorge Zaronikas ([gzaronikas](https://developer.jboss.org/people/gzaronikas)) and Sokratis Zappis (szappis AT redhat DOT com)\n\n__Communication channels__\n\nGitter : [JBossOutreach/GSoC - Gitter](https://gitter.im/JBossOutreach/GSoC)\n\nPlease take note - These channels are about generic doubts. For project-specific doubts you will need to contact project mentors and channels specified in the project description.\n\n__Idea template (for mentors)__\n\n### Project title\n\n\n**Summary of idea:**\n\n-Idea\n\n-Feature A\n\n-Feature B\n\nKnowledge prerequisite: Languages/Technologies goes here\n\nGithub repo:\n\nProject size: medium (~175 hours) or large (~350 hours)\n\nSkill level: Beginner/Intermediate/Advanced\n\nContact(s) / potential mentor(s): Mentor(s) name and contact details\n\nAssociated JBoss community project(s):\n\n__Idea Proposals__\n\n**WildFly Elytron - Add support for Kubernetes TLS secrets, for use in the WildFly application server**\n\n**Summary of idea:**\n\nKubernetes TLS secrets are used to secure traffic between users and services. These secrets are represented by PEM files, which can be mounted into the container. The goal of this project is to add the ability to load these secrets into the WildFly application server and use them to secure applications with TLS. The code submitted for this project should not be AI generated.\n\nKnowledge prerequisite: good experience with Java, Maven, Git\n\nGithub repo: [https://github.com/wildfly-security/wildfly-elytron](https://github.com/wildfly-security/wildfly-elytron)\n\nOther useful links:\n\nProject size: medium (~175 hours)\n\nSkill level: Intermediate\n\nContact(s) / potential mentor(s): Darran Lofthouse <darran.lofthouse@[jboss.com](http://jboss.com)>, Diana Krepinska <dvilkola@[ibm.com](http://ibm.com)>\n\nAssociated JBoss community project(s): WildFly, WildFly Elytron\n\n**Debezium source connector for Milvus **\n\n**Debezium source connector for Milvus**\n\n**Summary**: Milvus is a cloud‑native vector database widely used for high‑performance similarity search at scale. As of today, there is no Debezium source connector for Milvus; existing integrations focus on sinks into Milvus (e.g., Debezium Server Milvus sink). This project proposes a Debezium Source Connector for Milvus that reads Milvus’ ordered change stream (insert/delete and related DDL), converts it into Debezium’s standard change event envelope, and publishes it which enables downstream processing, multi‑cluster replication, audit trails, and hybrid pipelines that combine vector and relational data.\n\n\n**Features**:\n\n- Initial blocked Snapshot\n\n- Schema Handling\n\n- evaluate CDC strategies:\n\n- emit CDC events from Woodpecker WAL\n\n- emit CDC events using Milvus metadata (etcd)\n\n**Knowledge prerequisite**: Java Language, Databases, Vector Database\n\n**Github repo**: [https://github.com/debezium](https://github.com/debezium)[ ](https://github.com/debezium/)\n\n**Project size**: large (~350 hours)\n\n**Skill level**: Intermediate\n\n**Contact(s) / potential mentor(s)**:\n\n- Giovanni Panice <\n[gpanice@ibm.com>](mailto:gpanice@ibm.com)([kmos](https://github.com/kmos))\n\n- Vincenzo Santonastaso <\n[vincenzo.santonastaso@ibm.com>](mailto:vincenzo.santonastaso@ibm.com)([vsantona](https://github.com/vsantona))\n\nAssociated JBoss community project(s): [https://debezium.io/](https://debezium.io/)\n\n**Debezium source connector for SQLite **\n\n**Debezium source connector for SQLite**\n\n**Summary**: SQLite is a lightweight, in-memory relational database widely used in desktop, mobile, and edge/IoT applications. This project proposes a Debezium Source Connector for SQLite that captures table contents and ongoing mutations via a robust snapshot‑then‑incremental strategy, converts them into Debezium’s standard change‑event envelope, and publishes the stream to Kafka or Debezium Server targets. The connector will enable downstream processing, audit trails, observability for local data lifecycles, and edge‑to‑cloud pipelines; it also unlocks hybrid architectures that combine changes from SQLite with events from cloud data stores and services.\n\n*Features*:\n\n- Initial blocked Snapshot\n\n- Schema Handling\n\n- Streaming CDC event from WAL files\n\n\n**Knowledge prerequisite**: Java Language, Databases, Vector Database\n\n**Github repo**: [https://github.com/debezium/](https://github.com/debezium/)\n\n**Project size**: large (~350 hours)\n\n**Skill level**: Intermediate\n\n**Contact(s) / potential mentor(s)**:\n\n- Giovanni Panice <\n[gpanice@ibm.com>](mailto:gpanice@ibm.com)([kmos](https://github.com/kmos))\n\n- Vincenzo Santonastaso <\n[vincenzo.santonastaso@ibm.com>](mailto:vincenzo.santonastaso@ibm.com)([vsantona](https://github.com/vsantona))\n\nAssociated JBoss community project(s): [https://debezium.io/](https://debezium.io/)\n\n**Debezium CLI **\n\n**Debezium CLI**\n\n**Summary**: A unified Debezium CLI would provide developers and operators with a streamlined way to create, manage, and monitor CDC pipelines across heterogeneous data systems. Today, Debezium offers powerful CDC capabilities, but managing connectors, configurations, state, and observability is available only under the Debezium Platform. This project proposes a dedicated command‑line interface that simplifies pipeline lifecycle operations, exposes monitoring insights, and enables consistent workflows for both local development and production environments. By offering intuitive commands for provisioning connectors, validating configurations, and diagnosing issues, the CLI would significantly improve usability and operational efficiency.\n\n\n**Features**:\n\n- Build & prepare the environment for CDC\n\n- Execute CDC pipeline\n\n- Monitor CDC pipeline\n\n**Knowledge prerequisite**: Java Language, UI, DX\n\n**Github repo**: [https://github.com/debezium](https://github.com/debezium)[ ](https://github.com/debezium/)\n\n**Project size**: large (~350 hours)\n\n**Skill level**: Intermediate\n\n**Contact(s) / potential mentor(s)**:\n\n- Giovanni Panice <\n[gpanice@ibm.com>](mailto:gpanice@ibm.com)([kmos](https://github.com/kmos))\n\n- Mario Fiore Vitale\n[<mvitale@ibm.com]> ([mfvitale](https://github.com/mfvitale))\n\nAssociated JBoss community project(s): [https://debezium.io/](https://debezium.io/)\n\n**Host-Based Pipeline Deployment for the Debezium Platform **\n\n**Host-Based Pipeline Deployment for the Debezium Platform**\n\n**Summary**: Debezium Management Platform aims to simplify the deployment of Debezium to various environments in a highly opinionated manner. To achieve this goal, the platform uses a data-centric view of Debezium components.\n\nThe Debezium Platform already defines an environment-agnostic pipeline model and supports deployment on Kubernetes via the Debezium Operator. This project extends support to running Debezium on bare metal, virtual machines, and cloud services, using Debezium Server distributions (container images and standalone packages).\n\n\nThis enables consistent deployment, lifecycle management, and operational behavior across heterogeneous environments, and unlocks hybrid architectures that span Kubernetes and non-Kubernetes infrastructures.\n\n**Features**:\n\n- Automated provisioning of target environments to prepare them for running Debezium Server\n\n- Secure remote access to target hosts for deployment and management operations\n\n- Deployment of Debezium Server using container-based runtimes\n\n- Centralized management of pipeline and runtime configuration\n\n*(Optional)*Service component exposing APIs for managing the Debezium Server lifecycle (deploy, update, stop, remove)\n\n**Knowledge prerequisite**: Java Language, SSH, Rest API, Docker\n\n**Github repo**: [https://github.com/debezium-platform](https://github.com/debezium-platform)[ ](https://github.com/debezium/)\n\n**Project size**: large (~350 hours)\n\n**Skill level**: Intermediate\n\n**Contact(s) / potential mentor(s)**:\n\n- Mario Fiore Vitale <\n[mvitale@ibm.com]> ([mfvitale](https://github.com/mfvitale))\n\n- Giovanni Panice <\n[gpanice@ibm.com](mailto:gpanice@ibm.com)>([kmos](https://github.com/kmos))\n\nAssociated JBoss community project(s): [https://debezium.io/](https://debezium.io/)\n\n**PyDebeziumAI **\n\n**PyDebeziumAI**\n\n**Summary**: AI applications frequently rely on domain specific knowledge provided via retrieval-augmented generation or a similar technique that provides access to data stored in relational databases or elsewhere.\n\nThis project should research and develop Python library that will integrate as a first-class citizen into LangChain and LangGraph libraries to provide a database-backed context that would be updated immediately after the underlying database changes.\n\nThe project should implement the necessary API/SPIs and provide a bridge between Debezium sourced and target library expected data.\n\n\n**Features**:\n\n- Published Python library\n\n- Integration with LangChain and/or LangGraph frameworks\n\n- Seamless data conversion\n\n- Multiple example applications demonstrating the usage\n\n- User and developer documentation\n\n**Knowledge prerequisite**: Python, LLM, Java\n\n**Github repo**:\n\n**Project size**: large (~350 hours)\n\n**Skill level**: Intermediate\n\n**Contact(s) / potential mentor(s)**:\n\n- Jiri Pechanec <\n[jpechane@ibm.com](mailto:jpechane@ibm.com)> ([jpechane](https://github.com/jpechane))\n\nAssociated JBoss community project(s): [https://debezium.io/](https://debezium.io/)\n\n**JBoss Web Server - Add a Diagnostic + Configuration Validation Toolkit (“jws-diag”) for JBoss Web Server**\n\n**JBoss Web Server - Add a Diagnostic + Configuration Validation Toolkit (“jws-diag”) for JBoss Web Server**\n\n**Summary of idea:** If you want to learn real-world production diagnostics, this is your chance to build a tool that saves SREs and support engineers hours per incident. As a bonus, you’ll get to work on a project that sits at the intersection of Java, Linux, TLS, and container platforms.\n\nJBoss Web Server (JWS) is Red Hat’s downstream distribution of Apache Tomcat, used widely for enterprise Java web workloads. In practice, many outages and support cases are caused not by bugs but by misconfiguration, missing visibility, and environment drift (file permissions, TLS keystores, proxy headers, native/OpenSSL setup, etc.). Operators spend time reconstructing “what is actually running” and “what configuration is effectively in use”.\n\nThe purpose of this project is to build jws-diag, a read-only diagnostic CLI that can:\n\n- produce a concise “what’s installed + what’s running” summary\n\n- compute and present effective configuration (not just raw XML)\n\n- run a set of high-value validation checks with actionable findings\n\n- optionally generate a redacted support bundle suitable for sharing**Possible tasks for this project:**\n\n- Create a short design document describing:\n\n- discovery strategy for CATALINA_BASE/HOME, systemd env overrides, container detection\n\n- internal model for connectors/TLS/proxy settings\n\n- output formats (human + JSON) and stability requirements\n\n- redaction strategy for bundle mode\n\n- Implement the core CLI commands (minimum viable set):\n\n- jws-diag summary - versions, JVM, OS/container signals, native/OpenSSL status, detected base/home\n\n- jws-diag config -parse key config (starting with server.xml) and present effective connector/TLS/proxy settings\n\n- jws-diag validate-rules engine producing INFO/WARN/ERROR findings + exit codes (0/1/2)\n\n- Implement test cases:\n\n- fixture-based XML configs (good + broken)\n\n- golden output tests (especially for JSON output)\n\n- targeted tests to ensure “no secret leaks” in output/bundles\n\n- Write documentation:\n\n- quickstart usage and examples\n\n- what data is collected, what is not collected\n\n- mapping common findings -> fixes\n\n- (Stretch goal) Implement jws-diag bundle:\n\n- produce a .tar.gz bundle with configs + version manifest (+ optional logs)\n\n- default redaction, with strict mode available\n\n- Create a blog post giving an overview of the project and how to use it in real support / ops workflows.**Knowledge pre-requisites:**\n\n- Experience with Java\n\n- Git\n\n- Maven\n\n- Basic Linux familiarity (processes, permissions, systemd)\n\n- Bonus: TLS basics and Tomcat/JWS configuration familiarity**GitHub repo:**\n\n(new repo, e.g. web-servers/jws-diag)[https://github.com/web-servers](https://github.com/web-servers)\n\n**Other useful links:**\n\n- JBoss Web Server Operator docs:\n[https://docs.redhat.com/en/documentation/red_hat_jboss_web_server/6.1/html-single/red_hat_jboss_web_server_operator/index](https://docs.redhat.com/en/documentation/red_hat_jboss_web_server/6.1/html-single/red_hat_jboss_web_server_operator/index) - Apache Tomcat:\n[https://tomcat.apache.org/](https://tomcat.apache.org/)\n\n**Project size**: Medium (~175 hours)\n\n**Skill level**: Intermediate**Contact(s) / potential mentor(s):**\n\n- Dimitris Soumis <dsoumis@redhat.com>\n\n**Associated JBoss community project(s):** JBoss Web Server, JWS Operator\n\n**Project Koku ideas**\n\n[Project Koku](https://github.com/project-koku) is a 100% open source FinOps tool that does cloud and Kubernetes costs. It is the upstream of Red Hat Lightspeed cost management. For the first time, we are participating in Google Summer of Code. Keep reading for our ideas!\n\n**Per-pod data**\n\n**Per-pod data**\n\n**Summary of idea:**\n\nCurrently Koku gathers pod-level metrics and calculates cost per pod but never exposes it. What’s exposed is the per-namespace, per-node, per-cluser and per-tag data.\n\nThis is a relatively simple project about calculating, persisting and exposing the per-pod data.\n\n**Knowledge prerequisite: **Python, SQL (PostgreSQL/Trino), TypeScript, React\n\n**GitHub repo:** [https://github.com/project-koku/koku](https://github.com/project-koku/koku), [https://github.com/project-koku/koku-ui](https://github.com/project-koku/koku-ui)\n\n**Project size:** medium (~175 hours)\n\n**Skill level: **beginner\n\n**Contact(s):** Pau Garcia Quiles <[pgarciaq@redhat.com](mailto:pgarciaq@redhat.com)>\n\n**Associated JBoss community projects:** Project Koku [https://github.com/project-koku](https://github.com/project-koku)\n\n**New perspectives**\n\n**New perspectives**\n\n**Summary of idea:**\n\nKoku provides perspectives to see all the Kubernetes clusters, all the Kubernetes clusters on cloud, all the AWS/Azure/GCP data, all the Kubernetes on AWS/Azure/GCP. A few convenient perspectives are currently missing:\n\n- All (see everything, i.e. single pane of glass for all the spend across all clouds and on-prem)\n- Kubernetes on premise\n- KubeVirt virtual machines\n- All virtual machines (cloud and KubeVirt)\n\n\nThis is a relatively easy project that encompasses several small tasks.\n\n**Knowledge prerequisite: **Python, SQL (PostgreSQL/Trino), TypeScript, React\n\n**GitHub repo:** [https://github.com/project-koku/koku](https://github.com/project-koku/koku), [https://github.com/project-koku/koku-ui](https://github.com/project-koku/koku-ui)\n\n**Project size:** medium (~175 hours)\n\n**Skill level:** beginner\n\n**Contact(s):** Pau Garcia Quiles <[pgarciaq@redhat.com](mailto:pgarciaq@redhat.com)>\n\n**Associated JBoss community projects: **Project Koku [https://github.com/project-koku](https://github.com/project-koku)\n\n**Totally effective cost distribution type**\n\n**Totally effective cost distribution type**\n\n**Summary of idea:**\n\nAs of today, Koku calculates cost by looking at how many resources each pod consumes on each node, and what was the actual cost (including discounts, savings plans, etc) of that node at each moment in time. Then it checks how the user configured the cost model: distribute based on memory usage vs distribute based on CPU usage, and distribute based on request vs usage vs effective usage (greatest of usage and request).\n\nWhile this approach works really well, it only allows cost distribution based on one dimension: either CPU or RAM.\n\nThis project is about introducing newer ways of distributing cost:\n\n- Mix of CPU and memory, user-defined. I. e. Let the user decide what’s the weight of CPU and RAM (and maybe even GPU), eg. 70% CPU, 30% RAM.\n- Distribute cost based on maximum relative usage per pod. I. e. If a pod used 20% of the RAM but 80% of the CPU, calculate cost based on CPU; if a pod used 60% of the RAM but 40% of the CPU, calculate cost based on RAM.\n- Other alternatives you might think of?\n\n\nThis project is mainly backend work, with minimal frontend requisites.\n\n**Knowledge prerequisite: **mainly Python and SQL (PostgreSQL/Trino). Minimal TypeScript and React for frontend enhancements.\n\n**GitHub repo:** [https://github.com/project-koku/koku](https://github.com/project-koku/koku), [https://github.com/project-koku/koku-ui](https://github.com/project-koku/koku-ui)\n\n**Project size:** large (~350 hours)\n\n**Skill level:** intermediate\n\n**Contact(s):** Pau Garcia Quiles <[pgarciaq@redhat.com](mailto:pgarciaq@redhat.com)>\n\n**Associated JBoss community projects:** Project Koku [https://github.com/project-koku](https://github.com/project-koku)\n\n**Enhancements to cost of cloud services**\n\n**Enhancements to cost of cloud services**\n\n**Summary of idea:**\n\nKoku does cloud, Kubernetes and Kubernetes on the cloud costs but cloud costs have never been the focus so far. Currently, cloud costs are calculated per account, per region, per service, per tag, per organizational unit, etc but they are not itemized per resource id, ie. Koku will tell you the sum of the cost of all the Azure virtual machines running in region X or the sum of all the Azure SQL database tagged T=foo.\n\nThis project is about enhancing the cloud costs experience, adding the itemized costs of as many cloud services as possible, for one or more of the three major clouds (AWS, Azure, GCP): virtual machines (AWS EC2, Amazon Lightsail, Azure Compute, Google Compute Engine), databases (AWS RDS, AWS Aurora, Azure SQL, etc), load balancers, monitoring, etc. Since there is a computation and storage cost to generate and keep data, users (tenants admins) should be able to configure what cloud services will be itemized, and which ones will be presented only as high-level aggregates.\n\nThis project is relatively straightforward but requires database skills to make cost calculations computationally sensible and keep storage to reasonable needs.\n\n**Knowledge prerequisite:** Python, SQL (PostgreSQL/Trino), TypeScript, React\n\n**GitHub repo: **[https://github.com/project-koku/koku](https://github.com/project-koku/koku), [https://github.com/project-koku/koku-ui](https://github.com/project-koku/koku-ui)\n\n**Project size: **medium (~175 hours)\n\n**Skill level:** beginner\n\n**Contact(s):** Pau Garcia Quiles <[pgarciaq@redhat.com](mailto:pgarciaq@redhat.com)>\n\n**Associated JBoss community projects:** Project Koku [https://github.com/project-koku](https://github.com/project-koku)\n\n**Support third-party Kubernetes client clusters**\n\n**Support third-party Kubernetes client clusters**\n\n**Summary of idea:**\n\nKoku is the upstream of Red Hat Lightspeed cost management, targeting Red Hat OpenShift users. While there is nothing special in the data that’s gathered, how it is gathered, how it’s processed, etc, Koku relies heavily on OpenShift conventions:\n\n- Data is gathered by a Kubernetes Operator\n[https://operatorframework.io/](https://operatorframework.io/) - It relies on a Prometheus instance being present and configured in the OpenShift way, with the right data being written to it\n- It relies on Kessel, Red Hat’s implementation of SpiceDB to run the server side of Koku\n\n\nThis complex project is about making Koku support one or more third-party Kubernetes clients: EKS, AKS, GKS, etc.\n\n**Knowledge prerequisite: **Python, SQL (PostgreSQL/Trino), TypeScript, React\n\n**GitHub repo: **[https://github.com/project-koku/koku](https://github.com/project-koku/koku), [https://github.com/project-koku/koku-ui](https://github.com/project-koku/koku-ui)\n\n**Project size: **medium (~175 hours)\n\n**Skill level: **intermediate/advanced\n\n**Contact(s):** Pau Garcia Quiles <[pgarciaq@redhat.com](mailto:pgarciaq@redhat.com)>\n\n**Associated JBoss community projects:** Project Koku [https://github.com/project-koku](https://github.com/project-koku)\n\n**Forecasting enhancements**\n\n**Forecasting enhancements**\n\n**Summary of idea:**\n\nKoku does basic forecasting based on the current and past month of data, and it only forecasts until the end of the current month. Also, it doesn’t do a great job when there’s cost anomalies.\n\nThis project is about coming up with better forecasting:\n\n- Take anomalies into account\n- Expand forecasting beyond the current month, ideally up to 12 months from the current moment\n- Forecast non-running workloads based on infrastructure requirements\n\n\nThis project could be accomplished by implementing some forecasting algorithm(s) from scratch, or by using one of the many open source libraries that exist and could serve this purpose:\n\n[Merlion](https://github.com/salesforce/Merlion), by Salesforce[Augurs](https://github.com/grafana/augurs), by Grafana[Orbit](https://github.com/uber/orbit)by Uber[Moirai (AKA uni2ts)](https://www.salesforce.com/blog/moirai/)by Salesforce (collection of models, might eventually include TimeFM)[TimeFM](https://github.com/google-research/timesfm)by Google (single model)- More?\n\nThis project is not just coding but also thinking about the best forecasting strategies that would fit the different cases, how to treat anomalies, etc.\n\n**Knowledge prerequisite: **Python, SQL (PostgreSQL/Trino), TypeScript, React\n\n**GitHub repo:** [https://github.com/project-koku/koku](https://github.com/project-koku/koku), [https://github.com/project-koku/koku-ui](https://github.com/project-koku/koku-ui)\n\n**Project size:** large (~350 hours)\n\n**Skill level:** intermediate/advanced\n\n**Contact(s):** Pau Garcia Quiles <[pgarciaq@redhat.com](mailto:pgarciaq@redhat.com)>\n\n**Associated JBoss community projects:** Project Koku [https://github.com/project-koku](https://github.com/project-koku)\n\n**Cloud governance additions**\n\n**Cloud governance additions**\n\n**Summary of idea:**\n\nKoku calculates costs for cloud, Kubernetes on cloud and Kubernetes on premise, and it even takes cloud savings plans, discounts, etc into account but it provides no governance features.\n\nThis is a relatively straightforward project about adding cloud governance features:\n\n- What savings plans, reserved instances, commitments, etc I have (per account, per region, per cloud, etc)\n- When do they end (and get warnings a few months in advance)\n- How much money I might save by moving from pay-as-you-go to reserved/savings plan/private offer\n- etc\n\n**Knowledge prerequisite: **Python, SQL (PostgreSQL/Trino), TypeScript, React\n\n**GitHub repo:** [https://github.com/project-koku/koku](https://github.com/project-koku/koku), [https://github.com/project-koku/koku-ui](https://github.com/project-koku/koku-ui)\n\n**Project size:** medium (~175 hours)\n\n**Skill level: **beginner\n\n**Contact(s): **Pau Garcia Quiles <[pgarciaq@redhat.com](mailto:pgarciaq@redhat.com)>\n\n**Associated JBoss community projects: **Project Koku [https://github.com/project-koku](https://github.com/project-koku)\n\n**Other projects**\n\n**Other projects**\n\n**Summary of idea:**\n\nDo you have a different idea for Koku? Would you like to add cost of VMware, Nutanix, Oracle Cloud, Alibaba Cloud or alike? Implement a custom report builder? Propose your own idea!\n\n**Knowledge prerequisite: **Python, SQL (PostgreSQL/Trino), TypeScript, React\n\n**GitHub repo: **[https://github.com/project-koku/koku](https://github.com/project-koku/koku), [https://github.com/project-koku/koku-ui](https://github.com/project-koku/koku-ui)\n\n**Project size: **medium (~175 hours) / large (~350 hours)\n\n**Skill level: **beginner/intermediate/advanced\n\n**Contact(s):** Pau Garcia Quiles <[pgarciaq@redhat.com](mailto:pgarciaq@redhat.com)>\n\n**Associated JBoss community projects:** Project Koku [https://github.com/project-koku](https://github.com/project-koku)"
  },
  {
    "name": "Graphite",
    "slug": "graphite",
    "tagline": "Multimedia art/design editor and graphics engine",
    "description": "Graphite is an in-development raster and vector graphics editing suite that's free and open source. It is powered by a node graph compositing engine that fuses layers with nodes, bringing a generative, procedural approach to the workflows of artists, designers, and animators ranging from students and hobbyists to creative professionals and studios.\n\nThe node-based compositing engine is built similar to a game engine. It is both a real time render pipeline and a visual programming language, complete with a custom compiler letting artists export dynamic content to other applications.\n\nOver time, Graphite intends to evolve into the \"everything app\" across every major 2D creative discipline— a versatile creation suite for graphic design, photo manipulation, digital painting, motion graphics, desktop publishing, and generative art (both procedural and AI-powered).\n\nThe five-year-old project is being rapidly developed by a global team of volunteers, composed mostly of students, who are passionate about crafting high-quality code that will transform and democratize the broader 2D creative industry.\n\nThe mission of Graphite strives to unshackle the creativity of every budding artist and seasoned professional by building the best comprehensive art and design tool that's accessible to all. Mission success will come when Graphite is an industry standard. A cohesive product vision and focus on innovation over imitation is the strategy that will make that possible.",
    "ideas_url": "https://graphite.art/volunteer/guide/student-projects/",
    "website_url": "https://graphite.art",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "rust",
      "vulkan",
      "webgpu"
    ],
    "topic_tags": [
      "compilers",
      "programming languages",
      "graphics",
      "computational geometry",
      "fonts"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/graphite",
    "ideas_content": "Graphite offers a number of opportunities for students to contribute by building a self-contained project as part of a structured format. These projects are designed to be completed over several months and are ideal for Google Summer of Code or similar internship programs, solo or group university capstone projects, and other arrangements. Each project has a distinct focus and is a great way to make a meaningful contribution to open source over the length of the program while receiving mentorship and guidance from the Graphite team.\n\nStudent projects require adherence to a set schedule with regular check-ins, milestones, and evaluations. The structured setting is designed to provide a supportive environment for students to learn and grow as developers while gaining real-world industry experience from collaborating on a sizable software product and remaining accountable to stakeholders. It's our goal to make sure you succeed!\n\nUse this [contributor guide](https://graphite.art/) to start out with the code. Then when you're ready, reach out through [Discord](https://discord.graphite.art) and use the `#🎓student-projects`\n\nchannel to discuss and work towards proposing a project with the Graphite core team.\n\n## AI contribution policy\n\nBe sure to familiarize yourself with our [AI contribution policy](https://graphite.art/starting-a-task/ai-contribution-policy) before getting involved with the Graphite code base. Proposals also must not be written by AI or else they will be rejected.\n\n## Google Summer of Code\n\nGSoC is a program offering students a [stipend](https://developers.google.com/open-source/gsoc/help/student-stipends) for successful completion of an internship-style experience with an open source organization. Read about [how it works](https://summerofcode.withgoogle.com/how-it-works/).\n\nGraphite participated in GSoC [2024](https://summerofcode.withgoogle.com/programs/2024/organizations/graphite) and [2025](https://summerofcode.withgoogle.com/programs/2025/organizations/graphite) and we anticipate doing so again in [2026](https://developers.google.com/open-source/gsoc/timeline) if our organization is accepted back. We accept year-round contributions; getting involved early is a great way to have a head start and stand out in your application in the upcoming program.\n\n### Writing a proposal\n\nWriting a good proposal is an important step that demonstrates your understanding of the project and your ability to think ahead and execute it. A well-defined plan will set you up for success throughout the rest of the program. You are encouraged to reference the project idea list below to find several potential projects suited to your experience, interest, and choice of scope. Then, you must reach out to a When it comes to writing the proposal, which you will submit to the GSoC application website, we offer some guidelines below:## For proposal writing guidelines and requirements: click here\n\n[core team member](https://graphite.art/about#core-team) through Discord to discuss your plan in detail before writing a proposal. This will help you understand the project's scope and requirements and develop a detailed timeline for your expected summer-long work schedule. Importantly, it will also help us understand your background and capabilities to offer you feedback and suggestions for the best outcome in the competitive applicant selection process.**Proposal structure:** Please consult the [Blender GSoC application template](https://developer.blender.org/docs/programs/gsoc/application_template/) as reference for our desired format. For project ideas already listed below, omit the \"Benefits\" section. Remember: don't waste your—and our—time restating information that we already know, like background info about Graphite or our tech stack; we just want to hear your thoughts and plans about what you uniquely bring to the table and how you'll execute the project. Proposals should be utilitarian, not formal, while also demonstrating your professional communication skills. Using an LLM to write your proposal won't be to your advantage.**Experience:** We're especially interested in your background and work experience, so attaching a résumé or CV is an optional but recommended way to help us understand your capabilities. If able, please also include links to past open source contributions or personal projects in the bio section. Our goal is to provide an environment for you to learn and grow as a productive software engineer and team collaborator, not to help you learn the basics of coding, so any included work examples will help us understand your potential as a self-motivated contributor to the open source community.**Work timeline:** Your goal is to write a proposal that inspires confidence in your ability to successfully complete the project, which means understanding in detail what's involved at a technical level and how you plan to tackle it. A detailed work timeline is the most important written part of your proposal. It should be broken into weekly milestones with a couple sentences of technical detail. The summary in the project idea list below doesn't give enough information to develop a timeline, so you'll need to discuss this with the core team on Discord.**Prior PRs:** The largest factor in our selection decision will be the quality and extent of your prior contributions to Graphite made during the proposal formulation period (or before, if applicable). Include a link to `https://github.com/GraphiteEditor/Graphite/commits?author=YOUR_GITHUB_USERNAME`\n\nin your proposal and feel free to write up a summary of what you've contributed and learned from the process. You may also keep contributing during the month after applications close, before we've finalized our selections, for those additional PRs to be considered.\n\n## Project idea list\n\nProjects listed below vary considerably in their required skills and technical background. Some are very research-heavy and are only suited for students with years of self-motivated learning and project development in adjacent topics. Others have a more general focus and are approachable to a wider range of students. Please pay close attention to the \"Needed Skills\" and \"Difficulty\" indicators so you don't waste your opportunity applying to a project we don't think you're a good fit for.\n\n### Graphene language bidirectional type inference\n\n*Graphene needs to implement a more powerful type system so a generic type may be inferred based on surrounding context of the type's usage constraints.*\n\n**Possible Mentors:**[Dennis](https://github.com/truedoctor)**Needed Skills:**Rust, type theory, programming languages theory, past experience implementing such a system**Project Size:**Large*(GSoC: 350 hours)***Difficulty:**Hard**Expected Outcomes:**A complete implementation to upgrade the current limited type inference system. The new system should work like Rust's, where variables of unknown types can be given a type satisfying the later usages of the variable.\n\nConsider a node with a generic input parameter which is connected to a node supplying a concrete type. As long as the type is one that satisfies the constraints of the generic parameter, this is valid. The current system checks for this single-directional constraint. But many cases arise where this is insufficient. For example, if the generic parameter is used in multiple places with different constraints, the system needs to be able to infer a type that satisfies all of those constraints. Read more about ## For additional technical details: click here\n\n[HM type inference](https://en.wikipedia.org/wiki/Hindley%E2%80%93Milner_type_system), a powerful (but potentially more complex than necessary) model. See also the [GitHub issue](https://github.com/GraphiteEditor/Graphite/issues/2350) describing this, where you can ask questions if needed. This is an advanced topic and only suitable for individuals who have already implemented a similar system in a programming language or compiler project before.\n\n### Node equivalence rewriting\n\n*A sequence of nodes may perform operations on data that can be expressed using fewer equivalent nodes, and users may often wish to perform such simplifications.*\n\n**Possible Mentors:**[Dennis](https://github.com/truedoctor)**Needed Skills:**Rust, graph theory, algorithm design**Project Size:**Large*(GSoC: 350 hours)***Difficulty:**Hard**Expected Outcomes:**A system for classifying and tracking data transformations symbolically within the DAG of the node graph. A system for applying rewrite rules to selected portions of the graph to produce an equivalent graph with fewer nodes. Integration with the editor to allow users to apply simplifications to selected nodes, especially to transforms and geometry.\n\nOftentimes, node graphs contain redundant steps that collectively perform a simpler operation. For example, two Transform nodes may produce the same result as a single Transform node with the combined transformation. Or a node that generates a star shape, then a Path node that applies a differential modification to its geometry, may be equivalent to a single Path node that produces the same geometry in one step. This project is about architecting and integrating a system for tracking classes of data transformations, like transforms or geometric modifications or appearance changes, and allowing the user to select the redundant nodes to collapse or \"bake\" them into a simpler graph with identical output. This is sort of like selecting the terms of a math expression and applying algebraic simplification rules to reduce it to its simplified form. This is best for someone with an interest towards graph theory and compiler optimization topics like ## For additional technical details: click here\n\n[E-graphs](https://en.wikipedia.org/wiki/E-graph). Additional detail is provided in the [GitHub issue](https://github.com/GraphiteEditor/Graphite/issues/2021) including some introductory explanation about E-graphs from a Rust crate that implements them, [egg](https://egraphs-good.github.io/).\n\n### Machine learning architecture\n\n*AI/ML image/vision models for content editing will need to run in Graphite's node graph with a Rust-centric, modular, portable, deployable, scalable environment.*\n\n**Possible Mentors:**[Oliver](https://github.com/otdavies)**Needed Skills:**Machine learning (and potentially: Rust, Python, ONNX, Burn)**Project Size:**Large*(GSoC: 350 hours)***Difficulty:**Hard**Expected Outcomes:**Specifics will vary by proposal. In general, a useful end-to-end integration of at least one image model into Graphite's node graph which can run both locally and deployed to a hosting provider server.\n\nAI/ML is filling a rapidly growing role in the industry as a tool in some creative processes. Graphite's procedural node-based workflow is uniquely suited to leveraging the power and flexibility of AI nodes.\n\nThe approach should be extensible to future models. It needs to run fast and natively on the assorted hardware of local user machines with hardware acceleration. It should be a one-click installation process for users to download and run models without requiring dependencies or environment setup. Ideally, it should allow the more lightweight models to run locally in browsers with WebGPU. It needs to also be deployable to servers in a scalable, cost-viable manner that reuses most of the same code that runs locally. Runtime overhead, cold start times, and memory usage should be minimized for quick, frequent switching between models in a node graph pipeline. The tech stack also needs to be permissively licensed and, as much as possible, Rust-centric so it doesn't add complexity to our Wasm and desktop build processes. To meet most of these criteria, our current thinking is to distribute and run our models using the Another potential direction is to find a portable, modular, lightweight approach for bundling existing Python-based models. It would need to work across simple and complex models with different architectures. License compliance, if GPL code is involved, would be a consideration. Based on the experience and insight brought to the table by the student, the nature of the project should be defined through preliminary discussions with the mentors and codified in the proposal. Machine learning and MLOps are fields that Graphite's team lack deep expertise in, so we are looking for a knowledgable student who can bring forth a well-researched and well-architected proposal and then execute on it.[Segment Anything 2](https://ai.meta.com/research/sam2/) (object segmentation) and [Depth Anything 3](https://github.com/ByteDance-Seed/Depth-Anything-3) (depth estimation) are currently the models we are most [interested in integrating](https://github.com/GraphiteEditor/Graphite/issues/1694). The challenge is settling on an architecture and tech stack which is well suited for Graphite's requirements.## For additional technical details: click here\n\n[ONNX](https://onnx.ai/) format. This would integrate ONNX runtimes for WebGPU, native, and GPU cloud providers. One challenge is that many of the best-performing models are not packaged in ONNX format, but this approach also allows for direct implementation of model architectures in Rust.[Burn](https://burn.dev/) is Rust's most promising and advanced machine learning framework, and in addition to Rust model implementations, it also [supports](https://github.com/tracel-ai/burn-onnx) ONNX model loading for conversion into its native format.\n\n### Generalized graphical data rendering representation\n\n*Rendering graphical content like colors, gradients, patterns, and whole other layers needs to be possible in a more flexible way that can target the fills and strokes of vector shapes.*\n\n**Possible Mentors:**[Keavon](https://github.com/keavon)**Needed Skills:**Rust, SVG**Project Size:**Medium or Large*(GSoC: 175 or 350 hours)***Difficulty:**Medium**Expected Outcomes:**Improved SVG and Vello renderer implementations that can handle a wider variety of paint types and effects. Support for every combination of paint type with its application to fills, strokes, and full-canvas drawing. Inclusion of the specified paint source types in the graphical data model and appropriate nodes for generating and handling such data.\n\nPresently, Graphite has a limited methodology for defining what gets painted when rendering vector shape fills and strokes. Solid colors and spatially positioned gradients are supported for fills, but only solid colors for strokes. Also, gradients cannot be painted across the entire canvas, and patterns do not exist at all yet. This project involves refactoring the renderer and data model to support a more generalized representation of paint sources that can be applied to fills, strokes, and entire layers. It deprecates the current solid/gradient/none selection for fills and solid/none selection for strokes in favor supporting anything that could be painted as a layer. An extended description and a list of child issues is available in the ## For additional technical details: click here\n\n[GitHub issue](https://github.com/GraphiteEditor/Graphite/issues/2779). A large-sized project would likely include support for the polyfilled gradient types described in the sub-issues of [this task](https://github.com/GraphiteEditor/Graphite/issues/2304).\n\n### Marquee selection masking\n\n*Graphite's raster editing features requires the implementation of Select mode, where users can draw a mask which becomes a marquee (marching ants) selection.*\n\n**Possible Mentors:**[Keavon](https://graphite.art/about#keavon)**Needed Skills:**Rust, computer graphics**Project Size:**Large*(GSoC: 350 hours)***Difficulty:**Medium**Expected Outcomes:**Complete implementation of Mask mode and its marquee selection. Marching ants visualization shader effect. Integration of selection mask with the node graph and raster editing tools. Useful raster editing workflow.\n\nA central part of the workflow in raster image editors is the selection of portions of the image to constrain manipulations just to the masked areas. Tools such as the circular and rectangular marquee, lasso, and magic wand are used to create masks. Instead of using dedicated tools, Graphite's design reuses the existing vector and raster drawing tools (like Rectangle, Ellipse, Pen, and Fill) to create masks in a dedicated Mask mode. Returning from Mask mode reveals the marching ants selection that constrains further editing operations.\n\nThis is a key feature in Graphite's evolution to a fully-featured raster editor.\n\n### Testing and performance instrumentation\n\n*Graphite has many areas that could benefit from better automated testing for bugs and performance regressions.*\n\n**Possible Mentors:**[Dennis](https://graphite.art/about#dennis)**Needed Skills:**Rust, unit testing**Project Size:**Small*(GSoC: 90 hours)*or larger if proposed**Difficulty:**Easy**Expected Outcomes:**Specific focus and scope may vary by the student's interests and proposal. In general, a significant increase in the coverage of tests in useful code areas (such as document loading, tool manipulation, and rendering) and attention towards systems which measure performance metrics and identify bottlenecks and regressions.\n\nGraphite could benefit from better testing coverage in a number of areas, especially end-to-end testing in the tool, document, and node graph systems. This project is about identifying and addressing areas that are lacking and most vulnerable to suffering from regressions. The student will be responsible for identifying areas that could benefit from better testing.\n\n### Your own idea\n\n*If you have an idea for a project that you think would be a good fit, we'd love to hear it!*\n\n**Possible Mentors:**Varies**Needed Skills:**Varies**Project Size:**Varies**Difficulty:**Varies**Expected Outcomes:**Stated in your proposal.\n\nIf none of the projects above suit your interests or experience, we are very open to discussing your own project ideas that could benefit Graphite. You may consult our [task board](https://github.com/orgs/GraphiteEditor/projects/1/views/1) and [roadmap](https://graphite.art/features#roadmap) to get a feel for what our current priorities are.\n\nAs is the case with all projects, please discuss this with us on Discord to flesh out your idea. Unsolicited proposals that have not been discussed with us will almost certainly be rejected."
  },
  {
    "name": "The Mifos Initiative",
    "slug": "the-mifos-initiative",
    "tagline": "End Poverty One Line of Code at a Time",
    "description": "We are a global 501(c)3 fintech non-profit leveraging the cloud, mobile & open source community to democratize financial services worldwide and digitally transform the world’s 3 billion poor and underbanked. Mifos has pioneered open source banking technology for the past fifteen years transforming the entire sector at each major stage of evolution from microfinance to financial inclusion to digital financial services and now embedded finance. Mifos guides the open source community, steers the roadmap, and stewards the vibrant ecosystem of organizations building solutions on its open platform. Our building blocks for banking, recognized as digital public goods, make core banking commoditized infrastructure, empowering any organization, anywhere to embed any financial service to any customer via any channel. These building blocks provide the common functionalities for creating customers, managing wallets, savings and loan accounts, orchestrating payments, and  maintaining the financial ledger & reports. More than 65 million clients are reached by 500+ financial institutions across 70 countries using solutions powered by our APIs.",
    "ideas_url": "https://mifosforge.jira.com/wiki/spaces/RES/pages/5021990914/2026+Google+Summer+of+Code+Ideas+List",
    "website_url": "https://mifos.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "android",
      "java",
      "kotlin",
      "spring",
      "angular"
    ],
    "topic_tags": [
      "artificial intelligence",
      "cloud",
      "fintech",
      "financial inclusion",
      "mobile banking"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/the-mifos-initiative",
    "ideas_content": "# 2026 Google Summer of Code Ideas List\n\nWe have compiled a great 2026 Google Summer of Code Ideas List. This list is fresh ideas from our pool of Talented Mentors. If you have any questions please feel free to contact @David Higgins @Ed Cable or @Dmitry Pankov . Whilst we might tidy up or add more information you can consider this list stable now.\n\n- 1\n[2026 Google Summer of Code - Get to Know Mifos](https://mifosforge.jira.com#2026-Google-Summer-of-Code---Get-to-Know-Mifos)- 1.1\n[Core DPG Technology Stack](https://mifosforge.jira.com#Core-DPG-Technology-Stack) - 1.2\n[Digital Public Infrastructure](https://mifosforge.jira.com#Digital-Public-Infrastructure) - 1.3\n[AI for All](https://mifosforge.jira.com#AI-for-All) - 1.4\n[Security](https://mifosforge.jira.com#Security) - 1.5\n[Modularization on the Back and Front-End](https://mifosforge.jira.com#Modularization-on-the-Back-and-Front-End) - 1.6\n[Integrations & POCs](https://mifosforge.jira.com#Integrations-%26-POCs) - 1.7\n[Payments](https://mifosforge.jira.com#Payments) - 1.8\n[Small Projects](https://mifosforge.jira.com#Small-Projects) - 1.9\n[Awards](https://mifosforge.jira.com#Awards) - 1.10\n[Videos](https://mifosforge.jira.com#Videos)- 1.10.1\n[Mifos Finals Week 2025](https://mifosforge.jira.com#Mifos-Finals-Week-2025) - 1.10.2\n[Recent Talks at Conferences](https://mifosforge.jira.com#Recent-Talks-at-Conferences)\n\n- 1.10.1\n\n- 1.1\n- 2\n[Product Overviews](https://mifosforge.jira.com#Product-Overviews) - 3\n[Guidelines](https://mifosforge.jira.com#Guidelines)- 3.1\n[Expectations](https://mifosforge.jira.com#Expectations) - 3.2\n[Prerequisite Skills](https://mifosforge.jira.com#Prerequisite-Skills) - 3.3\n[Source Code of DPGs & Projects](https://mifosforge.jira.com#Source-Code-of-DPGs-%26-Projects)- 3.3.1\n[Mifos X](https://mifosforge.jira.com#Mifos-X) - 3.3.2\n[Mifos Gazelle](https://mifosforge.jira.com#Mifos-Gazelle) - 3.3.3\n[Mobile Apps: Overview](https://mifosforge.jira.com#Mobile-Apps%3A-Overview) - 3.3.4\n[Payment Hub EE](https://mifosforge.jira.com#Payment-Hub-EE)\n\n- 3.3.1\n- 3.4\n[Hints](https://mifosforge.jira.com#Hints)\n\n- 3.1\n- 4\n[Project Ideas](https://mifosforge.jira.com#Project-Ideas)- 4.1\n[Project Sizes](https://mifosforge.jira.com#Project-Sizes) - 4.2\n[Large Projects (350 hours)](https://mifosforge.jira.com#Large-Projects-(350-hours))- 4.2.1\n[Voice Agent Integration to our Mobile Apps](https://mifosforge.jira.com#Voice-Agent-Integration-to-our-Mobile-Apps) - 4.2.2\n[Update Mifos Gazelle to use the latest Mifos X release and all modules](https://mifosforge.jira.com#Update-Mifos-Gazelle-to-use-the-latest-Mifos-X-release-and-all-modules) - 4.2.3\n[Update Payment Hub EE dependencies](https://mifosforge.jira.com#Update-Payment-Hub-EE-dependencies) - 4.2.4\n[Mifos X Web App React version 2.0](https://mifosforge.jira.com#Mifos-X-Web-App-React-version-2.0) - 4.2.5\n[Production-Grade E2E & Unit Testing Infrastructure for Mifos X Web App](https://mifosforge.jira.com#Production-Grade-E2E-%26-Unit-Testing-Infrastructure-for-Mifos-X-Web-App) - 4.2.6\n[Pluggable workflow engine support](https://mifosforge.jira.com#Pluggable-workflow-engine-support) - 4.2.7\n[GenAI “Copilot” for System Configuration](https://mifosforge.jira.com#GenAI-%E2%80%9CCopilot%E2%80%9D-for-System-Configuration) - 4.2.8\n[Event driven architecture for stand-alone modules](https://mifosforge.jira.com#Event-driven-architecture-for-stand-alone-modules) - 4.2.9\n[Product Templates for Mifos X Web App UI](https://mifosforge.jira.com#Product-Templates-for-Mifos-X-Web-App-UI) - 4.2.10\n[Financial Analytics & Inclusive Dashboards for the Mifos Web App](https://mifosforge.jira.com#Financial-Analytics-%26-Inclusive-Dashboards-for-the-Mifos-Web-App) - 4.2.11\n[KMP Project Template](https://mifosforge.jira.com#KMP-Project-Template) - 4.2.12\n[Mifos Mobile 8.0: Next-Generation Offline-First Mobile Banking with Store5 & New UI AI driven claude product cycle](https://mifosforge.jira.com#Mifos-Mobile-8.0%3A-Next-Generation-Offline-First-Mobile-Banking-with-Store5-%26-New-UI-AI-driven-claude-product-cycle) - 4.2.13\n[Mifos Pay: Personal Money Management & Financial Analytics Module](https://mifosforge.jira.com#Mifos-Pay%3A-Personal-Money-Management-%26-Financial-Analytics-Module) - 4.2.14\n[Mifos X Field Officer App: Offline Sync & Enhanced Account Management](https://mifosforge.jira.com#Mifos-X-Field-Officer-App%3A-Offline-Sync-%26-Enhanced-Account-Management) - 4.2.15\n[Mifos X Savings Group App](https://mifosforge.jira.com#Mifos-X-Savings-Group-App) - 4.2.16\n[Mifos X Open Banking App](https://mifosforge.jira.com#Mifos-X-Open-Banking-App) - 4.2.17\n[Mifos Gazelle OpenSPP Integration](https://mifosforge.jira.com#Mifos-Gazelle-OpenSPP-Integration) - 4.2.18\n[Mifos Gazelle - Open G2P integration](https://mifosforge.jira.com#Mifos-Gazelle---Open-G2P-integration) - 4.2.19\n[Type safe native SQL storage layer](https://mifosforge.jira.com#Type-safe-native-SQL-storage-layer) - 4.2.20\n[Mifos Marketplace Module](https://mifosforge.jira.com#Mifos-Marketplace-Module) - 4.2.21\n[AI-driven digitisation, migration, and adoption for Mifos X](https://mifosforge.jira.com#AI-driven-digitisation%2C-migration%2C-and-adoption-for-Mifos-X) - 4.2.22\n[Mifos Credit Bureau Information Lifecycle](https://mifosforge.jira.com#Mifos-Credit-Bureau-Information-Lifecycle) - 4.2.23\n[AI-Powered Assistant for Mifos X WebApp Using MCP (Cloud and On-Premise LLMs)](https://mifosforge.jira.com#AI-Powered-Assistant-for-Mifos-X-WebApp-Using-MCP-(Cloud-and-On-Premise-LLMs)) - 4.2.24\n[Autonomous Document Intelligence Engine for Financial Inclusion](https://mifosforge.jira.com#Autonomous-Document-Intelligence-Engine-for-Financial-Inclusion) - 4.2.25\n[BNPL(Buy Now Pay Later) & Lending Application use case powered by Open-Banking APIs](https://mifosforge.jira.com#BNPL(Buy-Now-Pay-Later)-%26-Lending-Application-use-case-powered-by-Open-Banking-APIs)\n\n- 4.2.1\n- 4.3\n[Medium Projects (175 Hours)](https://mifosforge.jira.com#Medium-Projects-(175-Hours))- 4.3.1\n[Eclipse BIRT reporting engine](https://mifosforge.jira.com#Eclipse-BIRT-reporting-engine) - 4.3.2\n[AI for Developer Productivity (MCPs & Reviewers)](https://mifosforge.jira.com#AI-for-Developer-Productivity-(MCPs-%26-Reviewers)) - 4.3.3\n[Secure Software Supply Chain Pipeline (SBOM & Image Signing)](https://mifosforge.jira.com#Secure-Software-Supply-Chain-Pipeline-(SBOM-%26-Image-Signing)) - 4.3.4\n[Mifos Apps UI Library 2026 - Intelligent Prompt Generation System for AI-Driven Fintech UI/UX](https://mifosforge.jira.com#Mifos-Apps-UI-Library-2026---Intelligent-Prompt-Generation-System-for-AI-Driven-Fintech-UI%2FUX) - 4.3.5\n[API Security Assessment and Penetration Testing for Mifos Payment Hub EE](https://mifosforge.jira.com#API-Security-Assessment-and-Penetration-Testing-for-Mifos-Payment-Hub-EE) - 4.3.6\n[Security, Compliance & Privacy Assessment of the Mifos Tech Stack with Improvement Roadmap](https://mifosforge.jira.com#Security%2C-Compliance-%26-Privacy-Assessment-of-the-Mifos-Tech-Stack-with-Improvement-Roadmap) - 4.3.7\n[Mifos X Smart Contract & Loan Agreement Summarization with LLMs](https://mifosforge.jira.com#Mifos-X-Smart-Contract-%26-Loan-Agreement-Summarization-with-LLMs)\n\n- 4.3.1\n- 4.4\n[Small Projects (90 Hours)](https://mifosforge.jira.com#Small-Projects-(90-Hours))\n\n- 4.1\n- 5\n[2026 Mentors](https://mifosforge.jira.com#2026-Mentors)\n\n# 2026 Google Summer of Code - Get to Know Mifos\n\nWe're looking forward to participating in Google Summer of Code for our fourteenth year. In 2025 we worked with a total of 23 interns through Google Summer of Code, Mifos Summer of Code and our Code for GovTech across the back-end platform, our web and mobile apps, and our AI tools. We hope to continue building our next generation of contributors who are joining in our movement to fight poverty through open source software. We want you to be part of our mission of creating a world of [ 3 Billion Maries](http://www.openmf.org/impact/3-billion-maries/).\n\n## Core DPG Technology Stack\n\nGSOC Contributors in 2026 will have the option to work on a variety of projects related to our end to end open source stack for digital financial services including open source core banking, generative AI for financial services, real-time payment and instant payment integration, digitizing government to person (G2P) payments, mobile money and Open Banking APIs, deployment tools for the cloud, and our suite of cutting edge and web and mobile apps. Participating interns will get to work on our **Mifos X **core banking platform including the staff-facing web app built on Angular, a POC of a brand new React UI, our suite of mobile apps including field officer apps mobile banking mobile wallet apps built on Kotlin-Multiplatform, and integrations with GSMA mobile money API and Open Banking API.\n\nWe will once again have projects related to our award-winning **Payment Hub EE** which provides an orchestration engine to connect to real-time payment systems like Mojaloop, ACH, and emerging payment protocols like Interledger. Given the core stack is mature in its functionality, we continue to focus GSOC projects on maintainability and deployability, security, improving developer experience, user experience optimization in addition to bleeding edge exploratory efforts around AI and the cloud.\n\n## Digital Public Infrastructure\n\nWith the international development’s sector deepened focused on digital public infrastructure, we are also seeking interns to contribute to our efforts with open source digital public goods for G2P payments like our Payments Building Block powered by **Payment Hub EE** and OpenG2P, the initiative we've helped to launch to digitize large scale government cash transfer programs and parallel projects for in-kind transfer and management of social registries like OpenSPP.\n\nThis year, we’ll also have a heightened focus on AI as part of AI for All and Data Science for Good initiatives. We will also have project related to our newest product,\n\n**Mifos Gazelle**, our DaaS (DPI as a Solution) offering, providing a deployment tool to enable the rapid deployment and configuration of multiple DPGs for demonstration environments.\n\n## AI for All\n\nAI is a focus area for GSOC in 2026 and Mifos has long been known for its projects evaluating how AI can both enhance our products as well as assist our community. We will again be looking having a number of AI and Machine Learning projects which will have a profound impact on financial services.\n\nMifos has an active AI community primarily organised through its AI for All Working Group. It’s a key focus area of our community and we have a variety of projects that build upon our existing AI tools as well as exploratory ones to discover and innovate around the power Generative AI and LLMs and LAMs can have on digital financial services for the Base of the Pyramid.\n\nWe strongly encourage potential participants in AI project internships to join our working group in advance and participate, due to the fast moving field of AI this will show not only interest but also the ability to assimilate and adapt to the fast moving tech, which is often something we have to do during the project period.\n\n## Security\n\nSecurity is an imperative when working with the delivery of financial services via core banking or payments orchestration. This is a focus of GSOC in 2026.\n\nWe have worked extensively with previous interns on security-related projects to penetration test and harden our mission-critical platforms. The security and quality control experts in our community look forward to mentoring security-focused interns for all our projects as well as the emerging need for fraud detection especially as more institutions connect to real-time payments.\n\n## Modularization on the Back and Front-End\n\nWe have some major refactoring and modularization of **Mifos X** that contributors could continue to help with. As we modularize the back-end we are also moving towards modular resuable UI components across our web and mobile apps exploring the usage of new frameworks like Compose Multi-platform and ShadCN. Through re-usable UI components, cross-platform development, frameworks, and improving our mobile SDKs, we are seeking to significantly streamline the development and design of our mobile apps.\n\n## Integrations & POCs\n\nSince the boundaries of fintech and financial services extend so far beyond the core we also have a number of interesting POC integration projects lined up by our mentors this year including POCs with alternative reporting engines, mobile check deposit POCs, workflow engine integration, integration with KYC automation frameworks, POCs for selfie verification, and more. We also will continue to deepen our integration with peer projects in the DPG and Financial Inclusion space such OpenSPP for Beneficiary Management, OpenFN for workflow automation, Mojaloop for Instant Inclusive Payments, MOSIP for Digital Identity and Tazama for Fraud and Risk Management.\n\n## Payments\n\nWhile both the back and front-end development of our core banking DPGs will be a major focus, we will have more projects this year on top of our **Payment Hub EE** which provides an orchestration engine to enable the ease and participation of fintechs and financial institutions into modern payment systems.\n\nThis year we will continue to improve upon the user experience of our operations app and control center, make it easier to build mobile money connectors, connect into beneficiary management systems like OpenSPP and OpenG2P for social protection, add additional connectors for messaging formats like ISO 20022, deepen our integration with instant inclusive payment systems like Mojaloop, test out integrations with new solutions like Interledger Protocol and Rafiki, and leverage open payment and banking standards.\n\n## Small Projects\n\nWith the new category of smaller projects introduced in 2024, we do expect to have a number of projects that are more research and POC-based including:\n\nAlignment with emerging Open Wallet Standards\n\nIntegration with Open Banking and Open Payment Standards\n\nDesign and Adoption of new frameworks like Compose Multi-platform\n\n\n## Awards\n\nMifos X and Payment Hub EE are globally recognized digital public goods and listed as DPGs for DPI, they are also award-winning projects that sits at the cutting edge of inclusive fintech and embedded finance.\n\n## Videos\n\nMifos is the leader of the open source banking movement helping to commoditize core banking infrastructure enabling financial services to be embedded anywhere and everywhere.\n\nThe best way to understand what we do is to watch a few videos.\n\n### Mifos Finals Week 2025\n\n\n\n\n\n### Recent Talks at Conferences\n\n\n# Product Overviews\n\n\n\n\n**Why does Google Summer of Code matter so much to Mifos and what do we look for in contributors?**\n\n**How the Mifos Software is Used**\n\n# Guidelines\n\nRead about setting up the code and understand the basic concepts around MifosX.__Getting started__\n\n**Expectations**\n\nContributors working on Mifos X, Payment Hub EE and Mifos Gazelle will be expected to:\n\nGet access to reasonable bandwidth, ie: have a fast, reliable Internet connection\n\nIntroduce yourself to, and discuss on, the mifos-developer\n\n, the #gsoc and #gsoc-aspirants channels in the__mailing list__, and the__Mifos Slack workspace__if you think your project may be on the boundary with the Apache Fineract (R) Backend.__Apache Fineract (R) developer list__Have proven you can install the existing relevant Mifos Product in an environment (environments are available for trial use for free by alot of cloud providers)\n\nWork on issues such as our\n\n[starter issues](https://mifosforge.jira.com/jira/software/c/projects/GSBX/boards/364?useStoredSettings=true)by providing patches and pull requests.Follow the Mifos\n\nand__coding standards__[code of conduct](https://mifosforge.jira.com/wiki/spaces/RES/pages/4457857029)Make sure you\n\n__document your work__Attend daily standup on Slack as well as the weekly student check-in calls for Mifos Interns\n\nFreely open to communicating with community members on the public channels\n\nMifos has a policy of declaring where you have used AI in your contributions just like any other attribution you would make.\n\nMifos does not accept proposals/applications generated by AI we want to get to know you rather than an AI at this point.\n\n\n**Prerequisite Skills**\n\nBasics\n\nBe a quick learner\n\nBe well-behaved, act in good faith and be of good humour.\n\nTroubleshooting Wizard\n\nPassion for writing beautiful code\n\nExcellent communication skills\n\nKnowledge of developer tools\n\nsuch as a text editor, source control, how to build software\n\nexperience with specific tools will also help, such as Eclipse IDE, Git, IntelliJ\n\n\n\nMifos includes a wide variety of technologies, we do not expect a student to be an expert on all of these. But it will be helpful if you have some experience in some of these. Helpful skills (specific technology requirements vary with project chosen) and must be eager to learn and develop with the requirements:\n\nJava, Spring, MySQL, Jersey & Hibernate\n\nHTML, CSS, JavaScript (JQuery), Angular & Material Design\n\nJUnit, REST-assured\n\nAndroid, Kotlin\n\nHelm, Docker, Circle CI Pipelines, Cucumber Testing Frameworks, Scripting Tools (for Dev-Ops focussed projects)\n\n\n## Source Code of DPGs & Projects\n\n### Mifos X\n\nBack-End:\n\n|__Source Code__|__Mailing List__|__Slack__(mifos | password)__Demo__Web App:\n\n|__Source Code__|__Issue Tracker__|__Mailing List__|__Slack____User Manual__Android Client:\n\n|__Source Code__|__Issue Tracker____Slack__Docs -\n\n|__Static HTML__|__Swagger OpenAPI____Architecture__\n\n### Mifos Gazelle\n\n[ Overview](https://products.mifos.org/mifos-gazelle) |\n\n[|](https://github.com/openmf/mifos-gazelle)\n\n__Source Code__\n\n__Slack__**Mobile Apps: **__Overview__\n\n__Overview__\n\nMifosPay - Mobile Wallet Framework:\n\n|__Source Code__|__Issue Tracker____Slack__Mifos Mobile - Mobile Banking App:\n\n|__Source Code__|__Issue Tracker____Slack__OpenBanking App:\n\n__Source Code__Online Banking App - Web:\n\n__Source Code__\n\n**Overview:** [https://openmf.github.io/mobileapps.github.io/](https://openmf.github.io/mobileapps.github.io/)\n\n### Payment Hub EE\n\n[ Overview](https://payments.mifos.org) |\n\n[|](https://github.com/openMF?q=ph-ee)\n\n__Source Code__\n\n__Slack__## Hints\n\nWhen you need help, ask for help after exploring all options on the web. We are very excited for you to join us, but we need to know that you're willing to put in the time and effort required to do your part. When you do ask,\n\n.__ask well__Tips for a Good Application from former GSOC intern and Mentor, Ishan Khanna:\n\n[https://hackernoon.com/7-things-you-need-to-know-to-ace-your-gsoc-proposal-8e422f2b6abe](https://hackernoon.com/7-things-you-need-to-know-to-ace-your-gsoc-proposal-8e422f2b6abe)Not sure if you are qualified? Download and build the code, then run the Platform and the Mifos X distribution.\n\nInstructions for running the backend components are in\n\nin the__Getting Started Guide____Apache Fineract (R) Contributor's Zone__Getting started with the web app can be found in the\n\n__Getting Started Guide__\n\n[Join our Slack channel](https://join.slack.com/t/mifos/shared_invite/zt-3m6x47dgj-iX0Oqv8KS0VGgouNnuJrAg)and communicate with others. Reach out to mentors to understand more. Work on our[starter issues](https://mifosforge.jira.com/jira/software/c/projects/GSBX/boards/364?useStoredSettings=true).\n\n# Project Ideas\n\n**Update**\n\nOur 2026 Ideas list is now compiled with a wide range of projects for different aspects of the diverse Mifos Stack. The primary way to ask questions is to reach out and discuss in Mifos Slack either in our #GSOC channel or in the channels indicated on proposals.\n\n*2026 projects will be related to the Mifos X core banking suite including staff interfaces for the web (Web App) and mobile (Android client), our customer-facing apps including our Mobile Banking app, Mifos-Mobile, our Mobile Wallet App, MifosPay or our Online Banking App. There will also be projects focused on our Payment Hub EE payment orchestration engine and our efforts in Digital Public Infrastructure space around G2P Payments for Social Protection. We will also have projects focused on our newest product, Mifos Gazelle, our DaaS (DPI as a Solution) offering providing a deployment tool for rapid installation and evaluation of digital public goods in demonstration environments*.\n\n*Any projects related to the back-end core banking platform will be built as modules or plugins that sit alongside or on top of the Apache Fineract (R) platform, which Mifos developed and donated to the Apache Software Foundation.*\n\n## Project Sizes\n\nFor 2026, GSOC projects can be of three durations - large (350 hours) and medium (175 hours) and small (90 hours).\n\n## Large Projects (350 hours)\n\n### Voice Agent Integration to our Mobile Apps\n\nCategories/Tags | Large, Mobile, AI, Integration, Exploratory |\n|---|---|\nOverview and Objectives | AI is evolving at a rapid pace, with significant progress in language models as well as in speech and speech–language models. Alongside this, language models combined with tools have increasingly taken the form of agents that can perform real-world tasks. We worked on a few projects in a similar domain last year, and this year our focus is on exploring state-of-the-art tools that can be integrated directly into our mobile applications. Our goal is to build a voice agent that can be embedded into our mobile apps to improve accessibility and inclusivity—especially for users who face barriers due to technology constraints or differences in native languages. This voice agent will allow users to interact with the app entirely through voice, perform certain actions on their behalf, and understand different features and use cases of the app without relying on traditional UI interactions. The solution is intended to use a lightweight, small-footprint model with minimal memory requirements, making it suitable for mobile environments while still delivering effective voice-based interaction. |\nDescription | At a high level, the core of this project will involve research and exploration into how AI-powered voice agents can be effectively integrated into mobile applications. A major focus will be identifying which features and capabilities make the most sense to expose through voice interaction, and what kinds of user operations can be reliably and safely performed using a voice-first interface. This includes understanding user experience considerations, accessibility requirements, multilingual support, and limitations specific to mobile platforms. Another key aspect of the project will be evaluating the existing ecosystem of tools, frameworks, and models that can be used to build such voice agents. This includes researching speech-to-speech systems, lightweight language or speech–language models suitable for mobile environments, and agent frameworks that support tool usage. The intern will be expected to assess trade-offs between different deployment strategies, such as using hosted/cloud-based models versus running models locally on-device, taking into account factors like latency, privacy, cost, reliability, and memory footprint. |\nSkills | Kotlin / Mobile app development Python AI agents and tool-based workflows Speech-to-Text (STT) systems Text-to-Speech (TTS) systems Voice-first UX / accessibility On-device vs hosted model deployment Audio streaming and processing |\nResources | https://docs.ultravox.ai/overview |\nMifos Repositories |\n|\nImpact | Our mobile app is widely used in regions where English is not the primary language, and it also supports multiple Digital Public Goods (DPGs) and public infrastructure initiatives aligned with UNICEF’s goals, making inclusivity a core priority. By enabling seamless voice-based interaction, this project will allow users who may not speak English or who face technological barriers to use the app effectively through simple voice commands. In addition, the voice agent will help users better understand the app by providing guided, voice-only onboarding and explanations of its features. Overall, the project aims to significantly lower access barriers, improve user experience for diverse communities, and create meaningful social impact by making the app more accessible and inclusive. |\nProvisional Mentors | Aru Sharma, TBC |\nChannels to Discuss | Slack: Channel: #mifos-mobile #wg-ai-for-all |\n\n### Update Mifos Gazelle to use the latest Mifos X release and all modules\n\nCategories/Tags | Large, Gazelle, Integration, DevOps, Backend |\n|---|---|\nOverview and Objectives | Currently Mifos Gazelle only deploys a couple of components of MifosX and backend dependencies we want to have it configurable to deploy all modules e.g. reporting, credit bureau etc at the latest versions |\nDescription | In this project you will update the version of Mifos X included in the Mifos Gazelle release you will include all Mifos X module not just the web-app currently deployed this will require you to be able to check dependencies and also consider infrastructure rationalisation and system constraints across multiple environments. |\nSkills | cloud native technologies kubernetes, helm, java, bash scripting python |\nResources |\n|\nMifos Repositories | https://github.com/openMF/mifos-gazelle |\nImpact | This project will provide users access to a much more complete set of MifosX functionality via the simple Mifos Gazelle deployment model |\nProvisional Mentors | Tom Daly, TBC |\nChannels to Discuss | Slack: Channel: #mifos-gazelle-dev |\n\n### Update Payment Hub EE dependencies\n\nCategories/Tags | Large, Payment Hub EE, DPG, DPI, Integration, Mifos Gazelle, Backend, DevOps |\n|---|---|\nOverview and Objectives | Update Payment Hub EE Java components to most recent applicable JDK release and update corresponding dependencies such as SpringBoot, camel etc |\nDescription | This project will update the out of date dependencies within Payment Hub EE in particular focussed on but not limited to Java. These updates are essential to the long term sustainability of the DPG. These updates will also be used in Mifos Gazelle which incorporates Payment Hub EE for DPI demos. Whilst this project may sound simple it is not with many repos and interdependencies this project is for someone who is willing to dive deep, use investigative skills and happy that testing is a major part of upgrading of dependencies. |\nSkills | Java, SpringBoot , Apache Camel, Gradle build tools |\nResources | Paymenthub repos in |\nMifos Repositories | Paymenthub repos in |\nImpact | This a very important and strategic project which will enable the future development of PaymentHub EE. A longer term approach by building repeatable tests could set the scene for maintainability of PH-EE when dependancies need upgrading in the future. |\nProvisional Mentors | Tom Daly, David Higgins, TBC |\nChannels to Discuss | Slack: Channel: #payment-hub #mifos-gazelle-dev |\n\n### Mifos X Web App React version 2.0\n\nCategories/Tags | Large (350 days), Web App, UI, Front End |\n|---|---|\nOverview and Objectives | This project focuses on extending the existing React based Mifos X web app to make it production ready and a strong candidate to become the primary Mifos X web interface. It continues the previous development cycle by strengthening Apache (R) Fineract integration and Including the rest of the modules, bringing the React web app features and stability comparable to the current main web (angular) application. |\nDescription | The project involves further development and stabilizing the existing React based Mifos X web application, which is currently under active development and not yet production ready. The intern will implement the remaining functional modules and complete core workflows such as clients, groups, loans, savings, reports to reach feature similarity with the Angular based Mifos X web app. The work includes strengthening Apache (R) Fineract API integration using the OpenAPI generated client, adding remaining modules, improving error handling,, and refining the UI using ShadCN and Tailwind. |\nSkills | React, Typescript, Tailwind CSS, Apache Fineract, ShadCN |\nResources | React web app: React web app report: https://gist.github.com/Craig-Rosario/985588b2576f45686340557d5299c89a Issues with the current react web app (due to OpenAPI inconsistencies): https://github.com/openMF/mifos-x-web-app-react/blob/dev/ISSUES.md |\nMifos Repositories | |\nImpact | This project will help deliver a modern, production ready web interface for Mifos X, improving usability, and maintainability. By strengthening the React-based web app and connecting it with core Apache (R) Fineract using the OpenAPI client, it can serve as a strong alternative and next step for the future Mifos web interface. |\nProvisional Mentors | Craig Rosario |\nChannels to Discuss | Slack: Channel: #web-app |\n\n### Production-Grade E2E & Unit Testing Infrastructure for Mifos X Web App\n\nCategories/Tags | Large (350 days), Web App, UI, Front End, Testing |\n|---|---|\nOverview and Objectives | The Mifos X Web App currently operates with ~1.46% test coverage, leading to fragile releases and heavy reliance on manual QA. This project aims to modernize the repository quality assurance by building a production-grade hybrid testing infrastructure using the latest industry-standard tools: Playwright 1.57+ for E2E and Jest 29+ for Unit testing, fully compatible with Angular 20. Eliminate Manual Regression Testing: Automate 40-50 critical business workflows across Client, Group, and User modules. Modernize Architecture: Implement a strict Page Object Model (POM) pattern to ensure test maintainability and reduce code duplication. Enhance Developer Experience: Create a \"Testing SDK\" with reusable fixtures, mock factories, and templates, enabling any contributor to write high-quality tests easily. Secure the Supply Chain: Integrate robust CI/CD quality gates in GitHub Actions to block breaking changes before merge.\n|\nDescription | This project aims to engineer a production-grade testing ecosystem for the Mifos X Web App, shifting the repository from manual verification to a self-verifying Continuous Delivery model. By leveraging Playwright 1.57+ for End-to-End (E2E) reliability and Jest 29+ for logic isolation, the project will secure critical financial workflows currently prone to regression. Core Infrastructure & Architecture\nPage Object Model (POM): Implementation of a strict POM architecture (extending the Proof-of-Concept `BasePage` ) to decouple test logic from UI selectors. This ensures that UI changes (e.g., renaming a button) only require updates in one file (`PageClassName.ts` ) rather than dozens of tests.Testing SDK: Development of reusable \"Test Fixtures\" and \"Mock Factories\" to democratise testing. This includes utilities for generating random client data, mocking API responses, and handling authentication state programmatically to bypass repetitive login screens during test runs.\nDeep E2E Coverage (Client Module) The primary focus is the Client Module (171 files), which serves as the entry point for all financial operations. The project will automate the following complex business flows:\nLifecycle Management:End-to-end automation of the `Create Client` →`Approve` →`Activate` →`Close` state machine, ensuring valid transitions and error handling for invalid states (`Reject` ,`Withdraw` ).Financial Transactions: Validation of [payClientCharge], [waiveClientCharge], and [undoTransaction] logic to guarantee that account balances reflect accurately in the UI after operations. Identity & KYC: Automation of \"Know Your Customer\" workflows, including `Family Member` management,`Client Identifier` (document) uploads, and [Collateral] tracking to prevent compliance regressions.\nSecondary Module Coverage\nGroups Management: Automating group lifecycles (Creation, Meeting Notes, closure) to ensure community lending features remain stable. User Administration: Verifying the [User] module's role-based access control (RBAC), ensuring that only authorized staff can approve loans or activate clients.\nUnit Testing & Logic Isolation\n**Component Harnessing:**Using Jest to test complex Angular 20 components (`ActivateClientComponent` ,`CreateClientComponent` ) in isolation, verifying form validators (e.g., Activation Date logic) and pipe transformations without requiring a full browser environment.Service Resilience: High-coverage unit tests for [ClientsService]) and `GroupsService` , mocking efficient`HttpClient` responses to verify error handling (e.g., 404s, Network Failures) that are difficult to reproduce in E2E.\nCI/CD Pipeline Integration\nIntegration of a \"Test Sharding\" strategies in GitHub Actions to run tests in parallel, reducing pipeline duration. Configuration of **Quality Gates**that automatically block Pull Requests if they reduce overall coverage or introduce flaky tests, utilizing Playwright's \"Trace Viewer\" artifacts for rapid debugging of CI failures.\n|\nSkills | Typescript, Angular 17+ (Signals & Standalone Components), Playwright, Jest, RxJS, GitHub Actions (CI/CD), Docker, Unit Testing Principles, E2E Testing Patterns, Page Object Model (POM) Design Pattern |\nResources |\n**Merged Playwright Infrastructure (Proof of Concept):**[establish Playwright E2E testing infrastructure with configuration by devvaansh · Pull Request #2912 · openMF/web-app](https://github.com/openMF/web-app/pull/2912)**Initial E2E Foundation:**[E2E regression test for Audit Trails CSV download by devvaansh · Pull Request #2886 · openMF/web-app](https://github.com/openMF/web-app/pull/2886)**Merged jest unit testing pr's**:[Web 391 unit test coverage for url to string pipe by devvaansh · Pull Request #2742 · openMF/web-app](https://github.com/openMF/web-app/pull/2742)[WEB-422 unit test coverage for ViewTaxComponentComponent by devvaansh · Pull Request #2802 · openMF/web-app](https://github.com/openMF/web-app/pull/2802)[WEB-435 Unit Test Coverage for ViewCollateralComponent by devvaansh · Pull Request #2816 · openMF/web-app](https://github.com/openMF/web-app/pull/2816)[feat: add comprehensive unit tests for ActivateClientComponent by devvaansh · Pull Request #3041 · openMF/web-app](https://github.com/openMF/web-app/pull/3041)\n**Playwright Docs:**[https://playwright.dev/docs/intro](https://playwright.dev/docs/intro)**Angular Testing Guide:**[https://angular.dev/guide/testing](https://angular.dev/guide/testing)**Mifos X API Documentation:**[https://demo.mifos.io/api-docs/apiLive.htm](https://demo.mifos.io/api-docs/apiLive.htm)\n**Research on Page Object Model (POM):**\"Maintainable Automated Testing\" (Leotta et al., IEEE,link-[https://sepl.dibris.unige.it/publications/2013-leotta-ICSTW.pdf)](https://sepl.dibris.unige.it/publications/2013-leotta-ICSTW.pdf))- Demonstrated 3x faster maintenance and 8x code stability improvement.**Project Context:**The codebase a months ago underwent a major migration to Angular 18/19, highlighting significant regression risks which this project directly addresses.\n|\nMifos Repositories |"
  },
  {
    "name": "MIT App Inventor",
    "slug": "mit-app-inventor",
    "tagline": "Anyone can build apps with global impact",
    "description": "MIT App Inventor is a free, open source web app that anyone can use to build mobile apps. It has been used by over 8 million people worldwide who have built more than 30 million apps. It is available in twelve different languages and used by people from ages 13 and up.",
    "ideas_url": "https://docs.google.com/document/d/1hxtNVrg58HSPTyPsJDTi8BcOePXlpojC_1BzfcqXrm8/edit?tab=t.",
    "website_url": "http://appinventor.mit.edu",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "javascript",
      "java",
      "gwt",
      "swift"
    ],
    "topic_tags": [
      "education",
      "development tools",
      "android",
      "ios"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/mit-app-inventor",
    "ideas_content": "# Sign in\n\nto continue to Google Docs\n\nNot your computer? Use Guest mode to sign in privately.\n\n[Learn more about using Guest mode](https://support.google.com/chrome/answer/6130773?hl=en-US)- For my personal use\n- For my child\n- For work or my business\n\nto continue to Google Docs\n\nNot your computer? Use Guest mode to sign in privately. [Learn more about using Guest mode](https://support.google.com/chrome/answer/6130773?hl=en-US)\n\n- For my personal use\n- For my child\n- For work or my business"
  },
  {
    "name": "CERN-HSF",
    "slug": "cern-hsf",
    "tagline": "Umbrella for Particle Physics-related projects",
    "description": "CERN-HSF (High-Energy Physics Software Foundation) is the umbrella organization for high-energy physics-related projects in GSoC. The HEP Software Foundation (http://hepsoftwarefoundation.org/) facilitates the coordination of common international efforts in high-energy physics software and computing.\n\nCERN (European Organization for Nuclear Research, https://home.cern) has participated in GSoC since 2011 as the CERN-SFT group, which provides common software for CERN's experiments. In 2017, the program expanded to include many software projects from the whole field of high-energy physics. The vast majority of our GSoC projects do not require any physics knowledge.\n\nThe experiments at CERN, such as the Large Hadron Collider, the world’s largest and most powerful particle accelerator (http://home.cern/topics/large-hadron-collider) try to answer fundamental questions about the Universe. For example, what is the nature of mass? What are the elementary building blocks of the Universe? What was the early Universe like? What is the nature of dark matter and dark energy? Why is there an asymmetry between matter and antimatter? In 2012, LHC experiments announced the discovery of a new particle, the Higgs Boson, that helps explain how particles obtain mass. Also, CERN is the birthplace of the World Wide Web. Today, particle physicists are working on analyzing the data from the experiments to study the properties of the newly discovered particle and to search for new physics, such as dark matter or extra dimensions. This requires a lot of sophisticated software.\n\nThe open-source high-energy physics projects to which students can contribute during GSoC span many high-energy physics software projects: data analysis, detector and accelerator simulation, event reconstruction, data management and many others. We look forward to your contributions!",
    "ideas_url": "https://hepsoftwarefoundation.org/gsoc/2026/summary.html",
    "website_url": "http://hepsoftwarefoundation.org/activities/gsoc.html",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "c/c++",
      "data analysis",
      "artificial intelligence",
      "container orchestration"
    ],
    "topic_tags": [
      "machine learning",
      "big data",
      "algorithmics",
      "particle physics",
      "Performance Optimisation"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/cern-hsf",
    "ideas_content": "Skip to main content\nHSF\nActivities\nWhat are HSF activity areas?\nData Analysis\nDetector Simulation\nPhysics Generators\nSeason of Docs\nGoogle Summer of Code\nintelligent Data Delivery Service\nJuliaHEP - Julia in HEP\nLicensing\nPyHEP - Python in HEP\nReconstruction and Software Triggers\nReviews\nSoftware Developer Tools and Packaging\nHSF Training\nArchived Activities\nConvener Guide\nMeetings\nCompute and Accelerator Forum\nCoordination Meetings\nHSF Seminars\nSoftware and Computing Roundtable\nSoftware Forum\nCommunication\nCommunity Calendar\nMeetings: Indico\nTraining Schools\nMailing Lists and Forums\nMeeting Notes\nTechnical Notes\nDocuments\nMaterial for presentations\nNewsletters\nEvents & Workshops\nHSF on YouTube\nHSF Project Inventory\nProjects & Support\nHSF Affiliated Projects and Software\nProjects and Software Guidelines\nAffiliated Projects\nAffiliate Badges\nAbout\nGet involved!\nThe Steering Group\nHSF Advisory Group\nGoals of the HSF\nCommunity White Paper\nLetters from the HSF\nHSF Presentations\nHSF YouTube Channel\nWebsite Howto\nSummary of GSoC 2026 Proposals\nClick here for an overview of the GSoC program at HSF.\nFull List of Proposals\nATLAS:\nAutomated Software Performance Monitoring for the ATLAS experiment\nATLAS:\nAI-Accelerated Reconstruction for the ATLAS Tile Calorimeter at the HL-LHC\nBOA:\nBytewise Online Autoregressive (BOA) Constrictor for HEP data compression\nBelle2:\nEnabling Sustainable ARM Support for the Belle II Software\nBioDynamo:\nEnhancing a Next-Generation Platform for Computational Cancer Biology\nBioDynamo:\nBioDynaMo Large-Scale Antimatter Simulation\nCMS:\nAI Assistance for CMS Computing Operations\nCernVM-FS:\nDebugging CVMFS processes in D-state\nCernVM-FS:\nGrafana Template for CernVM-FS Deployments\nCernVM-FS:\nUnifying the CVMFS Build Flow for Dependencies\nClad:\nConsolidate and advance the GPU infrastructure in Clad\nClad:\nClad as a first-class gradient engine in LibTorch\nClad:\nEnable automatic differentiation of OpenMP programs with Clad\nClad:\nEnable automatic differentiation of C++ STL concurrency primitives in Clad\nConstellation:\nWeb Interface for Controlling and Monitoring Experimental Setups\nCppInterOp:\nImplement CppInterOp API exposing memory ownership and thread safety\nDUNE:\nFine grained storage for the DUNE experiment\nFCC:\nIntegration of Combine with FCCAnalyses\nGeant4 / ML4EP:\nOptimisation and validation of shower data for ML-based calorimeter simulation\nGreenMetaData:\nCreating a Metadata file format for Green Computing Practices in High Energy Physics and beyond\nHEP-CCE:\nCharacterizing I/O Performance for ML Data Loaders at Scale Using Darshan\nHSFCondDB:\nAI-Assisted PostgreSQL Optimization Using EXPLAIN Plans\nJuliaHEP:\nNative Julia HEP Geometry package\nJuliaHEP:\nParallel Processing Improvements in Julia Jet Reconstruction\nLHCb:\nTransformer-based Reconstruction for Electromagnetic Calorimeters in Future LHC Upgrade Experiments\nML4EP:\nML Inference on heterogeneous architectures using SOFIE\nML4EP:\nIntegrating hls4ml with SOFIE for Fast ML Inference\nML4EP:\nImproving the Keras and PyTorch Parsers for ML Inference in SOFIE\nNNPDF:\nThe EKO oxidation\nATLAS:\nNegative weight mitigation with cell resampling in ATLAS workflows\nMCFM:\nNegative weight mitigation with cell resampling and tests with MCFM\nOmnifold:\nPublication of Omnifold weights\nPODIO:\nAparche Arrow interface for PODIO\nROOT:\nEnhance and develop GeneROOT infrastructure\nROOT:\nS3 Backend for RNTuple\nSpack:\nGenerative-AI Assisted Testing of Complex Stacks of Spack Packages\nSpack:\nDebuggable Installations for Spack Packages\nSpack:\nExpanding User-Facing High-Energy Physics Spack Packages\nPhoenix:\nModernizing the Phoenix Event Display"
  },
  {
    "name": "OpenMS Inc",
    "slug": "openms-inc",
    "tagline": "Advancing Algorithms & AI for Biomedical Insights",
    "description": "OpenMS is an open-source C++ software library for mass spectrometry data management and analysis with python wrappers. OpenMS houses an expansive modular toolset and ready-to-use scientific workflows in Galaxy, KNIME and nextflow.",
    "ideas_url": "https://openms.de/news/gsoc2026/",
    "website_url": "https://OpenMS.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "cython",
      "c++",
      "pytorch",
      "Streamlit"
    ],
    "topic_tags": [
      "open science",
      "deep learning",
      "algorithms",
      "mass spectrometry",
      "webdev"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/openms-inc",
    "ideas_content": "# OpenMS Invites the Computational Mass Spectrometry Community to Join Google Summer of Code 2026!\n\n[Google Summer of Code (GSoC) 2026](https://summerofcode.withgoogle.com) OpenMS is planning to apply as an umbrella organization and we would like to extend an invitation to other projects and groups within the computational mass spectrometry and proteomics/metabolomics communities to join us in this effort.\n\n## GSoC Contributors\n\n- Make sure you are\n[eligible](https://summerofcode.withgoogle.com/get-started)to participate in GSoC 2026. - Review the list of themes and the projects available within. If you have specific questions about a project, our mentors are active on\n[Discord](https://discord.com/invite/4TAGhqJ7s5)and we will happily assist you. - Follow our instructions below on how to submit a proposal to us.\n\n## Submitting an Application:\n\n- Proposal must be uploaded to the GSoC webpage before the official deadline. Ensure your CV and contact information are included in the proposal document.\n- We highly recommend to get in touch with the mentors before submitting your proposal.\n\n## AI Usage policy:\n\nWe believe that the primary goal of your participation in GSoC should be learning how to participate in open-source communities. We also believe that it is quite possible to use generative AI to be a more effective participant in our community. Therefore we do not prohibit the responsible use of AI tooling in either your contributions, or your written communications. All AI models were trained on open-source code. We like to think that they can give back a bit to the community as well. This policy comes with a number of major caveats:\n\n### “A computer can never be held accountable”\n\n- Ultimately the code and communication that you submit is your responsibility. Generative AI can help with language barriers, repetitive tasks, and research, but ultimately you are the contributor to the project. We will hold you responsible for any mistakes that the AI makes the same as we would for your own code and communication. You must review any product of AI before you submit it.\n\n### If you are found submitting work that clearly hasn’t been reviewed, we reserve the right to take disciplinary action up to and including banning you from our project. It should go without saying that this would not result in your successful GSoC.\n\n- NOTE: this is not a prohibition against making mistakes, or even missing mistakes that the AI made. You are here to learn, and mistakes happen.\n\n### Make clear in any submission (code, communications, etc.) that you used AI tools.\n\n- This can simply be a line in the PR description saying “Made with AI tools”. It should be clear that this isn’t meant to pass judgement on you, work made with AI tools has a very different set of typical failure modes than work done entirely by humans, it helps us to understand where mistakes may have come from.\n\n### If we explicitly ask you to do something without AI tools, do not use them.\n\n- Yes, we can tell. We’ve all used AI tools as well. Doing this will also result in your getting banned from our project.\n\n### You must do your best to make sure that code produced with AI help uses consistant naming conventions and coding style.\n\n- This doesn’t need to be hard. Have your agent load\n[https://openms.de/doxygen/nightly/html/coding_conventions.html](https://openms.de/doxygen/nightly/html/coding_conventions.html)before writing any code, and ask it to check that it complied with all the coding conventions before code submission.\n\n### Suggestions for using AI effectively:\n\n-\nUsing an agent effectively can be challenging. Each model has specific ways that they fail, and specific limitations. Learn these before using an agent to build code.\n\n-\nThe skill that an agent has in writing and understanding code is proportional to how much similar code it has seen. In our experience this means that it is much better at solving pandas dataframe formatting issues than esoteric C++ bugs.\n\n-\nAsking an agent to explain code, or program logic can be a good first step to understanding. OpenMS is a large software project, and trying to unravel how a specific piece of logic works can be daunting. Our team has internally had very good success using agents to speed up learning how a section of code works. Just keep in mind that it can be wrong sometimes.\n\n-\nAsking the agent for proof is always a good idea.\n\n\n# Available Projects\n\n## Theme A) Data Formats and Interoperability\n\n### 1) imzML Parser in OpenMS\n\n**Proposed Mentors:** OpenMS Team\n\n**Skills:** C++, XML Parsing, Mass Spectrometry Imaging\n\n**Estimated Project Length:** 350 hours | **Difficulty:** Medium\n\nMass spectrometry imaging (MSI) is a powerful analytical technique that enables spatial mapping of molecules in biological tissues. The imzML format is the open standard for storing MSI data, consisting of two files: an XML metadata file and a binary data file. While imzML is widely used in the MSI community, OpenMS currently lacks native support for reading and writing this format.\n\nThe goal of this project is to implement a robust imzML parser in OpenMS, enabling seamless integration of mass spectrometry imaging data into existing OpenMS workflows.\n\nTasks:\n\n- Implement a C++ imzML reader that can parse both continuous and processed imzML formats.\n- Implement an imzML writer to enable export of imaging data.\n- Add support for common imzML metadata (coordinates, pixel size, spectrum parameters).\n- Integrate the parser with existing OpenMS data structures (MSExperiment, MSSpectrum).\n- Write comprehensive unit tests and validate against reference imzML datasets.\n- Document the new functionality and provide usage examples.\n\n### 2) Full Python Bindings Using Nanobind\n\n**Proposed Mentors:** OpenMS Team\n\n**Skills:** Python, C++, Nanobind, Cython\n\n**Estimated Project Length:** 350 hours | **Difficulty:** Medium to Advanced\n\nPyOpenMS provides Python bindings for OpenMS, enabling Python developers to access the powerful mass spectrometry algorithms implemented in OpenMS. Currently, these bindings are generated using Cython via the autowrap package. While functional, this approach has limitations in terms of maintenance overhead, compile times, and certain Python integration features.\n\nNanobind is a modern C++17 library for creating Python bindings with minimal overhead. An existing prototype demonstrates the feasibility of using nanobind for OpenMS Python bindings. This project aims to build upon this prototype to create comprehensive nanobind-based Python bindings for OpenMS.\n\nA key deliverable of this project is a thorough evaluation comparing nanobind-based bindings against the current autowrap/Cython implementation. This evaluation should cover:\n\n**Performance:**Binding overhead, memory usage, call latency**Build System:**Compile times, dependency management, CI/CD integration**Usability:**Python API ergonomics, documentation generation, IDE support**Maintenance:**Code complexity, debugging experience, update workflow**Compatibility:**Python version support, platform compatibility, NumPy/SciPy integration\n\nTasks:\n\n- Evaluate the existing nanobind prototype and identify gaps in coverage.\n- Extend the nanobind bindings to cover core OpenMS classes and algorithms.\n- Implement automatic binding generation where feasible to reduce maintenance burden.\n- Conduct systematic benchmarking comparing nanobind vs. autowrap/Cython bindings.\n- Document advantages and disadvantages of each approach with concrete examples.\n- Write unit tests ensuring feature parity with existing PyOpenMS functionality.\n- Provide a recommendation report for future binding strategy based on findings.\n\n### 3) Accelerating OpenSwathWorkflow for Large-Scale In Silico Spectral Libraries\n\n**Proposed Mentors:** Joshua Charkow\n\n**Skills:** C++, Algorithm Optimization, Profiling\n\n**Estimated Project Length:** 200 hours | Difficulty: Medium\n\nOpenSwathWorkflow is a central component of OpenMS for Data Independent Acquisition (DIA) analysis, enabling targeted extraction and scoring of chromatographic signals using spectral libraries. While OpenSwathWorkflow performs well for conventional experimental libraries, the increasing adoption of large in silico–generated spectral libraries presents substantial computational challenges. Such libraries can contain millions of precursors, leading to increased memory usage, longer runtimes, and scalability bottlenecks in candidate selection and scoring.\n\nThis project aims to analyze and improve the computational performance and scalability of OpenSwathWorkflow, with a particular focus on workflows using very large in silico spectral libraries. The goal is to identify bottlenecks, redesign performance-critical components where necessary, and introduce optimizations that enable efficient processing without compromising identification quality.\n\nA key deliverable of this project is a systematic performance evaluation of OpenSwathWorkflow before and after optimization.\n\nTasks:\n\n- Develop a comprehensive understanding for the OpenSwathWorkflow algorithm\n- Develop a benchmarking dataset for profiling.\n- Profile OpenSwathWorkflow to identify computational bottlenecks.\n- Identify algorithmic bottlenecks and propose changes.\n- Experiment with different algorithms using inspiration from other open source DIA projects.\n- Validate that the optimized implementation provides comparable results to the original implementation and other DIA software tools.\n\n## Theme B) Dependency management\n\n### Unify development dependencies using vcpkg\n\n**Proposed Mentors**: OpenMS Team\n\n**Skills**: CMake, Git, Command Line, Linux, macOS, Windows\n\n**Estimated Project Length**: 175 hours | **Difficulty**: Medium\n\nLike many large scale software projects, OpenMS has numerous\ndevelopment dependencies. Unfortunately, there is no straightforward\nway to quickly and easily install all of these dependencies. Some can\nbe installed using various package managers such as `apt-get`\n\n, `brew`\n\n,\nor `choco`\n\n, while others need to be installed with a Python package\nmanager such as `conda`\n\n. And finally, some dependencies need to be\ncompiled from source code manually.\n\nThe goal of this project is to unify dependency management using the vcpkg package manager. A successful outcome will be a simplified developer experience where only a small number of tools are required in order to set up a full OpenMS development environment. For OpenMS dependencies that are not available in vcpkg, it will be necessary to contribute a recipe to the vcpkg community using Git.\n\n## Theme C) Visualization and results\n\n### Interactive Proteoform-Centric Visualization and Targeted Spectrum Analysis for Top-Down Proteomics\n\n**Proposed Mentors**: Kyowon Jeong, Tom Müller\n\n**Skills**: Python, mass spectrometry, proteomics, data visualization, OpenMS, web development\n\n**Estimated Project Length**: about 350 hours | Difficulty: Advanced\n\nTop-down proteomics enables the direct analysis of intact proteoforms, providing unparalleled insight into proteoforms, distinct molecular forms of a protein arising from a single gene, including protein isoforms, truncations, and post-translational modifications. However, interpreting individual spectra and connecting observed masses to biologically meaningful proteoforms remains a major bottleneck. This project aims to develop an interactive, proteoform-centric visualization and manual analysis tool, inspired by ProSight Lite, to enable rapid interpretation of top-down mass spectrometry data at the single-spectrum level. By integrating advanced visualization with fast targeted searches, the tool will allow researchers to quickly assess truncations, modifications, and mass discrepancies for a given protein of interest. Moreover, it will include feature-level visualization of proteoform ions over m/z-retention time dimension that will allow for quick and accurate validation of proteoform quantification results. By lowering the barrier between raw spectra and biological interpretation, this project will directly support exploratory proteomics, method development, and hypothesis testing in challenging top-down datasets.\n\nProject Goals The student will design and implement an interactive analysis module that enables: Sequence-centric visualization of proteoforms, inspired by ProSight Lite, supporting user-defined mass inputs.\n\nMirror plots comparing user-supplied masses or m/z values against expected theoretical masses, enabling rapid validation and interpretation.\n\nOn-demand targeted searches, where a single spectrum triggers FLASHTnT via Python bindings to identify truncations and modifications for a specified target protein.\n\nOne-spectrum, one-protein analysis workflows, optimized for fast hypothesis testing rather than large-scale database searches. Intuitive feature (m/z and mass) visualization for quantitative analysis validation, to support exact and quick comparison between theoretical feature traces of quantified proteoforms and the observed ones ."
  },
  {
    "name": "Global Alliance for Genomics and Health",
    "slug": "global-alliance-for-genomics-and-health",
    "tagline": "We develop genomics tools to benefit human health",
    "description": "The Global Alliance for Genomics and Health (GA4GH) was formed to help accelerate the potential of genomic medicine to advance human health. It brings together over 400 leading genome institutes and centers with IT industry leaders to create global standards and tools for the secure, privacy respecting and interoperable sharing of Genomic data.",
    "ideas_url": "https://docs.google.com/document/d/1SeDP5Ny7Gt42g5oY9jdN15Wx6RXtJ9dDcaPeYBvKBcE/edit?tab=t.0#heading=h.qflicizcqlm",
    "website_url": "https://ga4gh.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "postgresql",
      "java",
      "react",
      "rust"
    ],
    "topic_tags": [
      "security",
      "genomics",
      "bioinformatics",
      "genetics",
      "standards"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/global-alliance-for-genomics-and-health",
    "ideas_content": "Die Datei kann in Ihrem Browser nicht geöffnet werden, weil JavaScript nicht aktiviert ist. Aktivieren Sie JavaScript und laden Sie die Seite noch einmal.\nGA4GH Projects for GSoC 2026\nTab\nExtern\nFreigeben\nAnmelden\nDatei\nBearbeiten\nAnsicht\nTools\nHilfe\nBedienungshilfen\nFehlerbehebung"
  },
  {
    "name": "Wagtail",
    "slug": "wagtail",
    "tagline": "The powerful Python CMS for modern websites",
    "description": "We build Wagtail, a popular content management system. It's built on Python, by an active and engaged open source community, which has grown rapidly since Wagtail's release in 2014. Wagtail is available in over 40 languages, and used by some of the world's best-known organizations, including NASA, Google, Mozilla, MIT, and the UK's National Health Service, as well as museums, universities, non-profits, governments, banks, studios, restaurants, startups and bloggers around the world.",
    "ideas_url": "https://github.com/wagtail/gsoc/blob/main/project-ideas.md",
    "website_url": "https://wagtail.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "django"
    ],
    "topic_tags": [
      "web",
      "accessibility",
      "cms"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/wagtail",
    "ideas_content": "# Project ideas\n\n🚧 please refer to our [AI policy](./ai-policy.md) to understand what generative AI use is acceptable when taking part in Google Summer of Code with Wagtail\n\n## Multilingual support improvements\n\n### Summary\n\n\nWe want to make widespread improvements to Wagtail’s capabilities that are relevant to multilingual websites, both in the core CMS and in packages like [wagtail-localize](https://github.com/wagtail/wagtail-localize). We have [extensive feedback from our community](https://github.com/wagtail/wagtail/discussions/13693) on possible improvements. Feature requests, long-standing bugs, maintenance hurdles. There are a lot of options with this project.\n\n### Expected outcomes\n\n- Better core support for common multilingual requirements, shipping in our August 2026 and November 2026 releases.\n- Better support for automation in translation workflows.\n- Demonstration of those changes on our [multilingual user guide website](http://guide.wagtail.org/).\n- TBC: complementary improvements to packages that build upon core features (wagtail-localize or others)\n\n### Implementation\n\nThere will be a discovery phase where we refine exactly which improvements are feasible. This will be based on talking to analyzing user needs and researching any dependencies of possible improvements. We will then proceed with pull requests to Wagtail core, per improvement.\n\nThere is also likely a need for documentation writing - explaining how to get the best results with Wagtail.\n\n### Skills\n\n- Understanding of internationalization needs\n- Backend web development with Django, Python\n- Bonus: front-end web development\n- Bonus: expertise with machine translation tools\n\n### Mentors\n\n- Lead: Thibaud Colas\n- Support: Coen van der Kamp, Sævar Öfjörð Magnússon\n\n## Demo website redesign\n\n### Summary\n\nThe [Wagtail UI team](https://github.com/wagtail/wagtail/wiki/UI-team) is kickstarting an incremental redesign of the [Wagtail bakery demo site](https://github.com/wagtail/bakerydemo), with the intention to make it a more suitable demo for larger projects, and other verticals than breadmaking. As part of Google Summer of Code, help us implement the new design.\n\n### Expected outcomes\n\n- New site sections and revamp of existing sections\n- New visual design for the site\n- Refactorings to simplify long-term maintenance of the site\n- Capabilities to test Wagtail with large amounts of content\n\n### Implementation\n\nWe will work exclusively on the bakery demo project, implementing the designs produced by the UI team. Implementing new site functionality to better demo Wagtail. Changes will be made iteratively so other contributors benefit from every improvement as they are made.\n\n### Skills\n\n- Front-end web development with Django, HTML, vanilla CSS\n- Backend web development with Django, Python\n- Bonus: expertise with visual design, user experience\n\n### Mentors\n\n- Lead: Thibaud Colas\n- Support: TBC - UI team\n\n## Starter kit (news template) upgrade\n\n### Summary\n\nOur [news template](https://github.com/wagtail/news-template) is intended as a great starting point to Wagtail, but it’s hard to use and also to maintain. We want to iterate on its implementation so it better serves its purpose as the best place to go when trying out Wagtail.\n\n### Expected outcomes\n\n- A new version of the starter kit demonstrating the latest Wagtail features\n- Automation to keep the starter kit up-to-date\n- TBC: different variations of the starter kit\n\n### Implementation\n\nAll changes will be implemented to the news template. First with a discovery phase to confirm what is feasible within the Google Summer of Code timeline. Then iterative development of planned improvements.\n\n### Skills\n\n- Backend web development with Django, Python\n- Bonus: Front-end web development with Django, HTML, vanilla CSS\n- Bonus: expertise with DevOps, automation, package management\n\n### Mentors\n\n- Lead: Meagen Voss\n- Support: TBC\n\n## Project proposal: your own idea\n\nYou can also propose your own idea. Your proposal should:\n\n- Have a concrete task.\n- Give a solid idea of what will constitute success. You tell us.\n- Present a detailed design specification.\n- Give insight into who you are. If you propose something ambitious, convince us that you are up to the task.\n- Give insight into your previous projects and experience.\n- Tell us about your experience with Python/Django/Wagtail.\n- Provide a schedule, including a detailed work breakdown and major milestones.\n- Contain your motivation and curriculum vitae.\n\nNote:\n\n- The project ideas above are starting points for your submission, but aren’t enough by themselves. You’ll need to come up with a more complete project plan, and use your own words.\n- Do not feel limited to the project ideas below.\n- If you have a project idea not listed, please direct message the [organisation admins](#organisation-admins). They can test the project eligibility and pair you with a mentor for initial feedback.\n\nProject proposals should fall into one of three categories:\n\n- Work on Wagtail itself. The core product.\n- Work on tools to support Wagtail. Example: Editor guide as a Wagtail website.\n- Wagtail third-party libraries. Example: [Wagtail Live](https://github.com/wagtail/wagtail-live) is a GSOC 2021 project.\n\nThe project you propose should be:\n\n- Something useful for the Wagtail project\n- A single well-scoped project\n- Achievable within the time of GSoC\n- And something the core developers can help mentor you on.\n\n## Template: project idea title\n\n### Summary\n\n### Expected outcomes\n\n### Implementation\n\n### Skills\n\n### Mentors\n\n- Lead: TBC\n- Support: TBC\n\n### Size\n\nExpected size of project approximately 350 hours.\n\n### Difficulty rating\n\nLow / Medium / High"
  },
  {
    "name": "GNU Octave",
    "slug": "gnu-octave",
    "tagline": "Free Your Numbers",
    "description": "GNU Octave is a high-level interpreted language, primarily intended for numerical computations. It provides capabilities for the numerical solution of linear and nonlinear problems and for performing other numerical experiments. It also provides extensive graphics capabilities for data visualization and manipulation. Octave is normally used through its interactive command line interface, but it can also be used to write non-interactive programs. The Octave language is quite similar to Matlab so that most programs are easily portable.\n\nOctave is continually being upgraded. Student projects may also involve developing or upgrading Octave Forge packages, which can be loaded to provide additional specialized functions that supplement those provided in Core Octave.",
    "ideas_url": "https://wiki.octave.org/wiki/index.php?title=Summer_of_Code_-_Getting_Started#Suggested_projects",
    "website_url": "https://www.octave.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c++",
      "hg"
    ],
    "topic_tags": [
      "mathematics",
      "scientific computing",
      "numerical computation",
      "numerical methods",
      "matlab"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/gnu-octave",
    "ideas_content": "# Summer of Code - Getting Started\n\n[Jump to navigation](https://wiki.octave.org#mw-head)\n\n[Jump to search](https://wiki.octave.org#searchInput)\n\n[mentoring organization for GSoC 2025](https://summerofcode.withgoogle.com/programs/2025/organizations/gnu-octave).\n\nSince 2011 the GNU Octave project has successfully mentored:\n\nin [Summer of Code](https://wiki.octave.org/Summer_of_Code) (SoC) programs by [Google](https://summerofcode.withgoogle.com/) and [ESA](https://esa.int/).\n\nThose SoC programs aim to advertise open-source software development and to attract potential new Octave developers.\n\n# Steps toward a successful application\n\n- 😉💬\n**We want to get to know you (before the deadline). Communicate with us.**- Join\nor**Octave Discourse**[IRC](https://wiki.octave.org/IRC)for general discussion and to ask questions (Please do not use the bug tracker for general GSOC inquiries unrelated to specific bugs found with Octave.) Using a nickname is fine. - Show us that you're motivated to work on Octave 💻. There is no need to present an overwhelming CV 🏆; evidence of involvement with Octave is more important.\n**If you never talked to us, we will likely reject your proposal**, even it looks good 🚮\n\n- Join\n- 👩🔬\n**Get your hands dirty.**- We are curious about your programming skills 🚀\n- Your application will be much stronger if you\n[fix Octave bugs](https://savannah.gnu.org/bugs/?group=octave)or[submit patches](https://savannah.gnu.org/patch/?group=octave)before or during the application period. - You can take a look at the\n[short projects](https://wiki.octave.org/Short_projects)for some simple bugs to start with.\n\n- Your application will be much stronger if you\n**Use Octave!**- If you come across something that does not work the way you like ➡️ try to fix that 🔧\n- Or if you find a missing function ➡️ try to implement it.\n\n\n- We are curious about your programming skills 🚀\n- 📝💡\n**Tell us what you are going to do.**- Do not write just to say what project you're interested in. Be specific about what you are going to do, include links 🔗, show us you know what you are talking about 💡, and ask many\n[smart questions](http://www.catb.org/esr/faqs/smart-questions.html)🤓 - Remember,\n**we are volunteer developers and not your boss**🙂\n\n- Do not write just to say what project you're interested in. Be specific about what you are going to do, include links 🔗, show us you know what you are talking about 💡, and ask many\n- 📔\n**Prepare your proposal with us.**- Try to show us as early as possible a draft of your proposal 📑\n- If we see your proposal for the first time after the application deadline, it might easily contain some paragraphs not fully clear to us. Ongoing interaction will give us more confidence that you are capable of working on your project 🙂👍\n- Here’s a sample proposal outline that you can use as a reference when drafting your own application.\n[Sample Proposal](https://docs.google.com/document/d/1kGtT9_f0FrXdCKwyKEWwOV6R-AU90bkd/edit?usp=sharing&ouid=115736651221450989198&rtpof=true&sd=true) - Then submit the proposal following the applicable rules, e.g. for\n[GSoC](https://google.github.io/gsocguides/student/writing-a-proposal). 📨\n\n\n# How do we judge your application?\n\nDepending on the mentors and SoC program there are varieties, but typically the main factors considered would be:\n\n**You have demonstrated interest in Octave and an ability to make substantial modifications to Octave**- The most important thing is that you've contributed some interesting code samples to judge your skills. It's OK during the application period to ask for help on how to format these code samples, which normally are Mercurial patches.\n\n\n**You showed understanding of your topic**- Your proposal should make it clear that you're reasonably well versed in the subject area and won't need all summer just to read up on it.\n\n\n**Well thought out, adequately detailed, realistic project plan**- \"I'm good at this, so trust me\" isn't enough. In your proposal, you should describe which algorithms you'll use and how you'll integrate with existing Octave code. You should also prepare a project timeline and goals for the midterm and final evaluations.\n\n\n# What you should know about Octave\n\nGNU Octave is mostly written in C++ and its own scripting language that is mostly compatible with Matlab. There are bits and pieces of Fortran, Perl, C, awk, and Unix shell scripts here and there. In addition to being familiar with C++ and Octave's scripting language, you as successful applicant will be familiar with or able to quickly learn about Octave's infrastructure. You can't spend the whole summer learning how to build Octave or prepare a changeset and still successfully complete your project 😇\n\nYou should know:\n\n- How to build Octave from its source code using\n[the GNU build system](http://en.wikipedia.org/wiki/GNU_build_system).- Read in this wiki:\n[Developer FAQ](https://wiki.octave.org/Developer_FAQ),[Building](https://wiki.octave.org/Building) - Tools to know:\n[gcc](https://en.wikipedia.org/wiki/GNU_Compiler_Collection),[make](https://en.wikipedia.org/wiki/Make_(software))\n\n- Read in this wiki:\n- How to submit patches (changesets).\n- Read in this wiki:\n[Contribution guidelines](https://wiki.octave.org/Contribution_guidelines),[Mercurial](https://wiki.octave.org/Mercurial) - Tools to know:\n[Mercurial (hg)](https://en.wikipedia.org/wiki/Mercurial),[git](https://en.wikipedia.org/wiki/Git)\n\n- Read in this wiki:\n\n# Suggested projects\n\nThe following suggested projects are distilled from the [Projects](https://wiki.octave.org/Projects) page for the benefit of potential SoC participants. You can also look at our [completed past projects](https://wiki.octave.org/Summer_of_Code), or the current [| Octave Development Roadmap](https://hg.savannah.gnu.org/hgweb/octave/file/tip/etc/ROADMAP.md) for more inspiration.\n\n**propose your own projects**. If you are passionate about your project, it will be easy to find an Octave developer to mentor and guide you. Please note that for such a proposal to be successful it will almost certainly involve initiating pre-proposal discussion over at the\n\n[Octave Discourse forum](https://octave.discourse.group).\n\n## Custom re-implementation of the texi2html (v.1.82) command line tool\n\nImplement a compiled .oct function to relax the dependency of the pkg-octave-doc package on texi2html (v.1.82) command line tool, which is no longer maintained or further developed but also not readily available to all linux distributions. The idea is to have a `texi2html` function within the pkg-octave-doc package that will replace the functionality of the texi2html (v.1.82) command line tool. This will also help improve the speed of pkg-octave-doc processing large packages, which contain specific tags (such as @math) which are currently handled within Octave code.\n\n**Project size**[[?]](https://wiki.octave.org#Project_sizes)and**Difficulty**\n\n- ~350 hours (hard)\n\n**Required skills**\n\n- Perl, C++, Octave, Texinfo, HTML\n\n**Potential mentors**\n\n## Add **anova** object to the statistics package\n\nImplement anova classdef including its methods and extend the functionality of the statistics package for Analysis of Variance. More information about this project can be found at the related [issue](https://github.com/gnu-octave/statistics/issues/265) in the statistics repository.\n\n**Project size**[[?]](https://wiki.octave.org#Project_sizes)and**Difficulty**\n\n- ~350 hours (hard)\n\n**Required skills**\n\n- Octave, analysis of variance, statistics, classdef\n\n**Potential mentors**\n\n## Add **LinearModel** and **CompactLinearModel** objects to the statistics package\n\nImplement LinearModel and CompactLinearModel classdefs including their methods and extend the functionality of the statistics package for linear regression by refactoring the existing fitlm function and implementing the missing stepwiselm function. More information about this project can be found at the related [issue](https://github.com/gnu-octave/statistics/issues/266) in the statistics repository.\n\n**Project size**[[?]](https://wiki.octave.org#Project_sizes)and**Difficulty**\n\n- ~350 hours (hard)\n\n**Required skills**\n\n- Octave, linear models, statistics, classdef\n\n**Potential mentors**\n\n## Implement missing ODE capabilities to support Chebfun\n\n[Chebfun](https://www.chebfun.org/) uses interpolation to approximate functions to very high accuracy, giving numerical computing that feels like symbolic computing. The software is implemented as collection of “classdef” classes and is licensed under the BSD license. In the past several years, we’ve made an effort to get Chebfun working on Octave; [see the current progress here](https://gitlab.com/chebfun-octave/chebfun). However, Chebfun does not yet fully work, largely due to differences and issues with missing Octave classdef and ODE related features. We plan to continue that effort, with a focus on implementing missing ODE functionality in Octave itself. Work may include improving or extending the ODE capabilities of Octave via the SUNDIALS package, patches to Chebfun itself, or general improvement to Octave’s “classdef” implementation, depending on interest.\n\n**Project size**[[?]](https://wiki.octave.org#Project_sizes)and**Difficulty**\n\n- ~350 hours (hard)\n\n**Required skills**\n\n- Octave, numerical differential equations, polynomial interpolation and approximation theory, C++.\n\n**Potential mentors**\n\n\n\n\n\n\n\n# Project sizes\n\nAs of 2024, possible project sizes are 90 (small), 175 (medium), or 350 hours (large) [1]."
  },
  {
    "name": "OWASP Foundation",
    "slug": "owasp-foundation",
    "tagline": "No more insecure software.",
    "description": "As the world’s largest non-profit organization concerned with software security, OWASP:\n\n* Supports the building of impactful projects; \n* Develops & nurtures communities through events and chapter meetings worldwide; \n* Provides educational publications & resources\n\nin order to enable developers to write better software, and security professionals to make the world's software more secure.",
    "ideas_url": "https://owasp.org/www-community/initiatives/gsoc/gsoc2026ideas",
    "website_url": "https://owasp.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "java",
      "ZAP",
      "Juice Shop"
    ],
    "topic_tags": [
      "web",
      "cloud",
      "application security",
      "cybersecurity",
      "DevSecOps"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/owasp-foundation",
    "ideas_content": "# GSoC 2026 Ideas\n\n[Bug Logging Tool (BLT)](https://owasp.org#bug-logging-tool-blt) • [OWASP DevSecOps Maturity Model](https://owasp.org#owasp-devsecops-maturity-model) • [OWASP Nettacker](https://owasp.org#owasp-nettacker) • [OWASP Nest](https://owasp.org#owasp-nest) • [OWASP Juice Shop](https://owasp.org#owasp-juice-shop) • [Pygoat](https://owasp.org#pygoat) • [OpenCRE](https://owasp.org#opencre) • [OWASP OWTF](https://owasp.org#owtf) • [OWASP Cornucopia](https://owasp.org#owasp-cornucopia)\n\nTips to get you started in no particular order:\n\n- Read the\n[Student Guidelines](https://owasp.org/gsoc2026). - Check our\n[GitHub organization](https://github.com/OWASP). - Contact one of the project mentors below.\n\n## List of Project Ideas\n\n[Bug Logging Tool (BLT)](https://owasp.org/www-project-bug-logging-tool/)\n\nOWASP BLT (Bug Logging Tool) is a community-driven OWASP Foundation project that develops and maintains open-source tools for structured vulnerability reporting, bug tracking, security automation, contributor engagement, and related infrastructure. The BLT ecosystem includes modular services, APIs, dashboards, browser and mobile applications, automation bots, and research initiatives, all developed transparently under OWASP governance and open-source licensing.\n\nBLT has evolved into a growing ecosystem that combines **modern full-stack engineering, AI-assisted security workflows, hands-on security education, distributed scanning infrastructure, and blockchain-backed incentive systems**. The platform functions both as a production-grade vulnerability management system and as a practical learning environment where contributors build real-world security expertise.\n\nThis year’s GSoC projects center on **core platform modernization, AI-native interfaces, automation-first workflows, distributed security infrastructure, hands-on security education, and meaningful gamification**. Our goal is to make BLT faster, more scalable, AI-agent ready, and deeply educational—turning real security work into structured learning pathways.\n\nPreference will be given to students who have at least\n\n5 merged PRsbefore GSoC selection.\n\n### 🔹 **2026 GSoC Ideas / All Large Projects**\n\n[BLT-Next](https://github.com/OWASP-BLT/BLT-Next) : Core BLT Migration to GitHub Pages and Cloudflare Python workers\n\n**Revamp BLT website with a fresh, modern design by removing non-core components to create a clear, enjoyable user experience focused on core value.** The project involves migrating the complete OWASP BLT platform from its current Django-based monolithic architecture to a lightweight static frontend deployed on GitHub Pages using plain HTML, vanilla JavaScript, and HTMX, with dynamic functionality powered by Cloudflare Python Workers at the edge. This migration will replace Django template rendering with modular static components and progressive enhancement, achieving sub-200ms global response times, simplified architecture, improved maintainability, and production-grade reliability while preserving full feature parity and positioning BLT as a fast, contributor-friendly reference implementation.\n\n[BLT-Preflight](https://github.com/OWASP-BLT/BLT-Preflight) : Pre-Contribution Security Intent & Risk Guidance\n\n**Provide security intent and risk guidance before contributors submit code to prevent common mistakes and improve contributor understanding.** This pre-contribution advisory system helps contributors understand security expectations before opening a pull request by evaluating security context through issue labels, repository metadata, and historical patterns, then providing plain-language guidance linked to relevant documentation. The system includes optional contributor intent capture (planned work areas, components to modify, AI assistance usage), a maintainer visibility dashboard for early identification of risky contributions, and a learning feedback loop that refines guidance rules over time. BLT-Preflight operates on a purely advisory basis with no blocking or enforcement mechanisms, focusing on prevention and clarity to reduce maintainer workload and improve the quality of security contributions.\n\n[BLT-Rewards](https://github.com/OWASP-BLT/BLT-Rewards) : BACON Rewards & Security Contribution Gamification\n\n**Security contribution gamification with BACON tokens, badges, reputation tiers, and leaderboards to increase contributor retention and engagement.** The system listens for verified security contributions and awards rewards idempotently including BACON cryptocurrency tokens (with existing blockchain mint infrastructure), achievement badges for different security domains, progressive reputation tiers (Beginner → Expert), severity-weighted leaderboards, and a swag redemption marketplace where tokens convert to physical merchandise. Built with robust anti-gaming architecture (idempotent rewards, fraud detection, admin oversight), the platform includes comprehensive audit trails, an education bridge API layer for learning platform integration, and tokenomics analysis to ensure long-term sustainability. BLT-Rewards transforms security work into an engaging, progression-based experience that prioritizes impact over volume while enabling education platforms to leverage BLT contribution data for personalized learning paths.\n\n[BLT-NetGuardian](https://github.com/OWASP-BLT/BLT-NetGuardian) : Distributed Autonomous Security Scanning Platform\n\n**Community-powered security scanning platform with distributed scanning, real vulnerability detection, and responsible disclosure workflows.** NetGuardian replaces stubbed scanners with real vulnerability detection (XSS, SQLi, CSRF, security headers plus Semgrep SAST), introduces distributed scanning via secure volunteer CLI clients with local resource caps, and implements Zero-Trust encrypted ingestion where sensitive evidence stays encrypted end-to-end until authorized organization users decrypt it client-side. The platform includes result validation and false-positive filtering with confidence scoring, basic deduplication using fingerprints, triage-lite UI with evidence viewer and “Convert to Issue” workflow, security.txt detection for improved responsible disclosure, and professional remediation reports (CSV/PDF) for organizations. NetGuardian emphasizes accuracy through curated evaluation targets and rule tuning, privacy-preserving architecture with signed and timestamped submissions, and lower reviewer workload through normalized findings and streamlined triage.\n\n[BLT University](https://github.com/OWASP-BLT/BLT-University) : Security-Focused Education Platform\n\n**Security-focused education tool that teaches users about security through hands-on, code-centric labs and community-driven knowledge sharing.** The platform transforms BLT’s existing theory-heavy labs into interactive exercises where learners analyze real vulnerable code, identify security flaws, explain exploitation scenarios, and apply secure fixes using a three-step workflow (Identify → Explain → Fix) with partial credit and progress tracking. BLT University establishes a safe, anonymized security intelligence pipeline that aggregates vulnerability patterns from BLT issues/PRs into public dashboards, monthly/quarterly reports with two-person approval workflows, and remediation playbooks that convert into mini interactive challenges. The unified architecture creates a feedback loop where real vulnerability patterns improve labs and playbooks, helping contributors learn security thinking inspired by OWASP Top 10 and CTF-style reasoning, with optional integration to badges/BACON gamification and future connections to NetGuardian findings for automatically mapped learning recommendations.\n\n[BLT-MCP](https://github.com/OWASP-BLT/BLT-MCP) : Model Context Protocol Server for Complete BLT Interface\n\n**An interface to the BLT ecosystem enabling AI agents and developers to log bugs, triage issues, query data, and manage workflows from IDEs or chat interfaces.** BLT-MCP implements the Model Context Protocol (MCP) standard to provide comprehensive, AI-agent-friendly access to all aspects of BLT through three layers: Resources (read-only access to issues, repos, contributors, workflows, leaderboards, rewards via `blt://`\n\nURIs), Tools (actions like submit_issue, award_bacon, update_issue_status, add_comment), and Prompts (reusable task templates like triage_vulnerability, plan_remediation, review_contribution). The system uses JSON-RPC 2.0 over stdio or HTTP/SSE with OAuth 2.0/API key authentication, enabling natural integration with Claude Desktop, custom AI agents, and third-party tools without requiring custom API documentation since agents discover capabilities automatically. BLT-MCP positions BLT as an AI-agent-first platform with standardized protocol access that unifies fragmented REST/GraphQL endpoints, creates novel use cases (autonomous issue triage, automated reward distribution, workflow tracking), and synergizes with other BLT ideas by exposing RAG bot capabilities, AI-guided recommendations, reputation scores, and gamification data through a single consistent interface.\n\n### ✅ **Expected Results**\n\n- Successfully implementing a\n**fully functional, production-ready**feature. - Contributions must align with\n**BLT’s core security and performance goals**. - Code should adhere to best practices, including\n**security testing, CI/CD integration, and documentation**.\n\n### 📌 **Knowledge Prerequisites**\n\nTo contribute effectively, familiarity with at least one or more of the following is recommended:\n\n**Back-End:**Python, Django, Django Ninja, SQL**Front-End:**HTMX, Tailwind CSS, HTML/CSS**Blockchain:**Bitcoin Ordinals, Solana, Smart Contracts**AI/ML:**NLP, Machine Learning for security analytics**DevOps & Security:**GitHub API, REST API, OAuth, Authentication\n\n### 👥 **Mentors**\n\n📌 *Confirmed Mentors:* (we’re all on the OWASP Slack in the [#project-blt](https://owasp.slack.com/archives/project-blt) channel)\n\n**Donnie Brown****Ahmed ElSheikh****Manikandan Chandran****Rinkit Adhana****Raj Gupta****Vinamra Vaswani****Carla Voorhees****Jigyasu Rajput****Rishab Kumar Jha****Akshay Behl**\n\n[OWASP DevSecOps Maturity Model](https://dsomm.owasp.org)\n\nJoin us in enhancing the DSOMM, a pivotal tool designed to improve the security and operational efficiency of software development processes. We are looking for passionate students to contribute to two major areas: our main application development in JavaScript and our metric analyzer and collector in Java. Whether you are looking to tackle medium-sized challenges or are ready to embark on a larger project, we have exciting opportunities for you.\n\nTo receive early feedback please:\n\n- put your proposal on Google Docs and submit it to the OWASP Organization on Google’s GSoC page in “Draft Shared” mode.\n- Please pick “dsomm” as Proposal Tag to make them easier to find for us. Thank you!\n\n##### Update of the DSOMM Application (Angular)\n\nPrimary Objectives:\n\n- Upgrade Angular Framework: Migrate the DSOMM application from its current Angular version to Angular 21\n- Updates: Update all related dependencies including TypeScript, RxJS, Angular CLI, and third-party libraries\n- Code Modernization: Refactor deprecated APIs and adopt modern Angular patterns (standalone components, signals, etc.)\n- Testing & Quality Assurance: Ensure all existing functionality works correctly after migration with comprehensive testing, this can lead to unit test optimization\n- Documentation: Update developer documentation with new setup instructions and migration notes\n\n#### Prerequisites\n\n- Proficiency in the corresponding programming language (JavaScript and Angular for the main application)\n- Previous contributions to open-source projects are highly desirable, demonstrating your commitment and collaborative skills\n\n##### Mentors\n\nReach out to us on Slack to discuss these and other ideas!\n\n[OWASP Nettacker](https://owasp.org/www-project-nettacker/)\n\nOWASP Nettacker is a Modular Automated Penetration Testing/ Information gathering Framework and Vulnerability Scanner fully written in Python. Nettacker can run a variety of scans discovering subdomains, open ports, services, vulnerabilities, misconfigurations, default credentials.\n\n\n##### Explanation of Ideas\n\n- improve/redesign WebUI / add a dashboard\n- implement more tests, get 85% code coverage level\n- implement more modules, focus on more coverage of CISA KEV CVEs\n- implement external API keys configuration using a config file, API and WebUI\n- implement module workflows e.g. run module B after module A only if module A returns any result/result matching condition\n- improve documentation\n- improve scan engine efficiency\n\n##### Your Own Ideas\n\nDo you have an idea to improve OWASP Nettacker?\nWe’d love to hear it, please reach out in OWASP Slack on channel [#project-nettacker](https://app.slack.com/client/T04T40NHX/CQZGG24FQ) to ensure that the idea fits OWASP Nettacker roadmap and goals.\n\n##### Getting Started\n\nRepositories:\n\n[OWASP Nettacker on OWASP GitHub](https://github.com/OWASP/Nettacker)[Documentation](https://nettacker.readthedocs.io)- Join OWASP Slack and contact us on channel\n[#project-nettacker](https://app.slack.com/client/T04T40NHX/CQZGG24FQ)\n\n##### Knowldege Requirements\n\n- Python\n- Flask\n- HTML/CSS/JavaScript\n- previous vulnerability scanning/bug bounty hunting experience, vulnerability scanning tools use (nmap, metasploit, other kali linux tools)\n\n##### Mentors\n\n[OWASP Nest](https://nest.owasp.org)\n\nOWASP Nest is a comprehensive, community-first platform built to enhance collaboration and contribution across the OWASP community. Acting as a central hub, it helps users discover chapters and projects, find contribution opportunities, and connect with like-minded individuals based on their interests and expertise.\n\n#### Repositories\n\n[OWASP Nest Backend](https://github.com/OWASP/Nest/tree/main/backend)[OWASP Nest Frontend](https://github.com/OWASP/Nest/tree/main/frontend)[OWASP Nest Schema](https://github.com/OWASP/nest-schema/)[API SDK Go](https://github.com/OWASP/nest-sdk)[API SDK Python](https://github.com/OWASP/nest-sdk-python)[API SDK TypeScript](https://github.com/OWASP/nest-sdk-typescript)\n\n#### Technical Stack\n\n- Python, Django, Pytest, Strawberry, Ninja\n- TypeScript, React, Apollo, Next.js. Jest, PlayWright\n- Hero UI, Tailwind CSS\n- PostgreSQL, Algolia, Redis\n- Docker, Ansible, Terraform, AWS\n\n#### Getting Started\n\n- Check out our\n[contributing guidelines](https://github.com/OWASP/Nest/blob/main/CONTRIBUTING.md) - Join OWASP Nest channel\n[#project-nest](https://owasp.slack.com/archives/project-nest) - Consider\n`good first issue`\n\nfrom OWASP Nest[issues page](https://github.com/OWASP/Nest/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22good%20first%20issue%22)\n\n#### Projects / Ideas\n\n\n-\n[OWASP Board Activity Standardization and Data Programmatic Access](https://github.com/OWASP/Nest/milestone/20): This milestone focuses on standardizing how OWASP Board activities are recorded, structured, and published. -\n[OWASP Board Candidate Information Transparency and Fact-Checking](https://github.com/OWASP/Nest/milestone/19): This milestone focuses on improving the transparency, accuracy, and trustworthiness of information related to OWASP board candidates. -\n[OWASP Community Snapshots](https://github.com/OWASP/Nest/milestone/16): Creating a summary of activities within OWASP projects, chapters, and events, including new blog posts and news, to keep the community informed about recent developments. -\n[OWASP Contributor Recognition Program](https://github.com/OWASP/Nest/milestone/22): This milestone introduces an OWASP-wide Contributor Recognition system in OWASP Nest to make contributions visible, measurable, and shareable across projects and chapters, inspired by community platforms like ContribCard, with potential integration into existing OWASP Nest badges and certificate delivery via services like Certifier. -\n[OWASP NestBot AI Assistant Improvement](https://github.com/OWASP/Nest/milestone/8): Develop an AI-powered OWASP NestBot Slack assistant that acts as an auto-responder for frequently asked questions, guides users to the appropriate OWASP channels, and handles typical OWASP community queries. -\n[OWASP Nest Monitoring and Observability](https://github.com/OWASP/Nest/milestone/21): Implement modern monitoring and observability practices across OWASP Nest infrastructure on AWS to ensure reliability, performance visibility, and proactive issue detection. -\n[OWASP Nest UI/UX Revamp](https://github.com/OWASP/Nest/milestone/23): This milestone delivers a comprehensive UI/UX revamp of OWASP Nest to improve usability, accessibility, visual consistency, and the overall contributor experience across the platform. -\n[OWASP Pulse](https://github.com/OWASP/Nest/milestone/24): This milestone introduces the OWASP Pulse page in OWASP Nest as a unified, near real-time activity feed that aggregates events across repositories with filters by user, project, repository, and chapter to improve visibility and engagement.\n\nPlease visit our planned [milestones page](https://github.com/OWASP/Nest/milestones) or `gsoc2026`\n\nlabeled [issues page](https://github.com/OWASP/Nest/issues?q=is%3Aissue%20state%3Aopen%20label%3Agsoc2026).\n\n#### Your own ideas\n\nDo you have an idea to improve OWASP Nest? We’d love to hear it, please reach out in Slack to ensure that the idea fits OWASP Nest goals.\n\n#### Expected Results\n\n- Your proposal projects/ideas are fully completed.\n- Your code follows our existing style guides and passes quality checks, test coverage, etc.\n\n#### Mentors\n\nPlease contact [Arkadii Yakovets](https://owasp.slack.com/team/U060W3NKLTF) or [Kate Golovanova](https://owasp.slack.com/team/U07PWB1JZ6Z) if you’re interested in participating as a mentor.\n\n[OWASP Juice Shop](https://owasp-juice.shop)\n\nOWASP Juice Shop is probably the most modern and sophisticated insecure web application! It can be used in security trainings, awareness demos, CTFs and as a guinea pig for security tools! Juice Shop encompasses vulnerabilities from the entire OWASP Top Ten along with many other security flaws found in real-world applications!\n\nTo receive early feedback please:\n\n- put your proposal on Google Docs and submit it to the OWASP Organization on Google’s GSoC page in “Draft Shared” mode.\n- Please pick “juice shop” as Proposal Tag to make them easier to find for us. Thank you!\n\n🛑 Please be aware that the OWASP Juice Shop project will\n\nnotconsider or even review any proposals which fail to include an AI Tool Disclosure statement. We recommend you use the following templated that we derived from the one enforced on Pull Requests to OWASP Juice Shop:`### AI Tool Disclosure - [ ] My GSoC proposal does not include any AI-generated content - [ ] My GSoC proposal includes AI-generated content, as disclosed below: - AI Tools: `[e.g. GitHub CoPilot, ChatGPT, JetBrains Junie etc.]` - LLMs and versions: `[e.g. GPT-4.1, Claude Haiku 4.5, Gemini 2.5 Pro etc.]` - Prompts: `[Summarize the key prompts or instructions given to the AI tools]``\n\n\n##### Explanation of Ideas\n\n###### Your own idea\n\n\n\nYou have an awesome idea to improve OWASP Juice Shop that is not on this list? Great, please submit it!\n\n##### Expected Results\n\n- A new feature or improvement of an existing one that makes OWASP Juice Shop even better\n- Your code follows our existing styleguides and passes all existing quality gates regarding code smells, test coverage etc.\n- Code that you write comes with automated tests that fit into\n[our available test suites](https://pwning.owasp-juice.shop/companion-guide/latest/part3/contribution.html#_testing).\n\n##### Getting started\n\n- Make sure your JavaScript/TypeScript is sufficient to work on the\nJuice Shop codebase. Check our\n[Codebase 101](https://pwning.owasp-juice.shop/companion-guide/latest/part3/codebase.html)here. Students with some experience with (or willingness to learn) Angular and Node.js/Express are usually prefered. - Read our\n[Contribution Guidelines](https://pwning.owasp-juice.shop/companion-guide/latest/part3/contribution.html)very carefully. Best make some small contributions before GSoC, so we can see how you work and help you dive into the code even better. - Get in touch\n[via Slack](https://owasp.slack.com/messages/project-juiceshop)or email (see below) to discuss any of the listed or your own idea for GSoC!\n\n##### Mentors\n\n[Bjoern Kimminich](https://owasp.org/cdn-cgi/l/email-protection#0c6e6663697e6222676561616562656f644c637b6d7f7c22637e6b)- OWASP Juice Shop Project Leader ([bkimminich](https://owasp.slack.com/team/U1S23SNE7)on Slack)[Jannik Hollenbach](https://owasp.org/cdn-cgi/l/email-protection#82e8e3ececebe9aceaedeeeee7ece0e3e1eac2edf5e3f1f2acedf0e5)- OWASP Juice Shop Project Leader ([Jannik](https://owasp.slack.com/team/UAM6MBY30)on Slack)\n\n[PyGoat](https://owasp.org/www-project-pygoat/)\n\nPyGoat is an open-source, intentionally vulnerable Python web application designed to help developers and security enthusiasts learn about web application security. It provides hands-on experience in identifying and mitigating common security vulnerabilities, making it a valuable resource for practicing secure coding and penetration testing techniques.\n\n#### Repository\n\n#### Skills Required\n\n- HTML/CSS/JavaScript\n- Python\n- Django\n- Docker\n- Basic knowledge of application security\n\n##### Getting started\n\n- Check\n[GitHub project](https://github.com/adeyosemanputra/pygoat)and[Website](https://owasp.org/www-project-pygoat/). - Join\n[OWASP Slack](https://owasp.org/slack/invite)and contact us on channel #project-pygoat\n\n#### Projects / Ideas\n\n\n- Refactor the webapp, move away vulnarable labs from the main website.\n- Deploy a microservice architecture based approch for the labs.\n- Add new labs to the project.\n- Add interactive dashboard for user performance and completion status.\n- UI consistency\n- Expand challenge section and playgrounds.\n- Extend labs to other languages as well.\n- Prepare for\n`OWASP Top 10:2026`\n\nsection\n\n#### Mentors\n\n[ardiansyah](https://owasp.org/cdn-cgi/l/email-protection#334352585756405244525d54525d73545e525a5f1d505c5e)[Rupak Biswas](https://github.com/RupakBiswas-2304)([Rupak](https://owasp.slack.com/team/U036WSR1684)on slack)[Garvita Kataria](https://github.com/Garvita-k)([Slack](https://owasp.slack.com/team/U08BJEKS5KQ))\n\n[OpenCRE](https://opencre.org/)\n\nOpenCRE is the world’s largest Cybersecurity knowledge graph. It semantically links information between standards, knowledge bases and security tools. Also, it allows users to extend the graph themselves and contains a RAG chatbot implementation. OpenCRE is a great GSOC project if you’re looking to add “Data science/engineering”, “Knowledge Graph and AI” with a focus on Legal Tech and cybersecurity in your CV.\n\n#### Repository\n\n#### Skills Required\n\n- HTML/CSS/React-Typescript\n- Python\n- Flask\n- Docker\n\n##### Getting started\n\n- Check the\n[GitHub project](https://github.com/OWASP/OpenCRE)and the issues marked as either`good first issue`\n\n,`help wanted`\n\nor`GSOC`\n\n- Join\n[OWASP Slack](https://owasp.org/slack/invite)and contact us on channel #project-opencre\n\n#### Projects / Ideas\n\n\n- There are many small, medium and large project in the\n[Issues Page tagged with GSOC](https://github.com/OWASP/OpenCRE/issues?q=state%3Aopen%20label%3A%22GSOC%22)that we are interested in, depending on your background and interests they are split in the following categories: AI, Frontend, Backend, FullStack. They all contain a bit of frontend and data analysis and graph operations. Priorities for us are: [Make the gap analysis functionality faster](https://github.com/OWASP/OpenCRE/issues/587)[MyOpenCRE](https://github.com/OWASP/OpenCRE/milestone/5)[Releasing the Explorer page](https://github.com/OWASP/OpenCRE/milestone/6)\n\n#### 🔹 **OpenCRE Scraper & Indexer (Project OIE) - Module Projects**\n\nThe OpenCRE Scraper & Indexer is an autonomous ETL pipeline that ingests OWASP security knowledge from various sources, filters noise, and links content to the OpenCRE knowledge graph. This project consists of four independent modules, each suitable for a GSoC project.\n\n**Important Requirements:**\n\n**Contributor Eligibility**: Applicants must have**at least 3 merged pull requests**to the OpenCRE repository before GSoC selection. This demonstrates familiarity with the codebase, contribution workflow, and project standards.**Code of Conduct**: All contributors must read and agree to follow the[OpenCRE Code of Conduct](https://github.com/OWASP/OpenCRE/blob/main/CODE_OF_CONDUCT.md). Violations will result in immediate project termination.**Pre-Code Experiments**: Each module requires completion of specific pre-code experiments before implementation begins. These experiments validate the approach and ensure technical feasibility.\n\nFor detailed architecture and requirements, see the [RFC: The OpenCRE Scraper & Indexer](https://raw.githubusercontent.com/OWASP/OpenCRE/1539e0a209b7891c2363b4aa9be407cad87fe319/docs/designs/owasp-pane-of-glass.md).\n\n##### 🔸 **Module A: Information Harvesting**\n\n\n**Primary Objectives:**\n\n- Build a GitHub Actions-based cron job that runs nightly at 02:00 UTC\n- Implement a config reader that parses a\n`repos.yaml`\n\nfile containing a list of high-value OWASP repositories (ASVS, WSTG, etc.) - Develop a diff fetcher that uses\n`git log --since=\"24h\"`\n\nto identify changes in the last 24 hours - Create a temporary storage system (Raw Change Bucket) to store raw diffs before processing\n- Handle GitHub API rate limits gracefully\n- Parse files to extract meaningful text changes (not raw diff syntax)\n\n**Technical Requirements:**\n\n**Tech Stack**: Python (requests, PyGithub), GitHub Actions (Cron)**Pre-Code Experiment**:- Manually inspect 10 random OWASP repositories to identify common junk files (package-lock.json, CNAME, _config.yml, etc.)\n- Create a regex exclusion list that eliminates 90% of noise without downloading files\n- Write a 10-line script to fetch only modified paragraphs from a large Markdown file using git diff, returning clean text (not raw diff syntax)\n\n\n**Expected Results:**\n\n- A production-ready GitHub Action that runs nightly\n- Configurable repository list via YAML\n- Efficient diff extraction that filters out noise files\n- Comprehensive error handling and logging\n- Unit tests with >70% code coverage\n- Documentation for configuration and maintenance\n\n**Difficulty Characterization:**\nThis is a **Medium** difficulty project requiring:\n\n- Understanding of GitHub API and rate limiting\n- Git operations and diff parsing\n- YAML configuration parsing\n- GitHub Actions workflow development\n- Incremental crawling strategies\n\n##### 🔸 **Module B: Noise/Relevance Filter**\n\n\n**Primary Objectives:**\n\n- Implement a two-stage filtering system: regex-based filtering followed by LLM-based relevance checking\n- Create regex filters to reject common noise files (*.css, lockfiles, tests/, etc.)\n- Integrate with managed LLM APIs (Gemini Flash or GPT-4o-mini) for semantic relevance checking\n- Design and tune prompts to accurately identify security knowledge vs. noise (formatting, linting, bureaucracy)\n- Build a knowledge queue system that routes relevant content to Module C\n\n**Technical Requirements:**\n\n**Tech Stack**: Python (langchain or raw API calls), Managed LLM APIs (Gemini Flash/GPT-4o-mini)**Pre-Code Experiment**:- Extract 100 real commit messages/diffs from OWASP repositories\n- Manually tag them in a spreadsheet: Relevant (Security Info) vs Noise (Typos, Admin, Formatting)\n- Run these 100 items through the proposed LLM prompt\n- Success Criteria: LLM must match manual tags >97% of the time\n\n\n**Expected Results:**\n\n- A filtering pipeline that processes raw changes and outputs relevant security knowledge\n- Tuned LLM prompts with >97% accuracy on validation dataset\n- Cost-effective implementation using managed LLM APIs\n- Comprehensive logging of filtered vs. accepted content\n- Unit tests with >70% code coverage\n- Documentation of prompt engineering process and results\n\n**Difficulty Characterization:**\nThis is an **Easy** difficulty project suitable for:\n\n- Entry-level developers interested in prompt engineering\n- Developers comfortable with API integration\n- Those who enjoy iterative prompt tuning (“vibe coding”)\n- No advanced ML knowledge required\n\n##### 🔸 **Module C: The Librarian (Smart Content Mapping)**\n\n\n**Primary Objectives:**\n\n- Implement a two-stage retrieval system: vector search (bi-encoder) followed by cross-encoder re-ranking\n- Set up vector search using pgvector to retrieve top 20 candidate CRE nodes\n- Integrate sentence-transformers library with ms-marco-MiniLM-L-6-v2 model for cross-encoder re-ranking\n- Handle the “Negation Problem” (e.g., “Do NOT use MD5” should map correctly)\n- Implement update detection logic to identify when content is an update to existing content\n- Add security gates to detect adversarial updates or contradictions to previous content\n- Set threshold-based routing: score > 0.8 links to CRE, score < 0.8 flags for human review\n\n**Technical Requirements:**\n\n**Tech Stack**: sentence-transformers (HuggingFace), pgvector, Python**Prerequisites**: Understanding of Embeddings, Bi-Encoders vs Cross-Encoders, Vector Similarity**Pre-Code Experiment**:- Select 50 random ASVS requirements and strip metadata\n- Feed them into basic Vector Search (Cosine Similarity)\n- Check mapping accuracy to correct CRE nodes\n- Run through Cross-Encoder and compare results\n- Success Criteria: Cross-Encoder must show 20% accuracy improvement over Cosine Similarity, especially for “Negative” requirements\n\n\n**Expected Results:**\n\n- Production-ready content mapping system with >80% accuracy on validation dataset\n- Vector search integration with pgvector\n- Cross-encoder re-ranking pipeline\n- Update detection and security gate implementation\n- Comprehensive evaluation metrics and logging\n- Unit tests with >70% code coverage\n- Documentation of model selection, tuning process, and accuracy metrics\n\n**Difficulty Characterization:**\nThis is a **Hard** difficulty project requiring:\n\n- Deep understanding of embeddings and semantic similarity\n- Experience with vector databases (pgvector)\n- Knowledge of bi-encoders vs cross-encoders\n- Ability to tune thresholds and evaluate model performance\n- Understanding of information retrieval concepts\n- Strong Python skills for ML/AI integration\n\n**Bonus/Pro-Mode**: Implement Hybrid Search (Vector + Keyword/BM25) for exact keyword matching (e.g., CVE IDs).\n\n##### 🔸 **Module D: Human-in-the-Loop (HITL) & Logging**\n\n\n**Primary Objectives:**\n\n- Build a simple admin UI for reviewing flagged content from Module C\n- Implement a fast review interface optimized for “Tinder-swipe” speed (keybind ‘y’ for yes, ‘n’ for no)\n- Create a logging system that appends corrections to JSONL files (stored in S3/MinIO)\n- Design the UI to allow review, approve/reject, and save corrections in under 3 seconds per item\n- Implement user authentication and authorization for maintainers\n- Build a dashboard showing review queue status and statistics\n\n**Technical Requirements:**\n\n**Tech Stack**: Flask/React, S3/MinIO for storage**Pre-Code Experiment**:- Draw wireframe or build 10-line HTML prototype\n- Test: Can a user review, approve/reject, and save a correction in under 3 seconds per item?\n- Success Criteria: UI must require minimal clicks (ideally keyboard shortcuts)\n\n\n**Expected Results:**\n\n- A production-ready admin UI for content review\n- Fast, keyboard-optimized review workflow\n- JSONL logging system integrated with S3/MinIO\n- User authentication and role-based access control\n- Review queue dashboard with statistics\n- Unit tests with >70% code coverage\n- Documentation for maintainers\n\n**Difficulty Characterization:**\nThis is an **Easy** difficulty project suitable for:\n\n- Junior developers or frontend contributors\n- Developers comfortable with standard CRUD web applications\n- Those interested in UX optimization\n- Full-stack developers (Flask + React)\n\n**Bonus/Pro-Mode**: Implement “Loss Warehousing” to capture structured loss events (Input + Wrong Prediction + Correct Label) for future model retraining.\n\n#### Mentors\n\n**For OpenCRE Scraper & Indexer (Project OIE) Module Projects (A, B, C, D):**\n\n[OWTF](https://owasp.org/www-project-owtf/)\n\nOWTF attempts to solve the “penetration testers are never given enough time to test properly” problem, or in other words, OWTF = Test/Exploit ASAP, with this in mind, as of right now, the priorities are:\n\n- To improve security testing efficiency (i.e. test more in less time)\n- To improve security testing coverage (i.e. test more)\n- Gradually integrate the best tools\n- Unite the best tools and make them work together with the security tester\n- Remove or Reduce the need to babysit security tools during security assessments\n- Be a respository of PoC resource links to assist exploitation of vulnerabilities in order to illustrate risk to businesses.\n- Help penetration testers save time on report writing\n\n#### Repository\n\n#### Skills Required\n\n- Python\n- Tornado\n- Docker\n- React/React ecosystem for application frontend\n- Basic knowledge of application security, tools used in bug bounty style hunting\n- Some knowledge of how TLS works, man in the middle proxies, HTTP internals, etc.\n\n##### Getting started\n\nPlease use the repositories’ issue tracker, GitHub discussions, and don’t forget to read the contributing guide. Join the community at #owtf on OWASP Slack and share your questions, project ideas.\n\nTo receive early feedback please:\n\n- put your proposal on Google Docs and submit it to the OWASP Organization on Google’s GSoC page in “Draft Shared” mode.\n- Please pick “owtf” as Proposal Tag to make them easier to find for us. Thank you!\n\n#### Projects / Ideas\n\nOWTF Modernization\n\nOWTF has evolved over time, but parts of the codebase are outdated, have technical debt, and may not be optimized for newer Python versions or best practices. This project aims to modernize the OWTF codebase, ensuring long-term maintainability, security, and efficiency. Key Objectives\n\n- Fix Long-Standing Bugs & Improve Stability\n- Audit and resolve GitHub issues related to stability, crashes, and performance bottlenecks.\n- Enhance logging and error handling for better debugging.\n- Improve unit tests and CI/CD pipelines to catch regressions early.\n\n- Optimize Plugin Execution & Dependency Management\n- Upgrade outdated third-party security tools used in plugins.\n- Reduce dependency bloat by removing redundant libraries.\n- Use async execution where applicable for better performance.\n\n\n###### Expected Outcomes\n\n✔️ OWTF will be cleaner, faster, and easier to maintain.\n\n✔️ The project will be future-proofed with up-to-date dependencies.\n\n✔️ Stability and performance will be significantly improved.\n\nMiTM proxy upgrade\n\nOWTF’s proxy was written almost 10 years ago based on the Tornado Web Framework. It is in rough shape and needs a lot of improvement on the transaction recording, storing, and modification side. We want to make it as good as [MiTM proxy](https://mitmproxy.org/).\n\n###### Expected Outcomes\n\n✔️ Modern mitm proxy that allows modificaiton of requests and responses on the fly\n\n✔️ Better integration with the framework to record a variety of requests and responses.\n\n✔️ Stability and performance.\n\n##### Mentors\n\n[OWASP Cornucopia](https://cornucopia.owasp.org/)\n\n#### Repository\n\n#### Skills Required\n\n- HTML/CSS/JavaScript\n- Python\n- Docker\n- No security knowledge required\n\n##### Getting started\n\n- Check\n[GitHub project](https://owasp.org/[https:/github.com/adeyosemanputra/pygoat](https:/github.com/owasp/cornucopia?tab=readme-ov-file#building-and-deploying-the-cornucopia-website)) - Get in touch with one of the project leaders\n[Sydseter](https://www.linkedin.com/in/sydseter/) - Join\n[OWASP Slack](https://owasp.org/slack/invite)and contact us on channel #cornucopia-project\n\n#### Projects / Ideas\n\n\n- Ensure the OWASP Cornucopia converter can create print-ready proofs for print-on-demand jobs. See:\n[Description](https://github.com/OWASP/cornucopia/issues/583). - Add the EoP Game to the card browser. See:\n[Description](https://github.com/OWASP/cornucopia/issues/1322). - Redesign for cornucopia.owasp.org. See:\n[Description](https://github.com/OWASP/cornucopia/issues/2194)."
  },
  {
    "name": "Machine Learning for Science (ML4SCI)",
    "slug": "machine-learning-for-science-ml4sci",
    "tagline": "Machine learning applications in science",
    "description": "Machine Learning for Science (ML4SCI) is an umbrella organization for machine learning-related projects in science. ML4SCI brings together researchers from universities and scientific laboratories with motivated students to join existing scientific collaborations and contribute to cutting edge science projects across a wide variety of disciplines. Students work on existing problems to develop new machine learning-based approaches and produce open source code that directly contributes to solving these scientific challenges. \n\nML4SCI currently includes projects from a variety of fields. For example, some of them explore the uses of machine learning for particle reconstruction and classification in high-energy physics, deep learning-based searches for dark matter in astrophysics, applications of machine learning techniques to data returned from planetary science missions, applications of quantum machine learning to science, and others.\n\nMachine learning ideas and approaches can be broadly applicable and transferable across the scientific domains. The goals of ML4SCI projects are to grow the open-source community in machine learning for science by addressing important scientific challenges and transferring the knowledge and tools of machine learning across the disciplines. We look forward to your applications!",
    "ideas_url": "https://ml4sci.org/activities/gsoc2026.html",
    "website_url": "https://ml4sci.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "machine learning",
      "c++",
      "data analysis",
      "artificial intelligence"
    ],
    "topic_tags": [
      "machine learning",
      "science and medicine",
      "algorithms",
      "physics",
      "astronomy"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/machine-learning-for-science-ml4sci",
    "ideas_content": "In 2026 ML4SCI plans to participate in the program as a GSoC umbrella organization.\nThe ML4SCI organization plans to partner with the [Google Summer of Code](https://summerofcode.withgoogle.com) in 2026 to broaden student participation in machine learning projects over a wide variety of scientific fields.\nML4SCI participants will be mentored by scientists at top research universities and laboratories on research projects at the cutting edge of science.\nProjects span a wide range of scientific domains, including physics, astronomy, planetary science, quantum information science and others.\n\nIn 2026 GSoC students work with their mentors for 175 hrs to produce open-source codes that apply machine learning solutions to solve science problems. Projects span three evaluation periods that allow for students and mentors to collaborate on their project and evaluate student progress. Detailed rules for the GSOC program can be found on Google’s [rules page](https://summerofcode.withgoogle.com/rules/).\nInterested students should look at the ideas page and contact the mentors. Candidates will be asked to complete an evaluation test for each project they apply to demonstrate the skills needed for the respective projects.\nIn the next step, students will produce a proposal which will be evaluated for final student selection.\n\nPlease see the [official GSoC Timeline](https://summerofcode.withgoogle.com/how-it-works/)\n\n|\n|\n\n[DeepLense](https://arxiv.org/abs/1909.07346) is a deep learning pipeline for particle dark matter searches with strong gravitational lensing.\n\nThe [End-to-End Deep Learning (E2E)](https://arxiv.org/abs/1807.11916) project focuses on the development of particle and event reconstruction and identification tasks with end-to-end deep learning approaches.\n\nThe purpose of EXXA is to use simulations and publicly available data from observations intended to identify exoplanets and physical processes in planet-forming environments.\n\nDeepFalcon is an ultra-fast non-parametric detector simulation package that automatically abstracts detector response, usually done by hand in fast-simulators used by particle physics experiments.\n\nFASEROH is an open source project researching seq2seq model that maps histograms to empirical symbolic representations.\n\nThe GENIE project focuses on the application of novel machine learning techniques to anomaly detection and event generation in particle physics\n\nHigh-Energy Physics Simulation (HEPSIM) applies modern machine learning and agentic AI methods to Monte Carlo event generation and simulation in high-energy physics. Projects range from developing symbolic regression techniques for event reweighting and curating jet observable libraries, to deploying ML algorithms that quantify simulation biases between generators such as Pythia and Herwig. More advanced projects explore agentic workflows for automating exclusion limit extraction and Lagrangian-level model identification from collider data.\n\nThe Lunar Occultation Explorer (LOX) is a lunar-orbiting nuclear astrophysics mission that will probe the Cosmos at MeV energies.\n\nLunar Prospector was the third mission selected by NASA for full development and construction as part of the Discovery Program. The 19-month mission was designed for a low polar orbit investigation of the Moon, including mapping of surface composition including polar ice deposits, measurements of magnetic and gravity fields, and study of lunar outgassing events. The mission ended July 31, 1999, when the orbiter was deliberately crashed into a crater near the lunar south pole, after the presence of water ice was successfully detected.\n\nNASA’s MESSENGER spacecraft orbited Mercury for more than four years. Among its accomplishments, the mission determined Mercury’s surface composition, revealed its geological history, discovered details about its internal magnetic field, and verified its polar deposits are dominantly water-ice. The mission ended when MESSENGER slammed into Mercury’s surface.\n\nData Quality Monitoring (DQM) is an important aspect of every high-energy physics experiment needed to avoid taking low-quality data. The goal of DQM is to track important information about the detector and the data and catch problems in realtime. This monitoring happens both online and offline to ensure optimal operation of the experiment. The goal of the ML4DQML project is to use machine learning to aid human shifters with identification of anomalies to help make better decisions about the quality of the data.\n\nThis project aims to develop a computational pipeline using the Contrastive Embedding for Behavioral and Neural Analysis (CEBRA) method to analyze time-locked EEG data from interacting participants.\n\nProject PrediCT aims to increase the predictive power of NCCT CAC (coronary artery calcium) scans for major adverse cardiac events (MACE) by integrating other features alongside calcium formation and enhancing the NCCT scan itself. We are currently focusing on robustly segmenting and visualizing calcium patterns, using the Stanford COCA dataset.\n\nQMLHEP project implements Quantum Machine Learning methods for physics analysis.\n\nShape optimization is an essential task in many engineering and physics domains when the geometry of an object strongly influences its performance and efficiency. The Shape optimization via Physics-Informed Neural Networks (SPINN) project aims to automate and streamline the task of shape optimization via the use of Physics Informed Neural Networks and Coordinate Projection Networks.\n\nSYMBA is an open source project researching symbolic machine learning techniques to predict the squared amplitudes and cross section for high-energy physics.\n\nRecent success in the domain of unsupervised and semi-supervised learning has been lately a pivotal factor for development of Physics Aware and Symmetry Aware Machine Learning techniques where a model learns the symmetry of a dataset as a meta task and ends up learning the physics through the same. This project will focus on ways to learn the symmetries using semi-supervised approaches using CMS data.\n\nThe |\n|\n\nThe [University of Alabama](https://www.ua.edu/) is a public research university in Tuscaloosa, Alabama. Established in 1820, the University of Alabama is the oldest and largest of the public universities in Alabama as well as the flagship of the University of Alabama System\n\nThe American University of Beirut (AUB) is a private, non-sectarian, and independent university chartered in New York with its campus in Beirut, Lebanon\n\nBirla Institute of Technology and Science, Pilani – Goa Campus is a private deemed university campus located in Goa, India.\n\nBirla Institute of Technology and Science, Pilani – Hyderabad Campus is a private deemed university campus located in Hyderabad, India.\n\nBrown University is a private Ivy League research university in Providence, Rhode Island, founded in 1764.\n\nThe Technical University of Catalonia, currently referred to as BarcelonaTech, is the largest engineering university in Catalonia, Spain. It also offers programs in other disciplines such as mathematics and architecture.\n\nCerium Laboratories, LLC is a world-class analytical laboratory located in Austin, Texas.\n\nAt [CERN](https://home.cern), the European Organization for Nuclear Research, physicists and engineers are probing the fundamental structure of the universe. They use the world’s largest and most complex scientific instruments to study the basic constituents of matter – the fundamental particles.\n\nCarnegie Mellon University is a private research university based in Pittsburgh, Pennsylvania.\n\nCornell University is a private, statutory, Ivy League and land-grant research university in Ithaca, New York.\n\nDartmouth College is a private Ivy League research university in Hanover, New Hampshire, United States.\n\nDavidson College is a private liberal arts college in Davidson, North Carolina.\n\nThe École polytechnique fédérale de Lausanne (EPFL) is a public research university located in Lausanne, Switzerland. It specializes in natural sciences and engineering. It is one of the two Swiss Federal Institutes of Technology, with three main missions: education, research and innovation.\n\nUniversity of Erlangen–Nuremberg is a public research university in the cities of Erlangen and Nuremberg in Bavaria, Germany. FAU is a member of the German Research Foundation DFG (Deutsche Forschungsgemeinschaft).\n\n[University of Erlangen-Nuremberg](https://www.fau.eu/) is a public university in Bavaria, Germany. Founded in 1742, the University’s main campuses are located in Erlangen and Nuremberg in Bavaria, Germany with a newer campus opened in 2009 in Busan, South Korea.\n\nUniversity of Florida is a public institution that was founded in 1853.\n\nFlorida State University is a public institution that was founded in 1851.\n\nThe University of Georgia (UGA or Georgia) is a public land-grant research university with its main campus in Athens, Georgia.\n\nThe Goddard Space Flight Center (GSFC) is a major NASA space research laboratory located approximately 6.5 miles (10.5 km) northeast of Washington, D.C. in Greenbelt, Maryland, United States.\n\nThe Johns Hopkins University Applied Physics Laboratory (APL) has provided critical contributions to critical challenges with systems engineering and integration, technology research and development, and analysis.\n\nThe University of Kansas (KU) is a public research university with its main campus in Lawrence, Kansas. The university is a member of the Association of American Universities and is classified among “R1: Doctoral Universities – Very high research activity”. Founded March 21, 1865, the university was opened in 1866 under a charter granted by the Kansas State Legislature in 1864.\n\nThe University of Kentucky (UK or UKY) is a public land-grant research university in Lexington, Kentucky.\n\nKettering Health is a non-profit organization headquartered in Kettering, Ohio, that operates hospitals, stand-alone emergency departments, clinics and Kettering College.\n\nKeck Graduate Institute (KGI) is a private graduate school in Claremont, California.\n\nLos Alamos National Laboratory (Los Alamos or LANL for short) is a United States Department of Energy national laboratory.\n\nThe University of Leeds is a public research university in Leeds, West Yorkshire, England.\n\nMathWorks is the leading developer of mathematical computing software for engineers and scientists.\n\nMiddle East Technical University (commonly referred to as METU) is a public technical university located in Ankara, Turkey.\n\nThe Massachusetts Institute of Technology (MIT) is a private land-grant research university in Cambridge, Massachusetts established in 1861.\n\nNew York University (NYU) is a private research university in New York City. Chartered in 1831 by the New York State Legislature, NYU was founded by a group of New Yorkers led by then Secretary of the Treasury Albert Gallatin.\n\nThe National Institute of Science Education and Research (NISER) is a public research institute in Bhubaneswar, Odisha, India. Founded in 2006, it was ranked second in the country by the Nature Index 2020.\n\nThe National (Metsovian) Technical University of Athens, sometimes known as Athens Polytechnic, is among the oldest higher education institutions of Greece and the most prestigious among engineering schools.\n\nThe Polytechnic Institute of Paris is a research university system located in Palaiseau, France.\n\nPrincess Sumaya University for Technology (PSUT), established in 1991, is a specialized, Non-governmental, Non-profit, Jordanian university, owned by the leading applied research centre in Jordan, the Royal Scientific Society (RSS).\n\n[Qassim University](https://www.qu.edu.sa/) is a major public university in Qassim, Saudi Arabia. It’s one of the top ranking and largest universities in Saudi Arabia with over 50,000 students enrolled.\n\nRWTH Aachen University is a German public research university located in Aachen, North Rhine-Westphalia, Germany.\n\nThe University of South Carolina (USC, UofSC, SC, or simply Carolina) is a public research university in Columbia, South Carolina.\n\nThe Technical University of Munich is a public research university in Munich, Germany. It specializes in engineering, technology, medicine, and applied and natural sciences.\n\nVishwakarma Institute of Technology (VIT) is an autonomous institute in Pune, Maharashtra, India.[1] Established in 1983, the institute is affiliated with the Savitribai Phule Pune University and run by the Bansilal Ramnath Agarwal Charitable Trust.\n\nThe University of Washington is a public research university in Seattle, Washington.\n\nThe [University of Wisconsin-Madison](https://www.wisc.edu/) is a public research university in Madison, Wisconsin. Since its founding in 1848, this campus has been a catalyst for the extraordinary.\n\n[Prof. Sergei Gleyzer (University of Alabama)](https://sergeigleyzer.com/)\n\n[Prof. Emanuele Usai (University of Alabama)](https://emanueleusai.com)\n\n[Dr. Patrick Peplowski (JHUAPL)](https://civspace.jhuapl.edu/people/patrick-peplowski)"
  },
  {
    "name": "LLVM Compiler Infrastructure",
    "slug": "llvm-compiler-infrastructure",
    "tagline": "LLVM Compiler Infrastructure",
    "description": "The LLVM Project is a collection of modular and reusable compiler and toolchain technologies. Despite its name, LLVM has little to do with traditional virtual machines. The name \"LLVM\" itself is not an acronym; it is the full name of the project.\n\nLLVM began as a research project at the University of Illinois, with the goal of providing a modern, SSA-based compilation strategy capable of supporting both static and dynamic compilation of arbitrary programming languages. Since then, LLVM has grown to be an umbrella project consisting of a number of subprojects, many of which are being used in production by a wide variety of commercial and open source projects as well as being widely used in academic research.\n\nIn addition to official subprojects of LLVM, there are a broad variety of other projects that use components of LLVM for various tasks. Through these external projects you can use LLVM to compile Ruby, Python, Haskell, Rust, D, PHP, Pure, Lua, Julia, and a number of other languages. A major strength of LLVM is its versatility, flexibility, and reusability, which is why it is being used for such a wide variety of different tasks: everything from doing light-weight JIT compiles of embedded languages like Lua to compiling Fortran code for massive super computers.",
    "ideas_url": "https://llvm.org/OpenProjects.html",
    "website_url": "http://www.llvm.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "llvm",
      "c++",
      "clang",
      "mlir"
    ],
    "topic_tags": [
      "compilers",
      "development tools",
      "libraries"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/llvm-compiler-infrastructure",
    "ideas_content": "The **LLVM** Compiler Infrastructure\n\nSite Map:\nDownload!\nSearch this Site\nUseful Links\nRelease Emails\nMaintained by the\n|\nOpen LLVM Projects\n- Google Summer of Code Ideas & Projects\n-\n[Google Summer of Code 2026](https://llvm.org#gsoc26) -\n[Google Summer of Code 2025](https://llvm.org#gsoc25)**LLVM Core****Clang****LLDB****LLVM libc****ClangIR****Clang Static Analyzer****Enzyme**(Former**Offload**)**OpenMP Offloading**\n-\n[Google Summer of Code 2024](https://llvm.org#gsoc24)**LLVM Core****Clang****LLDB****(OpenMP) Offload****ClangIR****LLVM libc**\n-\n[Google Summer of Code 2023](https://llvm.org#gsoc23)-\n**LLVM Core** **Clang**[Out-of-process execution for clang-repl](https://llvm.org#clang-repl-out-of-process)[Improve and Stabilize the Clang Static Analyzer's \"Taint Analysis\" Checks](https://llvm.org#clang_analyzer_taint_analysis)[Implement autocompletion in clang-repl](https://llvm.org#clang-repl-autocompletion)[Modules build daemon: build system agnostic support for explicitly built modules](https://llvm.org#clang-modules-build-daemon)[ExtractAPI Objective-C categories](https://llvm.org#clang-extract-api-categories)[ExtractAPI C++ Support](https://llvm.org#clang-extract-api-cpp-support)[ExtractAPI while building](https://llvm.org#clang-extract-api-while-building)[Improve Clang diagnostics](https://llvm.org#clang-improve-diagnostics2)[Tutorial development with clang-repl](https://llvm.org#clang-tutorials-clang-repl)[Add WebAssembly Support in clang-repl](https://llvm.org#clang-repl-wasm)\n-\n-\n**LLD** -\n**MLIR** -\n**Code Coverage** -\n**ClangIR** -\n[Enzyme](https://enzyme.mit.edu)\n-\n-\n[Google Summer of Code 2022](https://llvm.org#gsoc22)-\n**LLVM Core**[Implement a shared-memory based JITLinkMemoryManager for out-of-process JITting](https://llvm.org#llvm_shared_jitlink)[Modernize the LLVM \"Building A JIT\" tutorial series](https://llvm.org#llvm_build_jit_tutorial)[Write JITLink support for a new format/architecture](https://llvm.org#llvm_jit_new_format)[Instrumentation of Clang/LLVM for Compile Time](https://llvm.org#llvm_instrumentaion_for_compile_time)[Richer symbol dependency information for LTO](https://llvm.org#llvm_lto_dependency_info)[Machine Learning Guided Ordering of Compiler Optimization Passes](https://llvm.org#llvm_mlgo_passes)[Learning Loop Transformation Heuristics](https://llvm.org#llvm_mlgo_loop)[Evaluate and Expand the Module-Level Inliner](https://llvm.org#llvm_module_inliner)[Remove undef: move uninitialized memory to poison](https://llvm.org#llvm_undef_load)[Add ABI/API export annotations to the LLVM build](https://llvm.org#llvm_abi_export)\n**Clang**-\n**Polly** -\n[Enzyme](https://enzyme.mit.edu)\n-\n-\n[Google Summer of Code 2021](https://llvm.org#gsoc21)-\n**LLVM Core**[Distributed lit testing](https://llvm.org#llvm_distributing_lit)[Learning Loop Transformation Heuristics](https://llvm.org#llvm_loop_heuristics)[Fuzzing LLVM-IR Passes](https://llvm.org#llvm_ir_fuzzing)`llvm.assume`the missing pieces[Implement a shared-memory based JITLinkMemoryManager for out-of-process JITting](https://llvm.org#llvm_shared_jitlink)[Modernize the LLVM \"Building A JIT\" tutorial series](https://llvm.org#llvm_build_jit_tutorial)[Write JITLink support for a new format/architecture](https://llvm.org#llvm_jit_new_format)[Fix fundamental issues in LLVM's IR](https://llvm.org#llvm_ir_issues)[Utilize LoopNest Pass](https://llvm.org#llvm_utilize_loopnest)\n**Clang**-\n**OpenMP** -\n**OpenACC** -\n[Polly](https://polly.llvm.org) -\n[Enzyme](https://enzyme.mit.edu) -\n**Clang Static Analyzer** -\n**LLDB**\n-\n-\n[Google Summer of Code 2020](https://llvm.org#gsoc20)-\n**LLVM Core**[Improve debugging of optimized code](https://llvm.org#llvm_optimized_debugging)[Improve inter-procedural analyses and optimizations](https://llvm.org#llvm_ipo)[Improve parallelism-aware analyses and optimizations](https://llvm.org#llvm_par)[Make LLVM passes debug info invariant](https://llvm.org#llvm_dbg_invariant)[Improve MergeFunctions to incorporate MergeSimilarFunction patches and ThinLTO Support](https://llvm.org#llvm_mergesim)[Add DWARF support to yaml2obj](https://llvm.org#llvm_dwarf_yaml2obj)[Improve hot cold splitting to aggressively outline small blocks](https://llvm.org#llvm_hotcold)[Advanced Heuristics for Ordering Compiler Optimization Passes](https://llvm.org#llvm_pass_order)[Machine learning and compiler optimizations: using inter-procedural analysis to select optimizations](https://llvm.org#llvm_ml_scc)[Add PostDominatorTree in LoopStandardAnalysisResults](https://llvm.org#llvm_postdominators)[Create loop nest pass](https://llvm.org#llvm_loopnest)[Instruction properties dumper and checker](https://llvm.org#llvm_instdump)[Unify ways to move code or check if code is safe to be moved](https://llvm.org#llvm_movecode)\n**Clang****LLDB**[Support autosuggestions in LLDB's command line](https://llvm.org#lldb-autosuggestions)[Implement the missing tab completions for LLDB's command line](https://llvm.org#lldb-more-completions)[Reimplement LLDB's command-line commands using the public SB API.](https://llvm.org#lldb-reimplement-lldb-cmdline)[Add support for batch-testing to the LLDB testsuite.](https://llvm.org#lldb-batch-testing)-\n**MLIR**- See the\n[MLIR open project list](https://mlir.llvm.org/getting_started/openprojects/)\n- See the\n-\n-\n[Google Summer of Code 2019](https://llvm.org#gsoc19)-\n**LLVM Core** **Clang**\n-\n[Google Summer of Code 2018](https://llvm.org#gsoc18)[Google Summer of Code 2017](https://llvm.org#gsoc17)\nWelcome prospective Google Summer of Code 2026 Students! This document is your starting point to finding interesting and important projects for LLVM, Clang, and other related sub-projects. This list of projects is not only developed for Google Summer of Code, but open projects that really need developers to work on and are very beneficial for the LLVM community. We encourage you to look through this list and see which projects excite\nyou and match well with your skill set. We also invite proposals not on this\nlist. More information and discussion about GSoC can be found in\nThe LLVM project has participated in Google Summer of Code for many years\nand has had some very successful projects. We hope that this year is no\ndifferent and look forward to hearing your proposals. For information on how\nto submit a proposal, please visit the Google Summer of Code main\nAPI notes are a YAML-based \"sidecar\" file mechanism in Clang that allows users to add attributes to existing headers without modifying the header files themselves. This is particularly useful for Swift developers who want to annotate third-party C/C++ libraries and frameworks for better interoperability. However, API notes have limited support for C++ syntax (e.g., type conversion operators), and cannot annotate specific function overloads or template instantiations.\nThe -fbounds-safety extension for C adds bounds annotations and compiler-enforced bounds checking to prevent buffer overflow vulnerabilities. Developed by Apple and maintained in a The student will contribute to upstreaming by: - Taking a subset of features identified by the mentor\n- Extracting a relevant downstream feature and refactoring to meet upstream LLVM standards, writing tests and documentation\n- Backporting to the downstream fork to validate correctness in the full -fbounds-safety context\nThe LLVM libc project aims to provide a complete, correct, and high-performance C23 standard library. A key differentiator is its focus on correctly rounded math functions for all floating-point types, including float, double, long double, and float128 (IEEE 754 quad precision). However, not all compilers or architectures support these types natively. For example: - MSVC on Windows treats long double as 64-bit double and lacks a native __float128 type.\n- AArch64 targets typically use 128-bit long double, but lack the 80-bit extended precision format.\n- Clang on certain non-x86 targets may not enable __float128 by default.\nThis lack of host compiler support prevents LLVM libc from building and testing its high-precision math routines on these platforms.\nThe goal of this project is to implement standalone C++ classes (e.g., within LIBC_NAMESPACE::fputil) that emulate float80 and float128 semantics in software. These classes should provide the necessary operator overloads and storage (using UInt<128> or similar) to allow the existing templated math implementations to compile and run even when the host compiler does not support the native types.\n- Type Abstraction: Create wrapper classes that mimic the behavior of native floating-point types.\n- Soft-Float Arithmetic: Implement or connect these classes to soft-float arithmetic routines (add, sub, mul, div) so that math algorithms (like polynomial evaluation) can be executed.\n- Integration: Refactor the math function entry points to instantiate templates with these emulated types when native support is missing.\n- A header-only C++ implementation of float80 and float128 types that can be used where native support is missing.\n- Basic arithmetic operations (+, -, *, /) implemented for these types.\n- Demonstration of LLVM libc math functions compiling and passing tests using these emulated types on a target that lacks native support (e.g., building float80 math on Mac arm64, float128 math with MSVC).\n- Basic C++ skills.\n- Interest in understanding the intricacies of floating-point formats (IEEE 754 and extended precision).\ncompiler-rt builtins provide essential floating-point computation routines to support runtime execution when the underlying hardware does not support specific floating-point types natively. Unfortunately, the current implementations are under tested, leaving subtle numerical bugs lying dormant for years. Additionally, they are written in a mix of C and hand-written assembly, which substantially increases the maintenance burden.\nIn contrast, LLVM libc implements these basic floating-point operations with rigorous testing and formal verification.\nA recent Our goal is to demonstrate the feasibility and benefits of replacing legacy compiler-rt floating-point builtins with the modern, verified equivalents from LLVM libc.\n- Infrastructure: Ensure basic floating-point operations in LLVM libc are exposed as shared, free-standing headers suitable for inclusion in compiler-rt.\n- Integration: Add a CMake build option allowing compiler-rt builtins to be compiled using LLVM libc math routines instead of the legacy implementations.\n- Validation & Performance: Benchmark the new implementation on embedded targets. Analyze code size and performance, optimizing the build to achieve parity with the current C or hand-written assembly implementations.\n- Basic C++ skills.\n- Interest in understanding the intricacies of floating-point formats (IEEE 754) and the low-level implementation of arithmetic operations.\nModern heterogeneous applications rely heavily on GPU offloading, yet todayâs compilation pipelines strictly separate host and device compilation. This separation prevents whole-program reasoning across hostâdevice boundaries and limits optimization opportunities such as kernel specialization, launch-bound inference, and cross-boundary constant propagation.\nThis project proposes extending\nThe Clang compiler today emits separate compilation artifacts for host and device code (e.g., CUDA/HIP). While this model simplifies handling, it introduces fundamental limitations: - No cross-boundary analysis: The compiler cannot reason about kernel launches, argument values, or launch configuration at the call site.\n- Missed optimization opportunities: Kernel specialization, dead code elimination, and launch-bound inference require joint hostâdevice visibility.\nLLVMâs MLIR-based CIR provides a unique opportunity to address this limitation. Because both host and device code are represented in a structured, high-level IR, it becomes feasible to temporarily merge them, perform joint analyses and transformations, and then re-split them for conventional lowering. This project directly explores that opportunity.<\\p>\nClangIR is actively being upstreamed and already supports emitting CIR from Clangâs AST and lowering to LLVM IR. Initial experiments have demonstrated that host and device CIR modules can be merged in a controlled way. A work-in-progress implementation already exists which is capable of merging but there is still work to be done in incorporating the merging with the clang driver - A WIP\n[PR](https://github.com/llvm/clangir/pull/2097)on the incubator project presenting some of the required steps - An\n[issue](https://github.com/llvm/llvm-project/issues/175871)loosely tracking changes regarding the offload support on ClangIR.\n- Clang Driver extensions to optionally enable the capability.\n- Build the infrastructure to contain within a single translation unit both device and host code\n- Build the infrastructure to properly split a \"combined\" translation unit to individual ones representing device and host code\n- End to End execution of the new driver pipeline on benchmarks from PolyBench.\n- Reporting on compilation time overheads and execution time overheads.\n- Bonus Point: Implement an optimization pass that infers launch bounds from the host call site\n- Survey the current support gaps when using clangd for HLSL.\n- Create an RFC documenting the gaps and propose the best way to address them.\n- After refining the RFC, generate issues for the groundwork of implementation.\n- Implement these issues to complete HLSL support in clangd.\nWe do not expect all issues to be resolved and for full support of HLSL to be in clangd. It is however expected that the first 3 steps take ~90 hrs, and the remaining ~90 hrs are dedicated towards implementation.\nRequired: - Intermediate proficiency of C++.\n- Familiarity of how Language Server Protocols (LSP) work.\n- Interest in learning/knowing the HLSL language specification.\nDesired: - Previous experience programming with HLSL is a plus.\n- Previous experience developing with LSPs is a plus.\nMedium (~180hr).\nMedium.\nWelcome prospective Google Summer of Code 2025 Students! This document is your starting point to finding interesting and important projects for LLVM, Clang, and other related sub-projects. This list of projects is not only developed for Google Summer of Code, but open projects that really need developers to work on and are very beneficial for the LLVM community. We encourage you to look through this list and see which projects excite\nyou and match well with your skill set. We also invite proposals not on this\nlist. More information and discussion about GSoC can be found in\nThe LLVM project has participated in Google Summer of Code for many years\nand has had some very successful projects. We hope that this year is no\ndifferent and look forward to hearing your proposals. For information on how\nto submit a proposal, please visit the Google Summer of Code main\nUse the variable location information from the debug info to annotate LLDBâs disassembler (and `register read`) output with the location and lifetime of source variables. The rich disassembler output should be exposed as structured data and made available through LLDBâs scripting API so more tooling could be built on top of this. In a terminal, LLDB should render the annotations as text.\nframe #0: 0x0000000100000f80 a.out`main(argc=1, argv=0x00007ff7bfeff1d8) at demo.c:4:10 [opt] 1 void puts(const char*); 2 int main(int argc, char **argv) { 3 for (int i = 0; i < argc; ++i) â 4 puts(argv[i]); 5 return 0; 6 } (lldb) disassemble a.out`main: ... 0x100000f71 <+17>: movl %edi, %r14d 0x100000f74 <+20>: xorl %r15d, %r15d 0x100000f77 <+23>: nopw (%rax,%rax) â 0x100000f80 <+32>: movq (%rbx,%r15,8), %rdi 0x100000f84 <+36>: callq 0x100000f9e ; symbol stub for: puts 0x100000f89 <+41>: incq %r15 0x100000f8c <+44>: cmpq %r15, %r14 0x100000f8f <+47>: jne 0x100000f80 ; <+32> at demo.c:4:10 0x100000f91 <+49>: addq $0x8, %rsp 0x100000f95 <+53>: popq %rbx ... using the debug information that LLDB also has access to (observe how the source variable i is in r15 from [0x100000f77+slide)) $ dwarfdump demo.dSYM --name i demo.dSYM/Contents/Resources/DWARF/demo: file format Mach-O 64-bit x86-64 0x00000076: DW_TAG_variable DW_AT_location (0x00000098: [0x0000000100000f60, 0x0000000100000f77): DW_OP_consts +0, DW_OP_stack_value [0x0000000100000f77, 0x0000000100000f91): DW_OP_reg15 R15) DW_AT_name (\"i\") DW_AT_decl_file (\"/tmp/t.c\") DW_AT_decl_line (3) DW_AT_type (0x000000b2 \"int\")to produce output like this, where we annotate when a variable is live and what its location is: (lldb) disassemble a.out`main: ... ; i=0 0x100000f74 <+20>: xorl %r15d, %r15d ; i=r15 0x100000f77 <+23>: nopw (%rax,%rax) ; | â 0x100000f80 <+32>: movq (%rbx,%r15,8), %rdi ; | 0x100000f84 <+36>: callq 0x100000f9e ; symbol stub for: puts ; | 0x100000f89 <+41>: incq %r15 ; | 0x100000f8c <+44>: cmpq %r15, %r14 ; | 0x100000f8f <+47>: jne 0x100000f80 ; <+32> at t.c:4:10 ; | 0x100000f91 <+49>: addq $0x8, %rsp ; i=undef 0x100000f95 <+53>: popq %rbx The goal would be to produce output like this for a subset of unambiguous cases, for example, variables that are constant or fully in registers.\n- Adrian Prantl aprantl@apple.com (primary contact)\n- Jonas Devlieghere jdevlieghere@apple.com\nRequired: - Good understanding of C++\n- Familiarity with using a debugger on the terminal\n- Need to be familiar with all the concepts mentioned in the example above\n- Need to have a good understanding of at least one assembler dialect for machine code (x86_64 or AArch64).\nDesired: - Compiler knowledge including data flow and control flow analysis is a plus.\n- Being able to navigate debug information (DWARF) is a plus.\nmedium (~175h)\nhard\n- Setup the generated headers properly so that the type and the functions can be used with various compilers (+versions) and architectures.\n- Implement generic basic math operations supporting bfloat16 data types that work on supported architectures: x86_64, arm (32 + 64), risc-v (32 + 64), and GPUs.\n- Implement specializations using compiler builtins or special hardware instructions to improve their performance whenever possible.\n- If time permits, we can start investigating higher math functions for bfloat16.\nBasic C & C++ skills + Interest in knowing / learning more about the delicacy of floating point formats.\nModern GPUs are capable of unified addressing with the host. We currently use\nthis to provide I/O support using the\nThis interface is a ring buffer designed to accelerate syscalls. However, it\nprovides a\n- An implementation of\n`pwrite` and`pread` that runs on the GPU. - Support for\n`printf` by forwarding`snprintf` into`pwrite` . - If time permits, exploring GPU file APIs.\nBasic C & C++ skills + access to a GPU, Linux kernel knowledge, GPU knowledge.\nThe LLVM C library provides implementations of math functions. We want to profile these against existing implementations,\nsuch as CUDA's\nAdditionally, we want to verify the accuracy of these functions when run on the GPU via brute force testing.\nThe goal is to verify that the implementations are correct and at least conformant to the error ranges in the\n- Final performance results similar to\n[Old results](https://dl.acm.org/doi/fullHtml/10.1145/3624062.3624166)but with the more optimized functions and higher accuracy. - A test suite that can do brute force testing to confirm that the implementations are conformant.\nBasic C & C++ skills + access to a GPU, some math knowledge\nIn order to give community more frequent updates it'd be great if we can report ClangIR progress by measuring the coverage of existing Clang's CodeGen tests in face of a ClangIR enabled pipeline. By collecting information on crashing, passing or failing tests we can come up with a metric that is easier to report and understand, provide entry points for newcomers looking for tasks and help the project by classifying existing issues. Existing Clang CodeGen tests live in clang/test/CodeGen* and can be found in different states regarding ClangIR support: **FileCheck fails**. LLVM IR builds but FileCheck fails to match output- LLVM IR differs because ClangIR pipeline is emitting different IR (e.g. different instructions are used, missing attributes). Issues need to be created and ClangIR needs to be fixed.\n- LLVM IR differs because CHECK lines need be made more flexible (LLVM-IR dialect output is different, SSA value names, order of attributes, etc). It's possible a tool like llvm-canon might be of good use here.\n**Test crash / error**. ClangIR doesn't support some C/C++ construct or LLVM lowering hasn't been implemented.**Test pass**. Yay!\nIn order to retrieve the information above, the student needs to make changes to Clang's testing infra (LIT configs, scripts, tests, ???) such that it's easier to replay the same invocations with ClangIR enabled, compare against traditional pipeline result or retrieve special directives from tests. It's not clear what is the best methodology just yet, but it's expected that submitted proposals that want to be taken seriously should present few possible ideas on how to achieve this, prior discussion with other members of the community is encouraged. The student is also expected to interact with the ClangIR community, file github issues, investigate and/or make changes to failing codegen tests.\n- Build the infrastructure to run tests and collect results.\n- Present the results in a way that can be placed on a webpage.\n- File issues or change check lines for 50% of the \"FileCheck fails\" category\nabove. The only subdirectories that need consideration for the moment are:\nclang/test/CodeGen clang/test/CodeGenCXX clang/test/CodeGenOpenCL clang/test/CodeGenCUDA\n- Bonus point: find ways to automate/facilitate changes to tests, put PRs to fix problems in ClangIR.\nThe ClangIR project intends to unlock the possibility of better optimization, analysis, and diagnostics for C and C++ code by adding new abstractions that more closely model the source constructs, preserving more details than are available in standard LLVM IR. The ClangIR dialect is already being used to solve real-world problems using the implementation available in the ClangIR incubator, but we need to move this into the main LLVM repository in order to make this functionality available to a larger audience. This project will be an opportunity to gain hands-on experience with MLIR development with a focus on day-to-day software engineering discipline. Participants will work side-by-side with other LLVM contributors to achieve a common goal, and in the process will gain a deep understanding of the ClangIR dialect.\n- Migrate ClangIR support for C and C++ language features into the main LLVM repository\n- Improve the quality of code as it is being migrated\n- Suggest ways to improve the migration process\n- Identify the checks that can benefit from the\n`[[clang::lifetimebound]]` and`[[clang::lifetime_capture_by(X)]]` annotations. - Extend those checks to support these annotations.\n- Make sure the generated bug reports are high quality, the diagnostics properly explain how the analyzer took these annotations into account.\n- Validate the results on real world projects.\n- Potentially warn about faulty annotations (stretch goal).\nCurrently there is no easy way to take a collection of source files using C++20 modules and build an executable from them. This makes it hard to create simple tests or tiny programs using C++20 modules without first setting up a build system. This project's goal is to extend the extremely simple build system in Clang's driver to handle these cases. This can be done by using Clang's existing support for scanning for C++20 modules to discover the dependencies between the source files that have been passed in, and then build them in that order, passing in the right PCM files where needed. This may also be extended to support explicitly building Clang modules discovered via module map files too.\nInvoking clang similarly to clang -o program -std=c++20 main.cpp A.cppm B.cppmshould compile successfully where each translation-unit only imports modules defined in other source files on the command line, or the standard library. This should add no overhead to cases where modules are not used.\nIntermediate knowledge of C++; familiarity with how C++ code is built. Familiarity with C++20 modules is an asset, but not required.\nmedium (~175h)\nmedium\nUndefined Behavior Sanitizer (UBSan) is a useful compilation mode in Clang for finding uses of undefined behavior (e.g. signed integer overflow) and problematic C/C++ code (e.g. unsigned integer overflow). The default version of UBSan uses a compiler runtime that only works in userspace (e.g. it wonât work in the kernel or for embedded applications) and is not considered secure enough for use in production environments. To handle these other environments UBSan provides a trapping mode that emits trap instructions that immediately halts the application rather than calling into the UBSan runtime which normally diagnoses the problem and then carries on execution. Unfortunately trapping UBSan has some deficiencies which make it hard to use. In particular: - Clang silently ignores the\n`-fsanitize-trap=undefined`flag when it's passed without`-fsanitize=undefined`. This project would fix this as a âwarm up taskâ to get familiar with the Clang codebase. - When a UBSan trap is hit with the debugger attached it is not convenient to figure out the reason UBSan trapped. For x86_64 and arm64 some information is encoded in the instruction but decoding this is very inconvenient. While LLDB could be taught to look at the instruction and decode the meaning this is brittle because it depends on undocumented compiler ABI. Instead we can build upon the\n`__builtin_verbose_trap`work to encode the reason for trapping (\"trap reasons\") inside the debug information. If time permits we can also investigate emitting more precise trap reasons\n- When the\n`-fsanitize-trap=undefined`flag is passed on its own the compiler silently ignores it. Currently Clang requires that the`-fsanitize-trap=`flag is also passed. Clang should be taught to warn about this. - Teach Clang to emit the UBSan trap reasons in debug information on UBSan trap instructions similar to how\n`__builtin_verbose_trap`works. - Confirm LLDB is able to recognize the UBSan trap reasons and add tests for this.\n- If time permits we should investigate emitting more precise trap reasons by using information available in the compiler. We may want to implement a \"Sema Diagnostic\" like approach where trap reason strings can easily be constructed inside the compiler. This task is more open-ended and has potentially uses outside of UBSan (e.g.\n`-fbounds-safety`).\nGood understanding of C++\n- Familiarity with UBSan\n- Familiarity with LLDB\nsmall (~90h). but can be extended if time allows\nEasy. This project would be good for a beginner to LLVM. Note the \"emitting more precise trap reasons\" portion is more open ended and so the difficulty of this is entirely down to direction the applicant chooses.\n-Wdocumentationwhich can be used to validate the content of documentation comments during compilation). Unfortunately, Clangâs documentation parser is incomplete and has several issues: - Not all Doxygen commands are supported, limiting the Clang-Docâs usability.\n- Not all C/C++ constructs are currently handled, most notably C++20 features such as concepts.\n- Markdown support in documentation comments introduced in Doxygen version 1.8.0 is missing.\nEnzyme requires good information about the memory layout of types. LLVM-IR is intentionally opaque, e.g. `&f32` and `&f64` both have the LLVM-IR type `ptr`. Enzyme is generally able to infer the underlying type (e.g. f32 vs f64) through usage analysis, but that process is slow and can in some cases fail. To make autodiff more robust, we should lower either MIR or THIR type information into LLVM-IR metadata. This analysis is recursive, for example `&[T]` is a fat pointer and therefore will be represented as a (ptr, int) pair in LLVM-IR. In this case the algorithm should recursively also analyze `T` and generate metadata for it. The function The online compiler\nThe participant should find and select some interesting testcases, in which Enzyme either fails to differentiate an example due to inssuficient Type Information, or takes unreasonable long times (e.g. > 20x slower than compiling the code without autodiff). In the second case, a profiler should be used to verify that Enzyme causes a long compile time due to type analysis. The participant should then write (or later extend) the Type parser to generate the correct metadata, such that Enzyme can handle the new testcases. The LIT testcases should be added to the rust compiler, to avoid further regressions. Examples for code that currently is not handled correctly can be discussed in the project proposal phase.\nIntermediate knowledge of Rust and C++; Familiarity with profilers or LLVM metadata is an asset, but not required.\nmedium (~175h)\nmedium\nThe initial phase of the project will be to implement a prototype that can handle at least the x86_64 System V ABI. This will involve implementing the ABI type system, mapping of Clang types to ABI types and moving at least part of the X86 ABIInfo implementation from Clang to the new ABI library. This is to demonstrate general feasibility, figure out design questions and analyze compilation-time impact. Assuming the results from the prototype are positive, the next step would be to upstream the implementation by splitting it into smaller PRs. Finally, the implementation can be expanded to cover additional targets, ultimately removing Clang's ABI handling code entirely.\nIn addition to adding the new type, the project involves changing clang to lower chars to the new b8 type instead of i8, fixing incorrect lowerings of memory intrinsics, and tracking down the performance regressions.\nThere is already a\nCurrently, some of this informationâfor example, compilation remarksâcan be exported in JSON format. We want to create a tool to visualize, aggregate, and summarize the information. To aid accelerator development, we will start with the offload project as the primary candidate. Similar tools, such as opt-viewer, can be used as references and starting points.\nThe tool should generate an HTML-based report to help visualize the remarks. We envision a small client-server application using Python to spawn a local server as the visualization's front end. The server will expose the different reports and perform early analysis and aggregation. Additionally, the tool should be designed so that, in the future, the analysis of the remarks can provide generalized guidelines for the developer (e.g., show the most common remark, use LLM models to explain actions, etc.). The client (HTML viewer) will display the aggregated data, in-line remarks, profile information, etc. We do not expect the project to have all the features at the end of the GSoC but to serve as a placeholder for growth in the future. In particular, the outcomes of this project should be: - Together with the mentors, help the design of the compiler wrapper, data storage layer, and client/server infrastructure. This includes the server API. The outcome of this task is a design document (similar to an RFC).\n- Create a compiler wrapper that will dump different information in JSON format into the data storage layer (e.g., folders).\n- Create a simple server layer that exposes the backend API to the front end. Python is the right way to do this, but we welcome other suggestions that align with the LLVM project. We would like to avoid relying on external projects (e.g., Flask) to avoid adding more dependencies to the LLVM project.\n- Create a simple client-side visualization tool that can be extended in the future to show more reports.\n- Basic understanding of the LLVM Compiler to be able to generate compiler remarks, profiling data, and other information from the compiler.\n- Proficiency in Python and C++.\n- Full-stack web development.\nGoogle Summer of Code 2024 was yet another successful one for LLVM project. For the\nlist of accepted and completed projects, please take a look into Google\nSummer of\nCode Welcome prospective Google Summer of Code 2024 Students! This document is your starting point to finding interesting and important projects for LLVM, Clang, and other related sub-projects. This list of projects is not only developed for Google Summer of Code, but open projects that really need developers to work on and are very beneficial for the LLVM community. We encourage you to look through this list and see which projects excite\nyou and match well with your skill set. We also invite proposals not on this\nlist. More information and discussion about GSoC can be found in\nThe LLVM project has participated in Google Summer of Code for several years\nand has had some very successful projects. We hope that this year is no\ndifferent and look forward to hearing your proposals. For information on how\nto submit a proposal, please visit the Google Summer of Code main\n- Replace known patterns such as branch on undef/poison, memory accesses with invalid pointers, etc with non-UB patterns.\n- Use Alive2 to detect further patterns (by searching for tests that are always UB).\n- Report any LLVM bug found by Alive2 that is exposed when removing UB.\n- The SPIR-V instruction set's definition in TableGen is replaced with one that is autogenerated.\n- A script and documentation are written that support regenerating the definitions as needed given the JSON grammar of the SPIR-V instruction set.\n- Usage of the SPIR-V instruction set in the SPIR-V backend updated to use the new autogenerated definitions.\n- Add the intrinsics to LLVM IR.\n- Implement legalization/expansion support in SelectionDAG and GlobalISel.\n- Implement optimization support in ConstantFolding, InstSimplify, InstCombine, CorrelatedValuePropagation, IndVarSimplify, ConstraintElimination, IPSCCP, and other relevant transforms.\n- Make use of the intrinsics via InstCombine canonicalization or direct emission in clang/rustc.\n- Conduct a comprehensive content audit of the existing website.\n- Select appropriate technologies, preferably static site generators like Hugo or Jekyll.\n- Advocate for a separation of data and visualization, utilizing formats such as YAML and Markdown to facilitate content management without direct HTML coding.\n- Present three design mockups for the new website, fostering open discussions and allowing time for alternative proposals from interested parties.\n- Implement the chosen design, incorporating valuable feedback from the community.\n- Collaborate with content creators to integrate or update content as needed.\n// A.h #include <string> #include <vector> template <class T, class U = int> struct AStruct { void doIt() { /*...*/ } const char* data; // ... }; template<class T, class U = AStruct<T>> inline void freeFunction() { /* ... */ } inline void doit(unsigned N = 1) { /* ... */ } // Main.cpp #include \"A.h\" int main() { doit(); return 0; } This pathological example expands to 37253 lines of code to process. Cling builds an index (it calls it an autoloading map) where it contains only forward declarations of these C++ entities. Their size is 3000 lines of code. The index looks like: // A.h.index namespace std{inline namespace __1{template <class _Tp, class _Allocator> class __attribute__((annotate(\"$clingAutoload$vector\"))) __attribute__((annotate(\"$clingAutoload$A.h\"))) __vector_base; }} ... template <class T, class U = int> struct __attribute__((annotate(\"$clingAutoload$A.h\"))) AStruct; Upon requiring the complete type of an entity, Cling includes the relevant header file to get it. There are several trivial workarounds to deal with default arguments and default template arguments as they now appear on the forward declaration and then the definition. You can read more in [1]. Although the implementation could not be called a reference implementation, it shows that the Parser and the Preprocessor of Clang are relatively stateless and can be used to process character sequences which are not linear in their nature. In particular namespace-scope definitions are relatively easy to handle and it is not very difficult to return to namespace-scope when we lazily parse something. For other contexts such as local classes we will have lost some essential information such as name lookup tables for local entities. However, these cases are probably not very interesting as the lazy parsing granularity is probably worth doing only for top-level entities. Such implementation can help with already existing issues in the standard such as CWG2335, under which the delayed portions of classes get parsed immediately when they're first needed, if that first usage precedes the end of the class. That should give good motivation to upstream all the operations needed to return to an enclosing scope and parse something. Implementation approach: Upon seeing a tag definition during parsing\nwe could create a forward declaration, record the token sequence and mark it\nas a lazy definition. Later upon complete type request, we could re-position\nthe parser to parse the definition body. We already skip some of the\ntemplate specializations in a similar way [2, 3].\nAnother approach is every lazy parsed entity to record its token stream and change the Toks stored on LateParsedDeclarations to optionally refer to a subsequence of the externally-stored token sequence instead of storing its own sequence (or maybe change CachedTokens so it can do that transparently). One of the challenges would be that we currently modify the cached tokens list to append an \"eof\" token, but it should be possible to handle that in a different way. In some cases, a class definition can affect its surrounding context in a few ways you'll need to be careful about here: 1) `struct X` appearing inside the class can introduce the name `X` into the enclosing context. 2) `static inline` declarations can introduce global variables with non-constant initializers that may have arbitrary side-effects. For point (2), there's a more general problem: parsing any expression can trigger a template instantiation of a class template that has a static data member with an initializer that has side-effects. Unlike the above two cases, I don't think there's any way we can correctly detect and handle such cases by some simple analysis of the token stream; actual semantic analysis is required to detect such cases. But perhaps if they happen only in code that is itself unused, it wouldn't be terrible for Clang to have a language mode that doesn't guarantee that such instantiations actually happen. Alternative and more efficient implementation could be to make the lookup tables range based but we do not have even a prototype proving this could be a feasible approach.\n- Design and implementation of on-demand compilation for non-templated functions\n- Support non-templated structs and classes\n- Run performance benchmarks on relevant codebases and prepare report\n- Prepare a community RFC document\n- [Stretch goal] Support templates\n- Not all C/C++ constructs are currently handled by the Markdown and HTML emitter limiting the toolâs usability.\n- The generated HTML output does not scale with the size of the codebase making it unusable for larger C/C++ projects.\n- The implementation does not always use the most efficient or appropriate data structures which leads to correctness and performance issues.\n- There is a lot of duplicated boiler plate code which could be improved with templates and helpers.\nUse the variable location information from the debug info to annotate LLDBâs disassembler (and `register read`) output with the location and lifetime of source variables. The rich disassembler output should be exposed as structured data and made available through LLDBâs scripting API so more tooling could be built on top of this. In a terminal, LLDB should render the annotations as text.\nframe #0: 0x0000000100000f80 a.out`main(argc=1, argv=0x00007ff7bfeff1d8) at demo.c:4:10 [opt] 1 void puts(const char*); 2 int main(int argc, char **argv) { 3 for (int i = 0; i < argc; ++i) â 4 puts(argv[i]); 5 return 0; 6 } (lldb) disassemble a.out`main: ... 0x100000f71 <+17>: movl %edi, %r14d 0x100000f74 <+20>: xorl %r15d, %r15d 0x100000f77 <+23>: nopw (%rax,%rax) â 0x100000f80 <+32>: movq (%rbx,%r15,8), %rdi 0x100000f84 <+36>: callq 0x100000f9e ; symbol stub for: puts 0x100000f89 <+41>: incq %r15 0x100000f8c <+44>: cmpq %r15, %r14 0x100000f8f <+47>: jne 0x100000f80 ; <+32> at demo.c:4:10 0x100000f91 <+49>: addq $0x8, %rsp 0x100000f95 <+53>: popq %rbx ... using the debug information that LLDB also has access to (observe how the source variable i is in r15 from [0x100000f77+slide)) $ dwarfdump demo.dSYM --name i demo.dSYM/Contents/Resources/DWARF/demo: file format Mach-O 64-bit x86-64 0x00000076: DW_TAG_variable DW_AT_location (0x00000098: [0x0000000100000f60, 0x0000000100000f77): DW_OP_consts +0, DW_OP_stack_value [0x0000000100000f77, 0x0000000100000f91): DW_OP_reg15 R15) DW_AT_name (\"i\") DW_AT_decl_file (\"/tmp/t.c\") DW_AT_decl_line (3) DW_AT_type (0x000000b2 \"int\")to produce output like this, where we annotate when a variable is live and what its location is: (lldb) disassemble a.out`main: ... ; i=0 0x100000f74 <+20>: xorl %r15d, %r15d ; i=r15 0x100000f77 <+23>: nopw (%rax,%rax) ; | â 0x100000f80 <+32>: movq (%rbx,%r15,8), %rdi ; | 0x100000f84 <+36>: callq 0x100000f9e ; symbol stub for: puts ; | 0x100000f89 <+41>: incq %r15 ; | 0x100000f8c <+44>: cmpq %r15, %r14 ; | 0x100000f8f <+47>: jne 0x100000f80 ; <+32> at t.c:4:10 ; | 0x100000f91 <+49>: addq $0x8, %rsp ; i=undef 0x100000f95 <+53>: popq %rbx The goal would be to produce output like this for a subset of unambiguous cases, for example, variables that are constant or fully in registers.\n- Adrian Prantl aprantl@apple.com (primary contact)\n- Jonas Devlieghere jdevlieghere@apple.com\nRequired: - Good understanding of C++\n- Familiarity with using a debugger on the terminal\n- Need to be familiar with all the concepts mentioned in the example above\n- Need to have a good understanding of at least one assembler dialect for machine code (x86_64 or AArch64).\nDesired: - Compiler knowledge including data flow and control flow analysis is a plus.\n- Being able to navigate debug information (DWARF) is a plus.\nmedium (~175h)\nhard\nLLVM-reduce, and similar tools perform delta debugging but are less useful if many implicit constraints exist and violation could easily lead to errors similar to the cause that is to be isolated. This project is about developing a GPU-aware version, especially for execution time bugs, that can be used in conjunction with LLVM/OpenMP GPU-record-and-replay, or simply a GPU loader script, to minimize GPU test cases more efficiently and effectively.\nA tool to reduce GPU errors without loosing the original error. Optionally, other properties could be the focus of the reduction, not only errors.\n- Parasyris, Konstantinos parasyris1@llnl.gov\n- Johannes Doerfert jdoerfert@llnl.gov\nRequired: - Good understanding of C++\n- Familiarity with GPUs and LLVM-IR\nDesired: - Compiler knowledge including data flow and control flow analysis is a plus.\n- Experience with debugging and bug reduction techniques (llvm-reduce) is helpful\nmedium\nmedium\nModern C++ defines parallel algorithms as part of the standard library, like `std::transform_reduce(std::execution::par_unseq, vec.begin(), vec.end(), 0, std::plus\nImprovements to the prototype support of offloading in libcxx. Evaluations against other offloading approaches and documentation on the missing parts and shortcommings.\n- Johannes Doerfert jdoerfert@llnl.gov\n- Tom Scogland scogland1@llnl.gov\n- Tom Deakin tom.deakin@bristol.ac.uk\nRequired: - Good understanding of C++ and C++ standard algorithms\n- Familiarity with GPUs and (OpenMP) offloading\nDesired: - Experience with libcxx (development).\n- Experience debugging and profiling GPU code.\nlarge\nmedium\nLLVM has lots of thresholds and flags to avoid \"costly cases\". However, it is unclear if these thresholds are useful, their value is reasonable, and what impact they really have. Since there are a lot, we cannot do a simple exhaustive search. In some prototype work we introduced a C++ class that can replace hardcoded values and offers control over the threshold, e.g., you can increase the recursion limit via a command line flag from the hardcoded \"6\" to a different number. In this project we want to explore the thresholds, when they are hit, what it means if they are hit, how we should select their values, and if we need different \"profiles\".\nStatistical evidence on the impact of various thresholds inside of LLVM's code base, including compile time changes, impact on transformations, and performance measurements.\n- Jan Hueckelheim jhueckelheim@anl.gov\n- Johannes Doerfert jdoerfert@llnl.gov\n- William Moses wmoses@mit.edu\nRequired: - Profiling skills and knowledge of statistical reasoning\nDesired: - Good understanding of the LLVM code base and optimization flow\nmedium\neasy\nWe have begun work on a libc library targeting GPUs. This will allow users to call functions such as malloc or memcpy while executing on the GPU. However, it is important that these implementations be functional and performant. The goal of this project is to benchmark the implementations of certain libc functions on the GPU. Work would include writing benchmarks to test the current implementations as well as writing more optimal implementations.\nIn-depth performance for libc functions. Overhead of GPU-to-CPU remote procedure calls. More optimal implementations of 'libc' functions.\n- Joseph Huber joseph.huber@amd.com\n- Johannes Doerfert jdoerfert@llnl.gov\nRequired: - Profiling skills and understanding of GPU architecture\nDesired: - Experience with libc utilities\nsmall\neasy\nMore efficient GPU First framework that can support both NVIDIA and AMD GPUs. Optionally, upstream the framework.\n- Shilei Tian i@tianshilei.me\n- Johannes Doerfert jdoerfert@llnl.gov\n- Joseph Huber joseph.huber@amd.com\nRequired: - Good understanding of C++ and GPU architecture\n- Familiarity with GPUs and LLVM IR\nDesired: - Good understanding of the LLVM code base and OpenMP target offloading\nmedium\nmedium\nThe\nThe overall goal of this GSoC project is to identify and implement missing\nfeatures in ClangIR to make it possible to compile GPU kernels in the\nA good starting point for this work is the\n`GEMM` |"
  },
  {
    "name": "Jenkins",
    "slug": "jenkins-wp",
    "tagline": "Jenkins, build great things at any scale",
    "description": "Short description:\n\nJenkins is a popular open source automation server which is used for building, testing, CI/CD, deployment and many other use-cases. Our motto is \"Build great things at any scale\".\n\nLong description:\n\nJenkins, originally founded in 2006 as \"Hudson\", is one of the leading automation servers. Jenkins' motto is \"Build great things at any scale\". Using an extensible, plugin-based architecture, developers have created hundreds of plugins to adapt Jenkins to a multitude of build, test, and deployment automation workloads. As Jenkins is open-source, MIT License is used for most of the components.\n\nThis year we invite potential GSoC contributors to join the Jenkins community and to work together to improve Jenkins. We have many strategic project ideas which are important to potentially hundreds of thousands of Jenkins users.\n\nThe project has over 600 active contributors working on Jenkins core, plugins, website, project infrastructure, localization activities, etc. In total we have more than 2,000 components including plugins, libraries, and various utilities. The main languages in the project are Java, Groovy and JavaScript, but we also have components written in other languages (Go, C/C++, C#, etc.). Jenkins project includes multiple sub-projects (including Configuration-as-Code, Infrastructure and Remoting) and special interest groups. These entities participate in GSoC as a part of the Jenkins project.\n\nThe Jenkins project is a part of Continuous Delivery Foundation (CDF).",
    "ideas_url": "https://www.jenkins.io/projects/gsoc/2026/project-ideas/",
    "website_url": "https://jenkins.io",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "javascript",
      "java",
      "go",
      "docker",
      "kubernetes"
    ],
    "topic_tags": [
      "developer tools",
      "automation",
      "continuous integration",
      "continuous delivery",
      "devops"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/jenkins-wp",
    "ideas_content": "This page aggregates project ideas for Google Summer of Code\n2026.\nRefer to the Jenkins Google Summer of Code page\n[\nfor more information about this project and applications..\n](https://www.jenkins.io/projects/gsoc/)\n\nBelow you can find project ideas that have been proposed for this year.\nNew ideas may be proposed by interested mentors or GSoC contributors, such as new features in the core or \"write a plugin for MY_TOOL_OR_SERVICE\".\nProject ideas without potential mentors will be considered, though applicants may need to work with the community and GSoC org admins to find mentors.\nTo add a new project idea, see:\n[\nproposing project ideas\n](https://www.jenkins.io/projects/gsoc/proposing-project-ideas/).\n\nThe following list contains the project ideas that fully match the Jenkins project idea standard. The scope of these ideas is understood and we don't normally expect deep changes. All ideas have quick-start guidelines and newbie-friendly issues referenced. We welcome contributors to join the mentor teams and invite GSoC contributors to submit project proposal applications related to these ideas.\n\n| Project | Category | Skills to study/improve |\n|---|---|---|\n|\nAI Chatbot to Guide User Workflow\n|\n\nDevelop an AI-powered chatbot integrated into Jenkins to assist users in navigating workflows, accessing documentation, and troubleshooting issues efficiently..\n\nDevelop an AI-based chatbot to provide users with quick and intuitive access to Jenkins documentation, plugins, and community resources..\n\nUsing alternative tooling with Vite and Antora to build the Jenkins static site and provide versioned Jenkins documentation.\n\nUsing a modern and secure method to send Jenkins email notifications via Outlook SMTP with OAuth authentication by adding OAuth support (with client credentials flow) to email-ext..\n\nBuild a public, static visualization site that consumes the existing modernization dataset (from GitHub) during its build process to present dashboards and perâplugin reports.\n\nMigrate and redesign the Jenkins.io Contributor Spotlight website using Vite.js and React.js to enhance user experience and modernize the tech stack..\n\nTo revamp jenkins.io website's Success Stories feature to update both tooling and UI/UX experience with new design.\n\nTo help enhance observability of Jenkins jobs on ci.jenkins.io via the introduction of the use of OpenTelemetry.\n\nIn the following list, you can refer to draft project ideas, which are currently under review. The scope of such ideas may change during the discussions, but the idea is accepted in principle. You are welcome to comment on the draft and join the project as a mentor. If you are a GSoC contributor, it is also fine to explore and apply to the draft project ideas.\n\n| Project | Category | Skills to study/improve |\n|---|\n\nThese proposals are suggestions from the mailing list, which have not been published as project ideas yet. The feasibility is yet to be defined, and the idea may be dismissed depending on the feedback. Everyone is welcome to participate in the discussion and join as a potential mentor.\n\n| Project | Category |\n|---|"
  },
  {
    "name": "Neovim",
    "slug": "neovim",
    "tagline": "hyperextensible Vim-based text editor",
    "description": "Neovim is a fork of the Vim text editor, designed for extensibility and usability.",
    "ideas_url": "https://github.com/neovim/neovim/wiki/Google-Summer-of-Code",
    "website_url": "https://neovim.io/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "lua"
    ],
    "topic_tags": [
      "ai",
      "editor",
      "text-editor"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/neovim",
    "ideas_content": "# Introduction\n\nNeovim is a text editor based on Vim. One of the main [project goals](https://neovim.io/charter/) is to encourage hacking and collaboration.\n\n- Project proposals for [Google Summer of Code](https://summerofcode.withgoogle.com/) are tracked as [discussions](https://github.com/neovim/neovim/discussions?discussions_q=label%3Agsoc).\n- These projects may require familiarity with C, Lua, and Vimscript.\n- Documentation for Neovim developers is here: https://neovim.io/doc/user/dev.html\n\nThe Neovim source has roots going back to 1987 which means libraries such as [libuv](https://github.com/libuv/libuv) were not around at that time. The codebase can be made easier to maintain and understand by using these libraries. Project ideas that heavily involve \"internals\" will in general be more difficult than project ideas that add new features. However working with older/complex parts of the code base can also provide valuable learning feedback for writing simpler and more maintainable code.\n\n# Getting started\n\nProposals (and the final \"work submission\") are tracked as [discussions with the \"gsoc\" label](https://github.com/neovim/neovim/discussions?discussions_q=label%3Agsoc). We are happy to hear other ideas you may have, just [create a new discussion](https://github.com/neovim/neovim/discussions/new?category=ideas&labels=gsoc) and mention that it's for GSoC. Because communication is a big part of open source development you are expected to get in touch with us before sending your proposal, see [Where to ask questions](#where-to-ask-questions).\n\nTo get familiar with the project, \n\n- read [CONTRIBUTING.md](https://github.com/neovim/neovim/blob/master/CONTRIBUTING.md)\n- try a small coding task (choose from [complexity:low](https://github.com/neovim/neovim/issues?q=is%3Aopen+is%3Aissue+label%3Acomplexity%3Alow) issues)\n    - working on concrete tasks in the existing codebase, even if the tasks are unrelated to your proposal, gives us a valuable signal about your work style and communication. This is a key component of a successful proposal.\n\nTo get familiar with GSoC, read their materials. Especially:\n\n- https://google.github.io/gsocguides/student/\n- https://summerofcode.withgoogle.com/rules\n\nNote: this year we will likely accept 1-2 students. We expect to get more strong proposals than available slots, so we will need to turn some good proposals down.\n\n## AI-assisted work\n\nAI-assisted work is fine, but:\n\n- We cannot spend our time reviewing your AI output; it is *your* responsibility to review the AI output before asking *humans* to review it.\n- You are expected to distill the AI output into its essentials, reducing verbosity and removing \"slop\" such as irrelevant markdown files, misplaced or redundant tests, etc.\n- You are expected to ensure that the AI solution makes sense in the context of the Neovim codebase, and that it follows documented conventions and patterns.\n\n**We will close AI-assisted PRs that are overly verbose or include AI-generated slop.**\n\n## Tips\n\n- Anywhere a Vim concept (such as \"textlock\") is mentioned, you can find what it means by using the `:help` command in Nvim (`:help textlock`).\n- Ask questions and post your partial work frequently (every 1-2 days, if possible). It's OK if work is messy; just mark the pull request (PR) as \"Draft\".\n- Take advantage of the continuous integration (CI) systems which automatically run against your pull requests. When you send work to a PR, the full test-suite runs on the PR while you continue to work locally.\n- Only a text editor, `cmake`, and a compiler are needed to develop Neovim. LSP is very helpful also.\n- See `:help dev-tools` and [CONTRIBUTING.md](https://github.com/neovim/neovim/blob/master/CONTRIBUTING.md) for documentation on building, debugging, and development tips.\n\n## Where to ask questions\n\nAsk questions here:\n\n- https://github.com/neovim/neovim/discussions\n- https://matrix.to/#/#neovim:matrix.org\n\nDo *not* ask general GSoC questions on [the issue tracker](https://github.com/neovim/neovim/issues); use [discussions](https://github.com/neovim/neovim/discussions) for that. **Do not ask \"where do I start?\"** on the issue tracker. *Do* comment on related issues to ask specific technical questions about an issue. If your question is not specific to an issue, open a [discussion](https://github.com/neovim/neovim/discussions).\n\n# Making a proposal\n\nThe application period for GSOC is March 16-31 ([Timeline](https://developers.google.com/open-source/gsoc/timeline)). Send your proposal through the [GSOC page](https://summerofcode.withgoogle.com/programs/2026/organizations/neovim). We encourage students to send a first draft early in this period, this allows us to give feedback and and ask for more information if need.\n\n- [\"Writing a proposal\" guidelines](https://google.github.io/gsocguides/student/writing-a-proposal)\n- [Proposal evaluation criteria](http://intermine.org/internships/guidance/grading-criteria-2019/)\n\n## Tips for a successful application\n\nA **successful proposal** will have the following:\n\n- Start by describing the problem briefly.\n- The rest of the proposal should give confidence that it can actually be done. \n    - Concrete description of the technical approach, and implementation (code), increases confidence that the proposal is feasible in the timeline and the contributor is capable of delivering it.\n- Minimal verbosity/buzzwords. Vague descriptions lower confidence.\n- Appendix that links to:\n    1. Draft PR (or code pasted into the proposal) that shows how your idea is feasible, in code.\n    2. Neovim PR(s) that you worked on. This is the main way to demonstrate your approach to understanding the codebase and executing real work. Working on concrete tasks in the existing codebase, even if the tasks are unrelated to your proposal, gives us an important signal about your work style and communication. This is a key component of a successful proposal.\n\nBelow are some suggested issues. These are starting points. If you have a great idea, propose it!\n\n# GSoC Ideas 2026\n\n## Proposals are [tracked as discussions](https://github.com/neovim/neovim/discussions)\n\nProposals are tracked as [discussions](https://github.com/neovim/neovim/discussions) which implement features [tracked as issues](https://github.com/neovim/neovim/labels/gsoc).\n\n1. Choose an [existing issue](https://github.com/neovim/neovim/labels/gsoc), or [create a new issue](https://github.com/neovim/neovim/issues/new?template=feature_request.yml&labels=gsoc) to outline a feature/project proposal.\n    - Your proposal and work will not be discussed on the issue itself. Use discussions for that.\n2. Create a [discussion](https://github.com/neovim/neovim/discussions) to ask questions, talk about your idea(s), and (later) discuss your progress.\n\nBelow are some suggested issues. These are starting points. Your proposal should start with (1) a \"Problem\" section that describes the problem being solved, followed by (2) your proposed solution to the problem, including implementation details and constraints.\n\n## Multibuffer: many buffers stitched together as one virtual buffer\n\n- Size: 350 hours\n- Difficulty: Hard\n- Desirable Skills:\n    - C\n    - Lua\n- Code license: Apache 2.0\n- Mentor: TBD\n- Tracking issue: https://github.com/neovim/neovim/issues/30463\n\n**Description:**\n\ntodo\n\n**Expected Result:**\n\ntodo\n\n## Run Neovim in a web browser\n\n- Size: 350 hours\n- Difficulty: Hard\n- Desirable Skills:\n    - C\n    - javascript/wasm\n- Code license: Apache 2.0\n- Mentor: TBD\n- Tracking issue: https://github.com/neovim/neovim/issues/35567\n\n**Description:**\n\ntodo\n\n**Expected Result:**\n\n- Build system has a task which compiles Nvim to javascript or webassembly and runs fully in-browser\n- The task runs in CI and produces a usable artifact.\n\n## Restore `:terminal` buffers after restart\n\n- Size: 175 hours\n- Difficulty: Medium\n- Desirable Skills:\n    - Lua\n    - C (minimal)\n- Code license: Apache 2.0\n- Mentor: Justin M. Keyes ([@justinmk](http://github.com/justinmk))\n- Tracking issue: https://github.com/neovim/neovim/issues/28297\n\n**Description:**\n\nCurrently, the contents of `:terminal` buffers isn't preserved after Nvim restarts. Or when a `:terminal` buffer is closed, its contents can't be reloaded.\n\n**Expected Result:**\n\n- `:terminal` buffer contents can be saved to the filesystem.\n- User has a way to view saved terminal buffers and reload them.\n- Visiting a \"mark\" in a terminal buffer reloads the terminal buffer if it's not loaded.\n- `:terminal` buffers optionally are included in Nvim \"session\" files and restored when the session is reloaded.\n\n## Visual-first editing\n\n- Size: 350 hours\n- Difficulty: Medium-Hard\n- Desirable Skills:\n    - C and Lua\n    - Familiar with event-loop programming model\n- Code license: Apache 2.0\n- Mentor: Justin M. Keyes ([@justinmk](http://github.com/justinmk))\n- Tracking issue: https://github.com/neovim/neovim/issues/16296\n\n**Description:**\n\nVim tradtionally has a \"verb-object\" editing model, whereas editors like kakoune and helix have \"object-verb\". The existing visual-mode in Nvim could be enhanced to support this in Nvim.\n\n**Expected Result:**\n\nVisual-mode in Nvim becomes more intuitive and useful:\n\n- it can be repeated with dot (.)\n- introduce a modifier similar to `v`, except normal-mode commands work in this mode, after the \"selection\" is chosen.\n\n## GUI Features\n\n- Size: 175 hours\n- Difficulty: Medium-Hard\n- Desirable Skills:\n    - C and related tools\n    - Familiar with event-loop programming model\n- Code license: Apache 2.0\n- Mentor: Justin M. Keyes ([@justinmk](http://github.com/justinmk)), [@bfredl](http://github.com/bfredl)\n\n**Description:**\n\nNvim GUIs are implemented as processes communicating with Nvim. Originally the UI protocol exposed most functionality as a single, terminal-like screen grid. Work has been done to allow UIs (including embeddings in GUI editors, like VSCode) to render the screen layout themselves, based on semantic updates from Nvim. Some screen elements like the cmdline, popupmenu and message area has been externalized. As a result of a 2018 [GSOC project](https://github.com/neovim/neovim/issues/8320), windows can be drawn on separate grids.\n\n**Expected Result:**\n\nFurther improvements to the GUI protocol.\n\nSome UIs want to render the buffer contents themselves. A solution would be a UI protocol mode, where the rendered grid is not used, rather all decorations, such as syntax highlighting, conceals, virtual text are transmitted for the current viewport. Such an UI would be able to render text without the restrictions of the builtin monospace grid. Then the UI should be able to inform nvim about usage of virtual columns and wrapping, so that vim commands such as `gj` are consistent with how text is presented to the user.\n\nAnother path is to improve the core Nvim grid model. We could allow the width and height of cells be different for each row. This would allow for heading text with different font size, and pictures rendered inside windows.\n\nPutting forward your own ideas of UI improvements is encouraged. Read the [docs](https://github.com/neovim/neovim/blob/master/runtime/doc/ui.txt) for the implemented extensions as well as the [tracking issue](https://github.com/neovim/neovim/issues/9421) for ongoing/planned work, as a starting point.\n\n\n\n\n## IDE \"Vim mode\"\n\n- Size: 175 hours\n- Difficulty: Medium\n- Desirable Skills:\n    - Familiar with RPC\n- Code license: Apache 2.0\n- Mentor: Justin M. Keyes ([@justinmk](http://github.com/justinmk))\n\n**Description:**\n\nImplement \"Vim mode\" in an editor/IDE (such as IntelliJ) by embedding a `nvim` instance.\n\n**Expected Result:**\n\nFull Nvim editing should be available in the editor/IDE, while also allowing the user to use the native editor/IDE features.\n\nExamples:\n\n- [VSCode integration](https://github.com/asvetliakov/vscode-neovim)\n- [Sublime Text integration](https://github.com/lunixbochs/actualvim)\n\n\n# GSoC Ideas 2025\n\n## ✅ (DONE) AI primitives\n\n- Size: 350 hours\n- Difficulty: Medium\n- Desirable Skills:\n    - Lua\n- Code license: Apache 2.0\n- Mentor: Justin M. Keyes ([@justinmk](http://github.com/justinmk))\n- Tracking issue: https://github.com/neovim/neovim/issues/32084\n\n**Description:**\n\nAlthough Nvim doesn't plan to include AI features by default, it should provide basic features that make it easy to build AI plugins (chat, completion, etc.)\n\n**Expected Result:**\n\nIdentify and implement Nvim features that make it easy for users to build high-quality AI \"chat\" and \"completion\" plugins. For example:\n\n- ✅ Support `textDocument/inlineCompletion` from the LSP 3.18 spec.\n- ✅ Add a way to mark a buffer or window as \"busy\" or \"in progress\", that works with the default statusline (and custom statuslines).\n- ✅ Add a \"progress meter\" interface to the Nvim standard library.\n- ✅ Improvements to the \"prompt buffer\" concept\n    - multiline input\n    - paste into the prompt\n    - a builtin \"filetype\" with standard highlighting\n    - standard headers with distinctive highlighting\n    - standard mappings\n- ...?\n\n## ✅ ([DONE](https://github.com/neovim/neovim/pull/33953)) \":restart\" command\n\n- Size: 175 hours\n- Difficulty: Medium\n- Desirable Skills:\n    - C\n    - Lua\n- Code license: Apache 2.0\n- Mentor: Justin M. Keyes ([@justinmk](http://github.com/justinmk))\n- Tracking issue: https://github.com/neovim/neovim/issues/32484\n\n**Description:**\n\nDeveloping/troubleshooting plugins has friction because \"restarting\" Nvim requires quitting, then manually starting again, in some fashion.\n\n**Expected Result:**\n\nImplement a `:restart` command which allows Nvim to restart itself. This will involve some knowledge of inter-process communication / RPC.\n\n## \"Remote SSH\" features\n\n- Size: 350 hours\n- Difficulty: Medium\n- Desirable Skills:\n    - Lua\n- Code license: Apache 2.0\n- Mentor: Justin M. Keyes ([@justinmk](http://github.com/justinmk))\n- Tracking issue: https://github.com/neovim/neovim/issues/21635\n\n**Description:**\n\nWorking with remote systems could be more \"ergonomic\". VSCode's \"remote ssh\" plugin demonstrates how ergonomics can greatly improve usability.\n\n**Expected Result:**\n\nIntroduce a command or some sort of interface that Allows the user to:\n\n1. input a ssh URI (hostname + port)\n     - or select from a list of hosts discovered from your local `~/.ssh/config`\n2. nvim connects to the remote ssh endpoint using your local `~/.ssh` credentials\n    - or prompts for password as needed\n3. nvim starts a new local UI that attaches to a remote `nvim` server running on the remote machine.\n4. if necessary, nvim auto-installs itself on the remote machine.\n    - it also installs your plugins, on the remote!\n5. the local nvim UI controls the remote nvim server, and you can use it to work on the remote machine very much like a local nvim.\n\n\n\n\n---\n\n# GSoC Ideas 2019\n\n## ✅ (DONE) \"Multiprocessing\" feature\n\n**Description:**\n\np2p architecture for data sharing between multiple Nvim instances. Similar to Python's [multiprocessing](https://docs.python.org/3/library/multiprocessing.html) module, the idea is to to offload Nvim tasks (VimL and/or Lua) to child Nvim processes.\n\nHere's a picture of the potential workflow:\n\n1. parent calls `invoke_async(Foo)`\n2. parent spawns new child `nvim` process\n3. parent sends command name `Foo` + state to child\n4. parent does other, unrelated work\n5. child completes its `Foo` work\n6. child sends notification (method name + state) to parent\n\n**Difficulty:** Hard\n\n**Code license:** Apache 2.0\n\n**Mentor:** Justin M Keyes ([@justinmk](http://github.com/justinmk))\n\n## ✅ ([DONE](https://github.com/neovim/neovim/pull/10071)) TUI (Terminal UI) remote attachment\n\n**Description:**\n\nThe built-in UI is called the TUI. It looks like Vim, but internally it is decoupled from the UI and \"screen\" layout subsystem. It was designed to be able to connect to other (remote) instances of Nvim, but this hasn't been implemented yet. [#7438](https://github.com/neovim/neovim/issues/7438)\n\nNvim is both a server and a client. Nvim (client) can connect to any other Nvim (server). And Nvim [GUIs](https://github.com/neovim/neovim/wiki/Related-projects#gui) can show the screen of a remote Nvim server.\n\nBut the built-in Nvim TUI cannot show the screen of a remote Nvim server. That's the goal of this project.\n\n- It is not \"live share\". It's just showing the remote UI in a client TUI.\n- Networking question are out of scope. It is assumed the client has an SSH tunnel or named pipe to connect to.\n\nThe Nvim API model is:\n\n- `:help api`: general API functions\n- `:help ui`: UI events\n- Any client can call any API function.\n- If a client calls `nvim_ui_attach`, then it is a \"UI client\". This simply means that Nvim will send UI events as msgpack-rpc notifications on the channel.\n\nThat's how _every_ Nvim UI works. And that's how the TUI client (this project proposal) will work.\n\nPython \"demo UI\" may be helpful: https://github.com/neovim/python-gui\n\nThe simplest UI is the \"fake UI\" implemented in `test/functional/ui/screen.lua` from the Nvim test suite. It creates a text UI from real Nvim UI events. This allows us to write Lua tests that check the state of the UI, by simply writing the text UI in the test. In the Neoivm repo, \"git grep 'screen:expect'\" shows all of the places where this is used.\n\nThe `example_spec.lua` test shows a simple example. You can try it by running this shell command:\n\n    TEST_FILE=test/functional/example_spec.lua make functionaltest\n\nOverview of the `screen.lua` \"fake UI\" implementation:\n\n- `Screen._wait()` / `Screen:sleep()` runs the event loop to consume UI events\n- `Screen:_redraw()` dispatches UI events to the appropriate handlers\n- For example `Screen:_handle_grid_line()` consumes a line event, and updates some tables (self._grids and self._attr_table).\n    - And those tables are literally the contents of the fake UI that `Screen:expect()` tests against.\n\nUse cases:\n\n- Connect to any Nvim. Unlike tmux, Nvim UI client can connect to any other running Nvim, including GUIs.\n- Potential for using `libnvim` as the RPC core of any Nvim API client, to eliminate the need for clients to implement their own msgpack-RPC handling.\n\n**Expected Result:**\n\nImplement a TUI \"remote UI\" client. Modify the TUI subsystem so that it can display a remote Nvim instance.\nThe C codebase already has msgpack support, an event-loop, and the ability to connect to sockets/named pipes/etc.\n\n- Extend `tui/tui.c` to:\n  1. connect to a channel\n  2. get UI events from the channel\n  3. unpack the events and call the appropriate handlers\n- Extend `tui/input.c` to:\n  1. send user input to the channel (i.e. call the nvim_input() API function)\n\nExample:\n\n    nvim --servername foo\n\nwill connect to the Nvim server at address `foo`. The `nvim` client instance sends input to the remote Nvim server, and reflects the UI of the remote Nvim server. So the `nvim` client acts like any other external (G)UI.\n\n\n**Difficulty:** Medium\n\n**Code license:** Apache 2.0\n\n**Mentor:** Justin M Keyes ([@justinmk](http://github.com/justinmk)), Björn Linse ([@bfredl](http://github.com/bfredl))\n\n---\n# GSoC Ideas 2018\n\n## ✅ ([DONE](https://github.com/neovim/neovim/pull/8707)) UI protocol improvements\n\n**Description:**\n\nNvim GUI:s are implemented as processes communicating with Nvim over a protocol. Currently this protocol exposes most functionality as a terminal-like screen grid. A long term goal is enabling richer UIs (including embeddings in GUI editors, like VSCode) by refactoring the protocol towards semantic updates and letting the GUI actually draw buffer contents and other screen elements. Currently this has been implemented for a few specific elements, like the completion popup menu and the command line.\n\n**Expected Result:**\n\nThe UI protocol has gained new capabilities. This could involve substantial changes such as the GUI receiving redraw updates for each window separately, so that the GUI could be responsible for managing the overall layout of windows and statuslines.\n\nAlternatively, improvements could be done within the current global screen grid, such as the ability to display grid-aligned images in signs, buffers and statuslines. It could also involve adding semantic information to the grid, so that GUI:s can identify screen elements reliably rather than guessing it from highlights.\n\n- Code license: Apache 2.0\n\n**Difficulty:**\n\nMedium to Hard\n\n**Student:** ([@UtkarshMe](https://github.com/UtkarshMe))\n\n**Mentor:** Björn Linse ([@bfredl](http://github.com/bfredl))\n\n## Java client\n\n**Desirable Skills:**\n\n- Familiar with Vim/Nvim and Vim script (VimL)\n- Moderate/High experience in Java\n- Familiar with event-loop programming model\n\n**Description:**\n\nImplement a Nvim [API client](https://github.com/neovim/neovim/wiki/Related-projects#api-clients) using Java. \n\nImplement a client, written in Java, which allows Java applications to control Nvim using the Nvim RPC API.  If you are familiar with AWS or any other SaaS, note that a Nvim API client is just like a SDK for a REST web service, except that Nvim uses msgpack, not HTTP/JSON.\n\nThe Nvmi RPC API is documented at [:help api](https://neovim.io/doc/user/api.html) and [:help rpc](https://neovim.io/doc/user/msgpack_rpc.html).\n\nTo correctly implement the client one needs to understand the [msgpack-rpc](https://github.com/msgpack-rpc/msgpack-rpc/blob/master/spec.md) protocol. Some sort of event-loop mechanism will be needed to handle notifications.\n\nFor reference, you can find clients in other languages at the [related projects](https://github.com/neovim/neovim/wiki/Related-projects#api-clients) wiki page.\n\nThe ultimate goal is to have a library that can be used to create plugins for [IntelliJ](https://www.jetbrains.com/help/idea/plugin-development-guidelines.html) and [Eclipse](https://help.eclipse.org/mars/index.jsp?topic=%2Forg.eclipse.platform.doc.isv%2Fguide%2Ffirstplugin.htm).  **Minimizing third-party dependencies** may help there.\n\n**Expected Result:**\n\n- Java library that can be used to build Neovim extensions (UIs and other applications).\n  - Method signatures generated from `nvim --api-info`.\n  - Since `nvim` is already required (for `--api-info`), the Java code-generation script could be written in Lua (which is built-in to `nvim`).\n- Passes the test suite used by the Nvim [python-client](https://github.com/neovim/python-client).\n  - Using the [python-client tests](https://github.com/neovim/python-client/tree/master/test) as a guide, create equivalent tests using a Java testing framework.\n  - Test suite should be runnable from the command-line (should not require an IDE) via maven/gradle (or some other industry-standard build-tool).\n- Builds (and passes tests) on Linux (Travis CI) and Windows (AppVeyor)\n- End-user deliverable should be compatible Java 6 (this is negotiable)\n- Source-code can be latest version of Java (no backwards-compatibility requirement)\n- Code license: Apache 2.0\n\n**Difficulty:**\n\nMedium\n\n**Mentor:** Justin M Keyes ([@justinmk](http://github.com/justinmk))\n\n## ✅ ([DONE](https://github.com/neovim/nvim.net)) C# client\n\n**Description:**\n\nImplement a Nvim [API client](https://github.com/neovim/neovim/wiki/Related-projects#api-clients) using C#. \n\nImplement a client, written in C#, which allows C# applications to control Nvim using the Nvim RPC API.  If you are familiar with AWS or any other SaaS, note that a Nvim API client is just like a SDK for a REST web service, except that Nvim uses msgpack, not HTTP/JSON.\n\nThe Nvmi RPC API is documented at [:help api](https://neovim.io/doc/user/api.html) and [:help rpc](https://neovim.io/doc/user/msgpack_rpc.html).\n\nTo correctly implement the client one needs to understand the [msgpack-rpc](https://github.com/msgpack-rpc/msgpack-rpc/blob/master/spec.md) protocol. Some sort of event-loop mechanism will be needed to handle notifications ([hint1](https://blogs.msdn.microsoft.com/pfxteam/2012/01/20/await-synchronizationcontext-and-console-apps/), [hint2](https://blogs.msdn.microsoft.com/pfxteam/2012/02/02/await-synchronizationcontext-and-console-apps-part-3/)).\n\nFor reference, you can find clients in other languages at the [related projects](https://github.com/neovim/neovim/wiki/Related-projects#api-clients) wiki page.\n\nThe ultimate goal is to have a library that can be used to create plugins for Visual Studio.  **Minimizing third-party dependencies** may help there.\n\n**Expected Result:**\n\n- C# library that can be used to create C#-based Neovim extensions (UIs and other applications).\n  - Method signatures generated from `nvim --api-info`.\n  - Since `nvim` is already required (for `--api-info`), the C# code-generation build script could be written in Lua (which is built-in to `nvim`).\n- Passes the test suite used by the Nvim [python-client](https://github.com/neovim/python-client).\n  - Using the [python-client tests](https://github.com/neovim/python-client/tree/master/test) as a guide, create equivalent tests using a C# testing framework.\n  - Test suite should be runnable from the command-line (should not require an IDE) via MSBuild or some other industry-standard build-tool.\n- Builds (and passes tests) on Linux (Travis CI) and Windows (AppVeyor)\n- Builds against **.NET Standard 2.0**\n- Deliverable should be easy to install as a NuGet (or other) package.\n- Source-code can be latest version of C# (no backwards-compatibility requirement)\n- Code license: Apache 2.0\n\n**Difficulty:**\n\nMedium\n\n**Student:** ([@b-r-o-c-k](https://github.com/b-r-o-c-k))\n\n**Mentor:** Justin M Keyes ([@justinmk](http://github.com/justinmk))"
  },
  {
    "name": "MoFA Org",
    "slug": "mofa-org",
    "tagline": "Empower extraordinary with Composition AI",
    "description": "mofa-org is an open-source organization that builds and maintains the MoFA ecosystem — a modular AI agent framework that makes it easy to build, compose, and run complex AI applications & a collection of open-source tools and frameworks designed to:\n\n- Allow developers to compose AI agents like building blocks\n- Enable complex AI systems without heavy boilerplate or bespoke pipelines\n- Provide visual tooling (like MoFA Stage) for developer productivity",
    "ideas_url": "https://github.com/mofa-org/GSoC/blob/main/ideas-list.md",
    "website_url": "https://mofa.ai",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "rust"
    ],
    "topic_tags": [
      "development framework",
      "AI Agent",
      "Compostion AI"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/mofa-org",
    "ideas_content": "# MoFA GSoC 2026 Project Ideas\n\n> [中文版](./ideas-list-zh.md) |  English Version\n\nThis list contains detailed project ideas for Google Summer of Code 2026. While the overall outline is defined, internal details are open to modifications based on contributor suggestions under mentor guidance. We encourage contributors to propose their own approaches — the ideas below are starting points, not rigid specifications.\n\n## About MoFA\n\n[MoFA](https://mofa.ai/) (**Modular Framework for Agents**) is an open-source framework for building AI agents. Our recent project, **MoFA Studio**, is a desktop application for creating, running, and sharing AI-powered applications — built with Rust and Makepad, with [OminiX-MLX](https://github.com/OminiX-ai/OminiX-MLX) for on-device ML inference on Apple Silicon.\n\nWe mentor GSoC contributors on real-world problems spanning systems engineering, AI infrastructure, and developer tools.\n\n__Website:__ [mofa.ai](https://mofa.ai/)\n\n__GitHub Repos:__\n- Core runtime: [github.com/mofa-org/mofa](https://github.com/mofa-org/mofa) (`feature/mofa-rs` branch)\n- Studio application: [github.com/mofa-org/mofa-studio](https://github.com/mofa-org/mofa-studio)\n- Makepad UI components: [makepad-chart](https://github.com/mofa-org/makepad-chart), [makepad-d3](https://github.com/mofa-org/makepad-d3), [makepad-flow](https://github.com/mofa-org/makepad-flow), [makepad-element](https://github.com/mofa-org/makepad-element)\n- Node ecosystem: [github.com/mofa-org/mofa-node-hub](https://github.com/mofa-org/mofa-node-hub)\n\n__Organization Contact:__ dev@mofa.ai\n__GSoC Contributor Guidance:__ [README.md](./README.md)\n\n---\n\n## Idea 1: AgentForge — Composable Plugin System for Collaborative AI Development\n\n### Abstract\n\nIn the age of vibe coding, individual developers can generate agent code rapidly with LLMs. However, **merging outputs from multiple vibe coders into a coherent system remains the hardest unsolved problem** — human review bandwidth is the bottleneck, not code generation speed.\n\n**AgentForge** addresses this by building a composable plugin system for mofa-rs, where each developer independently creates a self-contained agent plugin with well-defined interfaces. The framework handles composition, validation, and conflict detection — enabling team-scale vibe coding without merge hell.\n\n__Mentors__: BH3GEI (Yao Li), Xiaokuge (Zonghuan Wu)\n\n### Goals & Ideas\n\n* **Plugin Interface Specification**: Define a clear contract for mofa-rs plugins — input types, output types, state schema, and lifecycle hooks. Each plugin is a self-contained unit that can be developed, tested, and vibe-coded independently\n* **Validation Tooling**: Build tools that verify plugin interface compatibility before composition — type checking, schema validation, and conflict detection between plugins\n* **Composition Engine**: Automatically wire multiple plugins together based on their interface declarations. Handle routing, data transformation, and error propagation across plugin boundaries\n* **Plugin Isolation**: Ensure one plugin's failure doesn't crash others. Sandbox runtime state so plugins can be hot-swapped during development\n* **Integration with Studio**: Generated plugin compositions can be loaded and run inside MoFA Studio\n\nContributors are also encouraged to explore alternative or complementary approaches, such as:\n\n* **Semantic Node Search**: Index [mofa-node-hub](https://github.com/mofa-org/mofa-node-hub) (400+ nodes) with vector embeddings to assist plugin discovery and composition\n* **Flow Synthesis**: Convert natural language descriptions to executable plugin compositions\n* **Makepad UI Generation**: Auto-generate UI for plugin configurations and outputs\n\n#### Example Scenario\n\nThree developers each vibe code an agent component:\n- Developer A: a web scraping agent plugin\n- Developer B: a summarization agent plugin\n- Developer C: a notification agent plugin\n\nAgentForge validates their interfaces are compatible, composes them into a pipeline, and runs the combined system — without any of the three developers reading each other's code.\n\n#### Refs\n\n* https://github.com/mofa-org/mofa/tree/feature/mofa-rs\n* https://github.com/mofa-org/mofa-studio\n* https://github.com/mofa-org/mofa-node-hub\n* https://makepad.dev/\n\n__Skills Required__: Rust, plugin architecture design, type systems, LLM integration\n\n__Time Estimate__: 120 hours (10 weeks)\n\n__Difficulty__: Hard\n\n---\n\n## Idea 2: Studio Observability Dashboard\n\n### Abstract\n\nMoFA Studio runs complex AI pipelines involving multiple models (ASR, LLM, TTS) and agent interactions. Currently, when something goes wrong or runs slowly, developers have limited visibility into what's happening inside. This project will build a **real-time observability dashboard** embedded directly into MoFA Studio, providing developers with instant insight into model performance, resource usage, and agent behavior.\n\nThe dashboard will leverage MoFA Studio's existing [makepad-chart](https://github.com/mofa-org/makepad-chart) and [makepad-d3](https://github.com/mofa-org/makepad-d3) GPU-accelerated visualization components.\n\n__Mentors__: BH3GEI (Yao Li), Bicheng Lou\n\n### Goals & Ideas\n\n* **Dashboard Server Development**:\n  - Build HTTP server (using axum or similar) exposing REST APIs for metrics\n  - Implement WebSocket endpoint for real-time streaming updates\n  - Design efficient metrics aggregation and caching\n\n* **API Design & Implementation**:\n  - `/api/agents` — list all agents with status\n  - `/api/agents/{id}` — detailed agent metrics\n  - `/api/metrics` — system-wide metrics snapshot (model states, memory, latency)\n  - WebSocket `/ws` — real-time event stream\n\n* **Model & Inference Monitoring**:\n  - Which models are currently loaded in memory and their sizes\n  - Per-model inference metrics: tokens/s, time-to-first-token, batch utilization\n  - Apple Silicon unified memory usage and pressure\n  - Model load/unload events and durations\n\n* **Pipeline Monitoring**:\n  - End-to-end latency for multi-model pipelines (e.g., ASR → LLM → TTS)\n  - Per-stage latency breakdown and bottleneck identification\n  - Request queue depth and throughput\n\n* **Studio Integration**:\n  - Makepad-based real-time visualization panels using [makepad-chart](https://github.com/mofa-org/makepad-chart) and [makepad-d3](https://github.com/mofa-org/makepad-d3)\n  - Agent status display (running, paused, error states)\n  - Resource usage dashboard with time-series charts\n  - Log aggregation with intelligent filtering\n\nContributors may also explore monitoring Dora-based dataflow runtimes if applicable, providing a unified monitoring interface across different orchestration backends.\n\n#### Refs\n\n* https://github.com/mofa-org/mofa-studio\n* https://github.com/mofa-org/makepad-chart\n* https://github.com/mofa-org/makepad-d3\n* https://github.com/mofa-org/mofa/tree/feature/mofa-rs/crates/mofa-monitoring\n* https://github.com/mofa-org/mofa/tree/feature/mofa-rs/crates/mofa-runtime\n\n__Skills Required__: Rust, HTTP/WebSocket servers (axum/tokio), real-time data visualization, Makepad UI\n\n__Time Estimate__: 90 hours (8 weeks)\n\n__Difficulty__: Medium\n\n---\n\n## Idea 3: Edge Model Orchestrator\n\n### Abstract\n\nOn edge devices, multiple models (ASR, LLM, TTS, embedding) compete for limited memory and compute. This project implements an intelligent **Model Scheduler** built into mofa-rs, enabling efficient multi-model orchestration on Apple Silicon devices.\n\nUnlike traditional approaches that communicate with model servers over HTTP (e.g., Ollama), this orchestrator calls [OminiX-MLX](https://github.com/OminiX-ai/OminiX-MLX) model crates **directly at the Rust API level** — `load_model()`, `Generate`, `forward()` — with compile-time binding and zero serialization overhead. This unlocks a key advantage of Apple Silicon's unified memory: **output tensors from one model (e.g., ASR) can be passed directly to another model (e.g., LLM) as zero-copy MLX Arrays**, eliminating the serialization-deserialization overhead inherent in HTTP-based or cross-process architectures.\n\nAn existing prototype, [mofa-local-llm](https://github.com/mofa-org/mofa-local-llm), already demonstrates single-model inference via this approach. This project extends it to multi-model concurrent scheduling.\n\n__Mentors__: BH3GEI (Yao Li), Xiaokuge (Zonghuan Wu), Bicheng Lou\n\n### Goals & Ideas\n\n* **Architecture Design**:\n  - Implement as a core component in mofa-rs (`mofa-foundation` layer)\n  - Call OminiX-MLX crates directly via Rust API (compile-time dependency, no HTTP middle layer)\n  - Design `ModelPool` managing multiple loaded model instances concurrently\n\n* **Lifecycle Management**:\n  - On-demand model loading with async initialization\n  - Idle timeout-based automatic unloading (LRU eviction)\n  - Memory pressure monitoring on Apple Silicon unified memory\n  - Graceful shutdown with state preservation\n\n* **Smart Scheduling**:\n  - Route requests to the right model based on task type (ASR/LLM/TTS) and availability\n  - Memory-aware admission control: reject or defer requests when memory is constrained\n  - Dynamic precision degradation (e.g., auto-switch from 8-bit to 4-bit quantization under pressure)\n\n* **Inference Pipeline**:\n  - Chain multiple models into a pipeline (ASR → LLM → TTS) with zero-copy tensor passing via MLX Arrays\n  - Streaming token output from LLM directly into TTS input\n  - Per-stage latency tracking and bottleneck reporting\n\n* **Degradation Strategies**:\n  - Auto-fallback to smaller models when primary models fail or resources are constrained\n  - Quality-of-service levels with corresponding model selections\n\n* **Integration**:\n  - Expose scheduling state and metrics to the Studio observability dashboard (Idea 2)\n  - Provide clean API for agents to request inference without managing model lifecycle\n\n#### Example Scenario\n\nA voice assistant pipeline with:\n- FunASR (ASR, ~2GB)\n- Qwen (LLM, ~8GB)\n- GPT-SoVITS (TTS, ~4GB)\n\nOn a 16GB MacBook, all three cannot be resident simultaneously. The orchestrator will:\n- Keep LLM resident (core functionality)\n- Load ASR on voice input, unload after 30s idle\n- Load TTS only during synthesis, pass LLM output tokens directly as MLX Arrays (zero-copy)\n- Under memory pressure, auto-switch Qwen from 8-bit to 4-bit quantization\n\n#### Refs\n\n* https://github.com/mofa-org/mofa-local-llm\n* https://github.com/OminiX-ai/OminiX-MLX\n* https://github.com/mofa-org/mofa/tree/feature/mofa-rs/crates/mofa-foundation\n* https://github.com/mofa-org/mofa/tree/feature/mofa-rs/crates/mofa-runtime\n\n__Skills Required__: Rust, systems programming, resource management, Apple Silicon / GPU computing\n\n__Time Estimate__: 140 hours (11 weeks)\n\n__Difficulty__: Hard\n\n---\n\n## Idea 4: Session Recorder & Visual Debugger\n\n### Abstract\n\nMulti-agent systems are notoriously difficult to debug. When agents exchange dozens of messages and state changes, traditional logs become unreadable. This is especially true in the era of vibe coding, where LLM-generated agent code often works in demo but fails in production with no clear explanation.\n\nThis project builds a **time-travel debugger** for MoFA — a differentiating capability that gives developers a reason to run their agents on mofa-rs. Think of it as \"Chrome DevTools for Agents\": load any agent (hand-written or vibe-coded), record its execution, inspect message flow, and replay with modifications.\n\nBuilding this debugger will also serve as an **architectural audit** for mofa-rs — the process of adding instrumentation hooks will force the framework to define clear internal APIs for event capture, state snapshots, and message interception.\n\n__Mentors__: BH3GEI (Yao Li), Xiaokuge (Zonghuan Wu), Bicheng Lou\n\n### Goals & Ideas\n\n* **Event Interception**:\n  - Hook into `mofa-kernel` message bus to capture all agent events\n  - Serialize message flow, state transitions, and tool calls\n  - Efficient storage format for long-running sessions\n  - Define a clear, stable Hook API that becomes part of mofa-rs's public contract\n\n* **Timeline Visualization**:\n  - Makepad-integrated or web-based timeline view\n  - See which agent sent what message to whom, when\n  - Filter by agent, message type, or time range\n  - Zoom in/out from millisecond to hour scale\n\n* **State Inspection**:\n  - Capture agent state snapshots at key points\n  - Diff view: compare agent state before/after message handling\n  - Inspect memory, context, and internal variables\n\n* **Time-Travel Debugging**:\n  - Replay recorded sessions at variable speed\n  - Pause, step forward/backward through execution\n  - Set breakpoints on specific message patterns\n  - Re-run specific agent with modified input\n\n* **Vibe Coding Support**:\n  - Load and debug agents generated by LLMs without modification\n  - Identify common failure patterns in vibe-coded agents\n  - Export recordings for bug reports or as context for LLM-assisted fixing\n\n* **Integration**:\n  - Optional Studio panel for seamless development workflow\n  - Export recordings for bug reports or documentation\n\n#### Use Case\n\nA developer vibe-codes a 5-agent workflow. It works in simple tests but fails intermittently with real data. With the recorder:\n1. Load the vibe-coded agents into mofa-rs with recording enabled\n2. When failure occurs, open the trace\n3. See exact message sequence leading to error\n4. Inspect agent state at last known good point\n5. Replay with modifications to test fixes\n6. Export the trace as context for LLM to generate a fix\n\n#### Refs\n\n* https://github.com/mofa-org/mofa/tree/feature/mofa-rs/crates/mofa-kernel\n* https://github.com/mofa-org/mofa/tree/feature/mofa-rs/crates/mofa-monitoring\n\n__Skills Required__: Rust, data visualization, systems design, debugging tools\n\n__Time Estimate__: 140 hours (11 weeks)\n\n__Difficulty__: Hard\n\n---\n\n## Idea 5: MoFA Input — Inference Stack Migration to OminiX-MLX\n\n### Abstract\n\n[MoFA Input](https://github.com/mofa-org/mofa-input) is a macOS global voice input method that runs entirely on-device. It currently uses llama.cpp with GGUF models for ASR (Whisper) and LLM (Qwen) inference. This project migrates the inference stack to [OminiX-MLX](https://github.com/OminiX-ai/OminiX-MLX), replacing the llama.cpp backend with native Rust inference optimized for Apple Silicon.\n\nWhy migrate? MLX's Metal GPU acceleration is faster than llama.cpp on Apple Silicon, unified memory cuts overhead, and the rest of the MoFA ecosystem (Studio, mofa-local-llm) already uses OminiX-MLX.\n\n__Mentors__: BH3GEI (Yao Li), Xiaokuge (Zonghuan Wu)\n\n### Goals & Ideas\n\n* **ASR Migration**: Replace the current llama.cpp-based Whisper ASR with OminiX-MLX's `funasr-mlx` or `funasr-nano-mlx` crate. Validate accuracy and latency against the current implementation\n* **LLM Migration**: Replace Qwen GGUF inference with OminiX-MLX's `qwen3-mlx` crate (safetensors format). Ensure streaming token output works with the existing UI\n* **Swift-Rust FFI**: Adapt the existing Swift ↔ Rust FFI bridge to call OminiX-MLX APIs instead of llama.cpp. Maintain the current macOS input method architecture (Fn hotkey, floating bubble, history window)\n* **Performance Benchmarking**: Compare latency, memory usage, and accuracy before and after migration on representative hardware (M1/M2/M3/M4)\n* **Model Management**: Integrate with `~/.mofa/models/` model storage and leverage OminiX-MLX's safetensors format exclusively\n\n#### Refs\n\n* https://github.com/mofa-org/mofa-input\n* https://github.com/OminiX-ai/OminiX-MLX\n\n__Skills Required__: Rust, Swift, FFI/interop, Apple Silicon development\n\n__Time Estimate__: 90 hours (8 weeks)\n\n__Difficulty__: Easy\n\n---\n\n## Idea 6: Makepad AI Application Toolkit\n\n### Abstract\n\nMoFA's desktop applications (Studio, moly-ai) are built with [Makepad](https://makepad.dev/), a GPU-accelerated UI framework in Rust. While the organization has built foundational Makepad components ([makepad-chart](https://github.com/mofa-org/makepad-chart), [makepad-d3](https://github.com/mofa-org/makepad-d3), [makepad-element](https://github.com/mofa-org/makepad-element)), there is currently no **reusable component library specifically designed for AI applications**.\n\nThis project builds a `makepad-ai-toolkit` — a set of polished, reusable Makepad widgets tailored for AI chat interfaces, model management, and inference visualization. These components will be immediately usable by MoFA Studio and any future Makepad-based AI application.\n\n__Mentors__: BH3GEI (Yao Li), Bicheng Lou\n\n### Goals & Ideas\n\n* **Chat Interface Components**:\n  - Chat bubble widget with support for user/assistant/system roles\n  - Streaming text renderer (tokens appearing in real-time)\n  - Markdown rendering within chat messages (code blocks, lists, headers)\n  - Code syntax highlighting\n\n* **Audio & Voice Components**:\n  - Audio waveform visualizer (for ASR input / TTS output)\n  - Recording indicator with real-time amplitude display\n  - Audio playback controls with seek bar\n\n* **Model Management UI**:\n  - Model selector dropdown with model metadata (size, type, quantization)\n  - Download progress indicator\n  - Model status badges (loaded, unloading, error)\n\n* **Inference Visualization**:\n  - Token-per-second counter and latency display\n  - Memory usage gauge (unified memory on Apple Silicon)\n  - Inference progress indicator (prefill vs decode phases)\n\n* **Integration**:\n  - Package as a standalone Makepad crate (`makepad-ai-toolkit`) publishable on crates.io\n  - Provide example applications demonstrating each component\n  - Documentation with usage patterns for common AI application layouts\n\n#### Refs\n\n* https://github.com/mofa-org/mofa-studio\n* https://github.com/mofa-org/makepad-chart\n* https://github.com/mofa-org/makepad-d3\n* https://github.com/mofa-org/makepad-element\n* https://makepad.dev/\n\n__Skills Required__: Rust, UI/UX design, Makepad framework\n\n__Time Estimate__: 90 hours (8 weeks)\n\n__Difficulty__: Medium"
  },
  {
    "name": "Mixxx",
    "slug": "mixxx",
    "tagline": "DJ Mixing App With Powerful Features For All DJs",
    "description": "Mixxx is a feature rich DJ mixing  application. It supports many MIDI and HID DJ controllers, runs on Win Linux and MacOs. It supports effects, harmonic mixing and beatmatching.\n\nMixxx has an unusually broad community for an open-source project, encompassing performing musicians, C++ addicts, amateur DJs, Internet radio broadcasters, and casual users.",
    "ideas_url": "https://github.com/mixxxdj/mixxx/wiki/GSOC-2026-Ideas",
    "website_url": "https://mixxx.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "javascript",
      "c++",
      "qt",
      "pytorch",
      "onnx"
    ],
    "topic_tags": [
      "music",
      "dj",
      "streaming"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/mixxx",
    "ideas_content": "## Student Project Ideas for Google Summer of Code 2026\n\nThis page lists the suggested tasks to build a 90 hour (small sized) a 175 hour (medium sized) or 350 hour (large) project for [Google Summer of Code 2026](https://summerofcode.withgoogle.com/). The ideas are already assigned to example projects, but you are encouraged to use them for building your own project adding your own ideas and make it suit perfectly to you, your skills and your time line.\n\nIf you are interested in applying to GSoC, read [GSoC Advice](gsocadvice)\nbefore applying or getting involved. Only beginner contributors that are active members\nof the Mixxx community are accepted. If this is not the case yet, just\nsay hello at <https://mixxx.zulipchat.com> and discuss your Ideas and\ndiscus cases with us.\n\n# Adding an AI infrastructure with cross-platform hardware acceleration\n\nTypical AI applications in the DJ environment (STEM separation, music analysis) require very high computing power. However, as the commercial DJ software DJay Pro demonstrates, it is possible to perform these on modern laptop hardware in real time with high audio quality. This is made possible by the use of the dedicated Neural Processing Unit (NPU) or powerful Graphical Processing Units (GPU).\nAs cross-platform software, Mixxx must be able to do this on:\n* macOS (ARM M1/2 with Neural Engine NPU)\n* macOS (x64 with GPU only)\n* Linux with various NPU and GPU solutions from different manufacturers\n* Windows with various NPU and GPU solutions from different manufacturers\n\nToday, there is only one AI framework that supports full hardware acceleration across all these platforms, which is ONNX Runtime ([onnxruntime.ai](onnxruntime.ai)).\nIn GSoC 2025, our student Anmol Mishra not only converted the widely recognized best STEM separation model DEMUCS to ONNX, but also benchmarked the achievable performance on different hardware: https://mixxx.org/news/2025-10-27-gsoc2025-demucs-to-onnx-dhunstack/ \nAs successor, this project is about the integration of ONNX Runtime with ExecutionProviders for CPU (all operating systems), as well as at least one NPU or GPU acceleration solution into Mixxx.\nThis project explicitly includes contributions to third-party projects, in particular to the package managers VCPKG and the Linux distribution Debian/Ubuntu, which Mixxx uses to integrate dependencies.\nA further aspect to handle is, that these libraries, as well as, the AI models itself are significiantly larger than the current dependencies that come with Mixxx. This requires the development of suitable solutions for the continuous code integration (CI) and for the distribution to the end users.\n* **Expected Outcome:** ONNX Runtime with ExecutionProviders for CPU (all operating systems), as well as at least one NPU or GPU acceleration solution builds within the Mixxx environment. All changes on third-party code is contributed upstream to the particuar projects. Our ONNX DEMUCS model is executable in Mixxx.\n* **Skills:** Knowledge of CMake, C++. Basic experience with contributing packages to package managers/Linux distributions.\n* **Possible Mentor:** Jörg\n* **Difficulty:** Medium \n* **Size:** 350 h\n\n# AI music analyzer to detect Beats, Downbeats, Phrases\n\nWhile Mixxx has a solid analyzer for beat/tempo detection, it is traditionally DSP-based, while the state of the art has moved to a hybrid approach of AI models that include some DSP routines for data pre-processing. Commercial DJ software with such AI music analyzers (DJay Pro, DJ Studio) demonstrates virtually always perfect beat recognition in DJ Medien's tests, even on challenging tracks with a variety of tempo changes.\nThere are OpenSource music analyzer models available, nanmely https://github.com/JoergAtGithub/all-in-one (https://huggingface.co/spaces/taejunkim/all-in-one / https://taejun.kim/music-dissector/0427_justthewayyouare). While a science project with impressive results, this is a PyTorch model that cannot be used in a C++ project with support for any kind of acceleration hardware (it's based on the Demucs HT model above), also here an ONNX model is needed.\nThis project is about building an infrastructure that allows Mixxx developers to optimize the analyzer, check the correctness of the results and generate production-ready ONNX models for the Mixxx DJ software in an automated workflow.\nIn particular, the process when a user reports a track with incorrectly detected beats/downbeats/phrase-length/phrase-type and we need to optimize the model needs to be implemented. The main focus of this process is to ensure that the optimization for one track does not lead to worse recognition for other tracks.\n* **Skills:** Knowledge of C/C++. Sound experience with the creation of AI models - preferably in ONNX.\n* **Possible Mentor:** Daniel Schürmann \n* **Difficulty:** Difficult\n* **Size:** 175 h\n\n# Using The Harmonix Set to automatically evaluate the output of our music analyzers \nThe Harmonix Set [https://github.com/urinieto/harmonixset](https://github.com/urinieto/harmonixset) repository contains human annotated labels for 912 Western Pop music tracks. This is a great base to benchmark current and future music analyzers in Mixxx.\nThis project is about the automatic execution of the Mixxx Analyzer in a local development environment using all tracks of the Harmonix Set, that are available on the developer's local hard disk and generate a report that visualizes the deviations.\n\n* **Expected Outcome:** A lightweight tool or script that can be executed out-of-the-box on Windows, macOS and Linux.\n* **Skills:** Experience C++ and a common scripting environment like Python\n* **Music files:** The Mixxx project cannot provide the music files, so the students must have a larger number of the music files listed in The Harmonix Set available themselves.\n* **Possible Mentor:** Jörg\n* **Difficulty:** Easy\n* **Size:** 175 h\n\n# Graphical representation of BPM and Musical Keys in the waveform\n\nNowadays DJs depend more and more on visual information and metadata than on their ears and knowledge of music/tracks. Features that once were gimmicks or nice-to-haves became for a lot of DJs relying info, for others crucial.\nInformation as BPM and Musical Key is displayed as an one-value-field showing the most occuring / average value.\nThis project is about displaying the complete detailed information.\nGoals: \n* BPM is now displayed as a single value, while the analysis results in a detailed overview of the beat positions, a consistent graphical representaion of the analysed BPMvalues (eg with use of Savitzky-Golay filter) as an optional overlay in the waveform. In this way the DJ will be able to see the BPM changes (Break, bridge, intermezzo) and the correct values in the waveform.\n* Musical KEY is now displayed a single value while the analysis results in a detailed list of KEYS, eg refrain, bridge, break, instrumental break, intermezzo can have a different (not displayed) key. The DJ should have the option to view a graphical representation of the musical Keys in the waveform.\n* As the BPM & Key representation in the waveform require a points in the waveform where the values change, these points should be showed on the waveform as POIs (Points of Interest): BPM-Change-Points & Key-Change-Points, the DJ should have the possibility to display these points, and eventually create hotcues, loops, beatjumps ... based on the position of these points.\n* The data to create the graphical representation of BPM-curve, Musical KEY-curve and POIs needs to be saved in an interchangeable format for easy recreation on other systems, other CMRT (see other GSoC idea)\n\n* **Expected Outcome:** A new visual representation of changing keys and BPMs. \n* **Skills:** Experience C++ and user interface design, OpenGL \n* **Possible Mentor:** Evelynne, Daniel \n* **Difficulty:** Medium\n* **Size:** 175 h\n\n# Cannonical Master Release Track based on the complete Chroma-Fingerprint of the track\n\nFirst step in the process to share advanced DJ-metadata. This is a combined Project with MetaBrains to implement a subcluster for Cannonical Master Release Track. First step in the process to share advanced DJ-metadata.\n\nAt the moment the link between AcoustId and the MusicBrainsDatabase has a shortage: Tracks with a different mastering are linked to the same AcoustId resulting in the same MBID (MusicBrainsID) for different versions/masterings of the same track. \nIn this project we want to solve this issue by creating sub-clusters clustering the same masterings in the parent MBID-cluster.\n* Herefore we need to use the complete Chromaprint-Fingerprint to identify and distinguish the different masterings of a track (Cannonical Master Release Track) eg the 'Original Album'-Mastering, '7inch'-mastering, 'best of'-mastering, 'streaming'-mastering, 'video'-mastering, 'Various Artists Album'-mastering.\n* In the Mixxx-analysis procedure we need to calculate the complete Chromaprint-Fingerprint and save it in a new table in the the MixxxDB together with the FingerprintDATE, Offset (pregap) and MBID.\n* If the user accepts (preferences) to use & share information anonymously from/with MB, the complete fingerprint in combination with other metadata is shared/compared with information in the MBDB. If the CMRT-sub cluster (CMRT) with the complete fingerprint is already present, the offset can be calculated (pregap) and needs to be saved. \n\n* **Expected Outcome:**\n  * Add a new table in the MixxxDB with advanced trackmetadata (complete Chromaprint-Fingerprint..)\n  * Find exact doubles in the collection of the user (based on complete fingerprint)\n* **Future featurese:**\n  * Upgrade versions in the collection (eg replace a lossy version with the lossless verwion of the same mastering)\n  * Add a new sub-clusteringsystem based on the complete Chromaprint-fingerprint in the MusicBrainsDB\n  * Expand the current MusicBrainsLookup in Mixxx to retrieve and save the advanced Metadata.\n  * Interchange advanced DJ-metadata through the MBDB (BPM, Musical Key...)\n* **Expected Outcome:** A new visual representation of changing keys and BPMs. \n* **Skills:** Experience C++ and Database Postgres Sqlite \n* **Possible Mentor:** Evelynne, Daniel \n* **Difficulty:** Medium\n* **Size:** 175 h  (or more depending on the project proposal)\n\n# Auto completion for the Genre track metadata\n\nMixxx allows to assign a Genre to a track. This is currently a free text field that allows different spellings for the same Genre like Hiphop, Hip-Hop or Hip Hop. If you use all of these, you will not see all tracks when filtering. This project shall fix it. \n\nWe have started this project last year and did some important steps regarding requirement engineering and data modeling. We initially underestimated the required work, so we have decided to split it up. The first phase ended with a working prototype not merged into the Mixxx source code.\n\nThis year we like to revise the requirement and decision by testing the prototype and start over making use of the good foundation we have created.    \n\nThe project may feature \n * auto-complete the Genre when entering\n * add multiple Genres to a track\n * Backed up by an N-N genres relationship tree/net \n * Genre Import from Discogs and [MusicBrainz](https://musicbrainz.org/genres) \n\nIt is up to the contributor to focus on one ore more topic that the project scope is kept small and the goal code get merged.  \n\n[Last years project description](https://github.com/mixxxdj/mixxx/issues/14897) \n\n* **Expected Outcome:** A new auto completer for the Genre edit box\n* **Skills:** Basic SQLite, Good C++\n* **Possible Mentor:** Daniel Schürmann\n* **Difficulty:** Medium \n* **Size:** 90 h\n\n# Rebuild the LateNight theme in QML\n\nAs we continue our work to rebuild the Mixxx UI in QML and aim to delivering a fresh user experience, we also aim to rebuild our iconic LateNight theme in QML. This will let users who prefer the classic look return to the familiar 2.x experience.\n\nThe project focuses on two key areas:\n- Rebuilding all components, using the legacy components using our QWidget rendering stack, with the XML definition and style sheet serving as reference for acceptance criteria.\n- Extend the C++/QML API for needed behaviour.\n- Collaborating with other maintainers to develop the core theme-loading system, enabling future custom themes managed by individuals or the community.\n\n* **Expected Outcome:** A LateNight QML theme.\n* **Skills:** Basic QML and Basic C++\n* **Possible Mentor:** Antoine\n* **Difficulty:** Medium \n* **Size:** 350 h\n\n# Replace the outdated portmidi library in Mixxx by libremidi\nSince the begining, Mixxx uses portmidi [https://github.com/PortMidi/portmidi](https://github.com/PortMidi/portmidi) to implement the low-level MIDI communcation over USB. This cross-platform library is written in C and has a very limited feature set.\nWith the upcomming of the [MIDI 2.0](https://en.wikipedia.org/wiki/MIDI_2.0) standard, Mixxx needs to switch to another libray for MIDI communication. The library of choice is [https://github.com/celtera/libremidi](https://github.com/celtera/libremidi), a cross-platform MIDI library written in modern C++. libremidi offers not only MIDI and MIDI 2.0 on all platforms, but also much more sophisticated support features for device detection and hot-plugging.\nAs there are hundreds of MIDI mappings for Mixxx out in the field, the main point of this work is to achieve 100% compatibility. This project is not about using the new features of libremidi yet.\nThe project should start with improving the automatic test cases for MIDI. Once this is done, the library change itself should be done.\n\n* **Expected Outcome:** A fully compatible Midi implementation using libremidi, with compatibility proven by systematic tests \n* **Skills:** Experience in C++ and accessing USB-MIDI devices\n* **Hardware:** The Mixxx project cannot provide hardware. The student must own at least one USB-MIDI device, preferable a DJ controller.\n* **Computer:** The student should have access to computers of at least two of the Mixxx supported platforms: Linux, macOS or Windows\n* **Possible Mentor:** Jörg\n* **Difficulty:** Medium\n* **Size:** 175 h\n\n\n# Test our controller scripting libraries using Fuzzing\nMixxx contains several JavaScript libraries (like [https://github.com/mixxxdj/mixxx/blob/main/res/controllers/midi-components-0.0.js](https://github.com/mixxxdj/mixxx/blob/main/res/controllers/midi-components-0.0.js)) which allow a wide area of inputs and complex decision trees. Fuzzing seems to be a promissing method to detect flaws in these libraries. \nGoogles https://github.com/google/oss-fuzz might be a good platform for such a setup.\n\n* **Expected Outcome:** A working Fuzzing setup for all JavaScript libraries in the Mixxx controller code and the proper fix of some detect bugs\n* **Skills:** Practical experience with Fuzzing and systematic software testing\n* **Possible Mentor:** tbd.\n* **Difficulty:** Medium\n* **Size:** 175 h\n\n# Something Else\\!\n\nAs always with Summer of Code, you aren't limited to the suggestions\nwe've made here. If you've got a great idea for a project involving\nMixxx then we're looking forward to hearing about it. We recommend\nspending more than a few days using Mixxx and participating in the\ncommunity to develop a better understanding of areas where Mixxx could\nuse improvement. Our issue tracker is full of [feature requests](https://github.com/mixxxdj/mixxx/issues?q=is%3Aopen+is%3Aissue+label%3Afeature) and other\nideas scattered throughout, so if you browse through it, you may find\nmany more ideas for GSoC projects.\n\n**IMPORTANT: You should [contact us](gsocadvice) first to get feedback\nif you're going to submit a proposal for your own project idea\\!** We\nvery rarely approve ideas students propose. If you're not already\nexperienced with DJ equipment, we recommend sticking with one of the\nideas above."
  },
  {
    "name": "Open HealthCare Network",
    "slug": "open-healthcare-network",
    "tagline": "Reimagining Healthcare Delivery",
    "description": "Open Healthcare Network (OHC), originally established as Coronasafe Network, is a pioneering open-source organization dedicated to enhancing healthcare delivery and management. At the core of OHC's innovation is its flagship Electronic Medical Record (EMR) system, recognized as the 50th Digital Public Good by the United Nations. This system transcends being merely a digital repository of patient records, evolving into a platform that supports advanced TeleICU capabilities.\n\nOHC represents a unique fusion of professional expertise and community-driven innovation, primarily fueled by a small team of dedicated developers and a dynamic community of college students. This collaborative model showcases a new paradigm in healthcare technology, emphasizing impactful, sustainable, and scalable solutions.\n\nOriginally a volunteer-driven initiative during the COVID-19 pandemic, OHC has continually addressed citizen-level healthcare problems. Its CARE software, adopted by several Indian states, played a crucial role in optimizing healthcare resource management during the pandemic. As the pandemic waned, CARE evolved to support the 10BedICU Project, enabling technology-driven ICU care in rural India and providing TeleICU services to the remotest regions, impacting thousands of lives.\n\nToday, beyond the 10BedICU Project, CARE is being adopted for various healthcare applications, including palliative care digitization, demonstrating its adaptability and growing significance in improving healthcare delivery across diverse settings. OHC's journey is a testament to the transformative impact of youth-driven initiatives in healthcare, touching the lives of millions across India.",
    "ideas_url": "https://github.com/ohcnetwork/care_fe/issues?q=is%3Aissue%20state%3Aopen%20label%3AGSoC",
    "website_url": "https://ohc.network/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "django",
      "react",
      "typescript",
      "NextJs"
    ],
    "topic_tags": [
      "electronic medical records",
      "Digital Public Goods",
      "Telemedicine and Remote Care",
      "AI in Health",
      "HMIS"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/open-healthcare-network",
    "ideas_content": "# Issues\n\n## Search results\n\n- Status: Open.#10599 In ohcnetwork/care_fe;\n- Status: Open.#10534 In ohcnetwork/care_fe;\n- Status: Open.#10508 In ohcnetwork/care_fe;\n\n{{ message }}\n\n- Status: Open.#10599 In ohcnetwork/care_fe;\n- Status: Open.#10534 In ohcnetwork/care_fe;\n- Status: Open.#10508 In ohcnetwork/care_fe;"
  },
  {
    "name": "IOOS",
    "slug": "ioos",
    "tagline": "Our eyes on the ocean, coasts, and Great Lakes",
    "description": "U.S. IOOS is a national and regional partnership working to provide ocean, coastal and Great Lakes observations, data, tools, and forecasts to improve safety, enhance the economy, and protect our environment.  Our primary purpose is to provide free and open data about the state of our oceans and Great Lakes to our users.  These data are fundamental to understanding the health of our marine ecosystems, to monitor the climate signal as captured in oceanographic conditions, and to provide predictions about the future state of our oceans and coasts.",
    "ideas_url": "https://github.com/ioos/gsoc/blob/main/2026/ideas-list.md",
    "website_url": "https://ioos.noaa.gov/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "java",
      "r",
      "Zarr",
      "NetCDF"
    ],
    "topic_tags": [
      "open data",
      "open science",
      "data management",
      "Oceanography",
      "Marine Biodiversity"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/ioos",
    "ideas_content": "# Project Ideas for 2026\n\nIOOS DMAC community's project ideas list for [Google Summer of Code 2026](https://summerofcode.withgoogle.com).\n\nMentoring organization application deadline: Feb 3, 2026.\n\n| **Project Title** | **Project Idea Link** | **Description** | **Hours** |\n|------------|---------------|---------|-----------|\n| Implement QARTOD Glider QA/QC recommendations in ioos-qc | https://github.com/ioos/gsoc/issues/102 | Check what tests are in the QARTOD glider manual, but not implement yet. Note that some of the test are similar and may just need a new kw rather than a fresh implementation. | 350 hours |\n| Flesh out xarray-erddap CIs, test suite and documentation | https://github.com/ioos/gsoc/issues/108 | The xarray-erddap package is a thin wrapper to erddapy that provides a new engine to xarray.  The wrapper requires a test suite. continuous integration tests and deployment, and some documentation. | 90 hours |\n| Add empirical dynamic model to FIMS | https://github.com/ioos/gsoc/issues/107 | The Fisheries Integrated Modeling System (FIMS) is an R package that uses RCPP to allow C++ to work inside of R to assess the status of marine populations that are fished. Currently, we have an age-structured assessment model and we are in the process of adding a surplus production model. It would be amazing to include an empirical dynamic model in the suite of models, which we call model families.  | 175 hours |\n| Scalable OCSMesh: Parallelization and Spatial Partitioning | https://github.com/ioos/gsoc/issues/112 | OCSMesh V.2.0+ is a Python package designed for generating unstructured meshes tailored to ocean modeling. A parallel version of OCSMesh size function was developed in GSoC 2025. This project expands on last years’ success to make OCSMesh a truly HPC-native tool capable of handling global-scale domains. | 350 hours |\n| Refactoring Hurricane Surrogate Model | https://github.com/ioos/gsoc/issues/113 | The Storm Surge Modeling team at the Office of Coast Survey (OCS) has developed a Python package, EnsemblePerturbation, for an end to end probabilistic prediction of tropical cyclone (TC)-driven coastal flood analysis.  EnsemblePerturbation has a large dependency tree which makes it difficult to be approved for use on NOAA’s operational system (Weather and Climate Operational Supercomputing System - WCOSS). The goal of this project is to reduce the external package dependency of EnsemblePerturbation to a minimum | 175 hours |\n| Echoshader: a package for interactive visualisation and dashboarding of ocean sonar data | https://github.com/ioos/gsoc/issues/110 | This project builds on Echopype, which standardises and processes sonar data from a wide range of platforms.  The goal of this GSoC project is to further develop Echoshader, an open-source companion visualisation tool written in Python, originally developed by a GSoC’22 contributor to facilitate ocean sonar data visualisation.  We aim to further develop the Echoshader package by extending the current functionalities, and demonstrate its capabilities on multiple types of datasets (from ships, moorings, and autonomous vehicles) through robust cloud deployment. In doing so, we aim to integrate recent developments from engine_echo_data_viz into echoshader. | 175 hours |\n| Improve FIMS uncertainty reporting | https://github.com/ioos/gsoc/issues/111 | The Fisheries Integrated Modeling System (FIMS) is an R package that uses RCPP to allow C++ to work inside of R to run statistical models for assessing the status of marine populations that are fished. Currently, FIMS calculates estimation uncertainty for all derived quantities (values calculated from combinations of parameters) in the model. The uncertainty calculations are computationally expensive and models with a large number of derived quanities are running into memory limits.  The aim of this project is to devise an interface for the user to turn on/off uncertainty reporting for specific derived quantities. | 175 hours |\n|  Enhancing Daily Skill Assessment Workflows for NOAA’s Global Surge and Tide Operational Forecast System | https://github.com/ioos/gsoc/issues/109 | This project focuses on enhancing the AUTOVAL package, which provides daily skill assessments and statistical summaries for different STOFS components. Currently, AUTOVAL generates static HTML reports evaluating model performance across different cycles and locations. The primary goal is to transform this existing Python-based evaluation logic into an interactive Chatbot interface. | 350 hours |\n|  Enhance NOS skill assessment package’s user and developer experience | https://github.com/ioos/gsoc/issues/100 | The National Ocean Service (NOS) is currently developing a Python package to assess the skill of their Operational Forecast Systems (OFS). The goal of this project is to work with the NOS team and improve the skill assessment package by: 1) Enhancing the user experience by expanding the existing graphical user interface (GUI) and adding a visualization dashboard that displays results, and 2) Expanding automated GitHub testing, debugging, and other code development tools used in the code development workflow. | 350 hours |\n| Enhancing the noaa_coops Python package | https://github.com/ioos/gsoc/issues/101 | The noaa_coops Python package provides a wrapper for the NOAA CO-OPS Tides & Currents data APIs. This project will upgrade the noaa_coops Python package to improve usability across CO-OPS’ products, ensuring a seamless user experience while adhering to API best practices.  Improvements will include simplifying access to data requests exceeding CO-OPS Data API data length limits, and introducing support for additional CO-OPS API endpoints, such as the derived product API. | 90 hours |\n| Add sex structure to FIMS statistical-catch-at-age model | https://github.com/ioos/gsoc/issues/114 | Right now, the statistical catch-at-age model in the Fisheries Integrated Modeling System (FIMS) has a single sex. Adding sex structure to allow for males, females, and hermaphrodites is high on the priority list. This will involve coding in both C++ and R, where the population dynamics are written in C++ and interacting with setting up the model and structuring the data are in R. | 350 hours |\n| Develop a universal installer for National Stock Assessment Program (NSAP) packages | https://github.com/ioos/gsoc/issues/115 | Scientific software often depends on a complex mix of system tools, compilers, and R packages, making setup difficult and error-prone. This project will build a universal installer that provides simple “one-command” setups (e.g., bash scripts) for National Stock Assessment Program projects such as Stock Assessment Workflows and the Fisheries Integrated Modeling System (FIMS) | 175 hours |"
  },
  {
    "name": "Open Science Initiative for Perfusion Imaging",
    "slug": "open-science-initiative-for-perfusion-imaging",
    "tagline": "Open access resources for perfusion imaging",
    "description": "Perfusion Magnetic Resonance Imaging (MRI) is a vital medical imaging technique that assesses blood flow in tissues and thus contributes crucial information for diagnosing conditions such as stroke, tumors, and neurological disorders. Unlike the standard MRI methods that are daily used in hospitals, raw perfusion MRI data require further processing and quantification. This requires dedicated software tools. However, the lack of standardization and the availability of standardized and tested analysis code makes perfusion MRI less accessible and hinders its widespread use. The ISMRM Open Science Initiative for Perfusion Imaging (OSIPI) aims to address this gap and create resources for best practices in perfusion MRI including software and data inventories, code repositories, challenges, and educational material.",
    "ideas_url": "https://docs.google.com/document/d/e/2PACX-1vTs3n_pm3ZM7t-6rKooThwrBtCRQMCkYJcbIyl0ekhm5O4jBgC0BqdBDFKVUDhDvbFM1ShBoV3Q2pFM/pub",
    "website_url": "https://osipi.ismrm.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "github"
    ],
    "topic_tags": [
      "artificial intelligence",
      "data visualization",
      "data analysis",
      "medical imaging",
      "reproducible science"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/open-science-initiative-for-perfusion-imaging",
    "ideas_content": "Our organization focuses on a subdomain of medical imaging: quantitative MRI. Our projects then use several imaging techniques: DSC, DCE, ASL, and IVIM. While our project descriptions use specific terminology, we do not require deep knowledge of the field unless explicitly stated otherwise. Our mentors will provide the necessary domain expertise so contributors can focus on the tasks at hand.\n\nPython development:\n\nWhile OSIPI's current software resources are in separate repositories, split by perfusion technique (ASL, DCE/DSC, and IVIM), our overall aim is to develop a unified OSIPI software package in which each technique is a submodule. This will require a collaborative effort from multiple developers and is not expected to be fully developed through GSoC. Here, we defined several medium- to large-sized subprojects to take the next steps toward the unified project.\n\n- Extend and consolidate the previous package to include several modeling and data-processing options:\n[BBB-ASL module](https://docs.google.com#id.shu6tzc3u2k9),[ASL QC toolbox](https://docs.google.com#id.piyqr5sux1r). - Improve and extend a module for\n[automatic parameter reporting](https://docs.google.com#id.h1shqbjnruls) - Create a GUI and preclinical functionality for the\n[pyASL toolbox](https://docs.google.com#id.ner8diw1oe19) - Implement a framework for scoring results from the\n[ASL and DSC/DCE](https://docs.google.com#id.fudc1iluezsr)challenges - Harmonize the previous modules developed within OSIPI into an\n[OSIPY toolbox](https://docs.google.com#id.ox5ezufao6u) - Create a repository for browsing and uploading examples of image artifacts:\n[AURA framework](https://docs.google.com#id.v85t7m48ki3e)\n\nGeneral GitHub link: [https://github.com/OSIPI](https://www.google.com/url?q=https://github.com/OSIPI&sa=D&source=editors&ust=1771587958742128&usg=AOvVaw1X4G2PWDJOKYDVvAAP2mXb)\n\nProposed mentors: Jan Petr, Ben Dickie\n\nLanguages/skills: Python, GitHub\n\nEstimated project length: 350 hours\n\nLinks: [BBB ASL module](https://www.google.com/url?q=https://github.com/limonenmelissa/gsoc_bbb/blob/main/src/bbb_exchange/README.md&sa=D&source=editors&ust=1771587958743319&usg=AOvVaw30fmldQz0FPasSyEdBqfyi)\n\nDifficulty: Large\n\nCategory: Intermediate\n\nProject description: Arterial spin labeling (ASL) data acquired at multiple timepoints need to be quantified by voxel-wise fitting a kinetic model to the acquired time series. Two options are generally used: nonlinear least-squares fitting or Bayesian fitting. Both options are currently implemented, providing two models that address standard multi-delay and multi-delay multi-echo ASL measurements in the [BBB ASL](https://www.google.com/url?q=https://github.com/limonenmelissa/gsoc_bbb/blob/main/src/bbb_exchange/README.md&sa=D&source=editors&ust=1771587958744549&usg=AOvVaw2xeNlTDuaCcG4lbkRfqy9K) Python package. While the package works in general, it is not very user-friendly, and the code needs to be cleaner and more modular. Several functionalities need to be implemented: 1) full modularity enabling independently choosing the fitting model and the ASL model, while making the code easy to expand with more models; 2) parameters of the fitting and the ASL model needs to be inputted in JSON configuration files rather than as commandline or hard-coded options; 3) several parameters (e.g, T1 of blood/tissue and T2 of blood/tissue) should be passed both as a scalar value and as an input image; 4) prepare the code so that it integrates seamlessly with [PyASL modules](https://www.google.com/url?q=https://github.com/OSIPI/TF2.2_OSIPI-ASL-toolbox/tree/main/PyASL/pyasl/modules&sa=D&source=editors&ust=1771587958745922&usg=AOvVaw0y8RYRgT-hpFZ6n-jFkkY5), following a similar architectural design (i.e., [https://pyasl.readthedocs.io/en/latest/modules/index.html](https://www.google.com/url?q=https://pyasl.readthedocs.io/en/latest/modules/index.html&sa=D&source=editors&ust=1771587958746367&usg=AOvVaw2noNfS6Ygkencgg5_jaei2)).\n\nExpected outcomes:\n\n- Modular package for fitting multi-timepoint ASL data\n\nRequirements:\n\n- Python proficiency, GitHub\n\nOptional:\n\n- Image processing, MRI physics, ASL\n\nProposed mentors: Jan Petr, Dave Thomas, Ibrahim Abdelazim\n\nLanguages/skills: Python, GitHub\n\nEstimated project length: 175 hours\n\nLinks: [GSoC 2025 report](https://www.google.com/url?q=https://medium.com/@ibrahim.abdelazim/google-summer-of-code-25-with-open-science-initiative-for-perfusion-imaging-osipi-2f95fab822ce&sa=D&source=editors&ust=1771587958748094&usg=AOvVaw3hnLEdFevBUjTqB3ByrzYo), [Documentation](https://www.google.com/url?q=https://docs.page/1brahimmohamed/ASL-Parameter-Generator&sa=D&source=editors&ust=1771587958748407&usg=AOvVaw2sVCDz1e7hhpp-RwEdX4XN), [Python package](https://www.google.com/url?q=https://pypi.org/project/pyaslreport/&sa=D&source=editors&ust=1771587958748597&usg=AOvVaw3_H1mYJficMzUu_MwrML5L), [Repository](https://www.google.com/url?q=https://github.com/1brahimmohamed/ASL-Parameter-Generator&sa=D&source=editors&ust=1771587958748779&usg=AOvVaw0TjNGu4nMzMO51EH6vq3Bl)\n\nDifficulty: Moderate\n\nCategory: Intermediate\n\nProject description: ASL Method section generator, as currently implemented, is a tool with a GUI that takes ASL-MRI data (but further extensions are possible) in BIDS format as input and creates a short paragraph as output that can be used for the methods section of scientific papers. It also allows DICOM images to be used as input and automatically extracts the necessary parameters. The goal of the current GSoC project is to improve the code's reliability and enable further extensions by writing automated tests that use a set of input files and compare their outputs with the expected outputs. Prepare a structure for the tests so that further testing files for all modules can be easily uploaded. Create a GitHub Actions workflow for automated CI tests.\n\nExpected outcomes:\n\n- Automated tests allowing easy extension to new examples and modules.\n\nRequirements:\n\n- Python proficiency, GitHub\n\nOptional:\n\n- DICOM, BIDS, MRI metadata knowledge\n\nProposed mentors: Lena Václavů, Olivia Jones, Puneet Kumar\n\nLanguages/skills: Python, Containerisation/Docker, Git/GitHub, skills for testing, documentation, and logging.\n\nEstimated project length: 175 hours\n\nLinks: [OSIPI/TF6.2_DCE-DSC-MRI_Challenges: TF6.2](https://www.google.com/url?q=https://github.com/OSIPI/TF6.2_DCE-DSC-MRI_Challenges&sa=D&source=editors&ust=1771587958752203&usg=AOvVaw3Qph3qvOb5Nzc5qJcLozfE), [ASL OSIPI Challenge](https://www.google.com/url?q=https://pubmed.ncbi.nlm.nih.gov/38502108/&sa=D&source=editors&ust=1771587958752593&usg=AOvVaw3S0tkW5jPVLLlDbtqEmOIZ), [DCE OSIPI Challenge](https://www.google.com/url?q=https://pubmed.ncbi.nlm.nih.gov/38115695/&sa=D&source=editors&ust=1771587958752794&usg=AOvVaw0Jum1ZZvIevFBWF9VCH6mW), [OSIPI TF 6.2](https://www.google.com/url?q=https://github.com/OSIPI/TF6.2_DCE-DSC-MRI_Challenges&sa=D&source=editors&ust=1771587958753007&usg=AOvVaw3rJI1z-TcM1ZQK0j3S_Vfx)\n\nDifficulty: Moderate\n\nCategory: Easy\n\nProject description: This project aims to benchmark methods and reveal the differences between various quantification methods, including both classical and emerging tools to compute parameter maps from perfusion imaging methods (i.e., cerebral blood flow, Ktrans, arterial transit time), in order to advance standardisation in (clinical) research and clinical use of multi-delay ASL and DCE/DSC MRI. The project will develop a software pipeline to handle incoming data submissions (including 3D parameter maps and the code used to create them) and to score results and evaluate performance metrics against the selected ground-truth dataset (accuracy, reproducibility, repeatability). The pipeline must have options for extension and must generalise to both ASL and DCE/DSC challenges.\n\nExpected outcomes:\n\n- Standardized pipeline in Python for evaluation of OSIPI challenges that:\n\n- Accepts data submissions (parameter maps + code)\n- Validates their format (NIfTI, parameter values, MRI data standard BIDS)\n- Runs the submitted codes in a controlled environment (e.g., Docker)\n- Performs scoring in a structured format (RMSE, bias, CoV, ICC, per voxel/region-of-interest of a mask)\n- Produces a report and visualisations (PDF or HTML)\n\nRequirements:\n\n- Python proficiency, GitHub\n\nProposed mentors: Maria Mora, Sudipto Dolui\n\nLanguages/skills: Python, GitHub\n\nEstimated project length: 350 hours\n\nLinks: [QC ASL MRICloud](https://www.google.com/url?q=https://analyticalsciencejournals.onlinelibrary.wiley.com/doi/abs/10.1002/nbm.4051&sa=D&source=editors&ust=1771587958839730&usg=AOvVaw10zAaG_EwgbHhp45d7syM_), [QEI ASL](https://www.google.com/url?q=https://pubmed.ncbi.nlm.nih.gov/38400805/&sa=D&source=editors&ust=1771587958840209&usg=AOvVaw3l0wyFJSCdmF3OOPN952nK), [Explore ASL QC](https://www.google.com/url?q=https://exploreasl.github.io/Documentation/1.12.0_beta/Tutorials-QC/&sa=D&source=editors&ust=1771587958840433&usg=AOvVaw2v5jIBgumQD7hPWKzmOQlL), [AURA ASL](https://www.google.com/url?q=https://redcap1.ugent.be/surveys/?s%3DHYRAL4AETKLHPKYY&sa=D&source=editors&ust=1771587958840618&usg=AOvVaw3DVgyA30VvvQOIZwknonNq)\n\nDifficulty: Moderate\n\nCategory: Advanced\n\nProject description: This project aims to develop a Quality Control (QC) Toolbox for Arterial Spin Labeling (ASL) MRI data. The toolbox will automatically compare current QC-derived cerebral blood flow (CBF) metrics against reference values to detect corrupted or low-quality ASL scans and optimize classification thresholds across different populations. The tool is intended to support data curation for large retrospective and multicenter clinical studies, enabling standardized, reproducible QC across datasets.\n\nExpected outcomes:\n\n- Develop QC-Toolbox with the following functionalities:\n\n- QEI\n- Motion tracking\n- Control-label pattern\n- M0 checking\n- SNR threshold\n- Histogram analysis, spatial CoV, RMS difference\n- Tissue mask quality assessment\n- Others\n\n- Establish thresholds to aid in curating data for retrospective clinical trials.\n\n- Test toolbox with AURA ASL dataset\n- Establish data-driven QC thresholds\n- Provide automated flagging of poor-quality ASL scans\n- Facilitate standardized data curation for retrospective clinical trials\n\nRequirements:\n\n- Python proficiency, GitHub\n\nOptional:\n\n- Image processing, MRI physics, perfusion imaging, ASL\n\nProposed mentors: Zhiliang Wei, Maria Mora\n\nLanguages/skills: Python, GitHub\n\nEstimated project length: 350 hours\n\nLinks: [PyASL](https://www.google.com/url?q=https://pyasl-doc.readthedocs.io/&sa=D&source=editors&ust=1771587958844605&usg=AOvVaw2XPBFgr_VTz-la2RywrGp1), [PyASL ISMRM 2025 abstract](https://www.google.com/url?q=https://archive.ismrm.org/2025/3692.html&sa=D&source=editors&ust=1771587958845022&usg=AOvVaw1x1Ne4XY21RIdn9p5TZ7wv), [ISMRM 2022 abstract - OSIPI TF 2.2 abstract](https://www.google.com/url?q=https://cds.ismrm.org/protected/22MProceedings/PDFfiles/0914.html&sa=D&source=editors&ust=1771587958845991&usg=AOvVaw3-kXJMnu_cstlx8Q8-00ss), [OSIPI TF 2.2](https://www.google.com/url?q=https://osipi.ismrm.org/task-forces/task-force-2-2/&sa=D&source=editors&ust=1771587958846346&usg=AOvVaw0hBs3R-ShxG4a53NIOm6Ry)\n\nDifficulty: Moderate\n\nCategory: Intermediate\n\nProject description: In previous roadmaps, we collected code to create PyASL, a Python library to preprocess ASL data (both preclinical and human brain data). PyASL not only enables users to compare different preprocessing pipelines, but its modular structure also allows users to mix and match functionalities from different established pipelines to best suit their needs. To facilitate its usage among non-experts, we aim to develop a GUI for this library and expand its functionalities.\n\nExpected outcomes:\n\n- To develop a GUI and batch-wise processing mode for PyASL to improve ease of use.\n- Add features to preclinical PyASL:\n\n- Co-registration\n- Normalization\n\nRequirements:\n\n- Python proficiency, GitHub\n\nOptional:\n\n- Image processing, MRI physics, perfusion imaging, ASL\n\nProposed mentors: Luis Torres\n\nLanguages/skills: Python, GitHub\n\nEstimated project length: 350 hours\n\nLinks:\n\nDifficulty: Moderate\n\nCategory: Advanced\n\nProject description: In previous road maps, modular code has been developed to process different perfusion MRI modalities. The overarching aim is to combine these modules into a single harmonised Python package. The purpose of this project is to design and build the architecture of that package in a way that can be easily extended and built upon as the field advances.\n\nExpected outcomes:\n\n- To develop the software architecture and skeleton code that defines the main functionality of OSIPY, including the 3 main perfusion modalities of ASL, DCE/DSC, and IVIM.\n\nRequirements:\n\n- Python proficiency, git, code design\n\nProposed mentors: Patricia Clements, Sudipto Dolui\n\nLanguages/skills: Python, GitHub\n\nEstimated project length: 350 hours\n\nLinks: [AURA Survey ](https://www.google.com/url?q=https://redcap1.ugent.be/surveys/?s%3DHYRAL4AETKLHPKYY&sa=D&source=editors&ust=1771587958852841&usg=AOvVaw23YfwIjK9u8hm49-xQCOPa)\n\nDifficulty: Moderate\n\nCategory: Intermediate\n\nProject description: For a year, OSIPI has been working on a user repository for perfusion artifacts, named AURA. This is mainly aimed to become an online dictionary to: a) create some more consensus on perfusion artifacts, b) better understand these artifacts, and c) aid researchers and clinicians in recognising perfusion artifacts. The goal of this project is to create a website or platform that allows users to consult dictionaries for ASL, DCE, DSC, and IVIM (initially for ASL, with the possibility of future expansion) and to upload perfusion image artifacts within AURA’s Framework.\n\nExpected outcomes:\n\n- To develop a platform that allows the creation of an artifact repository under AURA’s framework\n- Integrate Quality CheckToolbox V1.0\n\nRequirements:\n\n- Python proficiency, GitHub, Website Development\n\nOptional:\n\n- Image processing, MRI physics, perfusion imaging, ASL"
  },
  {
    "name": "The Linux Foundation",
    "slug": "the-linux-foundation",
    "tagline": "Non-profit consortium fostering growth of Linux",
    "description": "The Linux Foundation is a non-profit consortium dedicated to fostering the growth of Linux. Founded in 2007 as a merger of the former Free Standards Group (FSG) and the former Open Source Developer Lab (OSDL), the LF sponsors the work of Linux creator Linus Torvalds and is supported by leading Linux and open source companies and developers from around the world. The Linux Foundation promotes, protects and standardizes Linux by providing unified resources and services needed for open source to successfully compete with closed platforms. For more see our [About page](https://www.linuxfoundation.org/about/). All software produced by us is free software published under OSI-approved licenses. See project ideas page for the license used by each project.",
    "ideas_url": "https://github.com/LinuxFoundationGSoC/ProjectIdeas/wiki/Google-Summer-of-Code-2026",
    "website_url": "http://www.linuxfoundation.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "linux",
      "cups",
      "ai",
      "fuzz-testing"
    ],
    "topic_tags": [
      "kernel",
      "automotive",
      "printing",
      "iio",
      "zephyr"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/the-linux-foundation",
    "ideas_content": "# Google Summer of Code 2026\n\nThis is our list of project ideas for the [Google Summer of Code](https://summerofcode.withgoogle.com/) program in [2026](https://opensource.googleblog.com/2025/12/shape-future-with-google-summer-of-code.html).\n\n**Dear contributors**, if you want to apply for doing a Google Summer of Code project with us you can choose a project from our workgroup's lists but you can also present your own idea fitting to any of the workgroups below. Please note that you have to choose \"The Linux Foundation\" as your mentoring organization, independent of the workgroup where you want to do your project.\n\nThe organizers of the GSoC are especially welcoming projects about **security** and about **Artificial Intelligence/Machine Learning (AI/ML)**. They will give special support to these. We will also mark appropriate project ideas in the project idea lists. Also consider this if you come up with your own idea or if you are a mentor adding project ideas to our lists.\n\n## Dates\n\n  * *February 19, 2026* - The accepted mentoring organizations will get announced\n  * *March 16, 2026* - Applications open for contributors\n  * *March 31, 2026* - Deadline for contributors to apply\n\nFull [timeline](https://developers.google.com/open-source/gsoc/timeline)\n\n## Notes to take for contributors\n\n**Note:** Many of the links come from Google Summer of Code programs of the past. Therefore if you read the word \"student\", consider this as \"contributor\". No proof of enrollment at college or university is required (at least for those who enter as free-software newcomer).\n\n  * Read the [GSoC Manual](https://google.github.io/gsocguides/student/), the [timeline](https://developers.google.com/open-source/gsoc/timeline), and [GSoC FAQs](https://developers.google.com/open-source/gsoc/faq)\n  * On your application be sure to mention which of the listed Linux Foundation workgroups and, if applicable which of their listed project ideas you are applying for. If you are suggesting your own idea be sure to clarify that.\n  * Follow the scheme of our [[contributor application template|contributor-application-template]].\n  * Follow the [DOs and DON'Ts](http://google-opensource.blogspot.com/2011/03/dos-and-donts-of-google-summer-of-code.html?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+GoogleOpenSourceBlog+%28Google+Open+Source+Blog%29) for contributors.\n  * On the front page click the field to apply as a contributor and then choose \"The Linux Foundation\" as your mentoring organization from the long list. To find it, use the filter field under \"Name\" or use the drop-down menu at the bottom to display the full list (there are more than 150 organizations).\n\n## Contact us!\n\nBefore applying, please have a look at the page(s) of the desired workgroup(s) linked below and do not hesitate to ask questions using the contact info (e-mail, IRC) of the workgroup in which you want to do your project. Often they want to get involved with you before you apply, starting to integrate you into their community, so introduce yourself to them as soon as possible. For general questions about participating as GSoC contributor in projects of the Linux Foundation, please contact the organization administrotors (see below).\n\n**Mastodon/Fediverse: [#LinuxFoundation](https://ubuntu.social/tags/linuxfoundation|#LinuxFoundation)**\n\n## Linux Foundation GSoC Project groups\n\nThe Linux Foundation sponsors development in different areas. Each area has a set number of GSoC projects available for 2025 as suggested projects which you can apply for and they are also open for your project suggestion.\n\n  * [[OpenPrinting|GSoC-2026-OpenPrinting]]\n  * [[Automotive Grade Linux (AGL)|GSoC-2026-AGL]]\n  * [[IIO driver|GSoC-2026-IIO-Driver]]\n  * [[Sound Open Firmware (SOF)|GSoC-2026-Sound-Open-Firmware]]\n  * [[Device tree bindings conversions|GSoC-2026-Device-Tree-Bindings]]\n  * [[Zephyr|GSoC-2026-Zephyr]]\n  * [[SPDx|GSoC-2026-SPDx]]\n\n## Our source code repositories\n\nOur projects are free software and therefore open-source. So all the source code is publicly available. Usually it is managed by version control systems, in most cases GIT. Each workgroup manages the code by itself, most of them on [GitHub](https://github.com/), but also at other hosting services or the workgroup's own servers, for example https://github.com/linuxfoundation, https://github.com/OpenPrinting, https://git.kernel.org/, http://git.automotivelinux.org/, ...\n\nSee the workgroup's pages linked above for their web presence and code locations.\n\n## Organization Administrators\n\nThe participation of the Linux Foundation in the Google Summer of Code is organized by Till Kamppeter (till at linux dot com) and Aveek Basu (basu dot aveek at gmail dot com)."
  },
  {
    "name": "GRAME",
    "slug": "grame",
    "tagline": "Domain specific language for audio",
    "description": "Faust (Functional Audio Stream) is a functional programming language for sound synthesis and audio processing with a strong focus on the design of synthesizers, musical instruments, audio effects, etc. Faust targets high-performance signal processing applications and audio plug-ins for a variety of platforms and standards.",
    "ideas_url": "https://github.com/grame-cncm/faustideas/blob/master/GSOC.md",
    "website_url": "https://faust.grame.fr",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "javascript",
      "c++",
      "rust",
      "typescript"
    ],
    "topic_tags": [
      "audio",
      "compiler",
      "digital signal processing",
      "function programming language"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/grame",
    "ideas_content": "# Google Summer of Code possible projects\n\nThis page contains a list of possible GSoC projects, with a preliminary section explaining the prerequisites to follow before working on a real project.\n\n## Discovering the Faust ecosystem\n\nThe application process for GSoC consists of the next steps:\n\n- become acquainted with the [Faust language and ecosystem](https://faust.grame.fr). In particular looking at the [Powered By Faust](https://faust.grame.fr/community/powered-by-faust/) page can help understanding the variety of projects that have been developed using Faust. Read also the [technical documentation](https://faustdoc.grame.fr) and [papers on Faust](https://hal.science/search/index?q=GRAME+Faust). \n- for several of the proposed projects, we expect candidates to have a solid understanding of audio programming concepts such as DSP (Digital Signal Processing) basics, real-time audio processing, synthesis techniques, and audio plugin development. \n- join the [Faust discord server](https://discord.gg/RzuFg6B8zA) and #gsoc channel.\n- read the [GSoC guide for students](https://developers.google.com/open-source/gsoc/resources/guide). Develop your understanding of the various stages of the program. Read this [blog post](https://sayak.dev/gsoc-faqs/).\n- check the [GSoC contribution timeline](https://developers.google.com/open-source/gsoc/timeline).\n- read our [Contributing guidelines](https://github.com/grame-cncm/faust/wiki/Contributing).\n- get invite to chosen project in Faust github organization.\n- submit the application/proposal including all requirements at the Google Summer of Code Site.\n\n## Information Candidates Should Supply\n\nThe application process has several steps. First, verify that you meet the GSoC contributor [eligibility requirements](https://summerofcode.withgoogle.com/get-started), i.e. you are at least 18 years old, eligible to work in your country of residence, etc. As of 2023, GSoC eligibility has been expanded to include \"open source beginners\" in addition to students. The next step is to contact the mentor(s) of the project you are interested in; the best place to do so is in the `#gsoc` channel of the [Faust Discord server](https://discord.gg/vzh7CggBtj), where you can ask questions related to the project you're interested in working on, and submit draft proposals for feedback. Your goal is to convince prospective mentors that you are the right person to get the job done; you can do this by sharing your previous work, demonstrating relevant experience/intuition, asking pertinent questions, etc. Finally, submit a project proposal via your GSoC contributor dashboard. Your submission must include a PDF that should contain the following information:\n\n* Project:\n  * A detailed description of the project that you wish to tackle. Either select a topic from the list [below](#possible-projects), or, if you wish to work on an idea of your own, **we are pretty open as long as this serves the goal of consolidating Faust and its ecosystem as a whole**.\n  * A proposal of a technical solution with your envisioned methodology. The more detailed the better.\n  * A realistic schedule with objectives (one every two weeks for example) and deadlines. Focus on mid-term objectives as well as on the final evaluation.\n\n* Personal data:\n  * First name, last name, affiliation and geographical location.\n  * A brief list of the main studies and programming courses attended, with ranking.\n  * List of the most important software projects contributed and success.\n  * Which are your best skills in terms of programming ?\n  * In general what is your taste in terms of programming? language, methodology, team work, etc.\n  * Is there anything that prevents you from working full time on the project during the program period?\n  * How do you see your involvement after the program ends? Do you see yourself pushing the project further, or do you see yourself contributing to other Faust and its ecosystem projects?\n  * Are you more interested in the Faust language and its ecosystem, or do you feel more like a hacker?\n  * What are your long-term wishes in terms of job?\n  \n  \n## Use of LLM (ChatGPT, Mistral AI, etc.)\n\nUsage of LLM must be done responsibly. Improper use can undermine trust—and trust is the foundation of any successful collaboration. \n\nWe agree with this section of [Rust GSoC site](https://github.com/rust-lang/google-summer-of-code/tree/main): **We would appreciate if you used your own words when writing GSoC project proposals. It is fine to use LLMs/AI for spellcheck, language correction or translation, but do not rely on AI to write the proposal for you. We will ignore proposals that look like they were generated by AI. Please don't submit AI-generated proposals! They won't be accepted, and will just create additional work for us. We're interested in seeing your work and your thinking, since you are applying to do the project — not the AI!**.\n\nOr read the University of Alaska Anchorage [Acceptable and Ethical AI Use Policy](https://github.com/uaanchorage/GSoC/blob/main/Acceptable-and-Ethical-AI-Use-Policy.md). \n\n## Possible projects:\n\nhttps://github.com/grame-cncm/faustideas/blob/master/GSOC.md#integrated-faust-language-server-and-formatting-extension-for-vs-code-taken-in-2025\n\n- [Web-Based UI System for Faust (Inspired by Cmajor Patch GUIs)](#web-based-ui-system-for-faust-inspired-by-cmajor-patch-guis)\n- [Integration in the Heavy Compiler Collection](#integration-in-the-heavy-compiler-collection)\n- [Extending the Faust DSP Testbench](#extending-the-faust-dsp-testbench)\n- [Integration in Surge](#integration-in-surge)\n- [Integration in Bespoke](#integration-in-bespoke)\n- [Integration in BELA](#integration-in-bela)\n- [Integration in openFramework](#integration-in-openframework)\n- [PluginGuiMagic architecture ](#pluginguimagic-architecture)\n- [Faust programming by examples](#faust-programming-by-examples)\n- [Languages built on top of the signal API](#languages-built-on-top-of-the-signal-api)\n- [Developing modular synthesis using widget modulation](#developing-modular-synthesis-using-widget-modulation)\n\nSome [more ideas](#faust-ideas) could possibly be turned as GSoC projects.\n\n---\n### Web-Based UI System for Faust (Inspired by Cmajor Patch GUIs)\n\n**Mentor:** To be confirmed  \n\n**Expected size of project:** 175 hours\n\n**Description:**  \nFaust provides several automatic UI generation backends, but it currently lacks a **modern, fully web-based patch UI system** comparable to the [Cmajor](https://cmajor.dev) patch GUI model. This project proposes the design and implementation of a **standardized Web UI layer for Faust**, enabling DSP modules to expose rich, interactive graphical interfaces directly in the browser.\n\nInspired by the [Cmajor patch format](https://cmajor.dev/docs/PatchFormat#patch-guis), the project will define a **Faust Web UI specification**, along with a **reference implementation**. The system will rely on standard Web technologies (HTML, CSS, JavaScript) and provide real-time parameter control via WebAudio.\n\n- **Define a Faust Web UI specification:**  \n  Based on [Faust JSON format](https://faustdoc.grame.fr/manual/architectures/#dsp-json-description) and inspired by Cmajor’s patch GUI format.\n\n- **Implement the Web UI backend:**  \n  Generate parameter bindings and Web UI templates from Faust DSP code.\n\n- **Real-time DSP/UI communication:**  \n  Using WebAudio AudioWorklet and WebAssembly.\n\n- **Integration and demos:**  \n  Compatibility with Faust PWAs and online demo instruments/effects.\n\n**Expected outcomes:**\n\n- A new Faust Web UI architecture.\n- A standardized parameter binding and messaging format.\n- A set of documented Web-based Faust demo applications.\n\n**Skills required:** JavaScript/TypeScript, HTML/CSS, WebAudio API, Faust.\n\n**An easy, medium or hard difficulty rating of each project:** medium\n\n---\n### Integrated Faust Language Server and Formatting Extension for VS Code [Taken in 2025]\n\n**Mentor:** [Stéphane Letz](mailto:letz@grame.fr) \n\n**Expected size of project:** 175 hours\n\n**Description:** A [language server](https://en.wikipedia.org/wiki/Language_Server_Protocol), sometimes called an LSP, is a code analysis tool that allows programming environments to get information about projects. This lets them display information like code completions, inline errors, locations of function definitions, reference official documentation, and more. Many programming languages have their own language server (see https://langserver.org/ for a list), but Faust does not. If there was a Faust language server, it would make it easier to write Faust code using any IDE that supports LSP. This would make it easier for beginners to get started writing Faust using programming tools they're already familiar with, and it would make it easier for experts to navigate large codebases. The [tree-sitter-faust](https://github.com/khiner/tree-sitter-faust) project could be helpful in doing any parsing required for a language server.\n\nWe propose to create a Visual Studio Code extension that integrates the Faust Language Server with a dedicated Faust code formatter. Leveraging the `vscode-languageclient` package, the extension will launch the Faust Language Server to provide robust features (code completion, diagnostics, navigation) while also offering context-aware formatting tailored to Faust DSP syntax.\n\n- **Integrate the Faust Language Server:**  \n  Use `vscode-languageclient` to launch and manage the server, ensuring features like auto-completion and error checking are available for `.dsp` files.\n\n- **Develop a Faust Code Formatter:**  \n  Implement a formatter that understands Faust’s constructs, providing commands and auto-format-on-save functionality to improve readability and enforce best practices.\n\n**Expected outcomes:**\n\n- A fully functional VS Code extension that combines the Faust Language Server with a dedicated code formatter.\n- Enhanced developer productivity through improved code intelligence and formatting.\n- Comprehensive documentation and user-friendly configuration options, making it easier for the Faust community to adopt best practices.\n\n**Skills required:** Faust programming, TypeScript and Web programming.\n\n**An easy, medium or hard difficulty rating of each project:** medium\n\n---\n### Extending the Faust DSP Testbench\n\n**Mentor:** [Stéphane Letz](mailto:letz@grame.fr) \n\n**Expected size of project:** 175 hours\n\n**Description:** The [Faust DSP Testbench](https://github.com/grame-cncm/Faust-DSP-Testbench), a fork of the DSP-Testbench project, is designed to help developers using the JUCE framework to analyse their Faust DSP. This project will focus on extending the Testbench’s functionality to make it a more comprehensive and user-friendly tool for developers and researchers working with Faust.\n\nThe proposed extensions aim to:\n- Extend and improve the visualisation tools.\n- Enable better visualization of DSP performance and behavior.\n\n**Expected outcomes:**\n- A robust, user-friendly Faust DSP Testbench with automated testing, benchmarking, and visualization capabilities.\n- Comprehensive documentation and tutorials for using the Testbench effectively.\n\n**Skills required:** Faust programming, DSP theory, C++, knowledge of the [JUCE framework](https://juce.com).\n\n**An easy, medium or hard difficulty rating of each project:** medium\n\n---\n### Backend for MOJO [Will be taken in 2026]\n\n**Mentors:** [Stéphane Letz](mailto:letz@grame.fr) and [Yann Orlarey](mailto:orlarey@gmail.com)  \n\n**Expected size of project:** 175 hours\n\n[Mojo](https://www.modular.com/max/mojo) is a new programming language that bridges the gap between research and production by combining the best of Python syntax with systems programming and metaprogramming. Mojo combines the usability of Python with the performance of C, unlocking unparalleled programmability of AI hardware and extensibility of AI models. With Mojo, you can write portable code that’s faster than C and seamlessly inter-op with the Python ecosystem. Having [autodifferentiation](https://en.wikipedia.org/wiki/Automatic_differentiation) inside the language is not yet ready but is regularly discussed on [Mojo Discord](https://docs.modular.com/mojo/community). \n\nThe primary objective of the project is to [develop a backend](https://github.com/grame-cncm/faust/tree/master-dev/compiler/generator/template) for this new language, add architecture files, and measure how the generated code behaves doing various benchmarks. \n\n**Expected outcomes:**\n\n- a new backend to generate MOJO code \n- development of MOJO architecture files to create benchmarks and measure the speed of the generated code \n\n**Skills required/preferred:** C++ and basic Python programming, Faust programming\n\n**An easy, medium or hard difficulty rating of each project:** medium\n\n---\n### Differentiable DSP in Faust [Taken in 2024]\n\n**Mentors:** [Thomas Rushton](mailto:thomas.rushton@inria.fr), [David Braun](mailto:db1224@princeton.edu), [Stéphane Letz](mailto:letz@grame.fr), and [Yann Orlarey](mailto:orlarey@gmail.com)  \n\n**Expected size of project:** 175 hours\n\nDifferentiable programming is a technique whereby a program can be differentiated with respect to its inputs, permitting the computation of the sensitivity of the program's outputs to changes in its inputs.\n\nPartial derivatives of a program can be found analytically via [automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation) and, coupled with an appropriate loss function, used to perform gradient descent.\nDifferentiable programming has consequently become a key tool in solving machine learning problems.\n\nDifferentiable digital signal processing ([DDSP](https://intro2ddsp.github.io/background/what-is-ddsp.html)) is the specific application of differentiable programming to audio tasks. DDSP has emerged as a key component in machine learning approaches to problems such as source separation, timbre transfer, parameter estimation, etc. DDSP is reliant on a programming language with a supporting framework for automatic differentiation. In Python, this is provided by libraries such as TensorFlow and JAX; other languages, [Swift](https://github.com/apple/swift/blob/main/docs/DifferentiableProgramming.md) for example, may feature native support.\n\nWe would like to explore the possibility of implementing automatic differentiation in Faust; the successful implementation of a Faust library for differentiable programming would permit the application of Faust to DDSP \nproblems. Exploratory [work](https://github.com/hatchjaw/faust-ddsp) on such a library has begun; one aim is to turn this into a comprehensive package of support for differentiable Faust programs.\n\nRelated work, concerned with adding automatic differentiation capabilities to the Faust compiler, was conducted for a [previous edition](https://github.com/grame-cncm/faust/pull/939) of GSoC. Also consult David Braun's [DawDreamer](https://github.com/DBraun/DawDreamer) project, which uses Faust's [JAX](https://jax.readthedocs.io/en/latest/notebooks/quickstart.html) backend.\n\n**Expected outcomes:**\n\n- creation of an automatic differentiation library describing derivatives for \n  all of Faust's operators, helper functions for generalising the creation of \n  differentiable Faust programs, a variety of time- and frequency-domain loss \n  functions, etc.;\n- development of a series of practical applications of the new library;\n- a new autodiff (or machine learning) architecture file, to support the \n  training of machine learning models and the generation of parameter weights;\n- a means to use the generated weights for real-time inference.\n\n**Skills required/preferred:** Faust programming, machine learning\n\n**An easy, medium or hard difficulty rating of each project:** medium\n\n---\n\n### Support for CLAP format [Taken in 2025]\n\n**Mentor:** [Stéphane Letz](mailto:letz@grame.fr)\n\n**Expected size of project:** 175 hours\n\n[CLAP](https://github.com/free-audio/clap#learn-about-clap) is an Audio Plugin format (as pure C api), liberally licensed (MIT), entirely developers in the open (GitHub), with support from commercial developers ([u-he](https://u-he.com), [Bitwig](https://www.bitwig.com/de/), more). \nCLAP has many design goals, but a primary one was to allow developers to build their base plugin layer using a properly open clean C standard, to replace the VST2 API which most folks base their plugin model on, and then project into other systems. An extensive discussion can be [accessed here](https://www.kvraudio.com/forum/viewtopic.php?t=574861).\n\nThe project is to develop: \n- a `faust2clap` tool (see [faust2xx Tools](https://faustdoc.grame.fr/manual/tools/) and [Developing a faust2xx Script](https://faustdoc.grame.fr/manual/architectures/#developing-a-faust2xx-script)) to *statically* compile Faust DSP code in a CLAP plugin.\n- and a CLAP pluging embedding the [libfaust](https://faustdoc.grame.fr/manual/embedding/) based dynamic compilation chain, so that DSP programs can be *written and recompiled* on the fly\n- new [C++ architecture files](https://faustdoc.grame.fr/manual/architectures/) will have to be developed.\n\nLook at additional [CLAP projects](https://github.com/free-audio).\n\n**Expected outcomes:** The result will be a `faust2clap` script to compile a DSP program in a CLAP plugin, and a CLAP pluging embedding libfaust.\n\n**Skills required/preferred:** C++ programming, audio and Faust programming.\n\n**An easy, medium or hard difficulty rating of each project:** medium\n\n---\n\n### Integration in Surge\n\n**Mentor:** [Stéphane Letz](mailto:letz@grame.fr)\n\n**Expected size of project:** 175 hours\n\nThe Surge Synth Team is a group of musicians, developers, testers, documenters, and general volunteer open source enthusiasts who randomly assembled to work on the [Surge Synthesizer](https://surge-synth-team.org). Use the [Discord channel](https://discord.gg/aFQDdMV) to connect to their community.\n\nThe project is to develop a `faust2surge` tool (see [faust2xx Tools](https://faustdoc.grame.fr/manual/tools/) and [Developing a faust2xx Script](https://faustdoc.grame.fr/manual/architectures/#developing-a-faust2xx-script)) to *statically* compile Faust DSP code in a Surge plugin. This is currently [discussed here](https://github.com/surge-synthesizer/surge/issues/3669#issuecomment-967062337). You'll probably have to develop or adapt [C++ architecture files](https://faustdoc.grame.fr/manual/architectures/).\n\n**Expected outcomes:** The result will be a `faust2surge` script to compile a DSP program in a Surge plugin.\n\n**Skills required/preferred:** C++ programming, audio and Faust programming, knowledge of the [JUCE framework](https://juce.com).\n\n**An easy, medium or hard difficulty rating of each project:** medium\n\n---\n\n### Integration in Bespoke\n\n**Mentor:** [Stéphane Letz](mailto:letz@grame.fr)\n\n**Expected size of project:** 175 hours\n\n**More detailed description of the project:** [Bespoke](https://www.bespokesynth.com) is a modular DAW for Mac, Windows, and Linux. It contains a bunch of modules, which you can connect together to create sounds. Use the [Discord channel](https://discord.gg/YdTMkvvpZZ) to connect to their community. The integration could follow the two steps:\n\n- develop a `faust2bespoke` tool (see [faust2xx Tools](https://faustdoc.grame.fr/manual/tools/) and [Developing a faust2xx Script](https://faustdoc.grame.fr/manual/architectures/#developing-a-faust2xx-script)) to *statically* compile Faust DSP code in Bespoke modules\n\n- a complementary approach is to directly embed the Faust compiler ([using libfaust + LLVM JIT](https://faustdoc.grame.fr/manual/embedding/)), allowing DSP programs to be edited, dynamically compiled, and run in the platform\n\nThis is currently [discussed here](https://github.com/BespokeSynth/BespokeSynth/issues/317). You'll probably have to develop or adapt [C++ architecture files](https://faustdoc.grame.fr/manual/architectures/). A recent [Faust integration in TouchDesigner](https://github.com/DBraun/TD-Faust/) can be studied as an example.\n\n**Expected outcomes:** The result will be:\n\n- a`faust2bespoke` tool to compile Faust DSP code in Bespoke modules\n\n- a Bespoke plugin embedding the libfaust + LLVM library, and allowing DSP programs to be edited, dynamically compiled, and run in the platform\n\n**Skills required/preferred:** C++ programming, graphical programming, audio and Faust programming.\n\n**An easy, medium or hard difficulty rating of each project:** medium to hard\n\nReferences: \n\n- [Bespoke Anywhere](https://nime.pubpub.org/pub/8jaqbl7m/release/1?readingCollection=bd12ca41)\n---\n\n### Integration in Godot [Taken as an internship in 2025]\n\n**Mentor:** [Stéphane Letz](mailto:letz@grame.fr)\n\n**Expected size of project:** 175 hours\n\n**More detailed description of the project:** [Godot Engine](https://godotengine.org) is a feature-packed, cross-platform game engine to create 2D and 3D games from a unified interface. It provides a comprehensive set of common tools, so that users can focus on making games without having to reinvent the wheel. The integration could follow the two steps:\n\n- develop a `faust2godot` tool (see [faust2xx Tools](https://faustdoc.grame.fr/manual/tools/) and [Developing a faust2xx Script](https://faustdoc.grame.fr/manual/architectures/#developing-a-faust2xx-script)) to *statically* compile Faust DSP code in Godot modules\n\n- a complementatry approach is to directly embed the Faust compiler ([using libfaust + LLVM JIT](https://faustdoc.grame.fr/manual/embedding/)), allowing DSP programs to be edited, dynamically compiled, and run in the platform\n\nYou'll probably have to develop or adapt [C++ architecture files](https://faustdoc.grame.fr/manual/architectures/). A recent [Faust integration in TouchDesigner](https://github.com/DBraun/TD-Faust/) can be studied as an example.\n\n**Expected outcomes:** The result will be:\n\n- a`faust2godot` tool to compile Faust DSP code in Godot modules\n\n- a Godot plugin embedding the libfaust + LLVM library, and allowing DSP programs to be edited, dynamically compiled, and run in the platform\n\n**Skills required/preferred:** C++ programming, audio and Faust programming.\n\n**An easy, medium or hard difficulty rating of each project:** medium to hard\n\n---\n\n### Integration in Cables.gl [Taken in 2024]\n\n**Mentor:** [Stéphane Letz](mailto:letz@grame.fr)\n\n**Expected size of project:** 175 hours\n\n**More detailed description of the project:** [Cables.gl](https://cables.gl) is a tool for creating beautiful interactive content. With an easy to navigate interface and real time visuals, it allows for rapid prototyping and fast adjustments. You are provided with a set of operators, such as mathematical functions, shapes, materials and post processing effects. Connect these to each other with virtual cables to create the experience you have in mind. Easily export your piece of work at any time. Embed it into your website or use it for any kind of creative installation. Use the [Discord channel](https://discord.com/invite/AGTarWv) to connect to their community.\n\nThe project would be to integrate the [Faust Web Audio Library](https://github.com/grame-cncm/faust2webaudio) to dynamically compile and run Faust DSP programs in Cables.gl. \n\n**Expected outcomes:** The result will be a Cable.gl plugin embedding the libfaust WASM library, and allowing DSP programs to be edited, dynamically compiled, and controlled with an adapted Graphical User Interface. \n\n**Skills required/preferred:** TypeScript/JavaScript programming, Web technologies, audio and Faust programming.\n\n**An easy, medium or hard difficulty rating of each project:** medium\n\n---\n\n### PluginGuiMagic architecture \n\n**Mentor:** [Stéphane Letz](mailto:letz@grame.fr) and [Daniel Walz](daniel@foleysfinest.com)\n\n**Expected size of project:** 175 hours\n\n**More detailed description of the project:** [PluginGuiMagic](https://foleysfinest.com/developer/pluginguimagic/) is a WYSWYG runtime design system for [JUCE](https://juce.com) plugins. The foleys_plugin_magic module allows to have a generated UI, that can be edited at runtime using advanced layout and styling options. It also adds visualisers to display signals, levels and spectral with no extra coding involved. The project is to develop new C++ [architecture files](https://faustdoc.grame.fr/manual/architectures/) to ease the use of PGM in the [faust2juce](https://github.com/grame-cncm/faust/tree/master-dev/architecture/juce) tool.\nAnother [faust_juce_pgm_skeleton](https://github.com/unicornsasfuel/faust_juce_pgm_skeleton) project to look at.\n\n**Expected outcomes:** The result will be set of C++ architecture files and an improved `faust2juce` tool.\n\n**Skills required/preferred:** C++ programming, knowledge of the JUCE framework, knowledge of the foleys_plugin_magic module, audio and Faust programming.\n\n**An easy, medium or hard difficulty rating of each project:** medium\n\n---\n\n### VST plugin embedding the dynamic compiler [Taken in 2024]\n\n**Mentor:** [Stéphane Letz](mailto:letz@grame.fr)\n\n**Expected size of project:** 175 hours\n\n**More detailed description of the project:** A VST plugin using the [libfaust + LLVM JIT](https://faustdoc.grame.fr/manual/embedding/) to do DSP live coding in any VST aware host. FX and monophonic or polyphonic synthesizers can be written. The source code can be edited and recompiled on the fly. The GUI has to be automatically created. The [pMix](https://github.com/olilarkin/pMix2) and [Amati](https://github.com/glocq/Amati) projects can be used as starting points. An integration with the [PluginGuiMagic](https://foleysfinest.com/developer/pluginguimagic/) architecture could possibly be added. \n\n**Expected outcomes:** The result will be a VST plugin developed with the [JUCE framework](https://juce.com) .\n\n**Skills required/preferred:** C++ programming, audio and Faust programming, knowledge of the JUCE framework.\n\n**An easy, medium or hard difficulty rating of each project:** medium\n\n---\n\n### Integration in Audiokinetic Wwise [Taken in 2025]\n\n**Mentor:** [Stéphane Letz](mailto:letz@grame.fr)\n\n**Expected size of project:** 350 hours\n\n**More detailed description of the project:** [Audiokinetic](https://www.audiokinetic.com/en/) is the leading global provider of the most advanced and scalable cross platform interactive audio solutions. A trusted technology partner to the world’s largest developers, OEMs, and audio production companies, its flagship product Wwise is the gold standard interactive audio engine on the market. \n    [Wwise](https://www.audiokinetic.com/en/products/wwise) features a complete suite of design and development tools, making it easy to prototype and bring to life your creative vision for audio, no matter the scale of your project. The integration could follow the two steps:\n    \n- develop a `faust2wwise` tool (see [faust2xx Tools](https://faustdoc.grame.fr/manual/tools/) and [Developing a faust2xx Script](https://faustdoc.grame.fr/manual/architectures/#developing-a-faust2xx-script)) to *statically* compile Faust DSP code in Wwise modules\n\n- a complementatry approach is to directly embed the Faust compiler ([using libfaust + LLVM JIT](https://faustdoc.grame.fr/manual/embedding/)), allowing DSP programs to be edited, dynamically compiled, and run in the platform\n\nLook at the [faust2wwise](https://github.com/grame-cncm/faust2wwise) preliminary work. You'll probably have to develop or adapt [C++ architecture files](https://faustdoc.grame.fr/manual/architectures/).\n\n**Expected outcomes:** The result will be: \n\n- a new `faust2wwise` tool with the associated C++ architecture files to compile a DSP project in a ready to use Wwise plugin\n\n- a plugin embedding the libfaust + LLVM JIT dynamic compiler technology to allow Faust DSP live-coding\n\n**Skills required/preferred:** C++ programming, audio and Faust programming, knowledge of the Audiokinetic Wwise architecture.\n\n**An easy, medium or hard difficulty rating of each project:** hard\n\n---\n\n### Integration in BELA\n\n**Mentor:** [Stéphane Letz](mailto:letz@grame.fr)\n\n**Expected size of project:** 175 hours\n\n**More detailed description of the project:** [BELA](https://bela.io) is a maker platform for creating beautiful interaction. Designed for artists, musicians, researchers and makers, Bela brings the power of ultra-low latency interactive audio and sensors to your digital projects. A Faust/BELA integration has already been done in a `faust2bela` tool and some preliminary work on the [dynamic compilation chain](https://faustdoc.grame.fr/manual/embedding/) have [been done](https://github.com/giuliomoro/bela-faust-jit).  \n\n**Expected outcomes:** The result will be: \n\n- an improved `faust2bela` tool\n\n- a fully integrated Faust/BELA IDE that would allow to design and experiment Faust code in the Web plaform (using the dynamic WebAssembly based compilation chain), then compile it in C++ and deploy it on the BELA board. Monophonic DSP and MIDI controllable polyphonic instruments should be supported. \n\n- a finished dynamic compilation chain integration.\n\n---\n\n### Integration in openFramework\n\n**Mentor:** [Stéphane Letz](mailto:letz@grame.fr)\n\n**Expected size of project:** 175 hours\n\n**More detailed description of the project:** [openFrameworks](https://openframeworks.cc/about/) is an open source C++ toolkit designed to assist the creative process by providing a simple and intuitive framework for experimentation. It allows to access a lot of additional extensions and libraries in the form of [addons](https://ofxaddons.com). The project is to explore how Faust can be integated in the framework as an [ofxFaust](https://forum.openframeworks.cc/t/developing-a-faust-addon) addon, either statically (using the C++ generated code from a DSP program), or possibly embedding the [libfaust](https://faustdoc.grame.fr/manual/embedding/) compiler. Adapted architecture files will have to be developed.   \n\n**Expected outcomes:** The result will be a new **ofxFaust** and openFrameworks demo examples explaining how to use it.\n\n---\n\n### Integration in the Heavy Compiler Collection\n\n**Mentor:** [Alexander Chalikiopoulos](mailto:alexander@puikheid.nl)\n\n**Expected size of project:** 175 hours\n\n**More detailed description of the project:** [HVCC](https://github.com/Wasted-Audio/hvcc/) is a python-based dataflow audio programming language compiler that generates C/C++ code and a variety of specific framework wrappers. It's main focus is in parsing [Pure Data](https://puredata.info/) DSP patch files, statically interprets them, and converts them to C/C++. The project is to explore how Faust can be integrated into the compiler toolchain. Likely starting from [pd-faustgen](https://github.com/CICM/pd-faustgen) external and then internally calling [faustdoctor](https://github.com/SpotlightKid/faustdoctor) to wrap the resulting C into separate header and implementation files. A crude proof of concept integration between faust generated code and a heavy DSP graph was done to explore the feasibility of this integration.\n\n**Expected outcomes:** The result will be: \n\n- extending hvcc compiler steps `pd2hv`, `hv2ir` and `ir2c`\n- jinja2 templates that create Heavy compatible C header and implementation files, based on Faust code\n- successfully create DSP prototypes using PD and Faust that can be compiled to C/C++ projects based on Heavy\n\n**Skills required/preferred:** Python, C, Pure Data, audio and Faust programming.\n\n**An easy, medium or hard difficulty rating of each project:** medium\n\n---\n\n### Packaging system for Faust libraries [Taken in 2024]\n\n**Mentors:** [Yann Orlarey](mailto:orlarey@gmail.fr) and [Stéphane Letz](mailto:letz@grame.fr)\n\n**Expected size of project:** 350 hours\n\n**More detailed description of the project:** The idea is to develop a packaging system to facilitate the integration of Faust libraries in a DSP project. The inspiration comes from the [Julia](https://www.julialang.org) language with the [JuliaHub](https://juliahub.com/) project and/or the [Rust](https://www.rust-lang.org/) language with the [Cargo](https://doc.rust-lang.org/cargo/) package manager. \n\n#### Requirements\n\n- load packages containing Faust sources, either in .dsp or in .lib format\n- be able to load sets of files (typically a library that is written as several .lib files)\n- isolate packages in different environments, to avoid name conflicts\n- notion of a centralized directory on GitHub, where contributions can be made in the form of Pull Requests. Publishing tool (with search by content) of this directory, general, like **fausthub** (inspired for example by Juliahub https://juliahub.com/lp/).\n- at each PR, test of the syntax of the code with GitHub actions\n- cache management: typically 1) the package is loaded the 1st time and kept in a cache, 2) then the compiler uses the version in the cache. Work on the question of new version management.\n- automatic generation of the documentation from the lib files (starting from the existing tools and possibly adapting them), automatic deployment\n- preservation semantic: we want to be able to keep a project as a DSP file with all its needed libraries with specific version numbers   \n\n#### Syntax proposal\n\n##### Simple version\n\n`package(\"foo\")` ⇒ syntactic sugar for `library(\"https://faustpackages.grame.fr, \"path/to/actual/library.lib\")`\n\n##### Version with constraint on version number\n\n`package(\"foo\", \"3.4\")` ⇒ syntactic sugar for `library(\"https://faustpackages.grame.fr, \"path/to/actual/3.4/library.lib\")`\n\n`package(\"foo\").bar`\n\nor else: \n\n`foo = package(\"foo\")` and `foo.bar` in the DSP code\n\n#### Tools to describe packages\n\t\n- look at the package format of Rust or Julia: .toml file, src folders, tests\n\n- look at the TOML format (https://toml.io/en/), used by Rust and Julia\n\n**Expected outcomes:** \n\n- a working insfrastructure with a server hosting the published packages\n\n- an extended Faust compiler able to access the server\n\n**Skills required/preferred:** C++ programming, server/client technology.\n\n**An easy, medium or hard difficulty rating of each project:** hard\n\n---\n\n### Faust programming by examples\n\n**Mentors:** [Yann Orlarey](mailto:orlarey@gmail.fr) and [Stéphane Letz](mailto:letz@grame.fr)\n\n**Expected size of project:** 350 hours\n\n**More detailed description of the project:** The objective is to develop a new approach to Faust programming, not textual or graphical, but based on DAW-like examples. This programming principle is analogue to the one described in the article [Real time Composition in Elody](https://hal.archives-ouvertes.fr/hal-02158910/document). This approach is based on the idea of manipulating and editing virtual \"audio files\" which represent the real time audio inputs and outputs. \n\nTo take a simple monophonic example, let's call these two virtual audio files `INPUT` and `OUTPUT`. Let's note `t:file` the fact of placing in the DAW a file `file`at time `t` in seconds and `t:file*0.75` the fact of placing in the DAW a file at time `t` but also controlling its sound level. So the DAW construction `{0:INPUT, 1:OUTPUT*0.75}` corresponds to a realtime echo whose Faust translation is `process = + ~ (@(ma.SR):*(0.75));`. \n\n**Expected outcomes:** The project consists in exploring this model and see how standard DAW editing actions can be translated in Faust DSP programs. A prototype coded in TypeScript, JavaScript or any other scripting languages will be developed.\n\n**Skills required/preferred:** C++ programming, possibly TypeScript + JavaScript or other scripting languages.\n\n**An easy, medium or hard difficulty rating of each project:** hard\n\n---\n\n### Languages built on top of the signal API\n\n**Mentors:** [Yann Orlarey](mailto:orlarey@gmail.fr) and [Stéphane Letz](mailto:letz@grame.fr)\n\n**Expected size of project:** 350 hours\n\n**More detailed description of the project:** The [signal API](https://faustdoc.grame.fr/tutorials/signal-api/) opens an intermediate access inside the Faust compilation chain. Generating complex expressions by directly using it can quickly become really tricky and unpracticable. So a language created on top of the signal API is usually needed. This is exactly what the Block Diagram Algebra is all about, and the entire Faust language itself.\n\nBut some other approaches can possibly be tested. The [Elementary audio language](https://www.elementary.audio) for instance is built over a [similar signal](https://docs.elementary.audio/guides/making_sound) language and uses JavaScript as the upper layer language to help create complex signal graphs programmatically. \n\n**Expected outcomes:** The project consits in exploring various approaches to build a language on top of the signal API. It could be a textual one (like JavaScript, Haskell or scripting languages...) or a purely graphical tool. \n\n**Skills required/preferred:** C++ programming, possibly TypeScript + JavaScript, Haskell or other functional languages.\n\n**An easy, medium or hard difficulty rating of each project:** hard\n\n---\n\n### Developing modular synthesis using widget modulation  \n\n**Mentors:** [Yann Orlarey](mailto:orlarey@gmail.fr) and [Stéphane Letz](mailto:letz@grame.fr)\n\n[Widget modulation](https://faustdoc.grame.fr/manual/syntax/#widget-modulation) acts on the widgets of an existing Faust expression, but without requiring any manual modifications of the expression's code. This operation is done directly by the compiler, according to a list of target widgets and associated modulators. Target widgets are specified by their label, as used in the graphical user interface. Modulators are Faust expressions that describe how to transform the signal produced by widgets. \n\nThe project would be to develop a set of [modular synthesizers](https://en.wikipedia.org/wiki/Modular_synthesizer), typically by choosing and adapting existing functions in the [Faust Libraries](https://faustlibraries.grame.fr), each of them with a pretty GUI, to be combined in a patch like model. The widget modulation syntax will be used to prepare the widgets to be modulable. The implementation will be done using web technologies, and in particular [FaustWasm](https://github.com/grame-cncm/faustwasm), a high-level API that wraps around Faust compiler. Here is a list of possible steps:  \n\n- choose and adapt existing functions in the Faust Libraries and add a pretty GUI with [User Interface Primitives](https://faustdoc.grame.fr/manual/syntax/#user-interface-primitives-and-configuration) to create modules including oscillators (which generate sound), filters (which modify sound by frequency), amplifiers (which control the volume), and modulators (like LFOs and envelopes, which affect other parameters over time)\n\n- create sequencing modules, vital for composition in modular synthesis. It allows users to create a series of notes (a sequence) that can be sent to an oscillator to produce rhythmic patterns or melodies\n\n- define a library of modulation circuits, using the [lowest/highest](#TODO) primitives of the language, and define adapted signal mappings\n\n- create a global GUI to rack all used modules as in [VCV Rack](https://vcvrack.com), using Web technologies, and develop the connection logic needed between all considered modules, compiled and connected as separated Faust [Web Audio](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API) nodes\n\n**Expected size of project:** 350 hours\n\n**Expected outcomes:** The project aims in developing new libraries for modular synthesis and a prototype Web application. \n\n**Skills required/preferred:** Faust programming, Web programming\n\n**An easy, medium or hard difficulty rating of each project:** medium\n\n---\n\n## Past GSoC editions\n\n### 2024: FaustNet - DDSP, Faust in Cables.gl, Amati++, a VST/CLAP Plugin embedding the dynamic compiler and Faust Package Manager\n\n- **FaustNet - DDSP** aimed to continue the work done on adding automatic differentiation in Faust (started in a GSOC 2023 project), to leverage machine learning for audio processing tasks directly within the familiar Faust environment. It was worked on by [Advik Raj Basani](https://github.com/FloofCat) and contributed as a [Pull Request](https://github.com/hatchjaw/faust-ddsp/pull/1) on Thomas Rushton [faust-ddsp](https://github.com/hatchjaw/faust-ddsp) library. \n\n- **Faust in Cables.gl** aimed to develop a Cables.gl plugin that compiles Faust DSP code into a WASM AudioWorklet in real-time. It was worked on by [Fay Carsons](https://github.com/FayCarsons) and contributed as a separated [Faust Cables plugin](https://github.com/FayCarsons/Cables-Faust-Plugin) project.\n\n - **Amati++, a VST/CLAP Plugin embedding the dynamic compiler**, inspired by the pMix and Amati projects, this plugin has been built using the JUCE framework for the interface and libfaust with LLVM and interpreter backend API to compile Faust code. It was  worked on by [Tyler Li](https://github.com/Orisu179) and is still a [work-in-progress](https://github.com/Orisu179/AmatiPP).\n\n- **Faust Package Manager** aimed to add a packaging system to facilitate the integration of Faust libraries in a DSP project. It was worked on by [Shehab Khaled Roshdy](https://github.com/shehab299) and a was contributed as a [Pull Request](https://github.com/grame-cncm/faust/pull/1049) that is still in test in a [master-dev-pacman](https://github.com/grame-cncm/faust/tree/master-dev-pacman) branch.\n\n### 2023: Automatic Differentiation in the Faust Compiler and Better Faust on the Web\n\n- **Automatic Differentiation in the Faust Compiler** aimed at adding Automatic differentiation directly in the compiler, so that gradient calculation can be carried out natively in Faust, with applications in Machine Learning algorithms. The project was worked  by [Thomas Rushton](https://github.com/hatchjaw) and completed with this [Pull Request](https://github.com/grame-cncm/faust/pull/939), and finally integrated in the Faust [master-branch](https://github.com/grame-cncm/faust/commit/681a303b8ddc9ef2e67c2cc5d5df83f27323b865). \n\n- **Better Faust on the Web** aimed at enhancing Faust’s support for the web platform, and was worked on by [Ian Clester](https://ijc8.me/). Transitioning the Faust web tools to a rewritten TypeScript version has been completed and deployed in updated versions of the [Faust editor](https://fausteditor.grame.fr) and [Faust playground](https://faustplayground.grame.fr) and soon in the [Faust Web IDE](https://faustide.grame.fr) with this [Pull Request](https://github.com/grame-cncm/faustide/pull/72). A Faust web component embedding the libfaust JS/WebAssembly compiler has been [developed](https://github.com/ijc8/faust-web-component) and will be used soon in the [Faust documentation](https://faustdoc.grame.fr). The development is fully detailed in this [blog post](https://ijc8.me/2023/08/27/gsoc-faust/). \n\n### 2022: Integration in HISE\n    \nFaust Integration in HISE aimed at integrating support for the Faust audio programming language into HISE, an extensive framework for the creation of sample-based virtual musical instruments. The project has been [completed](https://resonant-bytes.de/blog/gsoc-final-submission/) by [Roman Sommer](https://resonant-bytes.de/about/) with the help of [Christoph Hart](https://github.com/christophhart) as mentor, and announced [here](https://forum.hise.audio/topic/6505/faust-is-here)."
  },
  {
    "name": "OSGeo (Open Source Geospatial Foundation)",
    "slug": "osgeo-open-source-geospatial-foundation",
    "tagline": "The Open Source Geospatial Foundation",
    "description": "The Open Source Geospatial Foundation (OSGeo) is a not-for-profit organization whose mission is to foster global adoption of open geospatial technology by being an inclusive software foundation devoted to an open philosophy and participatory community-driven development.<br/><br/>\n\nOSGeo serves as an umbrella organization for the Open Source Geospatial community in general and several code projects in particular:<br/>\n* <b>Web Mapping</b>: deegree, geomajas, GeoMOOSE, GeoServer, Mapbender, MapFish, MapGuide Open Source, MapServer, OpenLayers.<br/>\n* <b>Desktop Applications</b>: GRASS GIS, gvSIG, Marble, QGIS.<br/>\n* <b>Geospatial Libraries</b>: FDO, GDAL/OGR, GEOS, GeoTools, OSSIM, PostGIS.<br/>\n* <b>Metadata Catalogues</b>: GeoNetwork, pycsw.<br/>\n* <b>Content Management Systems</b>: GeoNode.<br/>\n* <b>Community Projects</b>: pgRouting, istSOS, MetaCRS, Opticks, Orfeo ToolBox (OTB), PyWPS, Team Engine, ZOO-Project.<br/>\n* <b>Other (non-code) Projects</b>: GeoForAll (Education and Curriculum), OSGeoLive DVD, Public Geospatial Data.<br/><br/>\n\nWe host regional and international FOSS4G conferences with typical attendance of 500-1100+ geospatial developers, industry and government leaders, and researchers. Our mailing lists collectively go out to ~ 30,000 unique subscribers.",
    "ideas_url": "https://wiki.osgeo.org/wiki/Google_Summer_of_Code_2026_Ideas",
    "website_url": "https://www.osgeo.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "python",
      "javascript",
      "java",
      "c++"
    ],
    "topic_tags": [
      "open science",
      "gis",
      "citizen science",
      "geolocation",
      "mapping"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/osgeo-open-source-geospatial-foundation",
    "ideas_content": "# Google Summer of Code 2026 Ideas\n\n[Jump to navigation](https://wiki.osgeo.org#mw-head)\n\n[Jump to search](https://wiki.osgeo.org#searchInput)\n\n- Back to the main OSGeo\n[Google Summer of Code 2026](https://wiki.osgeo.org/wiki/Google_Summer_of_Code_2026)wiki page.\n\n- See also ideas from\n[2025](https://wiki.osgeo.org/wiki/Google_Summer_of_Code_2025_Ideas),[2024](https://wiki.osgeo.org/wiki/Google_Summer_of_Code_2024_Ideas),[2023](https://wiki.osgeo.org/wiki/Google_Summer_of_Code_2023_Ideas),[2022](https://wiki.osgeo.org/wiki/Google_Summer_of_Code_2022_Ideas),[2021](https://wiki.osgeo.org/wiki/Google_Summer_of_Code_2021_Ideas),[2020](https://wiki.osgeo.org/wiki/Google_Summer_of_Code_2020_Ideas),[2019](https://wiki.osgeo.org/wiki/Google_Summer_of_Code_2019_Ideas),[2018](https://wiki.osgeo.org/wiki/Google_Summer_of_Code_2018_Ideas),[2017](https://wiki.osgeo.org/wiki/Google_Summer_of_Code_2017_Ideas),[2016](https://wiki.osgeo.org/wiki/Google_Summer_of_Code_2016_Ideas),[2015](https://wiki.osgeo.org/wiki/Google_Summer_of_Code_2015_Ideas),[2014](https://wiki.osgeo.org/wiki/Google_Summer_of_Code_2014_Ideas),[2013](https://wiki.osgeo.org/wiki/Google_Summer_of_Code_2013_Ideas),[2012](https://wiki.osgeo.org/wiki/Google_Summer_of_Code_2012_Ideas),[2011](https://wiki.osgeo.org/wiki/Google_Summer_of_Code_2011_Ideas),[2010](https://wiki.osgeo.org/wiki/Google_Summer_of_Code_2010_Ideas),[2009](https://wiki.osgeo.org/wiki/Google_Summer_of_Code_2009_Ideas),[2008](https://wiki.osgeo.org/wiki/2008_SoC_Merged_Ideas),[2007](https://wiki.osgeo.org/wiki/2007_SoC_Merged_Ideas).\n\n\n\n## OSGeo Google Summer of Code 2026\n\nThe [Open Source Geospatial Foundation](http://www.osgeo.org) would like to extend a welcome to the interested SoC contributors. On this page, you will find links to a host of ideas organized by project. You will find ideas ranging from the depths of computer science graph theory to the heights of visualization. One thing all these ideas have in common is lots and lots of spatial data.\n\nThese ideas are ***only*** to motivate you and serve as an example of the kind of hills we want to charge up. Your own ideas are more than welcome - they are encouraged. We view you as the next wave of open-source leaders and the future of the geospatial industry; show us what you've got!\n\n**Contributors: check out the**[Google Summer of Code Recommendations for Students](https://wiki.osgeo.org/wiki/Google_Summer_of_Code_Recommendations_for_Students)page.- If you need more information on how to apply you can contact us on\n[OSGeo's discourse](https://discourse.osgeo.org/c/initiatives/soc) - Read the\n[GSoC Roles and Responsibilities](https://developers.google.com/open-source/gsoc/help/responsibilities)to understand successful teamwork and interplay of project, mentors, and students.\n\n- There is a\n[Google SoC flyer](https://developers.google.com/open-source/soc/resources/flyers)to look at and post in appropriate places.\n\n[OSGeo](http://www.osgeo.org)is involved in working with maps and things, but what kind of projects does it really do? Have a look at the[live blog feed](http://planet.osgeo.org/)to see what people are working on right now.\n\n- Mentors, there's an additional link providing some tips and specifying your responsibilities on the main OSGeo\n[Google Summer of Code Administrative](https://wiki.osgeo.org/wiki/Google_Summer_of_Code_Administrative)wiki page.\n\n## Recent Modifications in GSoC (Must Read)\n\n- The program is open to all the students who are 18 years and older AND to the beginners in open source development, who might not be university students but are 18 years and older. With folks around the world changing careers, returning to the workforce, and learning on their own (outside of academic programs) we see an opportunity to reach a plethora of excited individuals who want to learn more about open source and be a part of our amazing GSoC communities. Check\n[Eligibility](https://summerofcode.withgoogle.com/rules/)here.\n\n- GSoC Contributors will be able to choose from multiple-size projects: medium at ~175 hours, large at ~350 hours and small at ~90 hours. This is to remove the barrier of available time that many potential contributors have and open the program to people who want to learn about open source development but can’t dedicate all or even half of their summer to the program.\n\n- We are building increased flexibility around the timing of projects - there is an option to extend the standard 12-week coding time frame to a maximum of 22 weeks. This is to allow folks who may realize that spreading the work over say, 16 weeks, is a more realistic goal with their current life situation. Or for contributors who have life happen in the middle of the program and they can’t work on their projects for a few weeks, but they can come back to it after a month to finish it. This would make it easier for GSoC Contributors and mentors to be able to navigate together when obstacles occur and the GSoC Contributor can successfully complete their project.\n\n## The ideas pages\n\nTo add your page, **please contact the GSoC admin team** to let them know of your ideas page, by sending an email to [gsoc-admin@osgeo.org](mailto:gsoc-admin@osgeo.org)\n\n### OSGeo Foundation graduated project\n\n:**pgRouting**Ideas[pgRouting](http://pgrouting.org)extends the PostGIS / PostgreSQL geospatial database to provide geospatial routing functionality and more.\n\n:**QGIS**Ideas[QGIS](https://qgis.org)is a user friendly Open Source GIS that runs on Linux, macOS and Windows. QGIS supports vector, raster, and database formats. It is written in C++ and Python.\n\n: The**istSOS**Ideas[istSOS](https://www.istsos.org)project is sensor data management tool that allows collection, maintenance and publishing of monitoring observations using the Open Geospatial Consortium (OGC) SensorThingsAPI standard.\n\n: The**ZOO-Project**Ideas[ZOO-Project](https://zoo-project.org/)is a WPS open source project released under a MIT/X-11 style license. It provides support for WPS 1.0.0 and 2.0.0 versions and is able to handle services implemented in various programming languages.\n\n\n\n## I want to apply as a student\n\nBefore applying as a student, check out the [Google Summer of Code Recommendations for Students](https://wiki.osgeo.org/wiki/Google_Summer_of_Code_Recommendations_for_Students) page.\n\n### Which project do I choose?\n\nMost of the software projects are available pre-built on our OSGeoLive { DVD | USB stick | VirtualMachine } with project overviews and short tutorials where you can try everything out.\n\n- View the documents and download the ISO from\n[https://live.osgeo.org](https://live.osgeo.org)\n\n### Important dates\n\n[Back to [Google Summer of Code 2026](https://wiki.osgeo.org/wiki/Google_Summer_of_Code_2026) @ OSGeo]"
  },
  {
    "name": "OpenVINO Toolkit",
    "slug": "openvino-toolkit",
    "tagline": "Make AI inference faster and easier to deploy!",
    "description": "OpenVINO is an open‑source toolkit designed to optimize and deploy deep learning models from cloud to edge. It accelerates inference for a wide range of use cases—including computer vision, generative AI, and agentic AI—supporting models from popular frameworks such as PyTorch, TensorFlow, ONNX, and more. With OpenVINO, you can convert and optimize models, then deploy them across diverse Intel hardware and environments, whether on-premises, at the edge, on AI PCs, or in the cloud.",
    "ideas_url": "https://github.com/openvinotoolkit/openvino/wiki/Google-Summer-Of-Code#project-ideas-for-2026",
    "website_url": "https://docs.openvino.ai/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "c++",
      "arm",
      "x86"
    ],
    "topic_tags": [
      "ai",
      "inference",
      "gen ai",
      "Agentic AI",
      "Model Serving"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/openvino-toolkit",
    "ideas_content": "Spend your summer doing something exciting and valuable for the open-source community, and join Google Summer of Code. Read more about how the program works on [this page](https://summerofcode.withgoogle.com/).\n\nOpenVINO Toolkit has been [a mentoring organization](https://www.youtube.com/watch?v=XEYysqPhX3s) since 2022!\n\nTake a look at our other organization ([Open Edge Platform](https://github.com/open-edge-platform/edge-ai-resources/wiki/Google-Summer-of-Code)) for more exciting projects - it was spun off from the OpenVINO Toolkit in 2026.\n\n## Announcements\n\nPlease subscribe [this discussion](https://github.com/openvinotoolkit/openvino/discussions/33737) and check it regularly for important announcements. \n\n## Prerequisite task\n\nWe require one pull request sent to our OpenVINO repository from each potential GSoC contributor before accepting participation for GSoC. We would like to see if you know how to code, use git and GitHub, and your coding style. To fulfill this requirement, please:\n\n1. Visit the [OpenVINO Good First Issues board](https://github.com/orgs/openvinotoolkit/projects/3).\n2. Select one of the unassigned tickets (\"Contributors Needed\" column) and ask for the assignment.\n3. Discuss the solution with the OpenVINO developers.\n4. Implement it according to the [OpenVINO contribution guide](https://github.com/openvinotoolkit/openvino/blob/master/CONTRIBUTING.md).\n5. If you encounter any issues talk to our developers on [Discord](https://discord.com/invite/7pVRxUwdWG).\n5. Create a new pull request with your work.\n6. Wait for the review and eventual merge.\n\nPlease note the above task is **mandatory**. However, we reserve the right to review and merge only the selected PRs. Not merging or closing your PR doesn't change your chances of being accepted for GSoC. Due to the expected large number of requests, the review process can be delayed, so please be patient.\n\nIf you're unfamiliar with git and GitHub, check out this [blog](https://medium.com/openvino-toolkit/how-to-contribute-to-an-ai-open-source-project-c741f48e009e). The blog is about contributing to OpenVINO core project, but the workflow is the same for all projects.\n\n## Application Template\n\n**Purely AI-generated applications are not allowed and will result in disqualification. Applicants must author their submissions themselves and be able to fully explain all content. AI tools may only be used to check grammar, punctuation, or slightly improve language style; they must not generate ideas, write sections of the application, or replace the applicant’s own reasoning. Submissions that appear to be primarily AI-generated will be rejected. The guiding principle is that AI may assist in polishing your application, but it cannot replace your thinking, creativity, or voice.**\n\nYour application should consist of the following parts:\n\n1. About you\n    1. Your full name\n    2. Your university/current enrollment\n    3. The timezone you live/work in\n    4. Short bio\n    5. Your experience in programming (especially C++ and Python)\n    6. Your experience in technologies required for the project\n2. About the project\n    1. What is your choice?\n    2. Why did you choose this specific idea?\n    3. How much time do you plan to invest in the project? \n    4. Provide an abstract of the solution\n    5. Provide a detailed timeline of how you want to implement the project (include the main points you want to cover and dates)\n3. General questions\n    1. How do you know OpenVINO?\n    2. What do you know about OpenVINO? \n    3. Have you already contributed to the OpenVINO project? (please include links)\n    4. How could you apply it to your professional development?\n    5. Describe any other career development plan you have for the summer in addition to GSoC.\n    6. Why should we pick you?\n4. Prerequisites\n    1. Link to your pull request (for the prerequisite task – the top part of this document), even if it is already merged or closed\n\nProposal examples can be found [here](https://google.github.io/gsocguides/student/proposal-example-1) and [here](https://google.github.io/gsocguides/student/proposal-example-2). Please get in touch with us early to discuss your application with the mentor.\n\nThe proposal must be uploaded to the GSoC website **during the GSoC contributor application period** (according to the dates in [timeline](https://developers.google.com/open-source/gsoc/timeline)) and **have the same name as the project name** (that will prevent your submission from being missed).\n\n## Project ideas for 2026\n\nAll project ideas for 2026 can be found [[here|Project ideas for 2026]].\n\n## Projects already implemented (2022-2025)\n\nProjects implemented in the past can be found [[here|OpenVINO at Google Summer Of Code in the past]].\n\n## Contribution guidelines\n\nContribution guidelines can be found [here](https://github.com/openvinotoolkit/openvino/blob/master/CONTRIBUTING.md).\n\n### AI Usage Policy for Google Summer of Code Contributions\n\nThis policy defines acceptable use of AI tools in GSoC contributions to ensure code quality, accountability, and learning outcomes.\nCore Rules\n\n1. Ownership and understanding\n\n    * Contributors must fully understand and be able to explain all submitted changes.\n\n2. No raw AI output\n\n    * All AI-assisted content must be reviewed, modified, and owned by the contributor.\n    * Non-conforming, unnecessary, or low-quality code must be rewritten or removed.\n\n3. Build and test requirements\n\n    * All changes must compile.\n    * Appropriate tests must be added and must pass.\n    * Untested or unbuilt code is not acceptable.\n\n4. AI is an assistant, not an author\n\n    * AI may be used only for research, learning, understanding, and test exploration.\n    * AI must not be the primary problem-solving or code-generating mechanism.\n\n**Please note the final decision of accepting code written with the help of AI is up to the project mentor.**\n\n## Contact us\n\n1. Open OpenVINO [discussions tab](https://github.com/openvinotoolkit/openvino/discussions)\n2. Start [a new discussion](https://github.com/openvinotoolkit/openvino/discussions/new/choose) by pushing the green button (if you cannot see the button, it means you're not logged in)\n3. Select a \"Google Summer of Code\" category and add the \"gsoc\" label\n4. Ask your question (please be aware everything you post there is publicly available)\n5. Tag the mentor to whom you address your question (the mentors are specified for all project ideas)\n\nPlease get in touch with us early to discuss your application with the mentor. Mentors will do their best to reply to all contributors, but due to a large contributor interest this year, they may not be able to respond to all inquiries"
  },
  {
    "name": "UC OSPO",
    "slug": "uc-ospo",
    "tagline": "Amplifying Research Impact through Open Source",
    "description": "The UCSC Open Source Program Office (OSPO) and the UC OSPO Network supports open source work throughout the University of California system. Beginning in 2022, the UCSC OSPO took over the programmatic responsibilities of the UCSC Center for Research in Open Source Software (CROSS), including mentorship activities such as GSoC. The UCSC OSPO creates partnerships with stakeholders within and outside the UC system in order to help students learn from open source communities, support scientists in using open source to accelerate research efforts, and connect students and scientists with sponsors from industry, government, and foundations. The OSPO helps bridge the gap between academic research and successful open source projects by promoting innovative projects maintained by UC-affiliated scientists and researchers. We support the transfer of cutting-edge technology resulting from UC-originating research to industry via successful open source projects. Due to the multi-campus nature of our current efforts, the projects we support and promote cover a wide range of topics and technologies - including:\n\n- Open Source Hardware and Chip Design\n- AI / Machine Learning\n- Storage Systems and Devices\n- Data Science and visualization\n- Scientific Computing & Research Infrastructure\n- Reproducibility\n- Cloud-based computation\nAll of our mentors are scientists and researchers who are actively involved in one or more of these open source projects.",
    "ideas_url": "https://ucsc-ospo.github.io/osre26/#projects",
    "website_url": "https://ucsc-ospo.github.io/osre26/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "c/c++",
      "machine learning",
      "pytorch"
    ],
    "topic_tags": [
      "education",
      "bioinformatics",
      "data science",
      "AI/ML",
      "research software"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/uc-ospo",
    "ideas_content": "Matching summer students with research mentors and sponsors.\n\nThe Open Source Research Experience (OSRE) program provides support for undergraduate and graduate students contributing to open source projects and reproducible research efforts. With its dual focus on both increasing open source communities and making computational research efforts reproducible, the OSRE supports a wide variety of projects. In connection with the OSRE, the UCSC OSPO has taken part in the [Google Summer of Code](https://summerofcode.withgoogle.com) as a mentor organization. Information from past OSRE years can be found here: [2025](https://ucsc-ospo.github.io/osre25), [2024](https://ucsc-ospo.github.io/osre24), [2023](https://ucsc-ospo.github.io/osre23) and [2022](https://cross.ucsc.edu/2022-osre/index.html) ([final 2022 reports](https://ucsc-ospo.github.io/post/20220929)).\nMentors interested in participating in the OSRE (including for projects relevant to GSoC and the SoR) can [post their project ideas](https://ucsc-ospo.github.io/osredocs/formentors/) for students to review. [Project ideas](https://ucsc-ospo.github.io#projects) are short abstracts that provide an overview of the tasks students will accomplish over the summer. See [mentor page](https://ucsc-ospo.github.io#formentors) for more details.\nInterested Students or other newcomers to open source or reproducibility should review these project ideas and work with mentors to develop a full proposal. Student projects are due by April. See [student information page](https://ucsc-ospo.github.io#forstudents) for more details.\n\n**Table of Content**: [OSRE News](https://ucsc-ospo.github.io#news) | [OSRE 2026](https://ucsc-ospo.github.io#osre26) | [For students](https://ucsc-ospo.github.io#forstudents) | [Student pages](https://ucsc-ospo.github.io#studentpages) | [For mentors](https://ucsc-ospo.github.io#formentors) | [For sponsors](https://ucsc-ospo.github.io#forsponsors) | [Timeline](https://ucsc-ospo.github.io#timeline) | [Projects](https://ucsc-ospo.github.io#projects) | [Tag cloud](https://ucsc-ospo.github.io#tags) | [Mentors and Contributors](https://ucsc-ospo.github.io#mentors)\n\nOpen Source Research Experience\n\nAs last year OSRE 2026 will include mentors across multiple University of California campuses. Project ideas are listed [below](https://ucsc-ospo.github.io#projects).\n\nIf you are interested, have a look at our [guidelines for students](https://ucsc-ospo.github.io/osredocs/forstudents), which includes timelines on when to contact mentors and proposal guidelines and expectations. Students may begin reaching out to mentors **after February 19, 2026**.\n\n**Students interested in applying to any of our projects must join our Slack channel before March 16, 2026 to be considered elgibile.** Email [ospo-info-group@ucsc.edu](mailto:ospo-info-group@ucsc.edu) to be added to our slack channel.\n\n**The FINAL proposal deadline is March 31 at 18:00 UTC.** Proposals should be submitted through the [GSoC portal](https://summerofcode.withgoogle.com/)! Do not send proposal to the organization admins or mentors unless specifically requested by them. If your proposal is not submitted to the GSoC portal by this deadline you will not be eligible for selection.\n\nDue to the open source nature of all OSRE projects, contributions are welcome from students or other newcomers from anywhere in the world. Please note that you must have work authorization in your country of residence to take part in this program. For students within the University of California system, you are welcome to participate but be aware we may not be able to place you with mentors from your own campus. Please contact [ospo-info-group@ucsc.edu](mailto:ospo-info-group@ucsc.edu) if you have any questions about your eligibility.\n\nWe typically support the work of undergraduate students; however graduate students may also apply to work on more advanced project ideas. Please check out the project ideas page and contact the mentor if you have questions.\n\nGo to [2025 student pages](https://ucsc-ospo.github.io/osre25/#studentpages)\n\nWe are asking OSRE 2026 students and contributors to share their progress on a regular basis. We are excited to be able to highlight their work on this website and in events such as our Open Source Symposium. This [blog post](https://ucsc-ospo.github.io/report/osre26/ucsc/admin/20241021-admin/) contains instructions on how to start highlighting contributor work with blog posts, also known as “student pages”. And here they are:\n\nThe UCSC OSPO is looking for mentors to be part of our 2026 Open Source Research Experience Program (OSRE). Please read the [FAQ for Mentors](https://ucsc-ospo.github.io/osredocs/mentorfaq) and, if interested in participating, [the instructions](https://ucsc-ospo.github.io/osredocs/formentors) for posting projects.\n\nWhile typical OSRE supported projects require mentors who are connected to University of California-based open source projects, the Summer of Reproducibility allows us to also support mentors interested in research projects related to the creation and usage of reproducibilty artifacts.\n\nThe OSRE aims to increase student capabilities in working in open source projects and creating reproducible artifacts, as well as add productive open source contributors and promote open source and reproducibility throughout the UC system and beyond.\n\nThe program team at the UCSC OSPO values diversity and inclusion in all our projects. We invite mentors from groups traditionally excluded in computer science/open source communities to participate in this program.\n\nIf you could use undergraduate* research assistance over the summer with your on-going research, this is a great opportunity to get matched to top students. Like Google Summer of Code, the OSRE allows the mentors to choose the students they want to work with based on an interactive and iterative proposal process. The proposal process provides mentors the opportunity to select someone they want to work with who will benefit their project and research.\n\nYour project needs to have at least one mentor affiliated with the University of California or associated DOE national labs.\n\n**For University of California (UC) projects:** Any UC-affiliated faculty, researchers or graduate students working on projects that are or will ultimately be part of an open source community/ecosystem.\n\n**For Summer of Reproducibility (SoR) projects:** Researchers and faculty looking to support the open source production or use of reproducibility artifacts.\n\nAll software created as part of an OSRE project must be released as free and open source under a license that is both approved by the Open Source Initiative (OSI) and recognized as free by the Free Software Foundation (FSF).\n\nFor more details, please see the [FAQ for Mentors](https://ucsc-ospo.github.io/osredocs/mentorfaq) and [the instructions](https://ucsc-ospo.github.io/osredocs/formentors) for posting projects.\n\n**Is your organization looking to use open source more effectively and want to support projects that directly benefit your business or industry?**\n\n**Does your company want to strengthen the talent pipeline able to work on technologies essential to your organization’s success?**\n\n**Do you want to collaborate with innovative open source projects being developed by University of California researchers?**\n\nThe UC Open Source Research Experience (OSRE) offers your organization the chance to participate in projects that can help your development cycles run faster, benefit from wide collaborations, and help support workforce development in domains your organization needs.\n\nTo become a sponsor, fill out the [Sponsorship Interest Form](https://forms.gle/9ZTg7pMwa1dQ94NS6). You will be asked to indicate the level of sponsorship you would like to fund and [the open source projects](https://ucsc-ospo.github.io/osre26/#projects) you are most interested in engaging with.\n\n- Collaborating on innovative project that are of strategic interest to your industry;\n- Supporting the teaching of open source techniques to a wide range of student contributors;\n- Interacting with the next generation of open source leaders and up and coming talent; and\n- Recognition as an OSRE Sponsor at the Open Source Research Symposium (Fall 2026)\n\n| Level | Amount |\n|---|---|\n| Bronze | $3,750 (covers 50% of one student stipend for summer) |\n| Silver | $7,500 (covers one student full-time for summer) |\n| Gold | $15,000 (covers two students full-time for summer) |\n\nBecoming a sponsor is easy! Fill out the [Sponsorship Interest Form](https://forms.gle/9ZTg7pMwa1dQ94NS6) or reach out to the [OSRE Admins](mailto:ospo-info-group@ucsc.edu) by April 20. Information requested by the form include: name of contact person, level of sponsorship, and projects you are most interested in (if applicable.) The [OSRE Admins](mailto:ospo-info-group@ucsc.edu) will follow up with next steps for finalizing the sponsorship process.\n\nGo to [2025 timeline](https://ucsc-ospo.github.io/osre25/#timeline)\n\n| Feb 19 | <a href=/post/02272025gsoc/ GSoC Mentor Organization Announcement / Interested contributors may begin reaching out to mentors (joining Slack Channel by March 15 is REQUIRED for proposals to be considered) |\n| Feb 20 | Final Deadline for mentors posting projects for OSRE consideration |\n| Mar 15 | Deadline for students to join Slack channel (required for proposal to be considered) |\n| March 31 | Student proposal deadline |\n| April 30 | Accepted student proposals announced |\n| May 1 | Begining of Onboarding |\n| Late May to August/September* | OSRE participants work on projects / includes one mid-term evaluation |\n| *Project start and end dates are flexible but need to be OK’d with Mentor and Org Admin |\n\nGo to [2025 projects](https://ucsc-ospo.github.io/osre25/#projects)\n\n*"
  },
  {
    "name": "International Catrobat Association",
    "slug": "international-catrobat-association",
    "tagline": "Free visual coding apps for computational thinking",
    "description": "Computational thinking for all with free visual coding apps\nThe Catrobat project develops useful frameworks to create games, animations, or apps easily within a short time. This set of mobile creativity tools for smartphones is inspired by the well-known Scratch framework by the Lifelong Kindergarten Group at the MIT Media Lab. The motivation behind the project is that programming is an important cultural technique on the same level as mathematics and physics, from a practical as well as from a philosophical point of view. Our aim thus is to popularize the skills needed to program from an early age in a fun and engaging way that will facilitate the spread of its adoption among young people all over the world.\n\nOur awarded Android app “Pocket Code” is currently the most famous outcome of the project. Without the need for any further devices, users have the possibility to create their first program directly on their mobile device in just a few steps using visual \"Bricks\". Pocket Code supports all common device sensors, provides special \"Bricks\" for different robotic devices (Lego Mindstorms, Robotix Phiro, etc.) as well as for hardware devices such as the Arduino board or the Raspberry Pi, and of course offers elements of programming languages such as variables, if-statements, concurrency, etc. We also work on \"Pocket Code\" for iOS and on a large number of extensions. That’s why developers of different fields help us to keep our products up-to-date to meet the current needs of our users.\n\nMotivated by prizes (such as the Lovie Award, the Austrian National Innovation Award or the Re-Imagine Education Award) and being featured by different programs (like Google Play for Education or code.org), our team is working on many different subprojects and extensions. Over 870 developers already contributed to our project on different topics such as app development, web technologies, graphics, usability, internationalization, or design.",
    "ideas_url": "https://developer.catrobat.org/pages/development/google-summer-of-code/2026/",
    "website_url": "https://www.catrobat.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "swift",
      "kotlin",
      "flutter"
    ],
    "topic_tags": [
      "education",
      "visual programming",
      "mobile programming",
      "game engines",
      "creativity tools"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/international-catrobat-association",
    "ideas_content": "# Ideas Page for Google Summer of Code 2026\n\nWe are thrilled to share our carefully curated project ideas for this year’s Google Summer of Code.\n\n## General Information\n\nThese ideas are just some topics we came up with, where currently nobody is working on. However, Catrobat is a project with a wide range of possibilities and we’re aware of our blindspots: So let’s live the spirit of Open Source and come up with improvements (e.g., new features, extensions, …) that are related to the project and in which you’re interested in. We do have many senior contributors who would be happy to mentor such a project. Don’t be shy and check out the last point on the list: Your idea!\n\nFor your submission, please follow [our instructions](https://docs.google.com/document/d/1vOGY2C80raXLV6RVRHXoqiAhcnBJFeZdU8wqMm-Rgo0/edit?usp=sharing) and submit a corresponding document via the [GSoC application site](https://summerofcode.withgoogle.com/).\n\n## AI tools policy\n\nYou may use AI tools as much as you like (brainstorming, code generation, refactoring, tests, documentation, review). We believe this can significantly improve quality and learning when used thoughtfully. What matters is the outcome: correctness, maintainability, Clean Code and tests. You must be able to explain and justify your implementation and tests.\n\nTo apply for some of the project ideas, please complete the associated entry task, if any, and include the links to the requested demo artifacts in your application. Entry tasks have on purpose been formulated in a little bit more difficult way so that it’s not easy to simply feed the idea into an AI, and let the AI completely answer for you. However, we understand that the time to complete an entry task can be substantial, and we therefore ask you to write down the time you need to finish the entry task. In case your proposal will be accepted, this time to complete the entry task will be subtracted from the number of hours that will be agreed to be completed by you. For substantial proposals that we could not accept, there will be some other way of recompense for you, to be decided.\n\n## General Knowledge Prerequisites for all Projects\n\n- Usage of Git and GitHub\n- Software testing (e.g., test doubles) and test-driven development\n- Kotlin, Java, or Flutter for Android ideas (depending on target project)\n- Swift for iOS ideas\n- Also please check that you have the proper hardware for the development (e.g., an Android/iOS smartphone for testing some of the projects, Mac for iOS development etc)\n\n## Idea Overview\n\n[Multiplayer, IoT, and Home Assistant support via two MQTT bricks](https://developer.catrobat.org#multiplayer-iot-and-home-assistant-support-via-two-mqtt-bricks)[SeaSee’r: Underwater Mapping and Exploration using Spatially anchored Panoramas](https://developer.catrobat.org#seaseer-underwater-mapping-and-exploration-using-spatially-anchored-panoramas)[Pocket Paint Flutter: backwards compatibility to old Android app](https://developer.catrobat.org#pocket-paint-flutter-backwards-compatibility-to-old-android-app)[Pocket Paint Flutter: antialiasing and smoothing (advanced options)](https://developer.catrobat.org#pocket-paint-flutter-antialiasing-and-smoothing-advanced-options)[AI Mentor for PocketCode Students](https://developer.catrobat.org#ai-mentor-for-pocketcode-students)[Pin projects to the Android launcher (“Play as app” shortcuts)](https://developer.catrobat.org#pin-projects-to-the-android-launcher-play-as-app-shortcuts)[Skeleton-Based Procedural Animation System for Marine Organisms](https://developer.catrobat.org#skeleton-based-procedural-animation-system-for-marine-organisms)[Gemini-Powered Ecosystem Narration and Analysis Interface](https://developer.catrobat.org#gemini-powered-ecosystem-narration-and-analysis-interface)[AI-Driven Dynamic Procedural Map Generation System](https://developer.catrobat.org#ai-driven-dynamic-procedural-map-generation-system)[Upgradation of AR-Based Interactive and Procedural Marine Ecosystem Simulation](https://developer.catrobat.org#upgradation-of-ar-based-interactive-and-procedural-marine-ecosystem-simulation)[AR Based Human Interaction Enabled Application for Marine Life](https://developer.catrobat.org#ar-based-human-interaction-enabled-application-for-marine-life)[Extension of Sandbox Toolkit for simplifying the Development of Marine based AR Modules](https://developer.catrobat.org#extension-of-sandbox-toolkit-for-simplifying-the-development-of-marine-based-ar-modules)[Web-Based Sandbox Toolkit for Marine AR Modules](https://developer.catrobat.org#web-based-sandbox-toolkit-for-marine-ar-modules)[Blockchain-Based Ethical Governance for IoT Care Systems](https://developer.catrobat.org#blockchain-based-ethical-governance-for-iot-care-systems)[Gemini-API–Powered Intelligent Care Assistant](https://developer.catrobat.org#gemini-apipowered-intelligent-care-assistant)[AR Rocket Builder & Space Flight Sandbox](https://developer.catrobat.org#ar-rocket-builder--space-flight-sandbox)[AR Gravity & Planetary Physics Simulator](https://developer.catrobat.org#ar-gravity--planetary-physics-simulator)[AR Interactive Physics Playground](https://developer.catrobat.org#ar-interactive-physics-playground)[Sentiment Analysis of Cephalopods](https://developer.catrobat.org#sentiment-analysis-of-cephalopods)[Minimal Open-Source IoT Cloud Platform with Secure Device Access](https://developer.catrobat.org#minimal-open-source-iot-cloud-platform-with-secure-device-access)[Your own Project Ideas …](https://developer.catrobat.org#your-own-project-ideas-)\n\n## Project Descriptions\n\n### Multiplayer, IoT, and Home Assistant support via two MQTT bricks\n\n90, 175 or 350 hours\n\n\nRequired Skills: Kotlin, Android-Development, Agile Development, Test Driven Development, Clean Code\n\nPossible Mentors: Wolfgang Slany, Paul Spiesberger\n\nExpected Outcome: Two new bricks for sending and receiving MQTT messages\n\nDifficulty level: Advanced\n\nTask link:[View task]\n\nImplement MQTT support for the Catrobat language in Catroid (Pocket Code and its flavors) so Catrobat programs can publish/receive network messages for multiplayer games, IoT, and Home Assistant setups. Add two new Catrobat bricks (activated via app settings):\n\n- Broadcast … via MQTT on channel …\n- When you receive a message via MQTT on channel … store it in …\n\nBroker/TLS/auth/client-id are configured globally in app settings, and connect/subscribe happen lazily to avoid boilerplate (wildcard channels should store channel+message as JSON). Provide example projects for two multiplayer architectures:\n\n- one phone acting as a local hub (extending the existing Bluetooth multiplayer variables concept) and\n- a dedicated hub over local Wi-Fi (e.g., Mosquitto) coordinating multiple players. Also provide a Home Assistant-oriented topic convention under catrobat/… enabling wall-tablet dashboards and home automations (Tuya/Smart Life and other Home Assistant-supported hardware).\n\nEnsure reliability (reconnect/offline handling) and strong automated tests for core logic (especially topic-filter matching and message routing).\n\nTo apply for this project idea, please complete [this entry task](https://docs.google.com/document/d/1jw87hf8iq5DStlKOhT9yvQP7trsnzgZ6jYcH99BxBMs/edit?usp=sharing) and include the links to the requested demo artifact in your application.\n\n### SeaSee’r: Underwater Mapping and Exploration using Spatially anchored Panoramas\n\n350 Hours\n\n\nRequired Skills: Web Development (Full Stack), Web 3D Graphics, Real-Time Rendering, Python, Computer Vision, Git, REST APIs\n\nPossible Mentors: Benedikt Kantz, Tobias Schreck, Wolfgang Slany\n\nExpected Outcome: A navigatable underwater map based on real multimodal data from a remotely operated vehicle (ROV), including panorama (videos) and sonar dataDifficulty level: Advanced\n\nProject size: Large\n\nTask link:[View task]\n\nProject Description\n\nModern underwater ROVs provide a magnitude of different data streams in both real-time and post-operation for scientific application. There is, however, a lack of systems integrating the domain-specific requirements for navigating and exploring these data, especially for frequent site visits to study the behavior of marine creatures.\n\nThe project therefore proposes the creation of an open-source system to ingest data from the ROV and display the panorama images spatially anchored based on the position and orientation of the vehicle at the specific time stamps. The resulting interface should also incorporate multimodal data, i.e. sonar data and possible further data streams like point clouds directly into the visual exploration system. Once this basic visualization system is set up, specific exploration tasks can be implemented, such as:\n\n- Mission and path planning, with\n- Search for prior exploration passes for detailed mission planning at specific sites,\n- Point cloud stitching / Image registration to compare passes over the same regions,\n- Site Re-Identification even in noisy environments through multimodal data use, and possible\n- Registration of new images and feeds live (during missions) to improve the navigation accuracy.\n\nThe project serves as an exploratory foray into bringing advances in spatial exploration and mapping techniques below the sea, and requires an extensible and longevity-focused architecture to enable downstream additions of data modalities and different vehicle types. The specific mission planning aspects need to be flexible in their structure as well, to allow for a rapid evolution in supported planning tooling; as the scientific goals might shift over time – or new aspects of the marine life are discovered, requiring new paradigms.\n\n### Pocket Paint Flutter: backwards compatibility to old Android app\n\n350 Hours\n\n\nRequired Skills: Flutter, Dart, Android-Development, Agile Development\n\nPossible Mentors: Abdulbaki Celebi, Mario Kaurin, Julia Herold, Thorsten Bandel\n\nExpected Outcome: Compatibility of the Kotlin/Java version file formats in the new Flutter-based version\n\nDifficulty level: Medium to advanced\n\nThe developer should have knowledge of Flutter. Develop and implement missing tools in Flutter that exist in our old Android app built with Android Native.\n\n### Pocket Paint Flutter: antialiasing and smoothing (advanced options)\n\n350 Hours\n\n\nRequired Skills: Flutter, Dart, Android-Development, Agile Development\n\nPossible Mentors: Julia Herold, Thorsten Bandel, Abdulbaki Celebi, Mario Kaurin\n\nExpected Outcome: Add antialiasing and smoothing as advanced options\n\nDifficulty level: Medium to advanced\n\nTask link:[View task]\n\nThe developer should have knowledge of Flutter. Develop and implement missing tools in Flutter that exist in our old Android app built with Android Native.\n\n### AI Mentor for PocketCode Students\n\n350 Hours\n\n\nRequired Skills: Kotlin, Python, JavaScript, Android AI and ML Tools, Android-Development, Agile Development, Test Driven Development, Clean Code\n\nPossible Mentors: Paul Spiesberger, Wolfgang Slany\n\nExpected Outcome: An integrated proof of concept AI mentor within PocketCode\n\nDifficulty level: Advanced\n\nAI is now capable of sophisticated programming and can automate many coding tasks. More importantly, it excels at explaining code to students, making learning more engaging and accessible. Our goal is to integrate our AI-powered mentor, developed during GSoC 2025, into PocketCode. This mentor understands a student’s programming context and provides real-time guidance to enhance learning and coding skills. We already have an existing [AI Tutor SDK](https://github.com/Catrobat/catrobat-ai-tutor) and are now ready to integrate it into PocketCode and its derivatives to test and improve students’ experiences with PocketCode + AI.\n\nThe AI mentor could:\n\n- Explain programming concepts, ranging from variables and loops to software design patterns and testing strategies\n- Suggest code from text prompts, help debug issues and propose project ideas\n- Assist with code architecture, naming conventions and writing tests in the Catrobat language\n- Explain and translate downloaded projects from other users\n\nYou won’t need to implement everything—just focus on the part that excites you most! The Catrobat team will provide the initial prompt and the necessary API access or local LLMs for support.\n\n### Pin projects to the Android launcher (“Play as app” shortcuts)\n\n90, 175 or 350 hours\n\n\nRequired Skills: Kotlin, Android-Development, Agile Development, Test Driven Development, Clean Code\n\nPossible Mentors: Wolfgang Slany, Patrick Ratschiller, Paul Spiesberger\n\nExpected Outcome: Pin to launcher option and functionality to execute projects directly from launcher.\n\nDifficulty level: Advanced\n\nTask link:[View task]\n\nAdd support in Catrobat/Catroid so users can pin a project to the Android home screen with an app-like icon (project thumbnail + title). Tapping the pinned icon must start the project immediately in Play mode (no IDE screens), and exiting Play must not return to the IDE but instead close the task back to the launcher. Implement this via a dedicated shortcut entry point (trampoline) and a stable project identifier, with graceful handling if the project was renamed or deleted. Deliver strong automated tests for intent parsing, task/back-stack behavior, and the exit contract across common Android versions.\n\nTo apply for this project idea, please complete [this entry task](https://docs.google.com/document/d/14BSMYM7JiwKSqJHJIXSPfNT_PcyK9orRc68WhBzh-3o/edit?usp=sharing) and include the links to the requested demo artifact in your application.\n\n### Skeleton-Based Procedural Animation System for Marine Organisms\n\n350 Hours\n\n\nRequired Skills: Python, C#, Procedural Animation, Skeletal Systems, Blender Scripting, 3D Geometry, Git Version Control, GitHub, Understanding and integration of ML models, Unity, Blender\n\nPossible Mentors: Nikhil Ranjan Rajhans, Abha Kumari\n\nExpected Outcome: A reusable skeleton-driven procedural animation framework for marine animals\n\nDifficulty level: Advanced\n\nProject size: Large\n\nTask link:[View task]\n\nProject Description\n\nThis project focuses on creating a skeleton-based procedural animation system for marine animals generated via AI or procedural 3D pipelines. Instead of keyframe animations, animal motion (swimming, turning, fleeing, idling) will be generated dynamically using rule-based skeletal deformation and motion constraints.\n\nAnimations will be driven by behavior states and environmental conditions, allowing seamless integration with AI behavior engines and ecosystem simulations. The system will be lightweight, reusable, and suitable for real-time educational applications.\n\n### Gemini-Powered Ecosystem Narration and Analysis Interface\n\n175 Hours\n\n\nRequired Skills: Python, C#, LLM Integration, Prompt Engineering, Explainable AI, Simulation Analysis, Git Version Control, Understanding and integration of ML models, Unity\n\nPossible Mentors: Abha Kumari, Garima Jain, Kumari Deepika\n\nExpected Outcome: An AI-powered narration and analysis layer for marine ecosystem simulations\n\nDifficulty level: Average\n\nProject size: Medium\n\nTask link:[View task]\n\nProject Description\n\nThis project integrates a Gemini-based natural language interface to enhance accessibility and explainability of marine ecosystem simulations. The AI will provide real-time narration, ecosystem summaries, causal explanations, and natural-language spawning of marine organisms and environmental events.\n\nThe LLM will act strictly as an interface and explanation layer, translating simulation states into human-readable insights and structured ecosystem modifications, while core logic remains deterministic and transparent.\n\n### AI-Driven Dynamic Procedural Map Generation System\n\n175 Hours\n\n\nRequired Skills: C#, Procedural Generation, AI Simulation Systems, Spatial Data Structures, Noise Functions, Environmental Modeling, Behavior Modeling, Git Version Control, Auth, DBMS, Understanding and integration of ML models, Unity, Blender\n\nPossible Mentors: Kumari Deepika, Atharva Prashant Joshi\n\nExpected Outcome: A dynamically evolving coral reef environment guided by AI-driven simulation models\n\nDifficulty level: Advanced\n\nProject size: Medium\n\nTask link:[View task]\n\nProject Description\n\nThis project extends the mARine AR application by combining procedural generation with AI-based environmental intelligence to create marine ecosystems that evolve realistically over time.\n\nInstead of static procedural placement, the environment will be guided by AI models that simulate reef growth, ecological balance, and adaptive behavior. The system will use a seed-based deterministic generator enhanced by AI rules, ensuring synchronized AR experiences across devices while still allowing intelligent variation.\n\nThe system should generate:\n\n- AI-guided terrain topology — Terrain shaped using noise functions enhanced by learned patterns from real reef structures\n- Intelligent coral and flora placement — AI models determine clustering, competition, and growth patterns to mimic natural ecosystems\n- AI-driven environmental motion — Coral sway, particle flow, and micro-movements based on simulated currents and environmental forces\n- Ecosystem evolution over time — Coral growth, decay, and adaptation using rule-based AI or lightweight simulation learning\n\nAll generations must remain deterministic from a seed, with AI models acting as rule systems that produce identical synchronized environments across devices.\n\nThe final system should feel alive, it should be biologically plausible and continuously evolving.\n\n### Upgradation of AR-Based Interactive and Procedural Marine Ecosystem Simulation\n\n350 Hours\n\n\nRequired Skills: C#, Java, Unity, Vuforia SDK, AR Foundation, Firebase, Cloud, Git Version Control, GitHub, REST API, Auth, DBMS, Understanding and integration of ML models, CI/CD, Blender\n\nPossible Mentors: Krishna Mohan Patel, Himanshu Kumar\n\nExpected Outcome: A more realistic, scalable, and performance-optimized AR marine ecosystem platform\n\nDifficulty level: Advanced\n\nProject Size: Large\n\nTask link:[View task]\n\nDescription\n\nThis project focuses on upgrading and strengthening the existing AR-based marine ecosystem simulation platform built during the previous GSoC cycle. The aim is to enhance both scientific realism and system scalability, enabling more accurate ecosystem interactions and smoother deployment across mid-range mobile devices.\n\nThe upgraded version will improve procedural generation of marine environments (reef, interaction, deep ocean), introduce more advanced ecosystem behaviors (predator-prey cycles, habitat-based movement, climate-driven changes), and implement performance-critical improvements like optimized LOD pipelines, shader efficiency, and streaming-based spawning.\n\nAdditionally, this project will expand infrastructure support using Firebase, cloud-ready services, enabling user authentication, progress storage, module sharing, and future backend integration. Optional integration of lightweight ML models can be explored for behavior prediction, adaptive learning, or intelligent content recommendation.\n\n### AR Based Human Interaction Enabled Application for Marine Life\n\n175 Hours\n\n\nRequired Skills: Python, YOLO, MediaPipe, Pose Detection Algorithms, Machine Learning, C#, Unity, Vuforia SDK, AR Foundation, Firebase, Cloud, Git Version Control, GitHub, REST API, Auth, DBMS, Understanding and integration of ML models, CI/CD, Blender\n\nPossible Mentors: Udit Narayan, Nikhil Ranjan Rajhans\n\nExpected Outcome: A complete gesture-driven AR marine learning experience\n\nDifficulty level: Advanced\n\nProject Size: Medium\n\nTask link:[View task]\n\nDescription\n\nThis project is focused at extending the marine AR learning system by introducing a human-interaction enabled interface, allowing students to interact naturally with marine life using body gestures and pose-based controls.\n\nInstead of relying only on buttons and UI controls, users will be able to perform interactions such as interfering with a creature’s movement using hand gestures, triggering behavior events (octopus camouflage/ink defense etc.), interacting with the ecosystem through human presence and activities through the device camera.\n\nThe expected goal is to achieve a complete gesture-driven AR marine learning experience that improves immersion, accessibility, and interaction realism.\n\n### Extension of Sandbox Toolkit for simplifying the Development of Marine based AR Modules\n\n350 Hours\n\n\nRequired Skills: Java, C#, Unity, Unity Editor tooling, Vuforia SDK, ScriptableObjects, AR Foundation, Firebase, Cloud, Git Version Control, GitHub, REST API, Auth, DBMS, Understanding and integration of ML models, CI/CD, Blender\n\nPossible Mentors: Somya Barolia, Shivendra Verma\n\nExpected Outcome: A reusable Unity-based Marine AR Module Builder\n\nDifficulty level: Advanced\n\nProject Size: Large\n\nTask link:[View task]\n\nDescription\n\nThis project enhances our existing Marine AR Module Builder to make it significantly easier for educators and developers to create, package, and distribute marine AR modules without deep technical knowledge.\n\nThe extension will focus on improved editor tools for drag-drop environment creation, actor placement & configuration workflows, reusable behavior templates (movement, interactions, ecology rules), JSON/script-based module definition support, validation tools (missing assets, invalid scripts, performance warnings), alignment with marine curriculum and optional cloud syncing (module hosting+version control support).\n\nThe toolkit will be built as a modular Unity package so it can be reused beyond this project and integrated into other Catrobat AR education initiatives.\n\n### Web-Based Sandbox Toolkit for Marine AR Modules\n\n350 Hours\n\n\nRequired Skills: JavaScript, WebAR (WebXR), Three.js / A-Frame, HTML/CSS, Firebase, REST API, Git/GitHub, Basic Cloud & CI/CD, Blender\n\nPossible Mentors: Somya Barolia, Shivendra Verma\n\nExpected Outcome: A lightweight, reusable Web AR Sandbox Toolkit for marine education\n\nDifficulty level: Advanced\n\nProject Size: Large\n\nTask link:[View task]\n\nDescription\n\nThis project extends an existing Web-based Marine AR Sandbox Toolkit to simplify the development and deployment of marine-focused Web AR learning modules. The aim is to enable educators and developers to create interactive marine AR experiences directly from a browser without requiring deep AR or 3D programming expertise.\n\nThe extension will introduce a dashboard-based module builder where users can visually assemble marine scenes, place 3D marine organisms, configure basic interactions, and publish Web AR modules that run on mobile browsers.\n\nScope of Work\n\n- Browser-based dashboard for creating and managing marine AR modules\n- Drag-and-drop placement of 3D marine assets in AR scenes\n- Reusable behavior templates for basic movement and interactions\n- JSON-based module definition and export/import support\n- Validation checks for missing assets and basic performance limits\n- Cloud-hosted module storage and versioning using Firebase\n\nExpected Outcome\n\n- A lightweight, reusable Web AR Sandbox Toolkit for marine education\n- Simplified creation and sharing of marine AR modules via URLs\n- A foundation for extending Web-based AR learning across marine science topics\n\n### Blockchain-Based Ethical Governance for IoT Care Systems\n\n350 Hours\n\n\nRequired Skills: Strong programming fundamentals, smart contract development, blockchain architecture understanding, API design and system integration, security and access-control conceptsPossible Mentors: Garima Jain, Supreeth Kumar MDesirable Skills: Privacy-by-design principles, cryptographic hashing, regulatory-aware system designExpected Outcome: A complete blockchain-based consent and governance framework for IoT care systems\n\nDifficulty level: Advanced\n\nProject Size: Large\n\nDescription\n\nThis project focuses on designing and implementing a blockchain-based governance and consent framework for ethical IoT-based care monitoring systems. The objective is to ensure trust, transparency, data ownership, and immutable consent management for sensitive care-related data generated by IoT devices used in assisted living environments.\n\nRather than storing health data on-chain, the blockchain will act as a trust and audit layer, recording consent decisions, access approvals, role assignments, and accountability events.\n\nProblem Context\n\nIoT-based care systems face critical challenges:\n\n- Consent is often implicit, unclear, or changeable without traceability\n- Care data access decisions are difficult to audit\n- Families, caregivers, and supervisors rely on centralized systems with limited transparency\n- Ethical compliance relies heavily on documentation rather than system-level enforcement\n\nThis project addresses these issues by embedding ethical governance directly into system architecture using blockchain.\n\nTechnical Scope\n\n**A. Governance Model Design**\n\n- Definition of care-related roles (patient, caregiver, supervisor, relative)\n- Consent lifecycle modeling (grant, update, revoke)\n- Human-in-the-loop approval workflows\n\n**B. Blockchain Layer**\n\n- Smart contracts for:\n- Consent registration and revocation\n- Role-based access authorization\n- Event logging for care-related decisions\n\n- Immutable audit trail for:\n- Who approved what\n- When access was granted or revoked\n- Which role initiated the action\n\n\n**C. Off-Chain / On-Chain Architecture**\n\n- Sensitive IoT data stored off-chain\n- Cryptographic hashes and metadata stored on-chain\n- Blockchain used purely for verification, not data storage\n\n**D. Integration Interface**\n\n- APIs to connect IoT systems with the blockchain layer\n- Verification endpoints for access checks\n- Read-only audit views for compliance and evaluation\n\nExpected Outcome\n\nAt the end of the project, the contributor will deliver:\n\n- A complete blockchain-based consent and governance framework\n- Deployed smart contracts implementing ethical access control\n- API layer enabling IoT system integration\n- Demonstrable immutable audit trail\n- System architecture documentation and threat analysis\n\nThe result is a production-relevant governance layer, not a theoretical blockchain demo.\n\n### Gemini-API–Powered Intelligent Care Assistant\n\n350 Hours\n\n\nRequired Skills: Backend development, API integration, prompt engineering for structured systems, data processing and normalization, system-level reasoning\n\nDesirable Skills: Human-centered AI design, ethical AI concepts, evaluation of AI outputs\n\nPossible Mentors: Supreeth Kumar M, Atharva Prashant JoshiExpected Outcome: An AI-powered, ethically governed intelligent care assistant built on Gemini API\n\nDifficulty level: Intermediate to Advanced\n\nProject Size: Large\n\nDescription\n\nThis project aims to build an AI-powered intelligent care assistant using the Gemini API to support caregivers, supervisors, and families by converting raw IoT activity signals into context-aware insights, summaries, and alerts—while maintaining ethical, permission-based access. The focus is on responsible AI usage, ensuring that AI augments human decision-making rather than replacing it.\n\nThe assistant acts as an interpretation and explanation layer over existing IoT-based care systems, not as a surveillance or diagnostic system.\n\nProblem Context\n\nIoT care systems generate large volumes of low-level signals such as:\n\n- Activity logs\n- Time-based events\n- Movement patterns\n- Routine confirmations\n\nThese signals are difficult to interpret meaningfully and ethically in real time. Manual monitoring often leads to caregiver overload, missed anomalies, and increased anxiety among family members. This project introduces an AI interpretation layer that summarizes and contextualizes data while preserving human oversight.\n\nTechnical Scope\n\n**A. Data Interpretation Layer**\n\n- Structured ingestion of non-invasive IoT activity data\n- Time-windowed summaries of daily routines\n- Detection of deviations from normal patterns\n\n**B. Gemini API Integration**\n\n- Natural-language summaries of patient routines\n- Context-aware explanations for alerts (why an alert was triggered)\n- Ethical prompt design to avoid medical diagnosis or inference\n- Role-aware output filtering (different outputs for caregivers, supervisors, and relatives)\n\n**C. Human-in-the-Loop Controls**\n\n- AI outputs require supervisor validation before escalation\n- Confidence indicators and uncertainty explanations\n- Manual override and feedback loop for continuous improvement\n\n**D. Responsible AI Safeguards**\n\n- Prompt constraints and system instructions\n- No medical diagnosis generation\n- Explainability-first responses\n- Logging and review of AI outputs\n\n**E. Application & System Integration**\n\n- Integration with a secure care monitoring application featuring role-restricted dashboards\n- Support for voice-assisted interactions to improve accessibility for elderly users\n- Backend services handling ingestion, summarization, and alert generation\n- Secure authentication and role-based access to AI-generated insights\n\nExpected Outcome\n\nBy the end of the project, the contributor will deliver:\n\n- An AI-powered intelligent care assistant service\n- Gemini API–based summarization and explanation engine\n- Ethical prompt and output governance framework\n- Role-based AI response filtering\n- Demonstration of AI-assisted, human-approved alerts\n- Complete documentation and evaluation report\n\nThe outcome demonstrates applied, responsible AI in a real-world care context, not chatbot experimentation.\n\n### AR Rocket Builder & Space Flight Sandbox\n\n350 Hours\n\n\nRequired Skills: Augmented Reality (ARCore/ARKit), Physics Simulation, Rigid Body Dynamics, Vector Math, Orbital Mechanics Basics, Unity & Flutter 3D Integration, Firebase, Cloud Sync, Git Version Control, REST API, DBMS, CI/CD\n\nPossible Mentors: Himanshu Kumar, Abhishek Kumar\n\nExpected Outcome: An AR rocket construction and flight simulator where users build rockets in their real environment and launch them with physics-accurate behavior\n\nDifficulty level: Advanced\n\nProject size: Large\n\nTask link:[View task]\n\nProject Description\n\nThis project transforms the app into an augmented reality rocket engineering sandbox. Users build rockets on real-world surfaces using AR placement and modular components. The launch simulation applies thrust, drag, gravity, and fuel consumption in real time.\n\nRockets launch directly from the floor or table in the user’s environment. Failures such as imbalance, insufficient thrust, or structural instability are visualized physically, helping children understand engineering constraints.\n\nEducational overlays explain forces, center of mass, and orbital velocity using visual arrows and motion trails. The system supports multiple gravity presets (Earth, Moon, Mars) and replay tools to analyze trajectories.\n\nThe architecture will allow reusable rocket parts, physics presets, and AR experiment modules for future aerospace learning features.\n\n### AR Gravity & Planetary Physics Simulator\n\n175 Hours\n\n\nRequired Skills: Augmented Reality Rendering, Newtonian Physics Simulation, N-Body Systems, Numerical Integration, Real-Time Optimization, 3D Visualization, Flutter, Unity Firebase, Cloud Systems, Git\n\nPossible Mentors: Abhishek Kumar, Ashwani Kumar Moudgil\n\nExpected Outcome: An AR gravity sandbox where users create planetary systems in their room and observe real-time orbital mechanics\n\nDifficulty level: Advanced\n\nProject size: Medium\n\nTask link:[View task]\n\nProject Description\n\nThis project creates a real-time AR gravity sandbox where celestial bodies appear inside the user’s physical environment. Users spawn planets, stars, or asteroids on tables or floors and observe how gravity shapes motion.\n\nThe simulation implements Newtonian gravitational models with optimized solvers for mobile performance. Users can walk around their planetary systems, view orbits from different angles, and physically scale the simulation.\n\nEducational visualizations convert invisible forces into arrows, trails, and orbit predictions. Presets include solar systems, binary stars, asteroid collisions, and black hole experiments.\n\nThe system is designed as a reusable AR physics engine supporting scalable multi-body simulations for future educational modules.\n\n### AR Interactive Physics Playground\n\n350 Hours\n\n\nRequired Skills: AR Interaction Design, Physics Engines, Collision Systems, Real-Time Rendering, Mobile Optimization, Educational Game Design, Flutter, Unity, Firebase, Git, REST APIs\n\nPossible Mentors: Shivendra Verma, Himanshu Kumar\n\nExpected Outcome: A modular AR physics playground that lets children run real-world science experiments in their environment\n\nDifficulty level: Advanced\n\nProject size: Large\n\nTask link:[View task]\n\nProject Description\n\nThis project introduces an augmented reality science playground where children run interactive physics experiments in their surroundings. Objects can be placed on real surfaces and manipulated using gestures to test forces, motion, and collisions.\n\nMini-labs include pendulums, ramps, projectiles, levers, bouncing systems, and gravity experiments. Each experiment includes guided prompts and simplified explanations.\n\nThe playground acts as a reusable AR education framework where new experiments can be plugged in easily. It bridges abstract physics concepts with real-world spatial interaction.\n\n### Sentiment Analysis of Cephalopods\n\n350 Hours\n\n\nRequired Skills: Java, Python, Machine Learning, Deep Learning, Multi-Modal Modelling, Knowledge Distillation, Model Optimization Techniques, Computer Vision, Git Version Control, GitHub, REST API, Authentication\n\nPossible Mentors: Aryavardhan Sharma, Krishna Mohan Patel, Himanshu Kumar\n\nExpected Outcome: An open-source multi-modal pipeline for automated cephalopod behavioral sentiment analysis\n\nDifficulty level: Advanced\n\nProject Size: Large\n\nTask link:[View task]\n\nDescription\n\nCephalopods exhibit complex cognition and emotional-like behavioral states (stress, comfort, aggression, curiosity). However, interpreting their state currently requires expert manual observation and lacks scalable tools.\n\nThis project aims to develop an open-source pipeline that uses multi-modal data (behavioral video, bioacoustic data) using computer vision and advanced machine learning algorithms to automatically infer and classify behavioral sentiment states along with recording them for further analysis.\n\nThe expected outcomes are to contain of:\n\n- Dataset ingestion pipeline + preprocessing scripts\n- Multi-modal model baseline (video + optional audio)\n- Behavioral feature extractor (movement, postures, color/pattern changes)\n- Sentiment label classification system (stress/calm/curious/aggressive/etc.)\n- Training + evaluation scripts with metrics\n- Documentation + reproducible experiments\n- Deployment API, demo dashboard\n\nThe project will help researchers, aquaculture facilities, and education/science communities by providing reproducible tools for cephalopod behavioral analysis. The system will be designed with extensibility in mind, supporting future datasets, species, and deployment environments (edge devices compatibility as well).\n\n### Minimal Open-Source IoT Cloud Platform with Secure Device Access\n\n175 Hours\n\n\nRequired Skills: Python, REST API development, backend engineering fundamentals, HTTP and JSON, databases (SQLite, PostgreSQL, or time-series databases), basic web technologies (HTML, CSS, JavaScript), Git version control, GitHub\n\nExpected Outcome: A lightweight, open-source IoT cloud platform with secure device authentication, telemetry ingestion, persistent storage, and a web-based visualization dashboard\n\nDifficulty level: MediumPossible Mentors: Atharva Prashant Joshi, Shivendra VermaProject Size: Medium\n\nDescription\n\nThis project focuses on building a minimal and educational open-source IoT cloud platform that exposes the core principles of device-to-cloud communication in a clear and transparent way. Instead of relying on fully managed or proprietary IoT services, the platform emphasizes explicit implementation of authentication, access control, data ingestion, storage, and visualization.\n\nDevices will be able to register with the platform and receive unique API keys used to authenticate all telemetry ingestion requests. Incoming data will be validated, securely associated with the correct device, and stored persistently in a structured time-series format. This ensures that only authorized devices can submit data while keeping the system simple and easy to reason about.\n\nTo make the system observable and useful, a lightweight web-based dashboard will be developed. The backend will expose REST APIs that return stored telemetry data as JSON, while the frontend will render this data as interactive time-series graphs using open-source JavaScript charting libraries. Backend processing will focus on correctness, validation, and basic aggregation, while the frontend handles visualization and interaction.\n\nThe platform is intentionally scoped as a learning-oriented reference implementation rather than a production-scale IoT cloud. Emphasis will be placed on clean architecture, readable and well-documented code, automated tests for authentication and ingestion logic, and reproducibility. The resulting system will serve as a strong foundation for future extensions such as MQTT-based ingestion, certificate-based device authentication, or more fine-grained access-control mechanisms.\n\n### Your own Project Ideas …\n\n90, 175 or 350 Hours\n\n\nRequired Skills: Kotlin, Java, Android-Development, iOS-Development, Agile Development\n\nRequirement: self-organized work\n\nDifficulty level: advanced\n\nIn the last years we found that you have many great ideas and knowledge! We’re aware that there are many ways how to improve performance, reduce memory usage, make our services more stable and of course the code easier to maintain. We’re sure you do have ideas how to achieve this, although we may have never heard of this approach before -> that’s the great thing about Open Source! And well, that’s also the experience we made at last year’s GSoC - and we liked it!\n\nAlso new features or extensions for iOS and Android are welcome to be introduced to us. Help us to spread coding and Open Source!"
  },
  {
    "name": "PEcAn Project",
    "slug": "pecan-project",
    "tagline": "Develop and promote tools for ecosystem modeling",
    "description": "Climate change science has witnessed an explosion in the amount and types of data that can be brought to bear on the potential responses of the terrestrial carbon cycle and biodiversity to global change. Many of the most pressing questions about global change are not necessarily limited by the need to collect new data as much as by our ability to synthesize existing data. This project specifically seeks to improve this ability. Because no one measurement provides a complete picture, multiple data sources must be integrated in a sensible manner. Process-based models represent an ideal framework for integrating these data streams because they represent multiple processes at different spatial and temporal scales in ways that capture our current understanding of the causal connections across scales and among data types. Three components are required to bridge this gap between the available data and the required level of understanding: 1) state-of-the-art ecosystem model, 2) a workflow management system to handle the numerous streams of data, and 3) a data assimilation statistical framework in order to synthesize the data with the model.",
    "ideas_url": "https://pecanproject.github.io/gsoc_ideas",
    "website_url": "https://pecanproject.github.io/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "r",
      "docker",
      "api",
      "geospatial"
    ],
    "topic_tags": [
      "data science",
      "ecosystem models",
      "scientific visualization",
      "climate science",
      "Ecological Forecasting,"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/pecan-project",
    "ideas_content": "# GSoC - PEcAn Project Ideas\n\nPEcAn is an open-source ecosystem modeling framework integrating data, models, and uncertainty quantification. Below is a list of potential ideas where contributors can help improve and expand PEcAn. To get started contributing to PEcAn, check out [this guide](https://github.com/PecanProject/pecan/discussions/3469). Come find us on Slack to discuss. If you have questions or would like to propose your own idea, contact @kooper in or join our ** #gsoc** channel in Slack!\n\n## Project Ideas[](https://pecanproject.github.io#ideas)\n\nBelow is a list of project ideas. Feel free to contact the listed mentors on Slack to discuss further or contact @kooper with new ideas and he can help connect you with mentors.\n\n[Refactor and Parallelize Input Processing Pipelines](https://pecanproject.github.io#input)[Benchmarking and Validation Framework](https://pecanproject.github.io#validation)[Increase PEcAn modularity](https://pecanproject.github.io#module)[Standardizing Model Couplers Across Models](https://pecanproject.github.io#couplertools)[LLM-Assisted Extraction of Agronomic Experiments into BETYdb](https://pecanproject.github.io#llm-betydb)\n\n### 1. Refactor and Parallelize Input Processing Pipelines[](https://pecanproject.github.io#input)\n\nInput-processing code in PEcAn (e.g., meteorological preparation) is currently centered around monolithic orchestration functions such as `do.conversions`\n\nand `met.process`\n\n. These functions mix low-level data transformations with sequential control flow, implicit dependencies, and caching behavior, making them difficult to test, debug, scale, or parallelize across sites and ensemble members.\n\nThis project will deprecate `do.conversions`\n\nas currently implemented and replace it with input preprocessing workflows that are explicitly structured around data dependencies and are naturally parallelizable across data streams, sites, and ensemble members. The work will refactor or deprecate `met.process`\n\nto remove monolithic orchestration and reduce or eliminate opaque caching, while retaining and strengthening existing low-level transformation functions.\n\nAs part of the refactor, orchestration logic should be rebuilt to make inputs, outputs, and dependencies explicit. A workflow tool such as `targets`\n\nmay be used to help define and validate the dependency graph and caching behavior, but must not become a required or exclusive execution path for PEcAn.\n\nThis refactoring should also reduce or eliminate implicit dependencies on the global settings object (see Project 3), enabling clearer APIs and improved testability.\n\n**Expected outcomes:**\n\nA successful project would complete the following tasks:\n\n-\nDeprecation plan for do.conversions, with a replacement that provides a modular suite of preprocessing tools that\n\n- explicitly defines inputs and outputs, and\n- supports parallel execution across products, sites, and ensemble members. Key here is a high-level plan for development that will continue beyond what is accomplished this summer.\n\n-\nRefactor and/or deprecation plan for met.process that:\n\n- removes monolithic orchestration and hidden control flow,\n- reduces or eliminates over-engineered caching,\n- retains and documents low-level transformation functions.\n\n-\nDemonstration of parallel execution on a multi-site or multi-ensemble example.\n\n-\nBasic correctness and performance benchmarks, including unit and integration tests and validation of PEcAn-standard inputs (formats and units).\n\n-\nUpdated developer documentation covering:\n\n- the new input-processing architecture,\n- how to add a new preprocessing step,\n- migration guidance from legacy entry points.\n\n\n**Prerequisites:**\n\n- Required: R (existing workflow and prototype is in R)\n- Helpful: familiarity with parallel computing, workflow refactoring\n\n**Contact persons:**\n\nChris Black (@infotroph), @Henry Priest\n\n**Duration:**\n\nLarge (350 hr)\n\n**Difficulty:**\n\nHigh\n\n### 2. Benchmarking and Validation Framework[](https://pecanproject.github.io#validation)\n\nA key task in any modeling workflow is the validation of model outputs against held out observations. When a validation dataset is used repeatedly and agreed upon by a broad community to have particular value in assessing model performance it often gets elevated to the status of a persistent \"benchmark\" dataset. In PEcAn, there is a need to replace our earlier benchmarking module, whose design was never fully implemented, with a simpler framework. In designing this framework we'd encourage participants to build upon the existing low-level infrastructure in the existing benchmarking module for model-data alignment tools and comparison metrics like RMSE, MAE, and R2. Work should also build upon and generalize existing examples of \"one off\" validation scripts (e.g., CARB cropland validations, North American data assimilation validations).\n\n**Expected outcomes:**\n\nA successful project would complete the following tasks:\n\n- A high-level design and plan for development that will continue beyond what is accomplished this summer\n- Unit and integration tests\n- A generalized example of a validation workflow and/or notebook using California cropland datasets spanning multiple sites and crop types.\n- Documentation\n\n**Prerequisites:**\n\n- Required: R (existing workflow and prototype is in R), familiarity with statistical methods for model validation\n- Helpful: Familiarity with existing benchmarking workflow systems\n\n**Contact person:**\n\nDavid LeBauer (@dlebauer), Akash BV (@divine7022)\n\n**Duration:**\n\nFlexible to work as either a Medium (175hr) or Large (350 hr)\n\n**Difficulty:**\n\nMedium\n\n### 3. Increase PEcAn modularity[](https://pecanproject.github.io#module)\n\nExisting PEcAn workflows rely heavily on reading a large `settings`\n\nobject and writing .RData files or other opaque artifacts to disk to pass state between steps. This behavior reduces transparency, testability, and user understanding. The high-level goal of this project is to make PEcAn’s core functionality more modular and transparent, so that users can more easily build, maintain, and expand PEcAn workflows.\n\nThis project refactors a single, well-defined workflow so that functions return explicit R objects (e.g., data frames or lists) instead of relying on hidden on-disk side effects.\n\nTo minimize disruption with existing workflows, the preferred approach would be:\n\n- To begin by documenting existing functionality\n- Where needed, write tests for existing functionality\n- Document new functionality\n- Write tests for new functionality (TDD)\n- Refactoring of functions to return objects\n- Then refactor downstream functions use those objects\n- Only after that’s working, stop writing out the files.\n- If time permits, analyze how PEcAn's high-level modules are using the\n`settings`\n\nobject and, where possible, refactor function inputs to only pass the required subset of variables or variable lists. - Along the way, it would also be beneficial to reassess which functions need to be exported, with the idea that fewer exported functions would make it easier for new users to see what PEcAn’s core modules actually are, and better documenting the core functions and modules we expect users to need to learn/use\n\n**Expected outcomes**:\n\n- Refactored functions that return explicit R objects instead of writing .RData\n- Clear definition and doucmentation of object structures passed between steps\n- Backward-compatible wrappers where needed to avoid breaking existing workflows\n- Unit tests that no longer depend on on-disk state or output_dir\n- Documentation describing .RData deprecation, migration guidance, and examples\n\n**Skills Required**:\n\n- Required: R (existing workflow and prototype is in R) and R package development\n- Helpful: familiarity with code refactoring\n\n**Contact person:**\n\nMike @Dietze\n\n**Duration:**\n\nSuitable for a Medium (175hr) or Large (350 hr) project.\n\n**Difficulty:**\n\nMedium\n\n### 4. Standardizing Model Couplers Across Models[](https://pecanproject.github.io#couplertools)\n\nPEcAn models frequently duplicate similar logic for writing configuration files, translating meteorological inputs, and handling model-specific I/O. This copy–paste pattern increases maintenance cost and makes it harder to integrate new models consistently.\n\nThis project identifies a small set of shared configuration and I/O patterns and refactors them into documented helper functions with well-defined interfaces. Possible examples include netCDF reading/writing, parsing standardized input files, test fixtures, settings validation, and others. The approach should be demonstrated across a limited number of models coupler packages under active development.\n\n**Expected outcomes:**\nA successful project will deliver an inventory of duplicated configuration and I/O patterns along with one or more of the following steps toward deduplication:\n\n- Shared helper functions with explicit inputs, outputs, and unit conventions\n- Refactored model code using standardized helpers\n- Unit tests ensuring consistent behavior across models\n- Updated developer documentation describing standard interfaces and recommended usage\n\n**Prerequisites:**\nRequired: Proficiency in R\nHelpful: experience with unit testing\n\n**Contact person:**\nChris Black, @infotroph\n\n**Duration:**:\nMedium (175hr) or Large (350 hr) depending on number of deliverables\n\n**Difficulty:**\nMedium\n\n### 5. LLM-Assisted Extraction of Agronomic and Ecological Experiments into Structured Data[](https://pecanproject.github.io#llm-betydb)\n\nManual extraction of agronomic and ecological experiments from scientific literature into a structured format that can be used to calibrate and validate models is slow, error-prone, and labor-intensive. Researchers must interpret complex experimental designs, reconstruct management timelines, identify treatments and controls, handle factorial structures, and link outcomes with correct covariates and uncertainty estimates. Data are often reported as summary statistics (for example mean and standard error) in text, tables, or figures and require additional context from disturbance or management time series. These tasks require scientific judgment beyond simple text extraction. Current manual workflows can take hours per paper and introduce inconsistencies that compromise downstream data quality and meta-analyses.\n\nThis project proposes a human-supervised, LLM-based system to accelerate data extraction while preserving scientific rigor and traceability. It will leverage existing labeled training data (scientific papers with ground‑truth entries), including aligned PDF‑to‑structured‑data records from [BETYdb](https://betydb.org) and [ForC](https://forc-db.github.io/index.html), which represent expert‑curated, production‑quality datasets. Combined, these resources include over 80,000 plant and ecosystem observations from more than 1,000 sources, providing high-quality supervision for extraction from text, tables, and figures. Evaluation should include held-out, out-of-sample papers. The system will ingest PDFs of scientific papers and produce tables compatible with the [spreadsheet used to upload data to BETYdb](https://docs.google.com/spreadsheets/d/e/2PACX-1vSAa7jBHSaas-bH0ARxQjVLKhz3Iq03t97wrxMZrgVVi98L5bYQi5ZUC0b57xIZBlHEkPH9qYf22xQS/pubhtml) (sites, treatments, management time series, traits+yields bulk upload table) with every field labeled as extracted, inferred, or unresolved and linked to provenance evidence in the source document.\n\nThe architecture follows a two-layer design: (1) a schema-validated intermediate representation (IR) preserving evidence links, confidence scores, and flagged conflicts, and (2) a materialization layer that enforces semantics, validation rules, and generates upload-ready CSVs or API payloads with full audit trails. Implementation is flexible—ranging from agentic LLM workflows to fine-tuned specialist models to an adaptive hybrid—and should be informed by empirical evaluation during the project.\n\nImplementation is flexible—ranging from agentic LLM workflows to fine‑tuned specialist models to an adaptive hybrid—and should be informed by empirical evaluation during the project.\n\n**Expected outcomes:**\n\nA successful project would complete the following tasks:\n\n- IR schema definition with validation rules and documented field semantics covering sites, treatments, managements, and traits/yields\n- Modular extraction pipeline for document parsing, information extraction, and IR generation with clear separation between extraction and validation logic\n- Independent validators for BETYdb semantics, unit consistency, temporal logic, and required fields\n- BETYdb export module producing upload-ready management CSVs and bulk trait upload formats with full provenance preservation\n- Scientist-in-the-loop review interface for approving, correcting, or rejecting extracted entries with inline evidence and confidence scores\n- Evaluation harness with automated metrics for extraction accuracy, inference quality, coverage, and time savings relative to manual curation on held‑out test papers\n- Documentation covering IR schema specification, developer guidance for adding new extraction components, and user guidance for the review interface\n\n**Prerequisites:**\n\n- Required: Python; familiarity with natural language processing, information extraction, and machine learning\n- Helpful: experience with LLM APIs and fine-tuning frameworks, knowledge of BETYdb schema and workflows, familiarity with scientific writing and agronomic or ecological experimental design/analysis\n\n**Contact persons:**\n\nNihar Sanda (@koolgax99), David LeBauer (@dlebauer)\n\n**Duration:**\n\nLarge (350 hr)\n\n**Difficulty:**\n\nHigh"
  },
  {
    "name": "Neutralinojs",
    "slug": "neutralinojs",
    "tagline": "Lightweight cross-platform desktop app framework",
    "description": "Neutralinojs is a lightweight and portable desktop application development framework. It lets you develop lightweight cross-platform desktop applications using JavaScript, HTML, and CSS. You can extend Neutralinojs with any programming language (via extensions IPC) and use Neutralinojs as a part of any source file (via child processes IPC).",
    "ideas_url": "https://github.com/neutralinojs/gsoc2026/blob/main/project-ideas.md",
    "website_url": "https://neutralino.js.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "javascript",
      "node.js",
      "c++",
      "typescript"
    ],
    "topic_tags": [
      "app development",
      "framework",
      "cross-platform",
      "Desktop App Development",
      "lightweight framework"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/neutralinojs",
    "ideas_content": "## GSoC 2026 project ideas\n\nWe have listed some tasks we extracted from our prioritized feature requests. Discuss\nyour own ideas with us via [Discord](https://discord.gg/cybpp4guTJ) or email (`neutralinojs[AT]gmail.com`) or create a GitHub discussion thread. You can contribute to the Neutralinojs framework, CLI, client library, and templates with your innovative ideas.\n\nThank you for contributing to open-source 🎉\n\n _[Click here](./README.md) to go back to the GSoC getting started guide._\n\n### Neutralinojs builder: a CLI plugin to generate platform-specific app installers\n\nNeutralinojs CLI generates platform-specific binaries for Linux, macOS, and Windows with a platform-independent resource file. Neutralinojs application developers currently should use various tools to create application installers (i.e., AppImage, NSIS) for each operating system. However, we have no plans to add application installer generation support directly to the neu CLI codebase to keep the CLI implementation minimal and less platform-dependent. So, we would like to implement the platform-specific installer generator as a plugin for the official CLI within the official Neutralinojs GitHub organization.\n\nSkills required: Node.js, Neutralinojs, Application bundling on operating systems\n\nDifficulty rating: Medium\n\nProject size: ~350h\n\nMentors: Shalitha Suranga and Athif Shaffy\n\n#### Suggested technical decisions\n\n- Developing a CLI plugin for the solution.\n- Expose a new command to generate application packages.\n\n```bash\n# Installing the plugin\nneu plugins --add neutralinojs-builder\n\n# neu builder <target> <arch>\nneu builder nsis --x64 # NSIS setup for Windows x64\nneu builder deb --ia32 # Debian package for GNU/Linux ia32\nneu builder appimage --x64 # AppImage for GNU/Linux x64\nneu builder deb # GNU/Linux Debian packages for all supported CPU architectures\n\n# Use configuration from neutralino.config.json\nneu builder\n\n# Removing the plugin\nneu plugins --remove neutralinojs-builder\n```\n- If the developer runs `neu builder` without any parameters, get the targets from the config file:\n\n```json\n\"cli\": {\n  \"builder\": {\n    \"linux\": {\n      \"targets\": [\n        {\n          \"target\": \"deb\",\n          \"arch\": [\n            \"x64\",\n            \"ia32\",\n            \"armhf\"\n          ]\n        }\n      ]\n    },\n    \"win\": {\n      \"targets\": [\n        {\n          \"target\": \"nsis\",\n          \"arch\": [\n            \"x64\",\n            \"ia32\"\n          ]\n        }\n      ]\n    }\n  }\n}\n```\n- Implement package targets as internal plugins (import only required modules based on targets). Try to use modules like `targets/deb.js`, `targets/nsis.js` for dynamic loading.\n- Keep the codebase minimal by following design patterns and principles that the official neu CLI project uses.\n- Use the neu CLI core APIs from the plugin and avoid repetitive code between the neu CLI and Neutralinojs builder projects.\n- Recommend users to install the builder plugin from the neu CLI if they need app installers\n\n### Rendering a native loading animation before loading the app\n\nNeutralinojs renders the frontend web content of apps using platform-specific webview components without using a loading animation. The current implementation doesn't create any issues for small app frontends, but large frontends render a blank white screen at startup for a short period, affecting the software quality and usability. The blank white screen appears for a considerable time in low-end devices and when developers load remote URLs. The only workaround for this issue is hiding and showing the app when it's ready, but it slows down the initial visible rendering time for users. This project idea suggests implementing a native loading animation for all supported platforms as a default feature to fix the startup white screen issue.\n\nRelated issue: https://github.com/neutralinojs/neutralinojs/issues/814\n\nSkills required: C++, Neutralinojs, platform-specific GUI development frameworks (GTK, Windows API, and Cocoa)\n\nDifficulty rating: Medium\n\nProject size: ~350h\n\nMentors: Shalitha Suranga and Athif Shaffy\n\n#### Suggested UI/UX decisions\n\n- Use platform-specific spinner or infinite progress bar controls\n- Allow developers to use a custom GIF animation or a static image\n- Center the loading animation within the app window\n- Use proper background and foreground colors based on the current system theme\n- Indicate the loading state in the mouse cursor by using an appropriate built-in icon\n\n#### Suggested technical decisions\n\n- Use native, built-in GUI controls in each operating system for the default loader\n- Let developers use a GIF from app resources and override the default loader setting\n- Keep the implementation only within the C++ webview library codebase fork\n- Use the following configuration block in `neutralino.config.json`:\n\n```js\n\"window\": {\n  \"startupLoader\": {\n    \"type\": \"image\", // none, system (default), image\n    \"image\": \"/resources/images/loader.gif\"\n  }\n}\n```\n\n### Extending the existing native API with essential functions \n\nNeutralinojs offers a well-structured, cross-platform native API for app developers. The current native API offers many JavaScript functions under several namespaces that most app developers can use for building general cross-platform apps. However, the current native API doesn't offer solutions for every specific development scenario -- app developers sometimes have to write native extensions or implement platform-specific command-line solutions as workarounds to implement several features that the framework itself can embed. For example, there are no built-in APIs to retrieve network details, handle file permissions, etc. This project idea suggests that contributors conduct research for such missing framework features and implement them within the framework codebase.\n\nRelated issues: [neutralinojs/neutralinojs#issues](https://github.com/neutralinojs/neutralinojs/issues?q=is%3Aissue%20state%3Aopen%20label%3AAPI%20label%3Afeature-request)\n\nSkills required: C++, JavaScript, Neutralinojs, platform-specific native APIs (POSIX and Windows APIs)\n\nDifficulty rating: Medium\n\nProject size: ~350h\n\nMentors: Shalitha Suranga and Athif Shaffy\n\n#### Research ideas\n\n- Evaluate existing GitHub issues and discussions\n- Finding missing functions by comparing Neutralinojs with other frameworks and built-in Node.js APIs\n- Search forum threads created by mentioning missing native APIs in Neutralinojs\n- Prepare a list of functions that can be added to the framework without heavily affecting bundle size, performance, and code complexity\n\n#### Suggested technical decisions\n\n- Implement new function names, parameters, and return values strictly adhering to the existing native API design\n- Search for minimal, header-only libraries if the C++ standard library doesn't offer a solution\n- Implement functions in a way that eliminates security vulnerabilities"
  },
  {
    "name": "OpenMRS",
    "slug": "openmrs",
    "tagline": "Write Code, Save Lives.",
    "description": "OpenMRS provides the foundational, electronic medical record technology for more than 6,500 health facilities in over 80 countries, touching and helping millions of patients throughout  the world.  \n\nThe OpenMRS Community’s mission is to improve healthcare delivery in resource-constrained environments. \n\nWe coordinate a global community that creates and sustains a robust, scalable, user-driven and open-source medical record platform and reference frontend application.\n\nWe maintain a platform that countries and implementers use to create a customized EMR system in response to actual needs on the ground.",
    "ideas_url": "https://openmrs.atlassian.net/wiki/spaces/RES/pages/752844801/Summer+of+Code+2026",
    "website_url": "https://openmrs.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "mysql",
      "javascript",
      "java",
      "reactjs",
      "fhir"
    ],
    "topic_tags": [
      "platform",
      "frontend",
      "Electronic Medical Record System",
      "QA automation"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/openmrs",
    "ideas_content": "# Summer of Code 2026\n\n## Write Code. Save Lives.\n\n[OpenMRS](http://openmrs.org/) is hoping to be a mentoring organization for [Google Summer of Code™](http://g.co/gsoc) 2026! Since 2007, we've enjoyed participating in this great program and we're extremely excited about the projects and mentorship opportunities available this year. Coding for OpenMRS is a great way to practice your coding skills and, at the same time, help benefit people in developing countries who are on the front lines of public health challenges.\n\nIf you are new to **OpenMRS**, we recommend starting with our [Guide to the New & Curious](https://openmrs.atlassian.net/wiki/spaces/docs/pages/25477628). It will introduce you to our community, the tools and spaces we use, and help you get to know the different squads and teams working on various community projects. For a more detailed history of who we are and what we do, please see [here](http://guide.openmrs.org/en/Introduction/a-brief-history.html). If you’re new to OpenMRS or wondering how to get started with your GSoC application, this video should help answer a lot of your questions:\n\n**On this page ....**\n\n**Google Summer of Code at OpenMRS **[om.rs/gsoc](http://om.rs/gsoc)\n\nLearn more about Google Summer of Code 2026:[Google Summer of Code website](https://summerofcode.withgoogle.com/)\n\n\n**Helpful Links**\n\nCommunity GSOC Slack Channel:\n\non**#gsoc**[OpenMRS Slack](https://slack.openmrs.org/)GSOC Topics on the\n\n[OpenMRS Forum](https://talk.openmrs.org/c/community/gsoc/9)\n\n## GSoC 2026 Program Administrators\n\n@beryl @Jayasanka Weerasinghe\n\nPlease see [GSoC Admin Guidelines](https://openmrs.atlassian.net/wiki/spaces/RES/pages/26270205) for more information, or [ Org Admin Tips](https://developers.google.com/open-source/gsoc/help/oa-tips) and\n\n[.](https://summerofcode.withgoogle.com/rules)\n\n**Program Rules**## Project Ideas for GSoC 2026\n\nTalk Thread for Idea collection:\n\n[Brainstorming GSoC 2026 Project Ideas](https://talk.openmrs.org/t/brainstorming-gsoc-2026-project-ideas/47974)**Guide: Defining a Project Ideas List**[Defining a Project (Ideas List) | Google Summer of Code Guides](https://google.github.io/gsocguides/mentor/defining-a-project-ideas-list)\n\nThe following ideas are not fully finalized, and their requirements may change or they may be removed. Most of these projects didn’t make it into last year’s GSoC list, but that doesn’t mean they should be forgotten. If you’re passionate about any of them, you’re very welcome to start exploring and working on them with the community.\n\n|\n|\n|\n|\n|\n|\n|\n|---|---|---|---|---|---|---|\nMedium | Growth Charts are a common need in Primary Health Care for children (pediatrics). Growth Charts are available in O2, but never yet added to O3. With more and more implementers using O3 for care that involves infants, babies, and young children, we need Growth Charts in O3!\n| React | @Anjula Samarasinghe |\n|\n| |\nMedium | This project aims to enforce stricter TypeScript configurations across OpenMRS repositories, ensuring developers follow best practices for strong typing. The primary goal is to eliminate the use of By implementing stricter TypeScript settings and refining type definitions, this project will enhance code maintainability, reduce runtime errors, and improve the overall developer experience. | React, Typescript | @Christopher Lumu |\n|\n| |\nIntegrating Data Filter for Data Segregation / Multi-tenancy | Large | Data Filter is a powerful module that uses Hibernate’s filtering APIs to add additional where clauses to various SELECT statements. The use-case for this is to allow system-wide filters to be applied to the data added. Currently Data Filter includes a default set of filters that restrict the availability of data on patients to a set of locations a user has access to. The point of this project would be to expand on these capabilities to add things like: an administrative UI for associating users and patients with specific locations, additional rules to account for the various modules used in the O3 RefApp, templates for additional rules that may be useful (i.e., tie the ability to see obs with certain codes to certain privileges). | Java, Hibernate | @Joshua Nsereko\n| @Wyclif Luyima |\n|\nLarge | In the scope of the project would be (depending on the progress we make using other contribution channels): Adjust codebase across core and O3 modules to use a new storage service described [here](https://talk.openmrs.org/t/new-storage-service/44655).Adjust code in core and O3 modules to use distributed caching Experiment with Hibernate Search using OpenSearch as backend instead of a local Lucene index.\n| Java, Hibernate | @Rafal Korytkowski |\n|\n| |\nImproved Appointments Calendar View | Medium | We have an appointments calendar that is meant to give an overview of appointments. Unfortunately, it is currently less useful than it should be. A few things we need to address: the ability to drill-down into, e.g., monthly, weekly, and daily views; the ability to see all appointments, not just the number per service, instead of changing screens when clicking on a day or service, the app should likely display a modal; the calendar view should not be hard-coded around the Gregorian calendar, but support the various calendars from the @internationalized/date package. | React | TBA |\n|\n|\nMedium | We have a service queues app in O3, which is functional, but needs some attention, both to the frontend design and to the backend APIs that are used to populate it. The goal here would be to fix various UI issues and improve the overall performance and reliability of the queue module. The Service Queues view is incredibly useful for managing outpatient clinics, allowing users to track who is waiting for service, how long they’ve been waiting for etc. | React, Java | @Ian Bacher |\n|\n| |\n| Medium | Many OpenMRS implementers have used HTML Forms (HFE) for many years. Some organizations have **dozens or even hundreds**of OpenMRS forms encoded in HTML. This makes it intimidating to consider moving to O3, since O3 uses a custom Form Schema.There was a previous community project with scripts that help convert HTML forms into the O3 Form Schema for the Angular Form Engine. This did not convert 100% of the form into the new schema, but got most of it done (60-80%) so that it is faster for a team to work on the transition. This project needs to be (1) updated to enable implementers to convert HTML forms into the newer *React*Form Engine schema, and (2) documented to explain how to use it.\n|\n| @nethmi |\n|\n|\nDynamic EHR: Custom Home screen (and other screens) based on User roles, locations and other values. (\n| Medium | We would like to show UI elements on the O3 home page and other pages that are most relevant to the user. Currently, there is ability to do so based on User privilege. However, this is limiting and not general enough. We would like to define what to show based on other values, such as Location, currenting displayed Visit / Encounter, etc… More generally, this can be solved by having a way to write custom logic (in the form of a reduced set of JavaScript expressions) to define whether an Extension should be shown. There is actually something (what?) similar in O2 already. We should be able to inject dynamic variable\n| React |\n|\n|\n|\n(Definitely a priority - either GSOC 2026 or anyone who’s interested in meantime) | Large | Voiding in OpenMRS is a form of soft-deleting. We basically set a binary column to |\n| @dkayiwa |\n|\n|\nBetter way to receive feedback from clinicians / users\n|\n|\n|\n|\n|\n|\n|\nPostgres support? |\n|\n|\n| @Wikum Weerakutti |\n|\n|\nPatient Visit Summary Printing | Medium | Requested by the Uganda team, the DRC team, and Palladium [Requirements](https://openmrs.atlassian.net/wiki/spaces/projects/pages/edit-v2/473333762)are documented and readyBuilds on the recently completed printing support Addresses real implementation needs\n| Java, Hibernate, Spring\n| @Veronica Muthee |\n|\n|\nA Native O3 Frontend for the Audit Trail. | Small |\n| React, Typescript | SolDevelo |\n|\n|\n\n\n## Program Timeline\n\nLook [here](https://developers.google.com/open-source/gsoc/timeline) for more info on the full GSoC 2026 program timeline.\n\nIn Progress\n\n**GSoC 2026 preparations:**Community Brainstorming\n\n## Guidelines\n\n**Student's guidelines****Mentor's guidelines****Mentor Guide**[https://google.github.io/gsocguides/mentor/](https://google.github.io/gsocguides/mentor/)**Roles and Responsibilities**[https://developers.google.com/open-source/gsoc/help/responsibilities](https://developers.google.com/open-source/gsoc/help/responsibilities)**Org Admin Tips**[https://developers.google.com/open-source/gsoc/help/oa-tips](https://developers.google.com/open-source/gsoc/help/oa-tips)**Defining a Project Ideas List**[https://google.github.io/gsocguides/mentor/defining-a-project-ideas-list](https://google.github.io/gsocguides/mentor/defining-a-project-ideas-list)**Program Rules**[https://summerofcode.withgoogle.com/rules](https://summerofcode.withgoogle.com/rules)**GSoC Discord Chat channel**[discord.gg/google-dev-community](http://discord.gg/google-dev-community)\n\n\n## OpenMRS resources to know\n\nGitHub:\n\n[https://github.com/openmrs](https://github.com/openmrs/openmrs-core)Talk Forum:\n\n[https://talk.openmrs.org](https://talk.openmrs.org)Help Desk:\n\n[https://help.openmrs.org](https://help.openmrs.org)Issue Tracker (JIRA):\n\n[https://issues.openmrs.org](https://issues.openmrs.org/browse/LBAC-25)"
  },
  {
    "name": "CCExtractor Development",
    "slug": "ccextractor-development",
    "tagline": "TV, Rust, Flutter, Linux, VR and C. In any order.",
    "description": "CCExtractor Development is the creator of the de-facto captions extraction tool - CCExtractor. It is the one tool that is free, portable, open source and community managed that can take a recording from a TV show and generate an external subtitle file for it.\n\nIf you regularly watch content with subtitles you download from fan sites - you should know that the source file is most likely generated by CCExtractor. If you are a student in a university that uses subtitles for natural language study, you should know that most likely we are involved somehow.\n\nWhile we already support subtitles from North America, Europe, Australia and more, our world map is not yet complete. We are actively looking for students that want to help us fill the gaps. We also want to automate many of the processes that are currently done manually, such as achieving perfect sync, our media file management.\n\nIn addition to continuously evolve our core tool, we have a growing number of new projects: support, AI, rclone, cloud, flutter, peer-to-peer and a few more that are starting to take shape.\n\nThe best part is - students have flexibility of choosing projects from a wide range of topics & technologies and even propose their own. We provide exceptional resources for students. Read more about the perks on our website.\n\nWe’re very excited to take part in GSoC for the 9th time. Most of our past students are still involved and are active in the community, which simply goes on to show how friendly and approachable is the environment. If you want to be a part of such community and help achieve our goals, come join our Slack group or mailing list!",
    "ideas_url": "https://ccextractor.org/docs/ideas_page_for_summer_of_code_2026/",
    "website_url": "https://www.ccextractor.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "linux",
      "rust",
      "flutter"
    ],
    "topic_tags": [
      "vr",
      "linux",
      "video",
      "subtitles",
      "mobile"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/ccextractor-development",
    "ideas_content": "# Google Summer of Code (GSoC) 2026 ideas page\n\n**Important:**Please read our\n\n[AI Policy](https://ccextractor.org/public/gsoc/ai_policy/)before submitting any PRs.\n\nFor classic, niche project ideas, check out the [Classic Projects page](https://ccextractor.org/docs/classic_ideas/).\n\n**NEW: Office Hours**\n\nStarting **February 8, 2026**, we will be holding **weekly office hours every Sunday** (depending on your timezone).\nThis is an open session where you can drop in, ask your questions, and have a conversation with an\n**org admin and/or mentor**—maybe more. There's no need to be formal, and if you're shy, you don't even have to turn\nyour camera on.\n\nTo join, simply use this ** Google Meet link**. The sessions will begin at\n\n**10:30 AM San Francisco Time**, which serves as the official reference time.\n\n\nThere is **no fixed agenda** for these meetings. Whether you want to ask about **GSoC, the organization, your project,\nor anything else**, you're welcome to join. If others are discussing something, you can also stay and listen. We will\nbe available for **at least 30 minutes**, but if a conversation is ongoing at **9:00 AM San Francisco Time**, we'll\n**continue as long as needed**.\n\nFeel free to drop by, ask questions, or just hang out. We look forward to seeing you there!\n\nWelcome to our ideas page. It's great you want to start early. Please join us in our Zulip space! (we'll leave this as an exercise for you to find --- it's on our website).\n\nAs you will see, this year has a lot of Rust. The reason is simple: Security. Our C code base has known (and we suspect, a lot of unknown) security issues caused by the usual memory management in C. Lots of people have touched the code over the years, and it shows.\n\nThere's also Flutter, which we love, and more.\n\nWe will provide resources for students --- we'll give access to a high-speed server, all our samples (we'll even ship a portable drive with them anywhere in the world, so don't worry about slow connections) and various other perks.\n\nYou are welcome to check out the page (actual ideas at the bottom of the page, with each project having it's own separate page as well) and start early in the community bonding process as well as learning a bit about our code ethics and practices. And of course, we'd love you to stay around even if we are not invited to GSoC or if we cannot invite you as a student.\n\n#### The ideas we currently have\n\nImportant: If you have something else in mind that relates to subtitles and accessibility please get in touch. We prefer that you do something that you are passionate about even if it's something we hadn't considered.\n\nAfter you check out our ideas please continue reading to the bottom of the page to get information about who we are, how we collaborate, what resources we will provide to you, etc.\n\n#### Niche ideas\n\nWe've moved the less mainstream ideas to their [own page](https://ccextractor.org/docs/classic_ideas/)\nThese ideas are not less important, but because they require more specialized skills (or mindsets) we've decided to\ngive them a place of their own :-) Please take a look after you are done with this page; maybe something there will\npick your interest.\n\n#### CCExtractor Core\n\nSince we are now feature complete, and the subtitles work have changed a lot (We won! Almost everything is subtitled now!) it's time to settle down, prepare a perfect, stable, battery included release so we can rest on our laurels for a bit after a fantastic run on our core tool.\n\n| Name | Description | Tech you need to know | Tech you will learn | Difficulty | Size |\n|---|---|---|---|---|---|\n|\n\n[Sample Platform NG](https://ccextractor.org/public/gsoc/2026/sample_platform_ng)#### Flutter\n\n| Name | Description | Tech you need to know | Tech you will learn | Difficulty | Size |\n|---|---|---|---|---|---|\n|\n\n[support more torrent clients](https://ccextractor.org/public/gsoc/flutter-more-clients)[Flood](https://flood.js.org)and[Deluge](https://deluge-torrent.org).[TaskWarrior](https://ccextractor.org/public/gsoc/2026/taskwarrior)#### Systems\n\n| Name | Description | Tech you need to know | Tech you will learn | Difficulty | Size |\n|---|---|---|---|---|---|\n|\n\n[Add complex layouts to sway](https://ccextractor.org/public/gsoc/2026/sway_complex)[Task Server III](https://ccextractor.org/public/gsoc/2026/taskserver)#### New things we're currently interested on\n\n| Name | Description | Tech you need to know | Tech you will learn | Difficulty | Size |\n|---|---|---|---|---|---|\n|\n\n`.desktop`\n\nfiles are used by app launcher to provide access to additional functionalities, typically via context menus. Ilia is an app launcher that currently doesn't support for Desktop Actions due to its keyboard based approach.#### About us\n\nWe are a small org, which means that your contribution will have a large impact. It's not going to mean a 0.5% improvement on a big project --- it's going to be more than 10% on a medium size one. If you like challenges and want a chance to shine this is your place.\n\nWe have *we think* statistically amazing continuity in the team: Most\nGSoC students from all the past years are still involved, even if they\nare no longer eligible as students. They still contribute code, and they\nmentor both in GSoC and the sister program GCI. As mentors, they also\ncome to the Summer of Code summit which traditionally takes place in\nOctober.\n\nWe have *mentors all over the world* (North America, Europe, Asia and\nAustralia), so time zones are never a problem. Our main channel of\ncommunication is a [Zulip instance](https://ccextractor.org/public/general/support) to\nwhich everyone is welcome. We expect all accepted students to be\navailable on Zulip very often, even if you don't need to talk to your\nmentor. This will help you ask questions when necessary, and you might\nbe able to help others out as well while working on your project.\n\nException: If your country (such as **Russia**) has banned Zulip please get in touch in we'll work out a solution with you. We absolutely want you to participate.\n\n**All our top committers will be mentoring**. Many of them are former GSoC students or winners of GCI.\n\n#### Perks\n\nAll accepted students get a programming book or course immediately after being accepted, with the hope that they read them before the coding starts. We want to see if this increases the quality of the work. You can pick any programming book or course under 100$, and we will provide it.\n\n#### About what we use\n\nThis is what we use **today**. It doesn't mean this is what we want\nto continue using. Probably not --- we're really open to change. We're\njust describing the status quo so you know what you are getting into :-)\n\nThe core tool that names the organization (CCExtractor) is a\ncommand-line program written in **C** (not C++), and new core parts are being written in **Rust**.\n\nThe current GUI is written in **flutter**.\n\nThe testing tool we use to run regression tests is mainly written in\n**Python**, but it also used Javascript, CSS and some shell\nscripting. The Test suite is written in C#. One of the projects this\nyear is to move it from a dedicated server to GSoC and improving the scalability of test runs.\n\nThe prototype real time subtitle website is written in **NodeJS**.\n\nWe also have a number of support tools that do a number of different\nthings, from downloading subtitles from streaming services to\ntranslating them with Google Translate or DeepL. Most of them are\nwritten in **Python**, but since they are small tools that do their\njob you don't need to worry much about them.\n\nFor totally new things you can use whatever tool you feel is best for the task at hand.\n\n#### About sample media and other resources\n\nWe work with huge files. Not all of them are huge, but many are. We know that many students don't have access to high speed internet. To those students we will ship (as soon as they are selected) a portable hard drive with all our samples. So if your internet connection is not good, don't worry --- as long as you can plug a USB drive to your development computer you can participate with us.\n\nWe also have a shared Linux development server with lots of storage and a Gigabit uplink. Students get an account on it and they are welcome to use it. There's nothing there except our own work, so it's a trusted environment (for a server that is connected to internet of course).\n\nThe sample platform also hosts a bunch of samples, both which are small or decently sized.\n\nSome projects have specific requirements, and we'll make sure that you get the resources you need: i.e. if your project requires some cloud resources (Google Compute Engine, for example), we'll make sure you get access to the resources.\n\nIn general, you are not expected to pay for anything (other than your own development computer and internet, of course) related to any project.\n\nIf you need anything not mentioned (such as a book) let us know. Within reason, we'll help you.\n\n#### About the projects and getting accepted\n\nQualification: Our selection system is based on several factors. Of course no student ranks in all criteria, so don't worry when you read the list below.\n\n**Work on our core tool**: Even if you are going to be working\non something totally different. This might seem counterintuitive,\nbut the thing is if you prove you can dig into our\n(messy) code base, find yourself your way around it, and fix a\nfew bugs, you are just the kind of person we can trust to\n\"figure things out\". GSoC is among other things, a learning\nexperience. No matter what project you decide to work on,\nthere's going to be roadblocks, things you don't know how to\ndo, etc. So we really like it when students embrace those\nsituations.\n\n**Qualification tasks specific to the project**: The detail page\nfor some projects contains specific qualification tasks that\napply to them.\n\n**Contributions to existing open source projects**: This can be\nanything. From a good GitHub profile to pull-requests sent to\nany other existing project, participation in hackathons, Google\nCode-In, past GSoCs and so on.\n\n**A good proposal**: This is the one criteria that is\nnon-negotiable. Your proposal has to be good, period.\n\n**Project popularity**: Some ideas just have more competition,\nso if participating in GSoC is a top priority for you (over\nworking on a specific project), consider applying to one of the\n\"niche\" ideas. After all, that's a great way to get your foot\nin the door :-)\n\n**Best core tool tasks**\n\nWe're added a difficulty level to most of our [open issues on GitHub](https://github.com/CCExtractor/ccextractor/issues).\nBest thing you can do is head there and see if you are able to fix some\nof the easy ones and work your way up. We don't expect you to be able\nto do the hard ones, but we'd be impressed if you did :-)\n\nFor some of the easy ones you don't even need to know C. Just being able to compile CCExtractor and dig around a bit will be enough.\n\nThe sample platform's issues are tagged with \"gsoc-proposal-task\", so you can easily see what you can work on.\n\n### Take home qualification tasks\n\nIf instead of working on existing code you'd prefer to show us your\nskills working on something new, you can pick one of [these projects](https://ccextractor.org/public/gsoc/takehome).\n\n#### Community etiquette\n\nIt goes without saying that everyone in the community has to be polite and respectful, and consider everyone else a member of a team and not a competitor.\n\nAll developers are part of the team, by the way. Our Zulip instance has mentors, code-in participants, other students, or developers and users that are none of the above, but they all play some kind of role in CCExtractor's community.\n\nPart of being respectful is giving consideration to everyone else's time. Most of us have day jobs, and as such are limited in the time we can use to guide you. We'd like to spend it on quality discussions, and not on things that are for example written on this website, things that you can easily retrieve by reading documentation on used libraries or on the software's help screen. Asking this kind of questions in the Zulip instance shows little respect for our time. This doesn't mean you can't ask questions, but remember that being a clueless user and a lazy developer are two very different things. If you ask those questions you will probably get an answer as if you were a clueless user (polite no matter what), but if you apply to GSoC you will be considered a lazy developer. Google is your friend ;)\n\nTell things as you see them. Politely -you're not Linus-, but don't sugar-coat it. We know some parts of our code is poorly written, poorly documented, etc. It stands out, so you will know when you dig in. No one is going to be offended by having that code rewritten or refactored. Peer review applies to everybody's work and is done by everybody.\n\n#### Cross project proposals\n\nBecause we use a number of libraries and in fact \"are a library\" ourselves (meaning other programs can link CCExtractor as a library, or invoke the binary) we interact with other communities and their software. From time to time there's a chance to do something interesting that affects CCExtractor and something else (FFmpeg comes to mind, but also Kodi, VLC, libGPAC, Red Hen, to mention just a few of our friends that typically participate in Summer of Code). So how does this work? As long as the work benefits CCExtractor, and it's part of your summer project, we're OK with you spending some time on the other project. For example if you are improving our MP4 support, for which we use libGPAC, and need to fix or improve something on libGPAC you are welcome to do so. If you do, make sure you submit your changes to their maintainers and follow through with their merge process.\n\n#### Your proposal\n\nYou can propose to do any of the following ideas, or you can bring your own. In any case, make sure you run them by us before you actually submit your proposal.\n\nAt the very least your proposal needs to:\n\n- Explain what you want to do, why it is important to you (don't make up a story here — the reason can be that you need it, that you just think it's cool, that you have an itch to work on it, etc.), and why it could be important or useful to us.\n- Explain how you intend to accomplish the goal, in enough detail that makes it clear that you have done your homework. For example, \"I will modify the CCExtractor binary so that it's able to convert audio to text with perfect accuracy\" is the same thing as sending your proposal to the trash. You need to have a plan.\n- Detail the timeline explaining what the expected progress is for each week or every two weeks (pay special attention to the milestones within the GSoC timeline itself, of course) and how we should validate the results.\n- Detail what kind of support you will need from us. For example, if you are going to need test streams, hardware, access to a server, etc., let us know, so we can prepare everything for you as soon as possible.\n- Detail your expected working hours in UTC. We're used to weird working schedules, so don't worry about working in the middle of the night, or weekends instead of other days, etc. Knowing your hours may help us to match you better with a mentor.\n- Mention your planned absences. We don't need you to detail what you will be doing when you are not working of course, but if you are going away for any reason we need to know so we don't think you've abandoned.\n- Link to your GitHub (or any other repository) profile, if you have one, so we can take a look at your previous work.\n- GSoC is a coding program: This means that ideas that are about testing (unless it involves coding something to test our programs ;) ), website design, etc., are out.\n- However, we want to have good documentation: Make sure you have time to write a good technical article explaining your work.\n- Be realistic and honest with the timeline. Consider each week you should work around 30 hours. If your timeline reserves a lot of time for minor things we'll think that you are not going to be working full-time in GSoC. On the other hand if you promise to do things in a lot less than that it seems realistic to us, it will seem that you don't really know how much work things take.\n- If you are going to be using 3rd party libraries (that's OK), make sure to validate that their license is compatible with GPLv2 (which is ours). List the libraries in your proposal. Check that they are cross-platform. If you will need to extend those libraries in any way please explain. In this case, your proposal should include time to get that extension submitted to the maintainers (we love to contribute to other projects).\n\nSomething else: Mentors often have their fingers in several pies. If you send the same proposal to several orgs everyone will know. So do yourself a favor and don't do that. You can apply to several organizations and that's totally fine, but each organization will want to see that you have put the time to write a great proposal that is focused on them."
  },
  {
    "name": "LibreHealth",
    "slug": "librehealth",
    "tagline": "Healthcare for Humanity",
    "description": "LibreHealth is the foundation of a worldwide ecosystem of open source Health IT innovation and is a place where people can come together to build tools that enhance the quality of healthcare around the world.\n\nWe currently have under our umbrella the following projects:\n\n- LibreHealth Toolkit (http://librehealth.io/projects/lh-toolkit/), a foundational base for - building Health IT tools\n\n- LibreHealth EHR (http://librehealth.io/projects/lh-ehr/), an electronic health record derived from best practices and technology from leading open source systems.\n\n- LibreHealth Radiology (https://librehealth.io/projects/lh-radiology), a specialized distribution of LibreHealth Toolkit customized for radiology healthcare professionals\n\nOur GSoC student projects will address the real-life needs of our projects to help improve the delivery of health care around the world. We have a team of expert mentors with decades of experience to help you in your work. They will be continually adding project ideas to our forum (https://forums.librehealth.io), and we encourage you to suggest ideas too as you learn more about our projects.\n\nCheck out project ideas (this will change from year to year): https://forums.librehealth.io/ideas",
    "ideas_url": "https://forums.librehealth.io/ideas",
    "website_url": "https://librehealth.io",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "android",
      "java",
      "dart/flutter"
    ],
    "topic_tags": [
      "web",
      "deep learning",
      "hfoss",
      "radiology",
      "mobile apps"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/librehealth",
    "ideas_content": "[LibreHealth Accepted into Google Summer of Code 2026](https://forums.librehealth.io/t/librehealth-accepted-into-google-summer-of-code-2026/5344)\nWe have been accepted into Google Summer of Code 2026 (GSoC)!!!\nThe timeline is as follows (we have no control over this aspect; Google sets the timeline, not us):\n2026-02-19T18:00:00Z (UTC): Google announces the list…\n|"
  },
  {
    "name": "Learning Equality",
    "slug": "learning-equality",
    "tagline": "Building equity in education to transform lives",
    "description": "Learning Equality is an education technology nonprofit focused on fostering  student-centered learning and advancing organizations working with underserved teachers and learners globally. Through community-driven innovation and strategic partnerships, we provide offline-first, open-source digital tools and implementation support to help them thrive.\nWe create and support open-source technology that directly and focally addresses the infrastructural and resource equity gaps that further marginalize learners with limited Internet. We started by enabling offline access to Khan Academy's videos and exercises and grew to become a key player in the global education technology landscape. For the past 13 years we’ve focused on boosting learning outcomes in some of the most challenging contexts, supporting disconnected learning in refugee camps, rural schools, out-of-school programs, and more.\nLearning Equality develops and maintains Kolibri, an adaptable set of open tools specially designed to support teaching and learning with tech but without the Internet for the third of the world that still lacks access to connectivity.\nKolibri is centered around an offline-first learning platform that runs on a variety of low-cost and legacy devices. It is complemented by a curricular tool, a library of open educational materials, and a toolkit of resources to support training and implementation. These tools are open and available in a variety of languages to better support learners and educators globally.\nAs a community-driven nonprofit, Learning Equality works closely to co-design Kolibri with a core network of collaborators, including national NGOs, UN agencies, government, and corporate partners. We also adopt a needs-based approach, constantly gathering insights from our community to inform the development of our tools.\nThrough its do-it-yourself adoption model and strategic collaborations, Learning Equality has conservatively reached  13 million  learners and educators in every country in the world. Given our offline access and distribution model, we learn about usage of Kolibri through a combination of telemetry ping backs of high level, aggregate, anonymized statistics, data from partners, and use of our Kolibri Data Portal. Since instances of Kolibri never need to connect to the Internet to be used, we do not know about usage across every instance, which is why this is an informed estimate from years of data.",
    "ideas_url": "https://docs.google.com/document/d/e/2PACX-1vShAAywLDbBu5WH-Wv44rxetISCOQmHxBwxDw63Nt_OcpPVIZW2jjT8sd_GLTpeNvspze8W-_c9JUdl/pub",
    "website_url": "https://learningequality.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "django",
      "vue.js"
    ],
    "topic_tags": [
      "education",
      "distributed databases",
      "offline",
      "learning"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/learning-equality",
    "ideas_content": "[Learning Equality](https://www.google.com/url?q=https://learningequality.org/&sa=D&source=editors&ust=1771587966480202&usg=AOvVaw1EFFD0t0QIMispTQ2FVm59) is an education technology nonprofit that develops and maintains [Kolibri](https://www.google.com/url?q=https://learningequality.org/kolibri/&sa=D&source=editors&ust=1771587966480358&usg=AOvVaw0nY7qetn26pshduJqqfxxw), an adaptable set of open tools specially designed to support teaching and learning with tech but without the Internet for the third of the world that still lacks access to connectivity.\n\nKolibri is centered around an offline-first learning platform that runs on a variety of low-cost and legacy devices. It is complemented by a curricular tool, a library of open educational materials, and a toolkit of resources to support training and implementation. These tools are open and available in a variety of languages to better support learners and educators globally.\n\nAs a community-driven nonprofit, Learning Equality works closely to co-design Kolibri with a core network of collaborators, including national NGOs, UN agencies, government, and corporate partners. We also adopt a needs-based approach, constantly gathering insights from our community to inform the development of our tools.\n\nThrough its do-it-yourself adoption model and strategic collaborations, Learning Equality has reached approx. 13M learners and educators in every country in the world.\n\nIf you are interested in knowing more about our GSoC project ideas, Kolibri or Learning Equality, send us an email to [gsoc@learningequality.org](mailto:gsoc@learningequality.org), and we will invite you to join our #gsoc-2026 Slack channel! We hope to see you soon!\n\n[Introduce user-generated UI themes in Kolibri to support accessibility and customization](https://docs.google.com#h.hfz6c4bl8ifv)\n\n[Implement an accessible, prototype multi-select dropdown component](https://docs.google.com#h.y0fvx4cvg7jv)\n\n[Update EPub rendering to a safely sandboxed viewer, using the maintained foliate-js library](https://docs.google.com#h.x1f7pytd3oan)\n\n[Learner Facing QTI Interactions](https://docs.google.com#h.6nmc2npa81c8)\n\nImplement automated accessibility testing on Kolibri\n\nEnable device owners and learners to customize the visual theme of Kolibri through a UI, including predefined accessibility themes and individual adjustments for contrast, text size, and line spacing.\n\nKolibri supports theming through code-level customization using theme tokens defined in packages/kolibri/styles/internal/themeSpec.js, but there is no user interface for applying or customizing themes. This prevents device owners from branding Kolibri for their programs and prevents learners from adjusting visual settings for accessibility needs (high contrast, larger text, increased line spacing).\n\n- Implement predefined themes (Default Kolibri, High Contrast, Dark Mode) and accessibility (Larger Text +125%, Increased Line Spacing +150%) with mutually exclusive and combinable color themes.\n- Create theme settings UIs for device owners (device-wide) and learners (personal overrides), with preview functionality before applying changes.\n- Extend database models and build backend API endpoints to store and retrieve theme preferences with proper permissions and hierarchy (device-wide as default, user-level overrides).\n- Ensure theme changes apply reactively across all Kolibri plugins and pages, meeting WCAG 2.1 Level AA standards.\n\nDevice owners can set branded themes device-wide, and learners can customize accessibility settings for their personal needs, with changes saved per user and meeting WCAG 2.1 Level AA standards.\n\nTo be confirmed. Please check back on 2 March, 2026 for final updates.\n\n- Full stack development (Vue.js/Javascript, Django)\n- Web accessibility\n- HTML/CSS\n\n175 hours in 12 weeks\n\nMedium\n\nReplace all instances of Vuetify's VCombobox component in Studio with a custom, fully-accessible multi-select dropdown component built using Vue.js and aligned with Kolibri Design System patterns.\n\nKolibri Studio is migrating away from Vuetify to rely entirely on the Kolibri Design System and custom components. The Vuetify VCombobox component is currently used in multiple workflows within Studio, blocking completion of this migration. Current challenges include:\n\n- Dependency on Vuetify 1.5.24 prevents full removal of the Vuetify library\n- Two distinct use cases exist:\n\n- Multi-select with predefined options only\n- Multi-select with ability to create custom chips via text input\n\n- Need to maintain feature parity while improving accessibility compliance\n- Opportunity to establish reusable patterns for future Studio and KDS components\n\nTechnical\n\n- Blocking the complete Vuetify migration in Studio\n- Vuetify 1.x is outdated and no longer maintained\n- Reduces bundle size and technical debt\n\nAccessibility\n\n- Opportunity to implement WCAG 2.1 Level AA compliance from the ground up\n- Current Vuetify component may have accessibility gaps\n\n- Custom multi-select component has feature parity with existing Vuetify VCombobox usage\n- All existing Vuetify VCombobox instances are replaced with the new component\n- Component meets WCAG 2.1 Level AA accessibility standards\n- Component is documented and reusable for future needs\n- No regressions in existing workflows\n\nTo be confirmed. Please check back on 2 March, 2026 for final updates.\n\n- Vue.js\n- HTML/CSS\n- Web accessibility\n- Javascript\n\n175 hours in 12 weeks\n\nMedium\n\nThe [EPub.js](https://www.google.com/url?q=http://epub.js&sa=D&source=editors&ust=1771587966487886&usg=AOvVaw03e8MiLjkG9c-i6QLjeEEv) library that we currently use to display EPubs has multiple extant bugs, and has resisted all attempts to upgrade in place. It also appears not to be actively maintained, and there appears to be no roadmap towards integrating important accessibility features such as the EPUB3 SMIL standard. By contrast, the foliate-js library is currently maintained, and has support for the EPUB3 SMIL standard.\n\n- Research the foliate-js library to understand its compatibility with Kolibri’s browserlist configuration - are there any blockers to integration, or can all necessary JS features be polyfilled or ponyfilled?\n- Understand the capabilities and architecture of the pluggable kolibri-sandbox that is used to render resources that can potentially execute arbitrary Javascript.\n- Update the existing epub_viewer plugin in Kolibri to use a sandboxed integration of foliate-js.\n- Retain all existing accessibility features and functionality, and update the UI where possible to bring it into line with broader platform norms and standards.\n\nOverhaul the epub_viewer plugin to make it more accessible, secure, and maintainable, while retaining existing functionality, progress tracking, and eliminating as many extant bugs as possible.\n\nTo be confirmed. Please check back on 2 March, 2026 for final updates.\n\n- HTML, Javascript, Vue.js\n- Inclusive design principles, familiarity with WCAG specification\n\n175 hours in 12 weeks\n\nMedium\n\nKolibri's assessment capabilities have been limited by the Perseus framework's strong focus on Mathematics exercises, restricting non-Mathematics subjects from having robust assessments. Expanding QTI 3.0 rendering support will enable a broader range of assessment types across all subjects, with accessible, mobile-responsive, right-to-left friendly rendering that can be used interchangeably with Perseus files in exercises, practice quizzes, and coach-created quizzes.\n\n- Implement rendering for priority QTI 3.0 interaction types: inline choice, matching, drag-and-drop, true/false, ordering, fill-in-the-blank.\n- Ensure all interactions are accessible and meet WCAG 2.1 Level AA standards with proper keyboard navigation and screen reader support.\n- Integrate with existing QTI viewer plugin and progress tracking functionality.\n- Implement answer validation and scoring for each interaction type per QTI 3.0 specification.\n- Test interactions across browsers and devices to ensure consistent behavior.\n\nLearners can complete a wider range of QTI 3.0 question types within Kolibri, with accessible, consistent rendering across all supported interaction types and proper answer validation and scoring.\n\n- HTML, JavaScript, Vue.js\n- QTI 3.0 specification understanding\n- Accessibility standards (WCAG, ARIA patterns) and accessibility testing\n\nTo be confirmed. Please check back on 2 March, 2026 for final updates.\n\n175 hours in 14 weeks\n\nChallenging\n\nCreating editing experiences for Perseus question types has been limited to multiple choice and simple math answer input, with other question types lacking sufficiently robust editing tools for proper integration into Kolibri. Kolibri Studio currently lacks authoring tools for creating QTI 3.0 questions, requiring content creators to import pre-existing QTI packages. Enabling QTI editing in Studio is the first step toward allowing educators to create a broader range of assessment types for non-Mathematics subjects directly within the platform.\n\n- Design and implement question authoring UI for priority QTI 3.0 interaction types: inline choice, matching, drag-and-drop, true/false, ordering, fill-in-the-blank (in addition to existing Multiple Choice and Text Entry).\n- Build backend to generate valid QTI 3.0 XML from Studio-authored questions.\n- Ensure created QTI packages are compatible with the Kolibri QTI viewer plugin.\n- Support answer validation/scoring configuration for each interaction type.\n- Follow Studio's existing content creation patterns and workflows.\n\nContent creators can author priority QTI 3.0 question types directly in Kolibri Studio, generating valid QTI packages that render correctly in Kolibri's learner-facing viewer, without requiring external QTI authoring tools.\n\n- Full-stack development (Vue.js, Django)\n- QTI 3.0 specification and XML generation\n- Form design and validation\n- Understanding of Kolibri Studio content pipeline\n\nTo be confirmed. Please check back on 2 March, 2026 for final updates.\n\n175 hours in 14 weeks\n\nChallenging"
  },
  {
    "name": "JdeRobot",
    "slug": "jderobot",
    "tagline": "Toolkit for developing Robotics applications",
    "description": "Robotics applications are typically distributed, made up of a collection of concurrent asynchronous components which communicate using some middleware (ROS messages, DDS...). Building robotics applications is a complex task. Integrating existing nodes or libraries that provide already solved functionality, and using several tools may increase the software robustness and shorten the development time. JdeRobot provides several tools, libraries and reusable nodes. They have been written in C++, Python or JavaScript.\n\nOur community mainly works on four development areas:\n1.- Education in Robotics\n* RoboticsAcademy (https://jderobot.github.io/RoboticsAcademy/): a ROS-based framework to learn robotics and computer vision with drones, autonomous cars.... It is a collection of Python programmed exercises for engineering students. \n* Unibotics: a web based framework for teaching robotics.\n\n2.- Robot Programming Tools\t\n* VisualCircuit (https://jderobot.github.io/VisualCircuit/) for robot programming with connected blocks, as in electronic circuits, in a visual way\n* VisualStates for robot programming with Finite State Machines in a visual way\n* WebSim2D robot simulator with web technologies\n\n3.- MachineLearning in Robotics\n* DeepLearningSuite: neural networks for robot control. It includes the BehaviorMetrics tool for assessment of neural networks for autonomous driving\n* RL-Studio: Robotic library for the training of Reinforcement Learning algorithms\n* DetectionMetrics tool for evaluation of visual detection neural networks and algorithms\n\n4.- FPGAs in Robotics\n* FPGA-robotics (https://github.com/JdeRobot/FPGA-robotics): programming robots with reconfigurable computing (FPGAs) using open tools as IceStudio and Symbiflow. Verilog-based reusable blocks for robotics applications.\n* NeuralFPGA: running deeplearning networks on FPGAs",
    "ideas_url": "https://jderobot.github.io/activities/gsoc/2026#ideas-list",
    "website_url": "http://jderobot.github.io",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "ros",
      "gazebo",
      "opencv",
      "tensorflow"
    ],
    "topic_tags": [
      "education",
      "artificial intelligence",
      "robotics",
      "computer vision",
      "developer tools"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/jderobot",
    "ideas_content": "# GSoC 2026\n\nRobotics applications are typically distributed, made up of a collection of concurrent asynchronous components which communicate using some middleware (ROS messages, DDS…). Building robotics applications is a complex task. Integrating existing nodes or libraries that provide already solved functionality, and using several tools may increase the software robustness and shorten the development time. JdeRobot provides several tools, libraries and reusable nodes. They have been written in C++, Python or JavaScript. They are ROS-friendly and full compatible with ROS2-Humble (and Gazebo Harmonic).\n\nOur community mainly works on three development areas:\n\n-\nEducation in Robotics.\n\n[RoboticsAcademy](https://jderobot.github.io/RoboticsAcademy/)is our main project. It is a ROS-based framework to learn robotics and computer vision with drones, autonomous cars…. It is a collection of Python programmed exercises and challenges for engineering students. -\nRobot Programming Tools. For instance,\n\n[BT-Studio](https://github.com/JdeRobot/bt-studio), for robot programming with Behavior Trees;[VisualCircuit](https://jderobot.github.io/VisualCircuit/)for robot programming with connected blocks, as in electronic circuits, in a visual way. -\nMachine Learning in Robotics. For instance, the\n\n[BehaviorMetrics tool](https://jderobot.github.io/BehaviorMetrics/)for assessment of neural networks in end-to-end autonomous driving. Another example is[PerceptionMetrics tool](https://github.com/JdeRobot/PerceptionMetrics)for unified evaluation of 2D and 3D perception models.\n\n# Ideas list\n\nThis open source organization welcomes contributors in these topics:\n\n## Project #1: PerceptionMetrics: GUI extension and support for standard datasets and models\n\n**Brief explanation**: [PerceptionMetrics](https://jderobot.github.io/PerceptionMetrics/) is a toolkit for evaluating perception models across frameworks and datasets. Past GSoC projects ([Vinay Sharma, 2017](https://github.com/TheRoboticsClub/2017-colab-vinay_sharma), [Jeevan Kumar, 2019](https://theroboticsclub.github.io/colab-gsoc2019-Jeevan_Kumar/)) contributed to its first stable release, published in *Sensors* ([Paniego et al., 2022](https://doi.org/10.3390/s22124575)). Recently, the tool has been revamped to support LiDAR, image segmentation, and object detection ([Sakhineti Praveena, 2025](https://github.com/TheRoboticsClub/gsoc2025-Sakhineti_Praveena)).\n\nMoving beyond our current focus on off-road navigation, this project aims to scale *PerceptionMetrics* for industry-standard benchmarks. The main goals are:\n\n- Exploring core segmentation/detection datasets in the industry for image and LiDAR (e.g., SemanticKITTI, Cityscapes), prioritizing, and adding support for them.\n- Extending the GUI to support image and LiDAR segmentation visualization (currently limited to object detection).\n- Generating comprehensive tutorials and documentation for different use cases, models, and data formats.\n- Improving the robustness of the project through an improved test suite.\n\n**Skills required/preferred**: Python, PyTorch, Deep Learning, Streamlit**Difficulty rating**: Medium**Expected results**: Support for new datasets, GUI extension for image and LiDAR segmentation, and comprehensive technical documentation.**Expected size**: Long (~350h)**Mentors**: David Pascual Hernández (d.pascualhe AT gmail.com), Sakhineti Praveena (sakhinetipraveena AT gmail.com)\n\n## Project #2: Robotics Academy: extend C++ support for more exercises\n\n**Brief explanation**: [Robotics-Academy](https://jderobot.github.io/RoboticsAcademy) is a framework for learning robotics and computer vision. It consists of a collection of robot programming exercises. The students have to code in Python the behavior of a given (either simulated or real) robot to fit some task related to robotics or computer vision. It uses standard middleware and libraries such as ROS 2 or OpenCV.\n\nNowadays, Robotics Academy offers the student up to 26 exercises. All of them come ready to use in the RoboticsAcademy docker image (RADI). The only requirement for the students its to download the docker image, all the dependencies are installed inside the RADI.\n\nCurrently, exercises can be solved using Python with our Hardware Abstraction Layer (HAL) or directly using ROS 2 interfaces (topics and services). Right now there are 2 exercises that also support C++: follow line and vacuum cleaner. The goal of this project would be to expand the selection of exercises that support the C++ language.\n\n**Skills required/preferred**: Python, C++, ROS2**Difficulty rating**: Medium**Expected results**: Extend C++ support for more exercises providing a simplified API and direct ROS**Expected size**: 90h**Mentors**: Javier Izquierdo Hernández (javizqh AT pm.me), Nikhil Gupta\n\n## Project #3: Robotics Academy: New power tower inspection using deep learning\n\n**Brief explanation**: The goal of this project is to develop a new deep learning based challenge in [RoboticsAcademy](https://jderobot.github.io/RoboticsAcademy/) for power tower inspection. In addition to the existing [classical power inspection](https://jderobot.github.io/RoboticsAcademy/exercises/Drones/power_tower_inspection) exercise, this project will introduce a new challenge where defect detection and classification are performed using a deep learning model trained and provided by the student, instead of relying on traditional image processing techniques. The expected work for this project includes:\n\n- Create new exercise, following the example of previous deep learning based exercises such as\n[end-to-end visual control](https://jderobot.github.io/RoboticsAcademy/exercises/AutonomousCars/end_to_end_visual_control/). - Extend or create simulated power tower environments and record and label datasets for students to train their models on.\n- Build comprehensive documentation, upload datasets to accessible repositories, and provide Jupyter Notebooks or similar materials to guide students.\n- Extend the\n*Simple API*used by deep learning exercises to define a structured way of setting results such as classification logits, bounding boxes for detection, and confidence scores.\n\n**Skills required/preferred**: Python, PyTorch, Deep Learning, ROS2, Gazebo**Difficulty rating**: Medium**Expected results**: New deep learning based power tower inspection exercise with comprehensive docs and learning materials.**Expected size**: Medium (~175h)**Mentors**: David Pascual Hernández (d.pascualhe AT gmail.com), Md. Shariar Kabir (skabircp08 AT gmail.com), Luis Roberto Morales (lrmoralesiglesias AT gmail.com)\n\n## Project #4: RoboticsAcademy: drone-cat-mouse chase exercise, two controlled robots at the same time\n\n**Brief explanation**: The goal of this project is to recover the drone-cat-mouse chase challenge in the new [RoboticsAcademy](https://jderobot.github.io/RoboticsAcademy/) architecture. This exercise requires the support for two robotics applications connected to the corresponding drones, one connected to the mouse-drone (which may fly autonomously following a 3D position pattern) and the second connected to the cat-drone. The RoboticsAcademy user has to program the cat-drone so it successfully chases the drone-mouse. This challenge should work in Gazebo Harmonic and use Aerostack2 middleware for drones, as all current available drone exercises at RoboticsAcademy. Additional exercises involving two concurrent agents in the same robotic world may also be designed using this plumbing.\n\n**Skills required/preferred**: Python, Gazebo, Linux processes**Difficulty rating**: Medium**Expected results**: A new drone-cat-mouse chase exercise, new internal architecture supporting two simultanous agents in RoboticsAcademy challenges and comprehensive technical documentation.**Expected size**: Long (~350h)**Mentors**: José María Cañas (josemaria.plaza AT gmail.com) and Prajyot (prajyotj04 AT gmail.com)\n\n## Project #5: Robotics Academy: using the Open3DEngine as robotics simulator\n\n**Brief explanation**: Open 3D Engine (O3DE) is an Apache 2.0-licensed multi-platform 3D engine that enables developers and content creators to build AAA games, cinema-quality 3D worlds, and high-fidelity simulations. It supports also simulation of most common robot sensors and actuators. The idea of this project is to integrate Open3DEngine into the RoboticsAcademy framework, with at least one exercise using it instead of Gazebo.\n\n**Skills required/preferred**: C++ programming, ROS**Difficulty rating**: Medium**Expected results**: A new robotics exercise in RoboticsAcademy using the Open3DEngine**Expected size**: 175h**Repository Link**-[Open 3D Engine](https://github.com/o3de/o3de),[RoboticsAcademy](https://github.com/JdeRobot/RoboticsAcademy),[RoboticsInfrastructure](https://github.com/JdeRobot/RoboticsInfrastructure)**Mentors**: José M. Cañas (josemaria.plaza AT gmail.com) and Pedro Arias (pedro.ariasp AT upm.es)\n\n## Project #6: VisualCircuit: Improving Functionality & Expanding the Block Library\n\n**Brief explanation**: VisualCircuit allows users to program robotic intelligence using a visual language similar to electronic circuits, simplifying the creation of code for robotics applications such as Deep Learning, ROS, and more.\n\nOver the past few years, we have focused on making VisualCircuit more robust by resolving Nested Blocks (multi-level blocks) with the Block Composition feature, developing a working prototype for dockerized execution of robotics applications directly from the browser, migrating the old POSIX IPC implementation to a cross-platform compatible Python Shared Memory implementation, and more.\n\nFor GSoC 2026, this project aims to improve and expand the VisualCircuit block library, enabling contributors to publish reusable blocks in a structured and validated manner. Each block will include metadata, execution logic, and visual assets, while automated CI pipelines will validate contributions. Alongside this infrastructure, the project will focus on developing high-quality reusable blocks and complete end-to-end robotics applications using VisualCircuit. The VisualCircuit frontend will integrate the block library as a built-in marketplace, allowing users to browse, install, and reuse blocks with minimal effort, while ensuring offline usability and seamless execution identical to native blocks.\nYou can read further about the tool on the [website](https://jderobot.github.io/VisualCircuit/).\n\n**Skills required/preferred**: ROS2, Gazebo, Python, TypeScript**Difficulty rating**: Medium**Expected results**: Expanding Block library for VisualCircuit, improving automated testing using GitHub Actions and creating real world robotics applications developed with latest functionalities of VC and resolving other major issues.**Expected size**: 175h**Mentors**: Toshan Luktuke (toshan1603 AT gmail.com) and Pankaj Borade (borade.pankaj825 AT gmail.com).\n\n## Project #7: Robotics Academy: Exploring optimization strategies for RoboticsBackend container\n\n**Brief explanation**: Our [Robotics Academy](https://jderobot.github.io/RoboticsAcademy) platform relies on a containerized environment that encapsulates robotics middleware, simulators, libraries, and the application management stack: the **RoboticsBackend**. This approach significantly lowers the technical entry barrier for students, allowing them to start learning robotics without dealing with complex environment setup. However, the large number of coexisting dependencies causes the container image to grow substantially in size, negatively affecting maintainability and increasing download times for first time users.\n\nThis project has a twofold objective. First, it aims to identify bottlenecks in the current container build and propose concrete strategies to reduce image size and build time. Potential approaches include layer optimization, dependency pruning, replacing heavy libraries such as OMPL when viable, and providing minimal installation variants for components like Aerostack2. Second, the project will explore alternative container technologies, such as Podman, as a replacement for Docker in the build pipeline. Podman offers a daemonless and rootless execution model while maintaining compatibility with existing container workflows, potentially improving security, portability, and maintainability.\n\n**Skills required/preferred**: Docker, Linux fundamentals, familiarity with common robotic software stack**Difficulty rating**: Medium**Expected results**: An optimized RoboticsBackend and a feasibility study of migration to Podman**Expected size**: 175h**Mentors**: Nikhil Gupta and Miguel Fernández\n\n## Project #8: Robotics Academy: palletizing with an industrial robot exercise\n\n**Brief explanation**: A few years ago we developed some exercises on industrial robots using MoveIt1 and ROS1-Noetic. A Work-In-Progress from the JdeRobot Industrial Robotics Working Group is the support in RoboticsAcademy to MoveIt2 and ROS2. Currently two exercises are available: (a) the Pick and Place application and (b) the MachineVision application (from GSoC-2025). The main goal of this project is to create a palletizing exercise with an industrial robot (UR5) over the base of the current exercises at RoboticsAcademy using ROS2, MoveIt2 and the easy API for the programming of industrial robots (similar to other solutions such as RAPID from ABB) already available.\n\n**Skills required/preferred**: C++ programming, Python, ROS, MoveIt**Difficulty rating**: Medium**Expected results**: A new robotics exercise in RoboticsAcademy using an industrial robot for palletizing application**Expected size**: 350h**Repository Link**-[RoboticsAcademy](https://github.com/JdeRobot/RoboticsAcademy),[RoboticsInfrastructure](https://github.com/JdeRobot/RoboticsInfrastructure)**Mentors**: José M. Cañas (josemaria.plaza AT gmail.com) and Shu Xiao (shuxiao19980101 AT gmail.com)\n\n# Application instructions for GSoC-2026\n\nAccepted mentoring organizations for GSoC 2026 have not been announced yet. In the meantime, we invite you to explore our list of tentative projects above and begin contributing to the organization. If you are interested in our flagship project, [RoboticsAcademy](https://jderobot.github.io/RoboticsAcademy/), please visit [this GitHub Discussion thread](https://github.com/JdeRobot/RoboticsAcademy/discussions/3381) for guidance on how to get started.\n\n# Previous GSoC students\n\n[Ashish Ramesh](https://github.com/TheRoboticsClub/gsoc2025-Ashish_Ramesh)(GSoC 2025) Robotics-Academy: support for solutions directly using ROS2 topics[Abdallah Ibrahim Ismail](https://github.com/TheRoboticsClub/gsoc2025-Abdallah_Ibrahim_Ismail)(GSoC 2025) Robotics-Academy: CI & Testing[Md. Shariar Kabir](https://github.com/TheRoboticsClub/gsoc2025-Md_Shariar_Kabir)(GSoC 2025) Robotics-Academy: new exercise on End-to-End Visual Control of an Autonomous Vehicle using DeepLearning[Nikhil Gupta](https://github.com/TheRoboticsClub/gsoc2025-Nikhil_Gupta)(GSoC 2025) Robotics Academy: improvement of Gazebo scenarios and robot models[Shu Xiao](https://github.com/TheRoboticsClub/gsoc2025-Shu_Xiao)(GSoC 2025) Robotics Academy: improvement of industrial robotics exercises with MoveIt2 and ROS2[Javier Izquierdo](https://github.com/TheRoboticsClub/gsoc2025-Javier_Izquierdo)(GSoC 2025) BT-Studio: a tool for programming robots with Behavior Trees[Sakhineti Praveena](https://github.com/TheRoboticsClub/gsoc2025-Sakhineti_Praveena)(GSoC 2025) Extend DetectionMetrics: GUI, CI Workflow, and Object Detection[Prajyot Jadhav](https://github.com/TheRoboticsClub/gsoc2024-Prajyot_Jadhav)(GSoC-2024) Robotics-Academy: migration to Gazebo Fortress[Mihir Gore](https://github.com/TheRoboticsClub/gsoc2024-Mihir_Gore)(GSoC-2024) Robotics-Academy: improve Deep Learning based exercises[Pankaj Borade](https://github.com/TheRoboticsClub/gsoc2024-Pankaj_Borade)(GSoC-2024) VisualCircuit: block library[Óscar Martínez](https://github.com/TheRoboticsClub/gsoc2024-Oscar_Martinez)(GSoC-2024) BT-Studio: a tool for programming robots with Behavior Trees[Zebin Huang](https://github.com/TheRoboticsClub/gsoc2024-ZebinHuang)(GSoC-2024) End-to-end autonomous vehicle driving based on text-based instructions: research project regarding Autonomous Driving + LLMs[Pawan Wadhwani](https://github.com/TheRoboticsClub/gsoc2023-Pawan_Wadhwani)(GSoC-2023) Robotics Academy: migration to ROS2 Humble[Meiqi Zhao](https://github.com/TheRoboticsClub/gsoc2023-Meiqi_Zhao)(GSoC 2023) Obstacle Avoidance for Autonomous Driving in CARLA Using Segmentation Deep Learning Models[Siddheshsingh Tanwar](https://github.com/TheRoboticsClub/gsoc2023-Siddheshsingh_Tanwar)(GSoC 2023) Dockerization of Visual Circuit[Prakhar Bansal](https://github.com/TheRoboticsClub/gsoc2023-Prakhar_Bansal)(GSoC 2023) RoboticsAcademy: Cross-Platform Desktop Application using ElectronJS[Apoorv Garg](https://theroboticsclub.github.io/gsoc2022-Apoorv_Garg/)(GSoC-2022) Improvement of Web Templates of Robotics Academy exercises[Toshan Luktuke](https://theroboticsclub.github.io/gsoc2022-Toshan_Luktuke/)(GSoC-2022) Improvement of VisualCircuit web service[Nikhil Paliwal](https://theroboticsclub.github.io/gsoc2022-Nikhil_Paliwal/)(GSoC-2022) Optimization of Deep Learning models for autonomous driving[Akshay Narisetti](https://theroboticsclub.github.io/gsoc2022-Akshay_Narisetti/)(GSoC-2022) Robotics Academy: improvement of autonomous driving exercises[Prakarsh Kaushik](https://theroboticsclub.github.io/gsoc2022-Prakarsh_Kaushik/)(GSoC-2022) Robotics Academy: consolidation of drone based exercises[Bhavesh Misra](https://theroboticsclub.github.io/gsoc2022-Bhavesh_Misra/)(GSoC-2022) Robotics Academy: improve Deep Learning based Human Detection exercise[Suhas Gopal](https://theroboticsclub.github.io/gsoc2021-Suhas_Gopal/)(GSoC-2021) Shifting VisualCircuit to a web server[Utkarsh Mishra](https://theroboticsclub.github.io/gsoc2021-Utkarsh_Mishra/)(GSoC-2021) Autonomous Driving drone with Gazebo using Deep Learning techniques[Siddharth Saha](https://theroboticsclub.github.io/gsoc2021-Siddharth_Saha/)(GSoC-2021) Robotics Academy: multirobot version of the Amazon warehouse exercise in ROS2[Shashwat Dalakoti](https://theroboticsclub.github.io/gsoc2021-Shashwat_Dalakoti/)(GSoC-2021) Robotics-Academy: exercise using Deep Learning for Visual Detection[Arkajyoti Basak](https://theroboticsclub.github.io/gsoc2021-Arkajyoti_Basak/)(GSoC-2021) Robotics Academy: new drone based exercises[Chandan Kumar](https://theroboticsclub.github.io/gsoc2021-Chandan_Kumar/)(GSoC-2021) Robotics Academy: Migrating industrial robot manipulation exercises to web server[Muhammad Taha](https://theroboticsclub.github.io/colab-gsoc2020-Muhammad_Taha/)(GSoC-2020) VisualCircuit tool, digital electronics language for robot behaviors.[Sakshay Mahna](https://theroboticsclub.github.io/colab-gsoc2020-Sakshay_Mahna/)(GSoC-2020) Robotics-Academy exercises on Evolutionary Robotics.[Shreyas Gokhale](https://theroboticsclub.github.io/colab-gsoc2020-Shreyas_Gokhale/)(GSoC-2020) Multi-Robot exercises for Robotics Academy In ROS2.[Yijia Wu](https://theroboticsclub.github.io/colab-gsoc2020-Yijia_Wu/)(GSoC-2020) Vision-based Industrial Robot Manipulation with MoveIt.[Diego Charrez](https://theroboticsclub.github.io/colab-gsoc2020-Diego_Charrez/logbook/)(GSoC-2020) Reinforcement Learning for Autonomous Driving with Gazebo and OpenAI gym.[Nikhil Khedekar](https://theroboticsclub.github.io/colab-gsoc2019-Nikhil_Khedekar/)(GSoC-2019) Migration to ROS of drones exercises on JdeRobot Academy[Shyngyskhan Abilkassov](https://theroboticsclub.github.io/colab-gsoc2019-Shyngyskhan_Abilkassov)(GSoC-2019) Amazon warehouse exercise on JdeRobot Academy[Jeevan Kumar](https://theroboticsclub.github.io/colab-gsoc2019-Jeevan_Kumar/)(GSoC-2019) Improving DetectionSuite DeepLearning tool[Baidyanath Kundu](https://theroboticsclub.github.io/colab-gsoc2019-Baidyanath_Kundu/)(GSoC-2019) A parameterized automata Library for VisualStates tool[Srinivasan Vijayraghavan](https://theroboticsclub.github.io/colab-gsoc2019-Srinivasan_Vijayraghavan/)(GSoC-2019) Running Python code on the web browser[Pankhuri Vanjani](https://theroboticsclub.github.io/colab-gsoc2019-Pankhuri_Vanjani/)(GSoC-2019) Migration of JdeRobot tools to ROS 2[Pushkal Katara](https://wiki.jderobot.org/Club-PushkalKatara)(GSoC-2018) VisualStates tool[Arsalan Akhter](https://wiki.jderobot.org/Club-aakhter)(GSoC-2018) Robotics-Academy[Hanqing Xie](https://wiki.jderobot.org/Club-hanqingxie)(GSoC-2018) Robotics-Academy[Sergio Paniego](https://wiki.jderobot.org/Club-spaniego)(GSoC-2018) PyOnArduino tool[Jianxiong Cai](https://wiki.jderobot.org/Club-jianxiong)(GSoC-2018) Creating realistic 3D map from online SLAM result[Vinay Sharma](https://wiki.jderobot.org/Club-VinaySharma)(GSoC-2018) DeepLearning, DetectionSuite tool[Nigel Fernandez](https://wiki.jderobot.org/Ni9elf-colab)GSoC-2017[Okan Asik](https://wiki.jderobot.org/Okanasik-colab)GSoC-2017, VisualStates tool[S.Mehdi Mohaimanian](https://wiki.jderobot.org/index.php?title=Deep_Reinforcement_Learning_in_Robotic&redirect=no)GSoC-2017[Raúl Pérula](https://wiki.jderobot.org/Raulperula-colab)GSoC-2017, Scratch2JdeRobot tool[Lihang Li](https://wiki.jderobot.org/Hustcalm-colab): GSoC-2015, Visual SLAM, RGBD, 3D Reconstruction[Andrei Militaru](https://wiki.jderobot.org/Militaru92-colab)GSoC-2015, interoperation of ROS and JdeRobot[Satyaki Chakraborty](https://wiki.jderobot.org/Chakraborty-colab)GSoC-2015, Interconnection with Android Wear"
  },
  {
    "name": "GNU Radio",
    "slug": "gnu-radio",
    "tagline": "The free & open software radio ecosystem",
    "description": "GNU Radio is a free & open-source software development toolkit that provides signal processing blocks to implement software radios. It can be used with readily-available low-cost external RF hardware to create software-defined radios, or without hardware in a simulation-like environment. It is widely used in research, industry, academia, government, and hobbyist environments to support both wireless communications research and real-world radio systems.\n\nIn brief, a software radio is a radio system which performs the required signal processing in software instead of using dedicated integrated circuits in hardware. The benefit is that since software can be easily replaced in the radio system, the same hardware can be used to create many kinds of radios for many different communications standards; thus, one software radio can be used for a variety of applications!\n\nYou can use GNU Radio to write applications to receive and transmit data with radio hardware, or to create entirely simulation-based applications. GNU Radio has filters, channel codes, synchronization elements, equalizers, demodulators, vocoders, decoders, and many other types of blocks which are typically found in signal processing systems. More importantly, it includes a method of connecting these blocks and then manages how data is passed from one block to another. Extending GNU Radio is also quite easy; if you find a specific block that is missing, you can quickly create and add it.\n\nGNU Radio applications can be written in either C++ or Python, while the performance-critical signal processing path is implemented in C++ using processor floating-point extensions where available. This enables the developer to implement real-time, high-throughput radio systems in a simple-to-use, rapid-application-development environment.",
    "ideas_url": "https://wiki.gnuradio.org/index.php/GSoCIdeas",
    "website_url": "https://www.gnuradio.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "c++",
      "qt",
      "simd"
    ],
    "topic_tags": [
      "real-time",
      "dsp",
      "communications engineering",
      "cybersecurity",
      "Software-Defined Radio"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/gnu-radio",
    "ideas_content": "# GSoCIdeas\n\n[Jump to navigation](https://wiki.gnuradio.org#mw-head)\n\n[Jump to search](https://wiki.gnuradio.org#searchInput)\n\nNote- also check out [Grant Ideas](https://wiki.gnuradio.org/index.php?title=Grant_Ideas) for additional ideas that are more suited towards grant money than GSoC.\n\n\n\n## Summer of Code 2026: Project ideas list\n\nThis is the list of project ideas for the summer of code 2026 within GNU Radio.\n\nRemember that these are **ideas** and are merely meant as an inspiration for you to write your own proposal.\n\nStudents who do not find a fit among these projects are encouraged to engage with us and suggest new ones. The [GNU Radio discussion mailing list](https://wiki.gnuradio.org/index.php?title=MailingLists) is the best place to contact all of us. Please do not contact us off-list for the sake of discussing the summer of code, unless you're contacting a mentor listed here to get feedback on a proposal.\n\nReviewing the [Google GSoC FAQ](https://developers.google.com/open-source/gsoc/faq) page for a broader understanding of project, mentor, and student responsibilities is recommended.\n\nIf you need a USRP or other radio hardware to complete the project, we will be able to arrange something.\n\nPlease add ideas to this list (you may cannibalize old ideas, of course!).\n\nGuidelines for good projects (when suggesting projects, please consider these):\n\n- Clearly defined scope, with a main target that can be done in 3 months\n- Clear benefits for the GNU Radio project\n- Not specific to a certain hardware. No specific embedded devices, either, please.\n- Both OOTs and in-tree improvements are welcome\n\n\n\n\n\n### Graphical interoperability between CyberEther and GNU Radio\n\nThe [CyberEther](https://github.com/luigifcruz/CyberEther) project comes with some neat graphical sinks that would be great to have access to in GNU Radio. This project entails creating a new CyberEther GUI workflow much like the [gr-bokehgui](https://github.com/gnuradio/gr-bokehgui) project, such that users can create flowgraphs with CyberEther sinks. This would allow the user to visualize GNU Radio data streams in one of the high-performance CyberEther plots (lineplot, waterfall, spectrogram, etc).\n\n**Prerequisites**\n\n- Knowledge of C++ and some Python\n- Familiarity with graphical APIs (OpenGL, Vulkan, Metal)\n- Basic Qt understanding\n\n**Outcome**\n\n- OOT module with CyberEther sinks\n- Support for both GNU Radio main branch and 3.10?\n\n**Project length**\n\nLong (350 hours)\n\n**Difficulty**\n\nMedium\n\n**Mentor(s)**\n\nLuigi Cruz, Håkon Vågsether\n\n\n\n### GNU Radio 4 signal processing server for MaiaSDR\n\nThe [MaiaSDR](https://maia-sdr.org/) project presents a modern web UI that would be great if it can be used with GNU Radio 4. This project entails creating a new signal processing server with GNU Radio 4 that provides the pre-processing and API to serve data to the MaiaSDR web frontend. The result may be very similar to what [gr-fosphor](https://github.com/osmocom/gr-fosphor) provides today with a spectrum plot, a history plot, and a waterfall plot. Depending of the target scope, additional features may be added.\n\n**Prerequisites**\n\n- Knowledge of C++ and Rust\n- Basic knowledge of server and client interaction\n- Basic Qt understanding\n\n**Outcome**\n\n- A full server to provide data to the MaiaSDR wasm frontend\n- Updated controls to stream from multiple hardware sources as well as a file source.\n- Updated reasonable controls\n\n**Project length**\n\nSmall (90 hours) - Medium (175 hours)\n\n**Difficulty**\n\nEasy - Medium\n\n**Mentor(s)**\n\nJohannes Sterz Demel, Daniel Estévez\n\n### GPU Accelerated Signal Processing Blocks\n\nGPUs offer incredible capability for accelerating a number of signal processing routines when the calculations can be done in parallel. Also, GNU Radio 3.10 brought in a \"custom buffers\" feature which provides support generally for accelerator devices by allowing blocks to have direct access to device memory, finally making accelerator processing feasible through a flowgraph (see [FOSDEM 2022 Presentation](https://fosdem.org/2022/schedule/event/radio_gr3_10/).\n\nOne piece that is missing for GNU Radio is a library of blocks that accelerate common DSP routines. There are several interesting libraries of GPU accelerated signal processing - primarily using CUDA because of its accessible programming paradigm and the ubiquity of NVIDIA hardware:\n\nIntegration of any of this functionality, along with additional kernels for signal processing would need to be predicated on using [gr-cuda](https://github.com/gnuradio/gr-cuda) custom buffers, and expanding this module as needed\n\nThis project can be broken into several subprojects:\n\n- Create gr-matx OOT\n- Add Matx Custom Buffer Type (after gr-cuda)\n- Create blocks wrapping Matx operations\n\n- Expand gr-cuda\n- Additional custom buffer types - pinned, unified\n- Create python custom buffers allowing zero copy into python blocks\n\n- Create gr-cuSignal\n- Wrap cuSignal functionality (dependent on python zero copy)\n\n- Replicate existing GR blocks as CUDA accelerated (things not in cuSignal or Matx)\n- Target for extensions to Matx, cuSignal, or CUSP (within our control)\n- FIR Filters\n- Polyphase Resampler\n- Signal Source\n- Moving Average\n- Polyphase Clock Sync\n- Stream Operators\n- ...\n\n\n**Prerequisites**\n\n- Knowledge of C++ and Python.\n- Familiarity with CUDA programming\n\n\n**Outcome**\n\nDepends on chosen subprojects (see above).\n\n**Project length**\n\n350 hours\n\n**Difficulty**\n\nMedium\n\n**Mentor(s)**\n\nJosh Morman, Andrej Rode\n\n### GRC and GR 4.0\n\nDevelopment of GR 4.0 is progressing quickly. In the current runtime prototype a plugin architecture is used to properly register blocks with the runtime. This allows a more dynamic construction of flowgraphs and introspection into the blocks. But this means the current way of assembling a flowgraph by generating a Python or C++ file needs updates.\n\nThe idea is to port and change necessary parts of GRC (Qt development version) to use the block registry in the new GNU Radio runtime [https://github.com/gnuradio/gnuradio4/](https://github.com/gnuradio/gnuradio4/) and assemble some of the example flowgraphs defined in GRC files and make them run.\nThe design for this is not finalized and therefore you will have freedom to propose your ideas.\n\n**Prerequisites**\n\n- Good Knowledge of C++ and Python\n- Experience with inter-language bindings (not necessarily C++ & Python) is useful\n- Basic Qt understanding\n\n**Outcome**\n\n- Prototype integration of GRC with the new plugin architecture of GR 4.0\n\n**Project length**\n\nLong (350 hours)\n\n**Difficulty**\n\nChallenging\n\n**Mentor(s)**\n\nAndrej Rode, Josh Morman\n\n\n\n\n\n\n\n### Revitalize in-tree and out-of-tree (OOT) modules\n\nA lot has changed since version 3.7, and GNU Radio has made great technical strides the last few years. However, some OOT modules haven't been updated to support the latest versions of GNU Radio, and these modules currently require the user to install an older version of the framework. This is unfortunate, and lowers the useability of GNU Radio as a whole. Some of these modules have been superseded by others, but might still have some blocks or flowgraphs that are useful, and these could be updated and moved in-tree. Some in-tree modules are also in need of attention, like gr-wavelet, which does not have any examples.\n\n**Prerequisites**\n\n- Knowledge of C++, Python and DSP.\n\n**Outcome**\n\n- More example code, tests and flowgraphs for various in-tree modules\n- Porting various OOT modules to support recent versions of GNU Radio\n- Possibly blocks/flowgraphs from old OOT modules moved in-tree\n\n**Project length**\n\nSmall (90 hours) - Medium (175 hours)\n\n**Difficulty**\n\nEasy - Medium\n\n**Mentor(s)**\n\nAndrej Rode, Håkon Vågsether\n\n\n\n### CI for maintenance branches and select OOT modules\n\nIt would be useful to have nightly builds for GNU Radio's maintenance branches (3.8, 3.9, 3.10) and some select OOTs.\n\n**Prerequisites**\n\n- Experience with Docker?\n- ?\n\n**Outcome**\n\n- Automated PPAs, Snaps, Flatpak apps\n\n**Project length**\n\n175 hours\n\n**Difficulty**\n\nEasy\n\n**Mentor(s)**\n\nHåkon Vågsether, ?\n\n### Hardware in the loop CI\n\nCurrent GNU Radio CI tests are software only, but real live usage usually involves hardware, and real over the air operations. It would be useful to have tests that run over actual hardware, with radio transmissions. The CorteXlab platform would host these, to have an isolated radio environment free of interference.\n\nThe idea is to define a set of relevant scenarios to test, as well as metrics for pass/fail criterion. And to implement them as flowgraphs that can run in CorteXlab. A final step would be to build the pipeline to automate these tests, triggered as GitHub actions.\n\n**Prerequisites**\n\n- Knowledge of DSP, and some Python/C++\n\n**Outcome**\n\n- Test scenarios definition, tests flowgraphs, automated CI pipeling\n\n**Project length**\n\n175 hours\n\n**Difficulty**\n\nMedium\n\n**Mentor(s)**\n\nCyrille Morin, ?\n\n### BokehGUI in GNU Radio 4.\n\ngr-bokehgui is an OOT module (created by a previous GSoC project) allowing remote and browser-based monitoring of running flowgraphs.\n\nThe idea is to make a similar module for GNU Radio 4.0, either with the Bokeh library, or another one that could provide this remote plotting and interaction capability.\n\n**Prerequisites**\n\n- Knowledge of C++ and Python\n- Some knowledge of DSP\n\n**Outcome**\n\n- OOT module with remote, browser-based plotting and widgets for interaction.\n\n**Project length**\n\n350 hours\n\n**Difficulty**\n\nMedium\n\n**Mentor(s)**\n\nCyrille Morin, ?\n\n## Old Ideas\n\nFeel free to browse [old ideas](https://wiki.gnuradio.org/index.php?title=OldGSoCIdeas) from previous years for inspiration."
  },
  {
    "name": "stdlib",
    "slug": "stdlib",
    "tagline": "The fundamental numerical library for JavaScript",
    "description": "stdlib is a standard library for JavaScript and Node.js with an emphasis on numerical and scientific computing applications. The project aims to provide functionality similar to NumPy and SciPy for use in JavaScript environments with special consideration for the unique constraints and opportunities afforded by the Web. stdlib is primarily written in JavaScript, C, and Fortran.",
    "ideas_url": "https://github.com/stdlib-js/google-summer-of-code/blob/main/ideas.md",
    "website_url": "https://stdlib.io",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "javascript",
      "node.js",
      "typescript",
      "webassembly"
    ],
    "topic_tags": [
      "mathematics",
      "web",
      "scientific computing",
      "numerical computing",
      "statistics"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/stdlib",
    "ideas_content": "# Ideas\n\n> List of potential project ideas.\n\nBefore working on your GSoC application, please review our list of ideas to see if you find a project which excites you. The list of existing ideas is provided to serve as inspiration and to indicate which directions may be good for stdlib.\n\nIf you do find an existing idea that you'd like to pursue, please be sure to contact us in the [GSoC Questions](https://stdlib.zulipchat.com/#narrow/channel/546969-gsoc-questions) channel of our [Zulip chat](https://stdlib.zulipchat.com) to discuss it first! **Always be sure to ask about these ideas prior to working on application in order to get the latest information about what is already implemented and what exactly must be done.**\n\nPriority, difficulty, technology, and topic area have no bearing on the chances of an idea being accepted. All ideas are equally good, and your chances of being accepted depend solely on the **quality of your application**.\n\n**Project Length**\n\nGSoC allows three different project lengths: **90** hours, **175** hours, and **350** hours. Each idea must indicate whether the idea is a better fit for 90, 175, or 350 hours.\n\nIn some cases, we may be able to extend a 175 hour project to a 350 hour project by extending the ideas of what can be done. Similarly, in some cases, a 350 hour project can be shortened to a 175 hour project by only implementing part of an idea and leaving the rest for a future project. In either case, if you want to adjust the project length, please be sure to contact us in our [GSoC Questions](https://stdlib.zulipchat.com/#narrow/channel/546969-gsoc-questions) channel to discuss it first!\n\n## Your Own Idea\n\nIf you'd like to submit your own idea, that is also welcome; just be sure to propose your idea to stdlib mentors first! After reaching out, we'll inform you whether the idea has already been implemented, if the idea will entail enough work to last the duration of the GSoC program, if the idea requires too much work to be meaningfully pursued during GSoC, and if the idea is within the scope of stdlib. **Unsolicited, undiscussed ideas are less likely to get accepted.**\n\nThe best project for you is the one you are most interested in and knowledgeable about. Excitement and aptitude are two key ingredients of a successful project and help ensure your commitment and ability to see a project through to completion. So if there is something you are especially passionate about and that you believe aligns with the scope and goals of stdlib, we'd be happy to hear your pitch!\n\nAfter discussing with us in our [Zulip](https://stdlib.zulipchat.com) chat and receiving approval to submit your idea, please open an [issue](https://github.com/stdlib-js/google-summer-of-code/issues/new?assignees=&labels=idea&template=idea.yml&title=%5BIdea%5D%3A+) which describes your idea using the [**idea issue template**](https://github.com/stdlib-js/google-summer-of-code/issues/new?assignees=&labels=idea&template=idea.yml&title=%5BIdea%5D%3A+).\n\n## Mentors\n\nTo learn who might mentor one of the projects listed below, consult the list of potential project [mentors](https://github.com/stdlib-js/google-summer-of-code/blob/main/mentors.md). For each mentor, the list includes a mentor's preferred project(s) and/or general interest area.\n\n* * *\n\n## Implement a broader range of statistical distributions\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/2>\n\n### Idea\n\nThe goal of this idea is to implement all distributions found in SciPy [stats](https://docs.scipy.org/doc/scipy/reference/stats.html#statsrefmanual). Distribution support will entail implementing APIs for computing PDFs, CDFs, quantiles, and other distribution properties. Additionally, stdlib should support APIs for drawing random variates from any implemented distributions.\n\n### Expected Outcomes\n\nstdlib users will be able to construct, and compute various properties of, every statistical distribution present in SciPy in JavaScript.\n\n### Involved Software\n\nNo runtime dependencies should be necessary. SciPy will be necessary in order to provide reference test results.\n\n### Prerequisite Knowledge\n\nJavaScript, Node.js. Familiarity with C/C++/Fortran would help.\n\n### Difficulty\n\nIntermediate. Difficulties may arise for distributions whose properties and moments have complicated formulations. Developing JavaScript implementations will likely require consulting C/C++ and possibly Fortran code.\n\n### Project Length\n\n350 hours.\n\n* * *\n\n## Provide APIs for computing Fast Fourier Transforms\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/3>\n\n### Idea\n\nThe goal of this idea is to expose a set of Fast Fourier Transform (FFT) interfaces similar to those available in NumPy and as documented in the [Data APIs Array API specification](https://data-apis.org/array-api/latest/extensions/fourier_transform_functions.html). Similar to stdlib's BLAS interfaces, we may want to allow switching out the FFT backend.\n\nOne potential reference implementation which could form the basis of this idea is pocketfft, as done in NumPy:\n\n- https://github.com/mreineck/pocketfft\n- https://gitlab.mpcdf.mpg.de/mtr/pocketfft\n\n### Expected Outcomes\n\nstdlib users would be able to evaluate FFT operations on stdlib ndarrays. Ideally, we'd also provide a set of C APIs.\n\n### Involved Software\n\nWill need to consult reference implementations in C/Fortran.\n\n### Prerequisite Knowledge\n\nJavaScript, Node.js, C/C++/Fortran\n\n### Difficulty\n\nHard. This may be a straightforward port, or it may not be. More R&D is needed.\n\n### Project Length\n\n350 hours.\n\n### Potential Mentors\n\n@kgryte @Planeshifter @rreusser @Pranavchiku @czgdp1807\n\n* * *\n\n## Expand support for additional pseudorandom number generators\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/5>\n\n### Idea\n\nThe goal of this idea is to implement a variety of PRNGs for use within stdlib to generate pseudorandom numbers. The project currently uses Mersenne Twister as its default PRNG; however, this PRNG, while common, is not ideal given its comparatively large internal state. Would be great to have a collection of PRNGs, such as PCG, Philox, Xorshift, and more.\n\n### Expected Outcomes\n\nstdlib users will have a wide selection of PRNGs from which to choose from based on their individual needs and considerations. Having a large selection of PRNGs will useful when replicating the results of numerical simulations which may use a PRNG which is not one of the currently supported stdlib PRNGs. Additionally, a desired outcome would be if we could replace MT19937 with a new default PRNG.\n\n### Involved Software\n\nNo other software should be necessary. We may be a bit constrained based on 32-bit limitations in JS. This would not, however, stop us from implementing in C for use in generating arrays of random numbers.\n\n### Prerequisite Knowledge\n\nJavaScript, Node.js. Familiarity with C/C++/Fortran would help.\n\n### Difficulty\n\nIntermediate/Hard. Depends. Some PRNGs may be straightforward to implement. Others, not so much.\n\n### Project Length\n\n175/350 hours. This idea can be adjusted according to needs and availability.\n\n### Potential Mentors\n\n@kgryte @Planeshifter @Pranavchiku\n\n* * *\n\n## Add support for visualizing benchmark results\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/6>\n\n### Idea\n\nWhile we currently support running benchmarks, we have yet to provide a means for easily visualizing and comparing benchmark results. Previously, when wanting to visualize and compare benchmark results, one has needed to manually parse TAP results and then plug into some other software (e.g., vega or Plotly).\n\nThe idea for this project would be to 1) implement a TAP parser with support for the latest TAP specification and 2) provide a plot frontend for consuming parsed TAP results. The plot frontend could be as simple as a Unicode bar chart plotter, which would be in line with our existing Unicode plotting facilities.\n\n### Expected Outcomes\n\nDevelopers will be able to run benchmarks and visually compare benchmark results based on the namespace and parameterization. Ideally, the plot would include small multiple/facet visualizations.\n\n### Involved Software\n\nNo other software or dependencies should be necessary. Will need to consult a reference TAP parser implementation (e.g., `node-tap`).\n\n### Prerequisite Knowledge\n\nJavaScript and Node.js.\n\n### Difficulty\n\nIntermediate.\n\n### Project Length\n\n350 hours.\n\n### Potential Mentors\n\n@kgryte @Planeshifter @steff456\n\n* * *\n\n## Develop a project test runner\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/7>\n\n### Idea\n\nCurrently, stdlib uses `tape`. The goal of this idea is to migrate away from `tape` and develop a test runner in-house, similar to `@stdlib/bench/harness`. This has long been on our TODO list and would allow us to have a simple test runner which is oriented toward stdlib conventions (e.g., we don't use most of the assertion methods in `tape`).\n\nBonus points if we can migrate away from `istanbul` to `nyc` or `c8`; however, this may be tricky if we want to support older Node.js versions.\n\n### Expected Outcomes\n\nAll unit tests have migrated to the in-house runner.\n\n### Involved Software\n\nNo additional runtime deps. Will need to consult `tape` as a reference implementation, along with our existing `@stdlib/bench/harness` implementation.\n\n### Prerequisite Knowledge\n\nJavaScript, Node.js.\n\n### Difficulty\n\nIntermediate.\n\n### Project Length\n\n175/350 hours. The scope of this idea can be adjusted depending on availability.\n\n### Potential Mentors\n\n@kgryte @Planeshifter @steff456\n\n* * *\n\n## Reimagine the stdlib plot API and implementation\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/8>\n\n### Idea\n\nCurrently, stdlib has a bespoke plot API which is useful for fast static rendering. However, our implementation is quite limited in the types of plots it can produce. The goal of this idea is to refactor our plot API to build atop of `vega` (or its specifications). For this, we'd need to migrate to an async plot generation API, which is probably necessary regardless if we want to support WebGL or some other async rendering engine.\n\nIdeally, we would retain the same plot API and internally generate a vega specification.\n\n### Expected Outcomes\n\nWe can generate simple plots using the new plot implementation.\n\n### Involved Software\n\nThis will involve using `vega` (or something similar depending on whether `vega` is sufficiently maintained). We will want to transpile to ES5 and vendor in order to ensure that we can support our supported Node.js versions.\n\n### Prerequisite Knowledge\n\nJavaScript, Node.js.\n\n### Difficulty\n\nIntermediate/Hard.\n\n### Project Length\n\n350 hours. This project has the potential to spiral out of control, as there are many unknowns we'd need to answer. Mentor would likely need to be actively involved in order to perform R&D and properly scope.\n\n### Potential Mentors\n\n@kgryte @Planeshifter @rreusser\n\n* * *\n\n## Achieve feature parity with async.js\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/9>\n\n### Idea\n\nCurrently, stdlib has a limited set of dedicated \"async\" APIs for performing various utility operations. The goal of this idea is to achieve feature parity with [`async.js`](https://caolan.github.io/async/v3/), a popular library providing callback-based async APIs.\n\nMotivation for this idea stems from certain advantages afforded by callback-based asynchronous programming. Notable among them is superior performance and the ability to more readily return and inspect status objects.\n\n### Expected Outcomes\n\nstdlib will have more or less 1:1 feature parity with `async.js` APIs.\n\n### Involved Software\n\n`async.js` will serve as a reference implementation for API design. Will want to modify to match stdlib conventions.\n\n### Prerequisite Knowledge\n\nJavaScript.\n\n### Difficulty\n\nBeginner. Would benefit from someone with JavaScript experience.\n\n### Project Length\n\n175/350 hours. Can be scoped accordingly.\n\n### Potential Mentors\n\n@kgryte @Planeshifter @steff456\n\n* * *\n\n## Achieve feature parity with builtin Node.js `fs` module\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/10>\n\n### Idea\n\nAchieve feature parity with Node.js `fs` package. We currently only support a limited selection of `fs` methods. Would be useful to support more.\n\nPart of this work involves providing an abstraction layer of Node.js built-ins in order to support newer functionality (e.g., options and/or behavior) not present in older Node.js versions. This is similar in concept to the userland `readable-stream` package.\n\n### Expected Outcomes\n\nstdlib will have complete feature parity with Node.js built-ins.\n\n### Involved Software\n\nNo other software is necessary.\n\n### Prerequisite Knowledge\n\nJavaScript, Node.js.\n\n### Difficulty\n\nIntermediate. Could require some creative solutions to ensure that abstractions work for older Node.js versions.\n\n### Project Length\n\n175/350 hours. Can be scoped accordingly.\n\n### Potential Mentors\n\n@kgryte @Planeshifter @steff456\n\n* * *\n\n## Add support for the multivariate normal distribution\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/11>\n\n### Idea\n\nThe goal of this idea is to implement the multivariate normal distribution. This distribution is fundamental in a wide variety of statistical applications and will help unblock stdlib in offering additional statistics APIs.\n\nAs a starting point, SciPy's multivariate normal distribution API and implementation could provide a suitable point of reference:\n\n- https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.multivariate_normal.html\n\n### Expected Outcomes\n\nUsers will be able to evaluate the PDF, CDF, logPDF, and logCDF and be able to draw random variates from a specified distribution.\n\n### Involved Software\n\nNo other software is necessary. Will require reading reference implementations written in Python, R, and Julia.\n\n### Prerequisite Knowledge\n\nJavaScript, Node.js.\n\n### Difficulty\n\nIntermediate.\n\n### Project Length\n\n175/350 hours. Can be scoped accordingly. A skilled contributor should be able to complete in 175 hours with the potential of using their implementation to implement higher order statistics APIs.\n\n### Potential Mentors\n\n@kgryte @Planeshifter @Pranavchiku\n\n* * *\n\n## Develop a Google Sheets extension which exposes stdlib functionality\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/13>\n\n### Idea\n\nThe goal of this idea is to allow users to call stdlib APIs from within Google Sheets. This will allow users to perform linear algebra and various machine learning operations directly on spreadsheet data and all within the browser.\n\nIn order to execute on this idea, we'll want to support\n\n- two-dimensional array broadcasting semantics\n- performant element-wise iteration APIs\n- input argument validation tailored to the Sheets context\n- Fused operations to avoid unnecessary network calls\n- documentation and tutorials demonstrating API usage\n- good generation and automation for creating extension builds\n- testing and performance measurement to guard against regressions\n\n### Expected Outcomes\n\nGoogle Sheets users will be able to install an extension which exposes stdlib functionality, run statistical tests, evaluate mathematical functions, and perform linear algebra operations using stdlib.\n\n### Involved Software\n\nNo other software is necessary.\n\n### Prerequisite Knowledge\n\nJavaScript, Node.js.\n\n### Difficulty\n\nBeginner/Intermediate. \n\n### Project Length\n\n175/350 hours. Can be scoped accordingly. A skilled contributor can work on a strategy for performant fused operations.\n\n### Potential Mentors\n\n@kgryte @Planeshifter @steff456\n\n* * *\n\n## Add support for bootstrap and jackknife resampling\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/15>\n\n### Idea\n\nManually constructing confidence intervals and other statistical properties can be useful when no analytic solution exists. The goal of this idea to implement APIs for bootstrap and jackknife resampling.\n\n### Expected Outcomes\n\nUsers will be to resample provided datasets.\n\n### Involved Software\n\nNo other software is necessary.\n\n### Prerequisite Knowledge\n\nJavaScript, Node.js.\n\n### Difficulty\n\nBeginner/Intermediate. \n\n### Project Length\n\n175/350 hours. Can be scoped accordingly. Scope can be expanded to implement different bootstrap algorithms.\n\n* * *\n\n## Develop a Jupyter backend for interfacing with the stdlib REPL\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/16>\n\n### Idea\n\nJupyter is a dominate force in scientific computing. While some effort has been done to expose JavaScript kernels to Jupyter/JupyterLab, most of these kernels are under-developed or lack numerical functionality.\n\nThe goal of this idea would be to develop a Jupyter backend based on stdlib.\n\n### Expected Outcomes\n\nA JupyterLab user will be able to connect to a stdlib kernel and invoke stdlib operations.\n\n### Involved Software\n\nThis goal will require interfacing with the Jupyter technology stack, including ZeroMQ and implementing messaging protocols.\n\n### Prerequisite Knowledge\n\nJavaScript, Node.js. Experience with Python would be very helpful.\n\n### Difficulty\n\nHard.\n\n### Project Length\n\n350 hours. This idea has many unknowns and will be hard to scope.\n\n### Potential Mentors\n\n@kgryte @Planeshifter\n\n* * *\n\n## Implement additional statistical tests\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/17>\n\n### Idea\n\nImplement various statistical tests which are not currently implemented in stdlib, but are implemented in other envs such as R, Python (SciPy, statsmodels), Julia, and MATLAB.\n\n### Expected Outcomes\n\nstdlib will have a broader array of statistical tests which can operate on ndarrays.\n\n### Involved Software\n\nNo other software should be necessary. However, we will need to do a needs analysis to determine which prerequisite packages/functionality is necessary in order to allow these tests to be implemented (e.g., BLAS, ndarray slicing, etc).\n\n### Prerequisite Knowledge\n\nJavaScript, Node.js. Familiarity with R, Python, C/C++ would be very useful, as will need to consult reference implementations.\n\n### Difficulty\n\nHard. Depends on the reference implementation requirements and algorithmic difficulty.\n\n### Project Length\n\n350 hours.\n\n### Potential Mentors\n\n@kgryte @Planeshifter @Pranavchiku\n\n* * *\n\n## Use ES6 modules for running unit tests and benchmarks in web browsers\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/21>\n\n### Idea\n\nCurrently, when generating stdlib API documentation, we generate UMD bundles for unit tests and benchmarks. When a user navigates to our package documentation, they can load unit tests and benchmarks and have those run without needing to setup a local environment. The pain point here is that creating separate bundles for each package is time consuming and adds significant heft to the `www` repo.\n\nThe goal of this idea is to refactor the way we support unit tests and benchmarks to use ES6 modules and potentially skip bundling altogether. This has the downside of not supporting older browsers which don't support the `<module>` tag, but is probably fine considering that running package unit tests and benchmarks is likely a forward looking concern.\n\n### Expected Outcomes\n\nUsers will be able to run unit tests and benchmarks directly in their web browsers by navigating to project API documentation and what is loaded are ES6 modules, not UMD bundles.\n\n### Involved Software\n\nNo other software is necessary.\n\n### Prerequisite Knowledge\n\nJavaScript, Node.js, HTML/CSS, JSX/React.\n\n### Difficulty\n\nIntermediate.\n\n### Project Length\n\n350 hours.\n\n### Potential Mentors\n\n@kgryte @Planeshifter @steff456\n\n* * *\n\n## Improve the REPL presentation framework\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/23>\n\n### Idea\n\nstdlib currently offers a REPL presentation framework for authoring presentations for use directly in the REPL. This is particularly useful for creating interactive tutorials illustrating how to use stdlib functionality for data analysis and visualization from the terminal. Some functionality is missing which would be quite useful. E.g.,\n\n- ASCII plotting\n- ASCII animations\n- syntax highlighting\n- pretty printing tables\n- speaker notes\n- multiplexing\n- theming\n\n### Expected Outcomes\n\nThe REPL presentation framework will have additional features similar to those in WYSIWYG presentation applications.\n\n### Involved Software\n\nNo other software is necessary.\n\n### Prerequisite Knowledge\n\nJavaScript, Node.js.\n\n### Difficulty\n\nIntermediate.\n\n### Project Length\n\n175/350 hours. Can be scoped according to project length.\n\n### Potential Mentors\n\n@kgryte @Planeshifter @steff456\n\n* * *\n\n## Functions for numerical integration and differentiation\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/24>\n\n### Idea\n\nThe goal of this idea is to add functions for numerical integration or differentiation to stdlib as building blocks for downstream algorithms. The functions could be ported from permissively licensed open-source libraries in other languages such as C or Fortran or alternatively be implemented from scratch by consulting the literature and reference implementations from various languages.\n\nSome work along these lines has been started in the scijs ecosystem, which can be used for initial inspiration (e.g., https://github.com/scijs/ode45-cash-karp), and more generally in SciPy (e.g., https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.ode.html).\n\n### Expected Outcomes\n\nstdlib will have a range of robust functions for performing numerical integration or differentiation\n\n### Involved Software\n\nNo other software is necessary.\n\n### Prerequisite Knowledge\n\nJavaScript, Node.js.\n\n### Difficulty\n\nIntermediate.\n\n### Project Length\n\n350 hours.\n\n### Potential Mentors\n\n@kgryte @Planeshifter @rreusser @Pranavchiku @czgdp1807\n\n* * *\n\n## Symbolic Math\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/25>\n\n### Idea\n\nThe goal of this idea is to add basic support for symbolic math operations in stdlib.\n\n### Expected Outcome\n\nUsers have the ability to perform basic symbolic math operations in JavaScript, such as solving equations, simplifying expressions, and using mathematical functions.\n\n### Involved Software\n\nNo other software should be necessary.\n\n### Prerequisite Knowledge\n\nJavaScript, Node.js, and an understanding of mathematics and calculus.\n\n### Difficulty\n\nIntermediate\n\n### Project Length\n\n350 hours.\n\n### Potential Mentors\n\n@kgryte @Planeshifter @rreusser\n\n* * *\n\n## Optimization Algorithms\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/27>\n\n### Idea\n\nWe currently do not have optimization algorithms in stdlib. Having support for Linear Programming, Convex Optimization, Quadratic Programming, and/or Non-Linear Optimization algorithms would be a great addition.\n\n### Expected Outcomes\n\nstdlib will have a broad array of optimization algorithms for solving problems.\n\n### Involved Software\n\nNo other software should be necessary. However, we will need to do a needs analysis to determine which prerequisite packages/functionality is necessary in order to allow these algorithms to be implemented (e.g., BLAS).\n\n### Prerequisite Knowledge\n\nJavaScript, Node.js. Familiarity with R, Python, C/C++ would be very useful, as will need to consult reference implementations.\n\n### Difficulty\n\nHard. Depends on the reference implementation requirements and algorithmic difficulty.\n\n### Project Length\n\n350 hours.\n\n### Potential Mentors\n\n@kgryte @Planeshifter @rreusser @Pranavchiku @czgdp1807\n\n* * *\n\n## Linear Algebra Functionality\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/28>\n\n### Idea\n\nCurrently, support for linear algebra operations in stdlib is limited. The goal of this idea would be to implement algorithms for linear algebra operations such as matrix multiplication, calculating the matrix inverse, eigenvalue calculation, singular value decomposition, Cholesky & LU Decomposition, and the like. This overlaps with the goal of increasing the amount of BLAS and LAPACK that is available in stdlib.\n\n### Expected Outcomes\n\nstdlib will have extended support for linear algebra operations which can be used to solve problems involving matrices and vectors.\n\n### Involved Software\n\nNo other software should be necessary. However, we will need to do a needs analysis to determine which prerequisite packages/functionality is necessary in order to allow these operations to be implemented (e.g., BLAS, ndarray slicing, etc).\n\n### Prerequisite Knowledge\n\nJavaScript, Node.js. C, Fortran. Familiarity with linear algebra would be very useful, as will need to consult and understand reference implementations.\n\n### Difficulty\n\nHard. Depends on the reference implementation requirements and algorithmic difficulty.\n\n### Project Length\n\n350 hours.\n\n### Potential Mentors\n\n@kgryte @Planeshifter @Pranavchiku @czgdp1807 @rreusser\n\n* * *\n\n## Develop C implementations for base special mathematical functions\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/34>\n\n### Idea\n\nThis idea builds on the work outlined in https://github.com/stdlib-js/stdlib/issues/649. Namely, implementing base special mathematical functions in C. Currently, all special mathematical functions have JavaScript implementations, which are often ports from other languages.\n\nThe goal of this idea is to port all JavaScript implementations to C. Having such implementations will allow stdlib to provide Node.js native add-ons for higher performance ndarray computation and is more generally necessary for achieving NumPy/SciPy parity.\n\n### Expected Outcomes\n\nUsers will be able to leverage C implementations for use in Node.js native add-ons, and stdlib will be able to expose element-wise APIs for evaluating base special math functions over ndarrays.\n\n### Involved Software\n\nNo other software is necessary.\n\n### Prerequisite Knowledge\n\nC, JavaScript, Node.js.\n\n### Difficulty\n\nIntermediate. Familiarity with C is beneficial. This idea mainly involves porting existing implementations (many of which are written in C/C++) and doing so in a manner which conforms with stdlib conventions.\n\n### Project Length\n\n90/175/350 hours. Can be scoped accordingly. Scope can be expanded to implement new special mathematical functions.\n\n### Potential Mentors\n\n@kgryte @Planeshifter @steff456 @rreusser @Pranavchiku @czgdp1807\n\n* * *\n\n## Develop an Excel add-on which exposes stdlib functionality\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/35>\n\n### Idea\n\nThe goal of this idea is to allow users to call stdlib APIs from within Excel. This will allow users to perform linear algebra and various machine learning operations directly on spreadsheet data and all within the browser.\n\nIn order to execute on this idea, we'll want to support\n\n- two-dimensional array broadcasting semantics\n- performant element-wise iteration APIs\n- input argument validation tailored to the Sheets context\n- Fused operations to avoid unnecessary network calls\n- documentation and tutorials demonstrating API usage\n- good generation and automation for creating extension builds\n- testing and performance measurement to guard against regressions\n\nThis idea is the Excel version of https://github.com/stdlib-js/google-summer-of-code/issues/13.\n\n### Expected Outcomes\n\nExcel users will be able to install an extension which exposes stdlib functionality, run statistical tests, evaluate mathematical functions, and perform linear algebra operations using stdlib.\n\n### Involved Software\n\nNo other software is necessary; however, access to a local copy of Excel will be beneficial. While Microsoft 360 can be used, debugging is more difficult and less stable.\n\n### Prerequisite Knowledge\n\nJavaScript, Node.js.\n\n### Difficulty\n\nBeginner/Intermediate. \n\n### Project Length\n\n175/350 hours. Can be scoped accordingly. A skilled contributor can work on a strategy for performant fused operations.\n\n### Potential Mentors\n\n@kgryte @Planeshifter @steff456\n\n* * *\n\n## Add BLAS bindings and implementations for linear algebra\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/36>\n\n### Idea\n\n[BLAS](https://netlib.org/blas/) routines are standard building blocks for performing basic vector and matrix operations. These building blocks are leveraged by most modern numerical programming languages and libraries, including NumPy, SciPy, Julia, MATLAB, R, and others.\n\nThe goal of this idea is to \n\n- reimplement reference BLAS routines in free-form Fortran 95\n- port reference BLAS routines to C\n- port reference BLAS routines to JavaScript\n- write Node.js bindings to allow calling BLAS routines in compiled C/ Fortran from JavaScript\n\n### Expected Outcomes\n\nUsers will be able to call BLAS routines from JavaScript. In web browsers, BLAS routines will be in JavaScript. In Node.js, provided native bindings have been compiled, BLAS routines will either be ported reference implementations or hardware optimized system libraries.\n\n### Involved Software\n\nNo other software is necessary apart from standard compilers (GCC, gfortran).\n\n### Prerequisite Knowledge\n\nC, Fortran, JavaScript, Node.js.\n\n### Difficulty\n\nIntermediate. Familiarity with C and Fortran will be beneficial. This idea mainly involves porting existing implementations and doing so in a manner which conforms with stdlib conventions.\n\n### Project Length\n\n90/175/350 hours. Can be scoped accordingly.\n\n### Potential Mentors\n\n@kgryte @Planeshifter @steff456 @rreusser @Pranavchiku @czgdp1807\n\n* * *\n\n## Implement incremental (online) machine learning algorithms\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/37>\n\n### Idea\n\nThe goal of this idea is to implement incremental machine learning algorithms to allow for real-time regression and classification. Such online algorithms would allow for point-by-point data processing and avoid the sometimes costly overhead of batch processing. Online algorithms are particularly useful in data streaming contexts (e.g., user clicks, photon collection, etc).\n\nWhile stdlib includes some incremental algorithms ([binary classification](https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/ml/incr/binary-classification), [k-means](https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/ml/incr/kmeans), and [stochastic gradient descent regression](https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/ml/incr/sgd-regression)), the project would benefit from additional algorithms.\n\nIndividuals interested in pursuing this idea should be prepared to research possible algorithms and propose specific APIs.\n\n### Expected Outcomes\n\nstdlib will expose one or more additional APIs for incremental machine learning.\n\n### Involved Software\n\nNo other software is necessary.\n\n### Prerequisite Knowledge\n\nJavaScript, Node.js.\n\n### Difficulty\n\nIntermediate. In order to implement ML algorithms, individuals will likely need to consult reference implementations written in other languages. Porting from these implementations may not be straightforward depending on the features involved.\n\n### Project Length\n\n90/175/350 hours. Can be scoped accordingly.\n\n### Potential Mentors\n\n@kgryte @Planeshifter\n\n* * *\n\n## Add support for string arrays in stdlib\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/44>\n\n### Idea\n\nSimilar to what's described in https://github.com/stdlib-js/google-summer-of-code/issues/43, a need exists to expand array data type support beyond numeric data types. One such data type is a `string` data type. The rationale for having a dedicated string data type is for better interoperation between JavaScript and C, and this is particularly paramount for supporting ndarrays having a string data type, as much of ndarray iteration machinery is written in C.\n\nAccordingly, the goal of this project is to add a dedicated string typed array called a `StringArray`, which will support variable-length strings. This new array type should follow a similar path to that of [@stdlib/array/complex64](https://github.com/stdlib-js/stdlib/tree/5dbb01dba2b1b305c6a11b66652ee2e4ccac15e2/lib/node_modules/%40stdlib/array/complex64), which provides a typed array dedicated to single-precision complex floating-point numbers; namely, `StringArray` should support standard typed array methods, as well as provide accessors for getting and setting array elements.\n\nNote, however, that a `StringArray` should be a typed array. A `StringArray` should not wrap a \"generic\" array. Instead, the array should be backed by fixed length memory, similar to how [@stdlib/array/complex64](https://github.com/stdlib-js/stdlib/tree/5dbb01dba2b1b305c6a11b66652ee2e4ccac15e2/lib/node_modules/%40stdlib/array/complex64) is backed by a `Float32Array`. One possibility is backing `StringArray` instances with Node.js `Buffer` objects, which are, in turn, `Uint8Array`s.\n\nThere are, however, some design considerations; namely, how to handle setting of array elements. In particular, what happens when a user attempts to update a `StringArray` element with a larger string? Does that lead to a new memory allocation and data copy? Or should elements have a fixed allocation to allow for elements to grow until some maximum size?\n\nAs part of this project, not only will a new `StringArray` be added to the project, but it will be integrated throughout stdlib. This will entail adding support for `StringArray`s wherever arrays are accepted/used, following the same precedent established by [@stdlib/array/complex64](https://github.com/stdlib-js/stdlib/tree/5dbb01dba2b1b305c6a11b66652ee2e4ccac15e2/lib/node_modules/%40stdlib/array/complex64) and other custom array types in stdlib. This includes adding support for string arrays in ndarray APIs.\n\n**Prior Art**\n\n- Recent work in NumPy adding UTF-8 variable length string support: https://numpy.org/neps/nep-0055-string_dtype.html\n\n### Expected outcomes\n\nThe expected outcomes of this idea should be (1) creation of a new `@stdlib/array/string` package exposing a new typed array constructor, (2) support for `StringArray` instances throughout `@stdlib/array/*`, (3) support for `StringArray` instances as backing arrays for ndarrays (which may involve working with various C APIs), and (4) any other integration opportunities.\n\n### Status\n\nWhile no work has been done to create a new `@stdlib/array/string` package, there exists prior art for adding custom typed arrays to stdlib; namely, `Complex64Array` and `Complex128Array`.\n\n### Involved software\n\nNo special software for initial work. Once work has progressed to ndarray support, will need access to a C compiler, as documented in the project development guide.\n\n### Technology\n\nJavaScript, C, nodejs, native addons\n\n### Other technology\n\nn/a\n\n### Difficulty\n\nIntermediate/Advanced\n\n### Difficulty justification\n\nThis project is ambitious, as there are many design considerations which need to be addressed  in order to ensure performance and allow for efficient JS/C interoperation.\n\nAdditionally, there will be difficulty beyond the creation of a new `StringArray` class in finding all the various bits of code throughout the project which need to be updated in order to more universally support `StringArray` instances throughout stdlib on equal footing with other array data types.\n\n### Prerequisite knowledge\n\nFamiliarity and comfort with JavaScript would be highly recommended, given that this project will require considerable programming in JavaScript. Some familiarity with C would also be good, especially for string array integration with ndarrays.\n\n### Project length\n\n350hrs, as will likely involve a decent amount of R&D.\n\n### Potential mentors\n\n@kgryte @Planeshifter\n\n* * *\n\n## Add support for `Float16Array`\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/94>\n\n### Idea\n\nWith `Float16Array` now on track for stage 4 approval in JavaScript (see https://github.com/tc39/proposal-float16array/issues/7), it is time we start thinking about adding support for `Float16Array` in stdlib. We have prior experience adding new array types, such as `array/bool`, `array/complex128`, and `array/complex64`, and this idea is a continuation of those efforts.\n\nThe expected roadmap is as follows:\n\n- add a new `array/float16` package which includes a polyfill for backward compatibility support. The polyfill should expose all common methods and properties as found on other typed array constructors. This package should contain complete tests, documentation, and benchmarks, as found in other typed array packages (e.g., `array/bool`).\n- add support for `float16` array dtypes throughout the `array/*` namespace.\n- add support for `float16` array dtypes throughout the `strided/*` namespace.\n- add support for `float16` array dtypes throughout the `ndarray/*` namespace.\n\n### Expected outcomes\n\nstdlib users will be able to create and operate on `Float16Array` instances the same way they do throughout the project, with `Float16Array` on equal footing with all other typed array classes.\n\n### Status\n\nNo work has been done on this idea; however, we expect that this should follow as similar path to `array/bool` and its integration throughout the project.\n\nRelated: https://github.com/stdlib-js/google-summer-of-code/issues/43\n\n### Involved software\n\nNo special software for initial work. Once work has progressed to ndarray support, will need access to a C compiler, as documented in the project development guide.\n\n### Technology\n\nJavaScript, C, nodejs, native addons\n\n### Other technology\n\nNone.\n\n### Difficulty\n\n4\n\n### Difficulty justification\n\nImplementing the polyfill will likely take some time, with the need for adding additional functionality to support the implementation (e.g., bit manipulation utilities, math utils, etc).\n\nThis project is ambitious, as arrays are fundamental to a lot of stdlib functionality; however, many of the more difficult integration aspects have already addressed given the widespread support for other array types throughout the project. The main project difficulty beyond the creation of a new `Float16Array` class will be finding all the various bits of code throughout the project which need to be updated.\n\n### Prerequisite knowledge\n\nFamiliarity and comfort with JavaScript would be highly recommended, given that this project will require considerable programming in JavaScript. Some familiarity with C would also be good, especially for float16 array integration with ndarrays.\n\n### Project length\n\n350\n\n* * *\n\n## Add LAPACK bindings and implementations for linear algebra\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/95>\n\n### Idea\n\n[LAPACK](https://netlib.org/lapack/) routines are standard building blocks for performing basic vector and matrix operations. These building blocks are leveraged by most modern numerical programming languages and libraries, including NumPy, SciPy, Julia, MATLAB, R, and others.\n\nThe goal of this idea is to\n\n- reimplement reference LAPACK routines in free-form Fortran 95\n- port reference LAPACK routines to pure C\n- port reference LAPACK routines to pure JavaScript\n- write Node.js bindings to allow calling LAPACK routines in compiled C/ Fortran from JavaScript\n\n### Expected outcomes\n\nUsers will be able to call LAPACK routines from JavaScript. In web browsers, LAPACK routines will be in JavaScript. In Node.js, provided native bindings have been compiled, LAPACK routines will either be ported reference implementations or hardware optimized system libraries.\n\n### Status\n\nSome work has begun toward this effort. See https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/lapack/base.\n\n### Involved software\n\nNo other software is necessary apart from standard compilers (GCC, gfortran).\n\n### Technology\n\nC, JavaScript, Fortran, nodejs, native addons\n\n### Other technology\n\nNone.\n\n### Difficulty\n\n4\n\n### Difficulty justification\n\nFamiliarity with C and Fortran will be beneficial. This idea mainly involves porting existing implementations and doing so in a manner which conforms with stdlib conventions. Some of the reference implementations are likely to be quite involved and testing the correct output can be tricky, especially for lower-level helper routines.\n\n### Prerequisite knowledge\n\nC, Fortran, JavaScript, Node.js.\n\n### Project length\n\n350\n\n* * *\n\n## Extend stdlib's doctesting approach to C examples\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/96>\n\n### Idea\n\nWe heavily rely on doctesting (see https://github.com/stdlib-js/stdlib/blob/develop/docs/doctest.md) to ensure that our Markdown and JSDoc examples are correct and do not become out-of-date. However, we currently have no such framework for ensuring that our C source code and Markdown examples are correct.\n\nThe goal of this project would be to implement doctesting for C source code and associated Markdown examples. While the approach is likely to be similar (e.g., parsing source code in scripts, Markdown code blocks, and in DOXYGEN examples), the technology stack is likely to be different and will require some R&D, especially as we won't be able to rely on things like ESLint. Instead, we'll need other tooling for identifying `// returns` annotations, instrumenting examples to collect return values, resolving source files to compile, compiling source files, executing scripts, and asserting that the output results match expectation.\n\n### Expected outcomes\n\nAs part of our CI workflows and in local development, developers will be able to test that their C examples are correct.\n\n### Status\n\nstdlib has its own doctesting framework for checking JavaScript examples. This should serve as inspiration and provide an idea of what we are looking for.\n\n### Involved software\n\nC compilers, AST generators, and stdlib tooling.\n\n### Technology\n\nC\n\n### Other technology\n\nNone.\n\n### Difficulty\n\n5\n\n### Difficulty justification\n\nThere is likely a need for R&D to determine the best tools and approach. For JavaScript examples, we are able to rely on the fact that we can lint and execute within the same JavaScript runtime. In this case, there will be additional steps needed to separately instrument, create temporary files, compile, execute, and collect.\n\n### Prerequisite knowledge\n\nExperience with C and creating tooling will be beneficial.\n\n### Project length\n\n350\n\n* * *\n\n## Add WebAssembly implementations for extended BLAS routines\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/97>\n\n### Idea\n\nWe've worked toward compiling BLAS routines to WebAssembly and offering ergonomic APIs for interfacing between JavaScript and WebAssembly binaries (see https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/blas/base/wasm). The goal of this project would be to extend these efforts to the `blas/ext/base` namespace, such that, for each typed interface in `blas/ext/base/(d|s|c|z|)*`, there would be a corresponding WebAssembly package in `blas/ext/base/wasm/*`.\n\n### Expected outcomes\n\nUsers wanting to potentially accelerate computation of extended BLAS routines will be able to consume a corresponding WebAssembly API.\n\n### Status\n\nWork has primarily happened in https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/blas/base/wasm. The efforts there would need to be replicated for the `blas/ext/base/wasm/*` namespace.\n\n### Involved software\n\nEmscripten, which is necessary for compiling C to WebAssembly. stdlib already offers tooling for automatically installing the emsdk and getting things up and running.\n\n### Technology\n\nC, JavaScript\n\n### Other technology\n\nNone.\n\n### Difficulty\n\n3\n\n### Difficulty justification\n\nGiven that most `blas/ext/base/*` routines are straightforward one-dimensional strided array interfaces, developing the wasm packages should be similarly straightforward. The main time-consuming task will be writing tests and documentation.\n\n### Prerequisite knowledge\n\nSome familiarity with WebAssembly will be helpful. Experience with JavaScript.\n\n### Project length\n\n90/175/350. Can be scoped accordingly.\n\n* * *\n\n## Add WebAssembly implementations for `stats/strided` routines\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/98>\n\n### Idea\n\nWe've worked toward compiling BLAS routines to WebAssembly and offering ergonomic APIs for interfacing between JavaScript and WebAssembly binaries (see https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/blas/base/wasm). The goal of this project would be to extend these efforts to the `stats/strided` namespace, such that, for each typed interface in `stats/strided/(d|s|c|z|)*`, there would be a corresponding WebAssembly package in `stats/strided/wasm/*`.\n\n### Expected outcomes\n\nUsers wanting to potentially accelerate computation of strided statistics routines will be able to consume a corresponding WebAssembly API.\n\n### Status\n\nWork has primarily happened in https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/blas/base/wasm. The efforts there would need to be replicated for the `stats/strided/*` namespace.\n\n### Involved software\n\nEmscripten, which is necessary for compiling C to WebAssembly. stdlib already offers tooling for automatically installing the emsdk and getting things up and running.\n\n### Technology\n\nC, JavaScript\n\n### Other technology\n\nNone.\n\n### Difficulty\n\n3\n\n### Difficulty justification\n\nGiven that most `stats/strided/*` routines are straightforward one-dimensional strided array interfaces, developing the wasm packages should be similarly straightforward. The main time-consuming task will be writing tests and documentation.\n\n### Prerequisite knowledge\n\nSome familiarity with WebAssembly will be helpful. Experience with JavaScript.\n\n### Project length\n\n90/175/350. Can be scoped accordingly.\n\n* * *\n\n## Create a prototype for transpiling a subset of TypeScript to C with automatic add-on generation\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/99>\n\n### Idea\n\nDrawing on some of the recent innovations in the numerical Python ecosystem (e.g., see [`pyccel`](https://github.com/pyccel/pyccel/tree/devel)), the goal of this project would be to see if we can define a restricted subset of TypeScript which can be transpiled to C for faster execution in Node.js and other server runtimes.\n\nThere is some prior art here; namely, [AssemblyScript](https://www.assemblyscript.org), which provides a TypeScript-like language which compiles to WebAssembly. However, we should be able to go farther here, especially in leveraging stdlib's richer collection of types (in particular, complex number dtypes). From this restricted subset, we can then automate transpilation of TypeScript to C, with the ability to automatically generate Node.js native add-ons bindings similar to what can be found in, e.g., https://github.com/stdlib-js/stdlib/blob/954e7c1e1716bfdd15903b4be7039741396927eb/lib/node_modules/%40stdlib/blas/base/dcopy/src/addon.c.\n\nThere would be some puzzle pieces to put together here. Namely,\n\n- defining a richer set of numeric types. Currently, stdlib uses `number`, `boolean`, `Float64Array`, and other built-in types, along with a couple of custom types, such as `Complex128` and `Complex64`. We'd like want to create named aliases for specific numeric types, such as `int64`, `int32`, etc (similar to AssemblyScript). These would not impact consumption of project type declarations in TypeScript; although, they would have the benefit of signaling expected types.\n- updating the TypeScript declarations for various packages (e.g., `blas/ext/base`) to use the newly defined types.\n- creating tooling which can resolve and read a TypeScript declaration for an exported function and then automatically generate an `addon.c` file. If we can reproduce the [`addon.c`](https://github.com/stdlib-js/stdlib/blob/954e7c1e1716bfdd15903b4be7039741396927eb/lib/node_modules/%40stdlib/blas/base/dcopy/src/addon.c) file in `blas/base/dcopy`, that would be a win.\n- potentially porting a subset of JavaScript implementations to TypeScript using the aliases defined above.\n- from the ports, creating tooling which can, with high fidelity, generate one or more JavaScript implementations.\n- from the ports, creating tooling which can, with high fidelity, generate one or more C implementations.\n\nNote that, when transpiling from TypeScript to C, we'd need to properly determine appropriate stdlib includes and dependencies. If we could auto-generate a basic `manifest.json` file, that could also be useful.\n\nWe could also explore a TypeScript to Fortran transpiler.\n\n### Expected outcomes\n\nA working end-to-end prototype which is capable of transpiling stdlib-flavored TypeScript to C and which can reproduce hand-authored C and JavaScript code.\n\n### Status\n\nNo work has begun on this.\n\n### Involved software\n\nTypeScript and C/Fortran compilers.\n\n### Technology\n\nC, JavaScript, native addons, Fortran\n\n### Other technology\n\nNone.\n\n### Difficulty\n\n4\n\n### Difficulty justification\n\nThis idea is exploratory, and, while conceptually straightforward, the project does involve a number of unknowns, particularly around how easy it will be to reproduce hand-optimized code. Given that the `blas/base/*`, `blas/ext/base/*`, and `stats/strided/*` namespaces provide a relatively contained environment for API design, it's possible that this will be achievable, but we won't know the best approach until after some R&D.\n\n### Prerequisite knowledge\n\nTypeScript, C, and JavaScript experience would be beneficial.\n\n### Project length\n\n350\n\n* * *\n\n## Add matrix format parsers and data loaders\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/100>\n\n### Idea\n\nThe goal of this project would be to implement various matrix and multi-dimensional format parsers and data loaders. E.g.,\n\n- [Matrix Market](https://math.nist.gov/MatrixMarket/formats.html#MMformat)\n- [NumPy `npy`](https://numpy.org/doc/stable/reference/generated/numpy.lib.format.html#module-numpy.lib.format)\n- [DLPack](https://dmlc.github.io/dlpack/latest/)\n- [MATLAB `mat`](https://www.mathworks.com/help/pdf_doc/matlab/matfile_format.pdf)\n- others?\n\nImplementing these parsers and loaders would facilitate array data interchange with other numerical computing ecosystems.\n\n### Expected outcomes\n\nUsers will be able to load multi-dimensional array data saved in other numerical computing environments into stdlib's `ndarray` data structure.\n\n### Status\n\nNo work has begun on this.\n\n### Involved software\n\nAccess to MATLAB/Octave would be useful for implementing the MAT-file parser. One would likely need to use Python and NumPy in order to save and work with `npy` files.\n\n### Technology\n\nJavaScript\n\n### Other technology\n\nNone.\n\n### Difficulty\n\n4\n\n### Difficulty justification\n\nSome of the file format specifications can be quite involved. It is also likely that we may encounter situations in which we cannot support particular formats in full due to dtype incompatibility, etc.\n\n### Prerequisite knowledge\n\nFamiliarity with JavaScript, Python, and MATLAB would be useful. Experience writing parsers and performing IO will also be beneficial.\n\n### Project length\n\n90/175/350. Can be scoped accordingly.\n\n* * *\n\n## Add support for working with arrays backed by memory-mapped files\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/101>\n\n### Idea\n\nMemory-mapped files allow accessing small segments of large disks stored on disk, without reading the entire file into memory. Not only can this be advantageous for memory performance, but it also facilitates shared memory between processes (e.g., operating on the same array in both Node.js and Python running in two separate processes).\n\nThe goal of this project is to add support for working with typed arrays backed by memory-mapped files. Memory-mapped-backed typed arrays should support all the APIs of built-in typed arrays, with the exceptions that the constructors will need to support `mmap`-related arguments (e.g., filename, mode, offset) and indexing will require accessors, not square bracket syntax. The project is well-prepared to support accessors (see `array/bool`, `array/complex128`, etc), such that, provided a memory-mapped typed array supports the accessor protocol, passing to downstream utilities should just work.\n\nSimilar to how we've approached fixed-endian typed arrays (see [`array/fixed-endian-factory`](https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/array/fixed-endian-factory)), we can likely create a package exposing a constructor factory and then create lightweight wrappers for type-specific constructors (e.g., [`array/little-endian-float64`](https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/array/little-endian-float64)).\n\nThis project may require figuring out a strategy for C-JS iterop which can be used across constructors.\n\n### Expected outcomes\n\nIdeally, we would have the following constructors:\n\n- `Float64ArrayMMap`\n- `Float32ArrayMMap`\n- `Int32ArrayMMap`\n- `Int16ArrayMMap`\n- `Int8ArrayMMap`\n- `Uint32ArrayMMap`\n- `Uint16ArrayMMap`\n- `Uint8ArrayMMap`\n- `Uint8ClampedArrayMMap`\n- `BooleanArrayMMap`\n- `Complex128ArrayMMap`\n- `Complex64ArrayMMap`\n\nAdditionally, the following constructors would also be useful:\n\n- `DataViewMMap`\n\n### Status\n\nNone.\n\n### Involved software\n\nC compiler such as GCC or Clang.\n\n### Technology\n\nC, JavaScript, nodejs, native addons\n\n### Other technology\n\nNone\n\n### Difficulty\n\n5\n\n### Difficulty justification\n\nFiguring out an effective bridge between JavaScript and C for working with memory-mapped files will likely require some R&D. It is not clear whether we'd need to first develop separate dedicated `mmap(2)`-like functionality in JavaScript or whether we can directly interface into C. Once the lower-level details are determined, the next steps will be implementing all the user-facing APIs expected from typed arrays. This should be straightforward; however, there may be some unexpected challenges and constraints surrounding read-only access, etc.\n\n### Prerequisite knowledge\n\nC, JavaScript, and Node.js experience will be useful.\n\n### Project length\n\n350\n\n* * *\n\n## Improve project supply chain security by bringing production dependencies in-house\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/102>\n\n### Idea\n\nstdlib currently depends on [`14`](https://github.com/stdlib-js/stdlib/blob/develop/package.json#L55) external packages. Ideally, we'd reduce this number to `0` in order to (a) reduce the risk of supply-chain security vulnerabilities and (b) ensure that all production code used within stdlib follows the \"stdlib way\" (i.e., docs, tests, examples, benchmarks, backward-compatibility guarantees, etc).\n\nAccordingly, this project seeks to bring external packages \"in-house\" by implementing stdlib equivalents which can replace their usage within stdlib. Immediate targets are dependencies such as `debug`, `glob`, `resolve`, and `minimist` which we'd like to bring in-house for their own sake.\n\nBringing `acorn` and friends in-house would likely require more work and impose an increased maintenance burden, so we'd want to be careful in determining whether we want to prioritize a stdlib implementation. That said, having a stdlib suite of JavaScript AST manipulators would be useful. The main concern is simply keeping up with yearly ECMAScript versions. If we stayed close enough to `acorn`, we could potentially just mirror changes into stdlib. Regardless, some thought would be required to determine whether we want to model any stdlib implementation after acorn or some other high-quality and performant AST parser third-party package.\n\nFor `d3-*` and friends, these would likely go away once we migrated our plot functionality to use `vega`. So their priority is lower.\n\nFor `vdom-to-html` and `virtual-dom`, these have been useful in the past; however, it is not clear whether these deserve inclusion in stdlib. They are currently used in the stdlib plot API. Similar to the `d3-*` packages, they might just naturally go away after migrating plot functionality to `vega`.\n\n`readable-stream` is a harder package to migrate. First and foremost, one should evaluate how much we actually need `readable-stream` and whether we can still retain desired backward compatible behavior with built-in Node.js streams. It is possible that the answer is yes; however, historically, using `readable-stream` has been critical in ensuring consistent behavior across Node.js versions.\n\n### Expected outcomes\n\nThird-party party production dependencies would have equivalent stdlib implementations, and we can remove them as dependencies in the project `package.json`.\n\n### Status\n\nNo work has begun on this.\n\n### Involved software\n\nNone.\n\n### Technology\n\nJavaScript, nodejs\n\n### Other technology\n\nNone.\n\n### Difficulty\n\n4\n\n### Difficulty justification\n\nIt depends on which dependencies are prioritized. Some, such as `acorn`, could be quite involved and require extensive testing. Others, such as `resolve` should be more straightforward. `glob` is likely to require significant R&D in order to understand and determine an ideal API.\n\n### Prerequisite knowledge\n\nExperience and a high degree of comfort with JavaScript and Node.js.\n\n### Project length\n\n90/175/350. Scope can be tailored accordingly.\n\n* * *\n\n## Implement ndarray APIs to achieve compliance with the Array API specification\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/176>\n\n### Idea\n\nThe [Array API standard](https://data-apis.org/array-api/latest/) is a specification describing a set of array operations for array libraries within the Python ecosystem. These operations including those for creating, transforming, and manipulating array contents and provide a common substrate upon which higher order libraries, such as those for machine learning, AI, statistical analysis, and data processing, can build. The Array API standard has seen rapid adoption within the Scientific Python ecosystem, with NumPy, CuPy, JAX, PyTorch, and others providing implementations, and downstream libraries, such as SciPy and scikit-learn, moving to adopt.\n\nThe goal of this idea is to implement the functions described in the Array API standard for use with stdlib's [ndarrays](https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/ndarray/ctor), which are efficient data structures for operating on multi-dimensional data. A principle difficulty in implementing these functions is ensuring efficient iteration of non-contiguous data. The main patterns for such iteration have been established in stdlib, but work remains to apply such patterns for top-level APIs. Having these functions would be a significant improvement for usability, as users from the Python ecosystem would benefit from a common vocabulary and set of building blocks, thus reducing the learning curve and facilitating stdlib adoption.\n\nFor those interested in this idea, you should\n\n- study https://data-apis.org/array-api/latest/\n- create a list of APIs present in the standard (e.g., in a Google spreadsheet)\n- find equivalent APIs already present in stdlib\n- identify which APIs have not already been implemented\n- survey libraries within the Python ecosystem (e.g., NumPy) to determine how the missing libraries are implemented\n- describe a plan for implementing the missing functions\n\n### Expected Outcomes\n\nUsers will be able to use implemented APIs (exposed as part of individual packages) for operating on ndarrays and will be able to implement various operations found in SciPy and sklearn using only the developed API primitives.\n\n### Involved Software\n\nNo other software is necessary.\n\n### Prerequisite Knowledge\n\nJavaScript, Node.js.\n\nFor APIs not accepting callbacks, certain kernels can be implemented in C, as time and scope allow.\n\n### Difficulty\n\nIntermediate. Writing the loop kernels can be involved, but, once understood, are straightforward to apply.\n\n### Project Length\n\n90/175/350 hours. Can be scoped accordingly. Scope can be expanded to implement additional ndarray kernels outside of the Array API standard.\n\n* * *\n\n## Integrate stdlib into scijs packages\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/177>\n\n### Idea\n\n[scijs](https://github.com/orgs/scijs/repositories?type=source) is a collection of numerical and scientific computing packages and utilities for working with multi-dimensional array data. While stdlib has surpassed scijs in terms of breadth and depth of functionality, scijs still includes a good bit of widely used functionality. One of the points of friction within the JavaScript ecosystem is the lack of interoperability between stdlib and scijs.\n\nThe goal of this idea is to integrate stdlib into applicable scijs packages, and, where appropriate, to implement scijs operations in stdlib which are not currently present. This effort will entail updating various scijs packages to accept and operate on stdlib ndarrays, and where stdlib equivalents already exist, updating the current scijs implementations to delegate to stdlib implementations (e.g., see https://github.com/scijs/ndarray-fill, which, after standardizing input arguments, could delegate to `@stdlib/ndarray/fill`).\n\nFor those interested in this idea, you should\n\n- study https://github.com/orgs/scijs/repositories?type=source\n- create a list of APIs present in scijs (e.g., in a Google spreadsheet)\n- find equivalent APIs already present in stdlib\n- identify which APIs have not already been implemented\n- identify which APIs are amenable to stdlib integration (note: not all APIs can be delegated to stdlib!)\n- describe a plan for achieving integration\n\n### Expected Outcomes\n\nUsers will be able to use scijs APIs with stdlib ndarrays and, where appropriate, scijs APIs will delegate to stdlib functionality.\n\n### Involved Software\n\nNo other software is necessary.\n\n### Prerequisite Knowledge\n\nJavaScript, Node.js.\n\n### Difficulty\n\nIntermediate.\n\n### Project Length\n\n90/175/350 hours. Can be scoped accordingly.\n\n* * *\n\n## Integrate stdlib in jstat\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/178>\n\n### Idea\n\n[jstat](https://jstat.github.io/all.html) is a collection of statistical APIs. While stdlib has surpassed jstat in terms of breadth and depth of functionality, scijs still includes a good bit of widely used functionality. One of the points of friction within the JavaScript ecosystem is the lack of interoperability between stdlib and jstat.\n\nThe goal of this idea is to integrate stdlib into jstat, and, where appropriate, to implement jstat operations in stdlib which are not currently present. This effort will entail updating jstat to leverage stdlib functionality. An initial exploration of this idea can be found in https://github.com/jstat/jstat/pull/260, but that effort likely needs to be scrapped, as stdlib has grown quite a bit since that time.\n\nFor those interested in this idea, you should\n\n- study https://github.com/jstat/jstat\n- create a list of APIs present in jstat (e.g., in a Google spreadsheet)\n- find equivalent APIs already present in stdlib\n- identify which APIs have not already been implemented\n- identify which APIs are amenable to stdlib integration (note: not all APIs can be delegated to stdlib!)\n- describe a plan for achieving integration\n\n### Expected Outcomes\n\nUsers will be able to use jstat whose APIs will delegate to stdlib functionality.\n\n### Involved Software\n\nNo other software is necessary.\n\n### Prerequisite Knowledge\n\nJavaScript, Node.js.\n\n### Difficulty\n\nIntermediate. Some care will need to be made to prevent jstat's bundle size from growing too large due to stdlib incorporation. This may require a specialized vendored bundle or the ability to only support select stdlib data types (e.g., no boolean or complex number arrays).\n\n### Project Length\n\n90/175/350 hours. Can be scoped accordingly.\n\n* * *\n\n## Add strided implementations of statistical hypothesis tests\n\nLinked issue: <https://github.com/stdlib-js/google-summer-of-code/issues/179>\n\n### Idea\n\nIn the [`@stdlib/stats`](https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/stats) namespace, we implement a number of hypothesis tests (e.g., z-test, t-test, chi-square test, Bartlett test, and more). Recently, we began work to create lower-level strided array implementations (e.g., see [`@stdlib/stats/strided/dztest`](https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/stats/strided/dztest)). These strided APIs allow us to create type-specialized implementations which can be implemented in both JavaScript and C, and they allow us to create higher-level ndarray APIs which can operate on one or more ndarray dimensions.\n\nThe goal of this idea is to build on the work implementing strided APIs for `ztest` and `ztest2` to implement strided APIs for the remainder of the statistical hypothesis test APIs.\n\nFor those interested in this idea, you should\n\n- study https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/stats/strided/dztest, https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/stats/strided/sztest, https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/stats/strided/ztest, etc, along with their dependency trees, in order to understand how these packages are put together.\n- create a list of currently supported hypothesis tests (e.g., in a Google spreadsheet)\n- find which ones we have already implemented lower-level strided array APIs\n- identify which APIs have not already been implemented\n- identify the prerequisite packages, such as dependencies, which are not currently available (e.g., C APIs) and will need to be implemented\n- describe a plan for implementing the missing functions\n\n### Expected Outcomes\n\nUsers will be able to use strided implemented APIs to operate on one-dimensional strided arrays.\n\n### Involved Software\n\nNo other software is necessary.\n\n### Prerequisite Knowledge\n\nJavaScript, Node.js.\n\n### Difficulty\n\nIntermediate. There may be some instances where we will need to ensure implementation of certain functions in C (e.g., certain `stats/base/dists/*` packages) and those may vary in difficulty (e.g., beta functions).\n\n### Project Length\n\n90/175/350 hours. Can be scoped accordingly. Scope can be expanded to implement additional statistical hypothesis tests which are not currently available in stdlib."
  },
  {
    "name": "MDAnalysis",
    "slug": "mdanalysis",
    "tagline": "Analysis of molecular simulations data with Python",
    "description": "MDAnalysis is a Python library for the analysis of computer simulations of many-body systems at the molecular scale, spanning use cases from interactions of drugs with proteins to novel materials. It is written by scientists for scientists and is used for cutting edge research in biophysics, chemistry, soft-matter physics, and materials research around the world in academia and national research labs. MDAnalysis strives to be highly interoperable and hence a growing number of projects use MDAnalysis as their foundational library or integrate it.\n\nThe goal of MDAnalysis is to make it easy for users to analyze data that are produced by simulations (primarily molecular dynamics simulations) that run on some of the largest supercomputers in the world. MDAnalysis accomplishes this goal by providing a toolkit of programming building blocks that provide an abstract Python interface to the simulation data — agnostic of the specific simulation package that produced it — that lends itself to interactive data exploration and rapid prototyping but is also a robust foundational library that can form the basis for new computational tools.\n\nMDAnalysis allows one to read particle-based trajectories such as the ones produced by MD simulations or individual coordinate frames (such as biomolecules in the Protein Databank format) and access the atomic coordinates through NumPy arrays. Together with a powerful selection language and many implemented analysis algorithms, MDAnalysis provides a flexible and fast framework for complex analysis tasks. Welcoming documentation such as the User Guide https://userguide.mdanalysis.org/ make it easy to get started. New releases are downloaded a few thousand times and the academic papers describing MDAnalysis are cited more than almost two thousand times, indicating the widespread use in the academic community.",
    "ideas_url": "https://github.com/MDAnalysis/mdanalysis/wiki/GSoC-2026-Project-Ideas",
    "website_url": "https://www.mdanalysis.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "cython",
      "c/c++"
    ],
    "topic_tags": [
      "science",
      "computational-chemistry",
      "high-performance-computing",
      "molecular-simulation",
      "machine-learning"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/mdanalysis",
    "ideas_content": "<img src=\"https://developers.google.com/open-source/gsoc/resources/downloads/GSoC-Vertical.png\" title=\"Google Summer of Code 2026\" alt=\"Google Summer of Code 2026\" align=\"right\" width=\"33%\" />\n\n<!--\n\n----\n\n**IMPORTANT:** THIS PAGE IS ONLY A DRAFT. Given that there is an application process for organizations — such as MDAnalysis — to participate in the [GSoC](https://summerofcode.withgoogle.com/) program, there is no guarantee that MDAnalysis will be selected by Google as a participating GSoC organization. Once we know more, we will share updates on our [public communication channels](https://www.mdanalysis.org/pages/community/), in particular in the [Announcement](https://github.com/MDAnalysis/mdanalysis/discussions/categories/announcements) discussion.\n\n----\n\n-->\n\nHello, and welcome to MDAnalysis! \n\nPlease **read [our blog post](https://www.mdanalysis.org/2026/02/19/gsoc2026)** for important official information.\n\nPlease see [[our Google Summer of Code wiki page|Google Summer of Code]] for general information, including advice on application writing, and [[our GSoC FAQ|GSoC-FAQ]] for commonly asked questions.\n\nIf you just found out about the MDAnalysis Python package from the GSoC website, you can watch the [MDAnalysis 2021 Trailer](https://www.youtube.com/watch?v=uMAfvwFkD3o) to get an overview of the scope of the MDAnalysis package.\n\n### Prerequisites\n\nMDAnalysis is a Python library for the analysis of computer simulations of many-body systems at the molecular scale, spanning use cases from interactions of drugs with proteins to novel materials. For Google Summer of Code, [we are also collaborating](#collaborations) with other organizations and software projects that use MDAnalysis. Our GSoC projects generally require a basic knowledge and hands-on experience in specific areas, so *for our suggested projects, please check carefully the project descriptions to see the associated desirable skills*. Broadly speaking, we found that applicants with experience in molecular dynamics (MD) simulations and the associated analyses — or equivalent experience in simulations and modeling of molecular systems (physics, biophysics, chemistry, or materials) — are very successful.\n\n### To Prospective Applicants\nIf you are interested in taking part, please get in touch on the [GSoC with MDAnalysis Discussion Forum](https://github.com/MDAnalysis/mdanalysis/discussions/categories/gsoc-discussions). Given the GSoC program structure (small, medium, and large projects), letting us know of your intentions to apply and getting acquainted with the project early will be very helpful.\n\n### To Prospective Mentors\nMDAnalysis welcomes new mentors; please get in touch on the [developer forum](https://github.com/MDAnalysis/mdanalysis/discussions/categories/development) if you are interested in taking part. We typically expect mentors to be familiar with our development process, as evidenced by contributions to the code base and interactions on the developer forum.\n\n# Overview\n\nSee below for a list of projects ideas for [[Google Summer of Code 2026|Google-Summer-Of-Code]].\n\nThe currently proposed projects are:\n\n1. Dashboard for tracking MD simulation progress with the new streaming interface\n2. Better interfacing of Blender and MDAnalysis\n3. Benchmarking and performance optimization\n4. Lazy trajectory loading and indexing\n5. Dashboard for tracking WESTPA simulation progress\n6. Interface for post-simulation analysis (\"crawling\") of WESTPA simulations\n\n**Or work on your own idea!** Get in contact with us to propose an idea and we will work with you to flesh it out into a full project. Contact us via the [GSoC with MDAnalysis Discussion Forum](https://github.com/MDAnalysis/mdanalysis/discussions/categories/gsoc-discussions) (or if your project is a specific feature you'd want to add, raise an issue in the [Issue Tracker](/MDAnalysis/mdanalysis/issues)).\n\nLook at the [list of all available mentors for MDAnalysis](https://github.com/MDAnalysis/mdanalysis/wiki/Google-Summer-Of-Code#available-mentors) for potential mentors for your project. Please send all communications to the [discussion forum](https://github.com/MDAnalysis/mdanalysis/discussions/categories/gsoc-discussions) (and don't contact mentors privately). You can certainly ask for the opinion of a specific mentor if you know that their expertise is particularly suitable for your project.\n\n## Collaborations\n\nFor GSOC, MDAnalysis collaborates with other projects that have direct links with MDAnalysis and where it is especially useful to draw on the combined mentoring expertise.\n\n### Molecular Nodes\n\nBuilt as an add-on for the popular and industry-leading 3D software [Blender](https://www.blender.org/), [Molecular Nodes](https://bradyajohnston.github.io/MolecularNodes/) (MN) enables import and visualization of complex molecular datasets inside of Blender. Many formats are supported such as static structures, electron density maps, EM (electromagnetic) tomography data and importantly, molecular dynamics simulation trajectories, powered by MDAnalysis. Blender is primarily intended for use via a GUI by artists, but scripting via the python API is also possible, with many potential avenues for automated animation and rendering.\n\nA great overview of the project is the talk given at the [Blender Conference in 2022](https://www.youtube.com/watch?v=adhTmwYwOiA). The [MN documentation](https://bradyajohnston.github.io/MolecularNodes/) includes a lot of information about how to get started, including written and video tutorials, with one [specific to MD trajectory import](https://bradyajohnston.github.io/MolecularNodes/tutorials/03_molecular_dynamics.html). Workshop materials are also publicly available for an online [Introduction to MDAnalysis and Molecular Nodes workshop](https://github.com/MDAnalysis/MDAnalysisWorkshop-Intro0.5Day/tree/feb24-ws) held in February 2024, which includes an interactive tutorial for visualizing imported MDAnalysis data in Molecular Nodes.\n\nIt's important to first familiarize yourself with using Blender and Molecular Nodes via a GUI and some of the quirks that go along with it, before trying to write code for it.\n\n### WESTPA\n\n[WESTPA](http://westpa.github.io/westpa) (The Weighted Ensemble Simulation Toolkit with Parallelization and Analysis) is a high-performance Python framework for applying the weighted ensemble (WE) path sampling strategy, which enables simulations of processes that are orders of magnitude longer than the simulations themselves. A WE simulation involves an iterative process: many MD simulations are executed in parallel and periodically evaluated to be replicated or terminated based on a set WE resampling criteria. To rigorously apply WE resampling, the MD simulations are analyzed during run time with tools such as MDAnalysis to determine the state of the simulated system.\n\nRead the [WE Overview](https://westpa.github.io/westpa/overview.html); [install the WESTPA package](https://github.com/westpa/westpa/wiki/Installing-WESTPA); and work through tutorials 7.1 and 7.5 of our [tutorials suite](https://github.com/westpa/tutorials) to start learning more about WESTPA.\n\n------\n\n# Project summary\n\nThe table summarizes the project ideas; long descriptions come after the table (or click on the links under each project name). The difficulty is a somewhat subjective ranking, where *easy* means that we know pretty much what needs to be done, *medium* requires some additional research into best solutions as part of the project, and *hard* is high risk/high reward where we think a solution exists but we will have to work with the student to find it and implement it. The project size is either 90 h (small), 175 h (medium) or 350 h (large) projects.\n\nEach project has one *primary mentor* assigned and potentially multiple additional mentors.\nEach primary mentor will only *mentor a single GSoC project*, even if listed as a potential mentor for multiple projects in the table. Mentor availability will be taken into account during the project selection process.\n\n| project | name                                                                                                                                                      | difficulty | project size | description                                                                                    | skills                      | mentors                                |\n|---------|-----------------------------------------------------------------------------------------------------------------------------------------------------------|------------|------------|------------------------------------------------------------------------------------------------|-----------------------------|----------------------------------------|\n| 1       | [Dashboard for tracking MD simulation progress with the new streaming interface](#project-1-dashboard-for-tracking-md-simulation-progress-with-the-new-streaming-interface)                                         | easy/medium     | 175/350 hours   | Create a web-based dashboard for real-time monitoring and analysis of MD simulations                                                                   | Python (frontend UI, multiprocessing), Networking (TCP/IP)                  | [@HeydenLab](https://github.com/HeydenLab) [@amrutesht](https://github.com/amrutesht) [@orbeckst](https://github.com/orbeckst) |\n| 2       | [Better interfacing of Blender and MDAnalysis](#project-2-better-interfacing-of-blender-and-mdanalysis)                                         | medium     | 350 hours   | Improve how Blender and Molecular Nodes interface with MDAnalysis to import and animate MD trajectories                                                                   | Python, MDAnalysis, Blender (and programming via its Python API)                  |  [@bradyajohnston](https://github.com/bradyajohnston) [@nilay-v3rma](https://github.com/nilay-v3rma) |\n| 3       | [Benchmarking and performance optimization](#project-3-benchmarking-and-performance-optimization)                                         | easy/medium     | 90/175/350 hours   | Write benchmarks for automated performance analysis and address performance bottlenecks                                                                   | Python/ASV, Cython                  | [@orbeckst](https://github.com/orbeckst) [@yuxuanzhuang](https://github.com/yuxuanzhuang) [@talagayev](https://github.com/talagayev) |\n| 4       | [Lazy trajectory loading and indexing](#project-4-lazy-trajectory-loading-and-indexing)                                         | medium     | 175/350 hours   | Improve performance of trajectory reading by implementing lazy indexing                                                                   | Python, trajectory I/O, performance optimization                  | [@yuxuanzhuang](https://github.com/yuxuanzhuang) [@orbeckst](https://github.com/orbeckst) [@talagayev](https://github.com/talagayev) |\n| 5       | [Dashboard for tracking WESTPA simulation progress](#project-5-dashboard-for-tracking-westpa-simulation-progress)                                         | easy     | 90 hours   | Create a graphical user interface to report MD trajectory progress                                                                   | Python (frontend UI, multiprocessing), Networking (TCP/IP)                  | [@jeremyleung521](https://github.com/jeremyleung521) [@ltchong](https://github.com/ltchong) [@nilay-v3rma](https://github.com/nilay-v3rma) |\n| 6       | [Interface for post-simulation analysis (\"crawling\") of WESTPA simulations](#project-6-interface-for-post-simulation-analysis-crawling-of-westpa-simulations)                                         | easy     | 90 hours   | Create an interface for reading, analyzing, and writing post-simulation data from WESTPA HDF5 Framework             | Python (frontend UI, multiprocessing), HDF5 Format (h5py, hdf5)         | [@jeremyleung521](https://github.com/jeremyleung521) [@ltchong](https://github.com/ltchong) |\n\n\n## Project 1: Dashboard for tracking MD simulation progress with the new streaming interface\n\n### Summary\n\nThis project will develop a browser-based, real-time dashboard for molecular dynamics simulations using the new IMDv3 streaming protocol, enabling live monitoring, analysis, and visualization of running simulations. The dashboard will leverage [imdclient](https://imdclient.readthedocs.io) and MDAnalysis to receive a data stream from a running simulation.\n\n### Detailed Description\n\nModern molecular dynamics (MD) simulations can run for days or weeks, yet most analysis workflows remain strictly post-hoc, requiring trajectory files to be written to disk and analyzed only after completion. Recently, we introduced IMDv3, a TCP/IP-based streaming protocol implemented in major MD engines such as LAMMPS, NAMD3, and GROMACS, together with a Python package, [imdclient](https://github.com/Becksteinlab/imdclient), that simplifies consuming these live data streams. In parallel, the MDAnalysis project now includes a reader ([IMDReader](https://docs.mdanalysis.org/stable/documentation_pages/coordinates/IMD.html))that can access IMDv3 streams as if they were conventional trajectory files.\n\nThe goal of this Google Summer of Code project is to build a browser-based dashboard that connects to a running MD simulation via imdclient/MDAnalysis and provides real-time feedback to users. At its most basic level, the dashboard will display simulation progress (e.g., current timestep or frame number) and connection status. Beyond this, the project will focus on interactive, live analysis: users should be able to select atoms or groups using familiar MDAnalysis selection syntax and compute properties on the fly as new frames arrive.\n\nThe project will explore both simple, frame-local analyses (such as distances, angles, or radius of gyration) and more advanced, time-dependent analyses that require buffering and processing historical data (e.g., autocorrelations or lag-time dependent observables). Results will be visualized live in the browser using plots and indicators. As an advanced extension, the project may integrate real-time 3D visualization via Blender and [Molecular Nodes](#molecular-nodes), enabling users to view the evolving molecular structure while analyses run in parallel.\n\nFinally, the dashboard may include basic event detection and warning mechanisms, such as flagging unusual structural changes or simulation instabilities. The end result will be a flexible foundation for interactive, remote, and collaborative monitoring of MD simulations, tightly integrated with the Python MDAnalysis ecosystem.\n\n### Expected Outcomes\n\n1. A web-based dashboard that can connect to running MD simulations via IMDv3 and imdclient\n2. Live display of simulation status and progress information\n3. An interactive GUI for defining and running real-time analyses using MDAnalysis\n4. Support for simple per-frame observables and buffered, time-dependent analyses\n5. Live visualization of analysis results (plots, indicators, status messages)\n6. (Optional/advanced) Live 3D molecular visualization using Blender and Molecular Nodes\n7. (Optional) Basic event detection and warning system for problematic simulation behavior\n8. Well-documented, open-source code suitable for long-term integration into the MDAnalysis ecosystem\n\n### Relevant Skills\n\n- Python (frontend UI, multiprocessing)\n- Networking (TCP/IP)\n- Web development (for browser-based dashboard)\n\n### Related issues/PRs/etc.:\n\n- https://imdclient.readthedocs.io\n- https://www.mdanalysis.org/2024/11/03/ASU_streaming_workshop/\n\n### Possible Mentors\n\n- [@HeydenLab](https://github.com/HeydenLab)\n- [@amrutesht](https://github.com/amrutesht)\n- [@orbeckst](https://github.com/orbeckst)\n\n\n### Expected Size of Project\n\nMedium/Large (175/350 hours, depending on targeted features)\n\n### Difficulty Rating\n\nEasy/Medium\n\n## Project 2: Better interfacing of Blender and MDAnalysis\n\n### Summary\n\nImprovements to how Blender and [Molecular Nodes](#molecular-nodes) interface with MDAnalysis which powers the import and animation of MD trajectories inside of Blender. Simple import is currently available when using the GUI in Blender, but there is still a lot of potential for improvements in scriptability, automated rendering, and using Blender as an analysis tool for MD trajectories.\n\n### Detailed Description\n\n[Blender](https://www.blender.org/) is industry-leading 3D modeling and animation software. Through the add-on [Molecular Nodes](https://bradyajohnston.github.io/MolecularNodes/), MDAnalysis universes are able to be imported into the 3D scene, enabling advanced rendering of molecular dynamics trajectories that is not possible inside of any other molecule viewer. The ability to script and automate this rendering is possible but limited with lots of room for improvement for visualizing many common MD datasets. Blender also provides a great platform for implementing a potential GUI, to enable interactive analysis of MD trajectories with stunning visuals, all powered by MDAnalysis under the hood.\n\nThis project focuses on:\n- Better improving the Molecular Nodes ↔ MDAnalysis integration\n- Improvements on Molecular Nodes notebook rendering API\n- Visualizing particular analysis results inside of Blender / using Molecular Nodes rather than just structural information\n\n### Expected Outcomes\n\n1. Prototype improved API for scripting and working with Molecular Nodes from [Jupyter](https://jupyter.org/) Notebooks or other similar environments\n2. Prototyping common analysis and visualization tasks that could be performed from within Blender via the GUI\n\n### Relevant Skills\n\n- Proficiency with Python\n- Working knowledge of MDAnalysis\n- Familiarity with Blender and programming via its Python API\n\n### Related issues/PRs/etc.:\n\n- https://github.com/BradyAJohnston/MolecularNodes/pull/719\n\n### Possible Mentors\n\n- [@bradyajohnston](https://github.com/bradyajohnston)\n- [@nilay-v3rma](https://github.com/nilay-v3rma)\n\n### Expected Size of Project\n\nLarge (350 hours)\n\n### Difficulty Rating\n\nMedium\n\n## Project 3: Benchmarking and performance optimization\n\n### Summary\n\nThe goal of this project is to increase the performance assessment coverage (using the existing ASV framework), identify code that should be improved, and optimize code.\n\n### Detailed Description\n\nThe [MDAnalysis Roadmap](https://www.mdanalysis.org/2023/10/25/towards_3.0/) emphasizes performance improvement. The performance of the MDAnalysis library is assessed by automated nightly benchmarks with [ASV](https://asv.readthedocs.io/en/latest/) (see https://github.com/MDAnalysis/benchmarks/wiki) but coverage of the code base is low. The goal of this project is to substantially increase the performance assessment coverage, identify code that should be improved, and possibly implement performance optimizations. \n\n### Expected Outcomes\n\n1. Write ASV benchmark cases for all major functionality in the core library\n2. Write ASV benchmark cases for often-used analysis tools\n3. Analyze performance history and generate a priority list of code that should be improved\n4. Document writing benchmarks with a short tutorial\n5. *Optional*: Optimize performance for at least one discovered performance bottleneck\n\n### Relevant Skills\n\n- Python/ASV\n- Cython\n\n### Related issues/PRs/etc.:\n\n- https://github.com/MDAnalysis/mdanalysis/issues/1023\n- https://github.com/MDAnalysis/mdanalysis/issues/1721\n- https://github.com/MDAnalysis/mdanalysis/issues/4577\n\n### Possible Mentors\n\n- [@orbeckst](https://github.com/orbeckst)\n- [@yuxuanzhuang](https://github.com/yuxuanzhuang)\n- [@talagayev](https://github.com/talagayev)\n\n### Expected Size of Project\n\nSmall/Medium/Large (90/175/350 hours)\n\n(This project can be tailored in scope to the desired length. Discuss the length and scope with us while you are writing your application.)\n\n### Difficulty Rating\n\nEasy/Medium\n\n## Project 4: Lazy trajectory loading and indexing\n\n### Summary\n\nThis project aims to improve MDAnalysis's trajectory reading performance by implementing lazy indexing for trajectory formats that currently build a complete frame index on first file open, which can take hours for large files.\n\n### Detailed Description\n\nA general assumption in MDAnalysis has been for a long time that a trajectory reader can access arbitrary frames in a trajectory file, corresponding to the usage in MDAnalysis of `ts = u.trajectory[frame]`. However, many trajectory formats do not support random access natively. To get around this problem, some MDAnalysis trajectory readers (in particular the ones for XTC and TRR formats) *always* build a hidden frame index on first opening the file by rapidly scanning the whole file. (MDAnalysis calls this frame index *offsets*.) For large files, this \"rapid scan\" can still take hours during which the user has no idea what's happening.\n\nThis project proposes implementing \"lazy trajectory loading\" whereby we eschew index building if we are only iterating forward and instead resort to frame-by-frame loading (or possibly use the header-seeking trick from the index building for larger step sizes). In a way, this treats these files more like *streams* than random-access trajectories.\n\nWhile reading we could then start building the index and possibly improve it iteratively while additional frames are being read. The index would be built right away if fancy indexing is used.\n\nThe behavior could potentially be made user-configurable at the Universe level with a kwarg like `index_trajectory=\"always\" | \"never\" | \"lazy\"`.\n\n### Expected Outcomes\n\n1. Implementation of lazy indexing mode for XTC/TRR readers\n2. Progressive index building during forward iteration\n3. User-configurable indexing behavior via Universe kwarg\n4. Performance benchmarks comparing lazy vs eager indexing\n5. Documentation for users and developers\n\n### Relevant Skills\n\n- Python\n- Understanding of trajectory I/O and file formats\n- Performance optimization\n\n### Related issues/PRs/etc.:\n\n- https://github.com/MDAnalysis/mdanalysis/issues/3793\n- [Notes on offsets for the XDRBaseReader](https://docs.mdanalysis.org/stable/documentation_pages/coordinates/XDR.html#MDAnalysis.coordinates.XDR.XDRBaseReader)\n\n### Possible Mentors\n\n- [@yuxuanzhuang](https://github.com/yuxuanzhuang)\n- [@orbeckst](https://github.com/orbeckst)\n- [@talagayev](https://github.com/talagayev)\n\n### Expected Size of Project\n\nMedium/Large (175/350 hours)\n\n### Difficulty Rating\n\nMedium\n\n## Project 5: Dashboard for tracking WESTPA simulation progress\n\n### Summary\n\n[WESTPA](#westpa) simulations involve running multiple MD trajectories in parallel, which makes it hard to track progress. This project aims to create a graphical user interface that exploits MDAnalysis’s streaming ability and WESTPA’s work managers to monitor the progress of a WESTPA simulation.\n\n### Detailed Description\n\nWhile [WESTPA](https://westpa.github.io/westpa) simulations [report status](https://github.com/westpa/westpa/blob/32bf2ca0d710f55c38e60d7f35b63d653ab01c92/src/westpa/core/sim_manager.py#L179) at regular intervals, these iterations could last minutes to hours, leaving users unsure of the intermediate progress or time estimate. The task here will involve creating a graphical user interface reporting trajectory progress and completion time estimates through MDAnalysis’s streaming abilities and extracting relevant information from WESTPA’s [work managers](https://github.com/westpa/westpa/wiki/Work-Managers-and-Running-with-MPI) ([ZMQ](https://github.com/westpa/westpa/blob/westpa2/src/westpa/work_managers/zeromq/core.py), python [multiprocessing](https://github.com/westpa/westpa/tree/westpa2/src/westpa/work_managers)) and [data managers](https://github.com/westpa/westpa/blob/westpa2/src/westpa/core/data_manager.py).\n\n### Expected Outcomes\n\n1. New CLI tool for WESTPA tracking simulation progress\n2. MDAnalysis module for aggregating/tracking multiple simulations\n\n### Relevant Skills\n\n- Python (frontend UI, multiprocessing)\n- Networking (TCP/IP)\n\n### Related issues/PRs/etc.:\n\nNot applicable\n\n### Possible Mentors\n\n- [@jeremyleung521](https://github.com/jeremyleung521)\n- [@ltchong](https://github.com/ltchong)\n- [@nilay-v3rma](https://github.com/nilay-v3rma)\n\n### Expected Size of Project\n\nSmall (90 hours)\n\n### Difficulty Rating\n\nEasy\n\n## Project 6: Interface for post-simulation analysis (\"crawling\") of WESTPA simulations\n\n### Summary\n\n[WESTPA](#westpa) simulations involve running multiple MD trajectories in parallel. This makes post-simulation extraction of features and observables (that were not saved during the simulation) somewhat cumbersome. This project aims to create a simpler method for analyzing and extracting data from WESTPA simulation saved using the HDF5 Trajectory Storage Framework.\n\n### Detailed Description\n\nWhile users who wish to extract more data from their trajectories/WE Simulation can use [`w_crawl`](https://github.com/westpa/westpa/wiki/man:w_crawl), it requires writing and testing custom Python code to get it right. The task here is to simplify the process for users who have already saved their trajectory data with WESTPA's HDF5 Trajectory Storage Framework (\"HDF5 Framework\"), just by loading their [`west.h5` file](https://github.com/westpa/westpa/wiki/HDF5-File-Organization-of-Simulation-Data#user-content-Overall_structure_of_westh5). The resulting code for this project would read in the \"west.h5\" as a MDAnalysis universe object, allowing users to run analysis promptly and save it back into the west.h5 file as auxiliary data. Code that translates the topology in the HDF5 Framework to that of MDAnalysis has already been written and included in the source code of v2022.13.\n\n\n### Expected Outcomes\n\n1. New CLI/Python tool for analyzing trajectory data saved with WESTPA HDF5 Trajectory Storage Framework\n2. New MDAnalysis/MDAKit parser for WESTPA west.h5 files (turns west.h5 + related iteration files into a MDAnalysis Universe object)\n\n### Relevant Skills\n\n- Python (frontend UI, multiprocessing)\n- HDF5 (h5py, hdf5)\n\n### Related issues/PRs/etc.:\n\n- [WESTPA 2.0 Paper](https://pubs.acs.org/doi/full/10.1021/acs.jctc.1c01154)\n- Tutorial 7.5 from [WESTPA 2.0 Tutorials](https://livecomsjournal.org/index.php/livecoms/article/view/v5i1e1655)\n- HDF5 Framework update https://github.com/westpa/westpa/pull/484\n\n### Possible Mentors\n\n- [@jeremyleung521](https://github.com/jeremyleung521)\n- [@ltchong](https://github.com/ltchong)\n\n### Expected Size of Project\n\nSmall (90 hours)\n\n### Difficulty Rating\n\nEasy"
  },
  {
    "name": "Rizin",
    "slug": "rizin",
    "tagline": "Rizin reverse engineering framework and toolset",
    "description": "The Rizin project is a fork of the famous Radare2 project that started in 2006. Since then the codebase has been rewritten multiple times, modularized and extended to support many new features. The Rizin project aims to provide stability, focus on the most important features, and provide a user friendly interface. Along with Cutter - a Qt-based GUI and the RzGhidra decompiler it makes the effective tool for everyday reversing tasks.\n\nRizin is composed of a hexadecimal editor at its core, with support for several architectures and binary formats. It features code analysis capabilities, scripting, data and code visualization through graphs and other means, a visual mode, easy UNIX integration, a binary diffing engine for code and data, a shellcode compiler, multi-platform debug with reverse debug capabilities and much, much more!",
    "ideas_url": "https://rizin.re/gsoc/2026/#project-ideas",
    "website_url": "https://rizin.re",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "python",
      "go",
      "c++",
      "qt"
    ],
    "topic_tags": [
      "reverse engineering",
      "computer security",
      "debugging",
      "emulation",
      "disassembly"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/rizin",
    "ideas_content": "**TL;DR** Jump to the [Ideas list](https://rizin.re#project-ideas).\n\n# Introduction[#](https://rizin.re#introduction)\n\nThis year, we participate again, effectively continuing the tradition since 2015.\n\n## Mentors[#](https://rizin.re#mentors)\n\nMembers of the Rizin and Cutter core teams have volunteered to guide participants for GSoC’26. They have already been guiding the participants for the GSoC and RSoC in past years. Please feel free to reach out to any of them if you need any help in selecting a project.\n\n**Anton Kochkov**Mattermost: xvilka –[@akochkov](https://twitter.com/akochkov)**Giovanni Dante Grazioli**Mattermost/Telegram: @deroad[@der0ad](https://twitter.com/der0ad)- And many others\n\n## Development methodology[#](https://rizin.re#development-methodology)\n\nCurrently, all repositories are hosted on GitHub [main](https://github.com/rizinorg/) organization account and bugs are tracked on GitHub [issues](https://github.com/rizinorg/rizin/issues) too. We are primarily using [our own Mattermost instance](https://im.rizin.re), IRC, and [Telegram](https://t.me/rizinorg)) for communication.\nWe have a [testsuite](https://github.com/rizinorg/rizin/tree/dev/test) (which is running on GitHub Actions, [Travis CI](https://travis-ci.com/rizinorg/rizin), [AppVeyor](https://ci.appveyor.com/project/rizinorg/rizin) and SourceHut) to test and verify that all the features are still working and that a pull requests or commits don’t break anything, to ensure the support of different operating systems (Linux, MacOS, Windows, FreeBSD, OpenBSD), different architectures (x86/x86_64, ARM64, PowerPC, SystemZ), and to find regressions.\nWe encourage contributors to write test cases and documentation in order to verify the implementation and ensure that everything fits well together. For complex bugs and examples, we’re using [ASCIInema](http://asciinema.org/) to record the sessions.\n\nSee also our guides for corresponding projects:\n\n- Rizin\n[Contributing Guide](https://github.com/rizinorg/rizin/blob/dev/CONTRIBUTING.md)and[Developers Intro](https://github.com/rizinorg/rizin/blob/dev/DEVELOPERS.md) - Cutter\n[Contributing Guide](https://github.com/rizinorg/cutter/blob/master/CONTRIBUTING.md)and[Developers Intro](https://cutter.re/docs/code.html)\n\nFor those who want to get introduced to the Rizin codebase and practices, we recommend to pick one of the easy issues for [Rizin](https://github.com/rizinorg/rizin/labels/good%20first%20issue) or [Cutter](https://github.com/rizinorg/cutter/labels/good%20first%20issue) to start with.\n\nDue to concerns about the quality of code generated by AI agents, we strongly discourage applicants who solely rely on them, from applying to our Google Summer of Code program. We require all the GSoC participants to demonstrate understanding of the code they submit to our repositories, and therefore reserve the right at any moment of time, to request the prompts sent to their AI tools to assess actual skills and comprehension of the person.\n\n## License[#](https://rizin.re#license)\n\nRizin is modular: this means that it aims to make all the elements and features easily reusable from other projects. The choice of [LGPL3](https://www.gnu.org/licenses/lgpl.html) as a license is the minimum requirement to get code merged in Rizin. Contributors can choose Apache, BSD, MIT, Public Domain, or other similar licenses. The reason to exclude GPL as a valid license for the project is because we aim to support proprietary software that uses Rizin while protecting our free codebase.\n\n## Instructions for participants[#](https://rizin.re#instructions-for-participants)\n\nParticipants who want to apply to the Rizin project for the Google Summer of Code 2026 are required to submit a small pull request accomplishing one of the [microtasks](https://rizin.re#microtasks) (see below) as part of their application. You can also choose any of the GitHub issues for Rizin if they are big enough to be a qualification task and still small enough to be finished in no more than a couple of weeks. To help participants understand how to contribute to the project, there are issues marked as **“good first issue”** for both [Rizin](https://github.com/rizinorg/rizin/labels/good%20first%20issue) and [Cutter](https://github.com/rizinorg/cutter/labels/good%20first%20issue).\n\n\nIMPORTANTAI tools must not be used to fix GitHub issues labelled`good first issue`\n\n. These issues are generally not urgent, and are intended to be learning opportunities for new contributors to get familiar with the codebase. Whether you are a newcomer or not, fully automating the process of fixing this issue squanders the learning opportunity and doesn’t add much value to the project.Using AI tools to fix issues labelled as.`good first issues`\n\nis forbidden\n\n## Programming languages[#](https://rizin.re#programming-languages)\n\nMost of Rizin is written in C (conforming to the C99 standard), and hence, we expect participants to be familiar with C programming language. For some of our tasks or microtasks, such as [rz-pm](https://github.com/rizinorg/rz-pm), they should know the Go programming language. For the [Cutter tasks](https://rizin.re#cutter), it is a requirement to know C++ and Qt framework basics.\n\n## Recommended steps[#](https://rizin.re#recommended-steps)\n\n- Read Google’s instructions for participating\n- Grab any of the projects from the list of ideas that you’re interested in (or propose your own).\n- Write a first draft proposal using Google Docs and\n[our template](https://docs.google.com/document/d/1kDPGgr_D5tQuYLQi_gEGlkuQ-DlU8GH5kDBqZbVSC7I/edit?usp=sharing)and ask one of the mentors or administrators to review it with you. - Submit it using Google’s web interface.\n\n## Participant proposal guidelines[#](https://rizin.re#participant-proposal-guidelines)\n\n- Keep it simple enough to fit in no more than a couple of pages. Try to be clear and concise in your writing.\n- Try to split the entire GSoC period into tasks and each task into subtasks. It helps us understand how you plan to accomplish your goals, but more importantly, it’ll help you understand the task deep enough before starting and prioritize important things to do first.\n- Please note how much time a day/week you can spend on this project.\n- Please specify which category you apply for - medium task or extended deadline one.\n- Specify your timezone so we can assign you a mentor in the same one to ease communication.\n- Submit your proposal early, not at the last minute!\n- Be sure to choose a “backup” idea (the second task you want to do) so that conflicts (two participants for one task) can be resolved.\n\n# Project Ideas[#](https://rizin.re#project-ideas)\n\n# Cutter[#](https://rizin.re#cutter)\n\n## Improving usability and user experience (175 hour project)[#](https://rizin.re#improving-usability-and-user-experience-175-hour-project)\n\nThis project focuses on making Cutter’s interface more flexible and maintainable. The goal is to address significant user pain points by updating UI behaviors and styling systems to match the flexibility of modern reverse engineering tools.\n\n### Task[#](https://rizin.re#task)\n\n- Make docking optional rather than enforced, allowing users to move and float windows freely\n[#3095](https://github.com/rizinorg/cutter/issues/3095) - Implement the ability to minimize and maximize individual widgets within the interface\n[#3060](https://github.com/rizinorg/cutter/issues/3060) - Fully specify color palettes for existing themes and replace explicit colors in stylesheets with palette roles\n[#2138](https://github.com/rizinorg/cutter/issues/2138)\n\n### Skills[#](https://rizin.re#skills)\n\nThe participant should be comfortable with the C++ and be familiar with Qt framework. Basics of the design/UX would be a plus.\n\n### Difficulty[#](https://rizin.re#difficulty)\n\nAdvanced\n\n### Benefits for the participant[#](https://rizin.re#benefits-for-the-participant)\n\nThe participant will learn to build flexible desktop layouts and manage professional UI design systems using C++ and Qt.\n\n### Benefits for the project[#](https://rizin.re#benefits-for-the-project)\n\nIt will make interface and user experience more consistent, on par with Rizin itself, and other tools.\n\n### Assess requirements for midterm/final evaluation[#](https://rizin.re#assess-requirements-for-midtermfinal-evaluation)\n\n- 1st term: Implement optional docking logic and widget minimize/maximize functionality.\n- Final term: Complete the theme palettization and replace explicit colors with palette roles to deduplicate stylesheets.\n\n### Mentors[#](https://rizin.re#mentors-1)\n\n- xvilka\n- Megabeets\n\n### Links/Resources[#](https://rizin.re#linksresources)\n\n[Window moving - docking should be optional](https://github.com/rizinorg/cutter/issues/3095)[Allow minimize / maximize widgets](https://github.com/rizinorg/cutter/issues/3060)[Paletize the Cutter color themes](https://github.com/rizinorg/cutter/issues/2138)\n\n## Plugins and Python High Level API (175 hour project)[#](https://rizin.re#plugins-and-python-high-level-api-175-hour-project)\n\nOur current public API to be used by plugin authors is somewhat limited. We need to improve a lot of things about our Plugins support and take it few steps ahead. This task is only about improving the public C++ and Python interface of Cutter, specifically its graphical user interface components. For a task about exposing Rizin’s API for disassembly, analysis and other purposes, see the Rizin bindings task above.\n\n### Task[#](https://rizin.re#task-1)\n\n- Expose everything Cutter can offer for plugin authors. This includes high level API, integration of the plugin management etc.\n- Accessing everything from Python (like Blender) - see\n[issue #1662](https://github.com/rizinorg/cutter/issues/1662) - Python integration and IPython console.\n\n### Skills[#](https://rizin.re#skills-1)\n\nThe participant should be comfortable with the C++ and Python languages, and be familiar with Qt framework\n\n### Difficulty[#](https://rizin.re#difficulty-1)\n\nAdvanced\n\n### Benefits for the participant[#](https://rizin.re#benefits-for-the-participant-1)\n\nThe participant will gain an experience of creating a suitable API for scripting graphical interface programs.\n\n### Benefits for the project[#](https://rizin.re#benefits-for-the-project-1)\n\nIt will greatly improve the scripting experience, will make API more consistent and will ease creating Cutter plugins by the community. Moreover, it will simplify testing of the Cutter features.\n\n### Assess requirements for midterm/final evaluation[#](https://rizin.re#assess-requirements-for-midtermfinal-evaluation-1)\n\n- 1st term: Design of the high level API and required Rizin changes. Review and implement all missing API functions that are accessible as interface controls.\n- Final term: Implement the way to show the API when hovered over some interface control, create documentation.\n\n### Mentors[#](https://rizin.re#mentors-2)\n\n- xvilka\n- deroad\n\n### Links/Resources[#](https://rizin.re#linksresources-1)\n\n## Multi-Tasking and Event-driven architecture (350 hour project)[#](https://rizin.re#multi-tasking-and-event-driven-architecture-350-hour-project)\n\nThe information Cutter gets about functions, strings, imports, and the analysis are all performed in Rizin and only displayed in Cutter. Currently, it is pulling most information from Rizin only on demand. This is problematic because sometimes the user performs changes (via plugins, the console widget, and more) that are affecting the information from Rizin, but Cutter doesn’t know about these changes to apply the to the UI. For example, if a user will define a new function in a Python script or via the console widget by using the Rizin command `af @ <addr>`\n\n, Cutter will not show this new function in the Functions widget until the user will refresh the interface manually (Edit -> Refresh Contents).\nThe goal of this task is to use an event-driven architecture to overcome this limitation.\n\nIn addition, this task will also handle the analysis in the background feature, to allow the analysis performed by Rizin to happen while the interface is active.\n\n### Tasks[#](https://rizin.re#tasks)\n\nThe overall implementation of this task should start from Rizin by adding events to many of the functions. This can be done using `rz_events`\n\n. For example, add an event for function creating, for section creation, for flag deletion, for name changed, and more\n\n- Add events to all the relevant functions inside Rizin\n- Add support for these events in Cutter and refresh and update the relevant widgets per each event\n- Support analysis in the background and allow the user to start its session while Rizin is analyzing (see\n[#1856](https://github.com/rizinorg/cutter/issues/1856),[#1574](https://github.com/rizinorg/cutter/issues/1574))\n\n### Skills[#](https://rizin.re#skills-2)\n\nThe participant should be comfortable with the C++ for Cutter and C for Rizin. They should also be familiar with Qt framework. Experience in GUI code architecture, for example using functional reactive programming or Elm-like approaches is a plus.\n\n### Difficulty[#](https://rizin.re#difficulty-2)\n\nAdvanced\n\n### Benefits for the participant[#](https://rizin.re#benefits-for-the-participant-2)\n\nThe participant will gain an experience of creating complex event-driven software in both C and C++ languages.\n\n### Benefits for the project[#](https://rizin.re#benefits-for-the-project-2)\n\nIt will allow to work on big files effortlessly in Cutter, will improve analysis quality as well.\n\n### Assess requirements for midterm/final evaluation[#](https://rizin.re#assess-requirements-for-midtermfinal-evaluation-2)\n\n- 1st term: Implement events everywhere in the relevant places across Rizin code and event-driven interaction with Cutter.\n- Final term: Add support for the Cutter interface refresh based on the events from Rizin, implement analysis in background.\n\n### Mentors[#](https://rizin.re#mentors-3)\n\n- xvilka\n\n## Heap viewer completion (175 hour project)[#](https://rizin.re#heap-viewer-completion-175-hour-project)\n\nThanks to the work that was done in the previous GSoC, Cutter and Rizin have nice visualizations of the heap and memory maps. We would like to expand on this feature with performance improvements to the heap parsers and support more memory allocators.\n\n### Task[#](https://rizin.re#task-2)\n\n- Complete Cutter’s implementation of the windows heap widget #\n[2723](https://github.com/rizinorg/cutter/pull/2723) - Improve the performance of the Windows heap parser\n- Fix Windows heap parsing errors\n- Make the implementation work with remote debugging modes\n\n### Skills[#](https://rizin.re#skills-3)\n\nThe participant should be comfortable with the C++, and be familiar with Qt framework\n\n### Difficulty[#](https://rizin.re#difficulty-3)\n\nMedium\n\n### Benefits for the participant[#](https://rizin.re#benefits-for-the-participant-3)\n\nThe participant will gain the understanding on how modern runtimes provide the heap for various programs, which will be beneficial for the binary exploitation skills.\n\n### Benefits for the project[#](https://rizin.re#benefits-for-the-project-3)\n\nIt will greatly improve the debugging and reverse engineering experience for complex programs, also provides the way to design the exploitation techniques with the help of Rizin/Cutter.\n\n### Assess requirements for midterm/final evaluation[#](https://rizin.re#assess-requirements-for-midtermfinal-evaluation-3)\n\n- 1st term: Design and implement heap visualization widgets, add Rizin test and fixes\n- Final term: Various bugfixes related to the heap inspection support on various platforms and allocators, tests and documentation.\n\n### Mentors[#](https://rizin.re#mentors-4)\n\n- xvilka\n- Megabeets\n\n### Links/Resources[#](https://rizin.re#linksresources-2)\n\n[Issue #1041](https://github.com/rizinorg/cutter/issues/1041)[Heap Viewer plugin for IDA Pro](https://github.com/danigargu/heap-viewer)[Heap parsing for MacOS, tmalloc, jmalloc](https://github.com/rizinorg/rizin/issues/208)[Dynamic Allocator Detection](https://github.com/rizinorg/rizin/issues/157)[“heap”-marked Rizin issues](https://github.com/rizinorg/rizin/labels/heap)\n\n## Diffing mode (175 hour project)[#](https://rizin.re#diffing-mode-175-hour-project)\n\nBinary diffing is one of the most common tasks for the reverse engineer. There are many\ntools available, but most of them are either detached from the main RE toolbox or poorly integrated.\nRizin provides basic diffing features out of the box with `rz-diff`\n\ntool, but Cutter has no\ninterface to represent similar functionality.\n\n### Task[#](https://rizin.re#task-3)\n\n- Expose basic\n`rz-diff`\n\nfeatures in the Cutter - Create the interface to choose two files for diffing\n- Create the way to show the differences in all main widgets:\n- Hexadecimal view\n- Disassembly view\n- Graph view\n- Pseudocode view\n\n\n### Skills[#](https://rizin.re#skills-4)\n\nThe participant should be comfortable with the C++ language, and be familiar with Qt framework\n\n### Difficulty[#](https://rizin.re#difficulty-4)\n\nMedium\n\n### Benefits for the participant[#](https://rizin.re#benefits-for-the-participant-4)\n\nThe participant will gain an experience of creating efficient graphical interfaces.\n\n### Benefits for the project[#](https://rizin.re#benefits-for-the-project-4)\n\nIt will greatly benefit the project since Cutter will be the only FOSS RE tool to provide this feature out of the box.\n\n### Assess requirements for midterm/final evaluation[#](https://rizin.re#assess-requirements-for-midtermfinal-evaluation-4)\n\n- 1st term: Expose the\n`rz-diff`\n\nfeatures in the Cutter core and create the interface for opening files for diffing. Implement the diff modes for hexadecimal and disassembly views. - Final term: Implement the diff modes for graph and pseudocode views, create the documentation.\n\n### Mentors[#](https://rizin.re#mentors-5)\n\n- xvilka\n- deroad\n\n### Links/Resources[#](https://rizin.re#linksresources-3)\n\n# Rizin[#](https://rizin.re#rizin)\n\n## Classes analysis for C++/ObjectiveC/Swift/Dlang/Java (350 hour project)[#](https://rizin.re#classes-analysis-for-cobjectivecswiftdlangjava-350-hour-project)\n\nAnalysis classes, accessible under the `ac`\n\ncommand, is a relatively new feature of rizin.\nThey provide a way to both manually and automatically manage and use information about classes in the binary. But their support is only bare bones, without supporting various analysis integration, as well as display in the disassembly output.\n\nIn GSoC 2025 initial work on this task had been done, but a bulk of the task still needs to be completed. For example, [the #5415 PR - ObjectiveC inheritance](https://github.com/rizinorg/rizin/pull/5415) needs to be updated, finished, and merged.\n\nApart from that, parsing additional information like SEH is sometimes helpful for reconstructing C++ (and other languages) classes: [#2271](https://github.com/rizinorg/rizin/issues/2271) and [#2247](https://github.com/rizinorg/rizin/issues/2247).\n\nConsider the following call: `call dword [eax + 0x6c]`\n\nLet’s assume eax is the base pointer of a vtable we have saved in class analysis and we want to find out the actual address of the called method.\n\nSo there should be a command that takes the offset (in this case 0x6c) and looks up the actual destination. It should be possible to call this command with a specific class, so it only looks into its vtable, or without a class, so it gives a list of possible destinations for all vtables that are not too small for the offset.\n\nWhen that is implemented, one could also add a command that does the same thing, but automatically takes the offset from the opcode at the current seek.\n\n### Task[#](https://rizin.re#task-4)\n\n- Connecting classes with their methods\n- Class inheritance - nesting data structs\n- Constructors and destructors autorecognition\n`try`\n\n/`catch`\n\n/`finally`\n\nrecognition and marking- arguments recognition\n- ASCII/graphviz graph of class inheritance/structure inheritance\n- Tests with sources for C++, FreePascal, D language, ObjC and Swift, for rizin-testbins\n- Classes list via\n`Vb`\n\n. It already supports browsing bin classes. The same thing should be implemented for classes from analysis.\n\n### Skills[#](https://rizin.re#skills-5)\n\n- Good knowledge of the C language\n- Good knowledge of the C++ language (other languages, like ObjC, Swift, D, etc are a plus)\n\n### Difficulty[#](https://rizin.re#difficulty-5)\n\nHard\n\n### Benefits for the participant[#](https://rizin.re#benefits-for-the-participant-5)\n\nParticipant will understand how OOP languages work under the hood, and will master technique of detecting various high level (classes, methods) abstractions in the binary code.\n\n### Benefits for the project[#](https://rizin.re#benefits-for-the-project-5)\n\nIt will greatly benefit the project to allow efficient reverse engineering of the programs written in C++ and other OOP languages.\n\n### Assess requirements for midterm/final evaluation[#](https://rizin.re#assess-requirements-for-midtermfinal-evaluation-5)\n\n- 1st term: implement classes integration into the analysis, type inference; detect constructors and destructors,\n`try`\n\n/`catch`\n\nblocks. - Final term: Class inheritance recognition, virtual methods detection, building class inheritance graphs, visual mode to inspect classes and methods relationships.\n\n### Mentors[#](https://rizin.re#mentors-6)\n\n- xvilka\n- deroad\n\n### Links and resources[#](https://rizin.re#links-and-resources)\n\n[Improve vtable detection for C++, ObjectiveC, Dlang and Swift binaries - issue #416](https://github.com/rizinorg/rizin/issues/416)[Devirtualize method calls using class vtables - issue #414](https://github.com/rizinorg/rizin/issues/414)\n\n## FRIDA integration (175 hour project)[#](https://rizin.re#frida-integration-175-hour-project)\n\n[FRIDA](https://frida.re) is the famous dynamic instrumentation toolkit that is immensely popular among mobile device researches. Rizin could be easily integrated with Frida by creating a plugin that will allow to connect to the Frida instance, receive traces, set breakpoints, get information and events from it.\n\n### Task[#](https://rizin.re#task-5)\n\n- Create the basic plugin that allows attaching, spwaning, launching processes within Frida loco ally\n- Support remote connection\n- Add feature to receive information from the Frida instanced\n- Add breakpoints and run/step/continue feature’s\n- Support calling functions and scripts in the context of the instrumented process\n\n### Skills[#](https://rizin.re#skills-6)\n\nParticipant should know C as well as have the experience of working with debuggers.\n\n### Difficulty[#](https://rizin.re#difficulty-6)\n\nHard\n\n### Benefits for the participant[#](https://rizin.re#benefits-for-the-participant-6)\n\nParticipant will understand and learn how to use Frida toolkit, also the internals of the debugging and instrumentation processes.\n\n### Benefits for the project[#](https://rizin.re#benefits-for-the-project-6)\n\nIt will allow easy dynamic code instrumentation right from the Rizin or Cutter session, allowing tracing and code inspection.\n\n### Assess requirements for midterm/final evaluation[#](https://rizin.re#assess-requirements-for-midtermfinal-evaluation-6)\n\n- 1st term: Implement core of the FRIDA plugin, allowing local and remote debugging features\n- Final term: Add support for extended features like calling functions or scripts within the context\n\n### Mentors[#](https://rizin.re#mentors-7)\n\n- xvilka\n- deroad\n\n### Links/Resources[#](https://rizin.re#linksresources-4)\n\n## Exploitation capabilities improvements (175 hour project)[#](https://rizin.re#exploitation-capabilities-improvements-175-hour-project)\n\nSince modern architectures are now enforcing [W^X](https://en.wikipedia.org/wiki/W%5EX), exploiters are using [ROP](https://en.wikipedia.org/wiki/Return-oriented_programming). (Un)fortunately, building ROP chain by hand can be tedious, this is why some tools can be used to ease this construction: ImmunityDBG has [mona.py](https://www.corelan.be/index.php/2012/12/31/jingle-bofs-jingle-rops-sploiting-all-the-things-with-mona-v2/), there is also [ROPgadget](http://www.shell-storm.org/project/ROPgadget/) and [dropper](https://github.com/rizlik/dropper). There exist even tools that can generate ROP chains automatically, for example [exrop](https://github.com/d4em0n/exrop). It’s a shame that despite having [RzIL](https://github.com/rizinorg/rizin/blob/dev/doc/rzil.md), Rizin doesn’t have something similar yet. One of the possible solutions would be to build an external plugin or tool which will reuse power of librz and rz-gg. Moreover it makes sense to think about SROP, COOP and BROP support.\n\nThe last year (GSoC'24) one of our participants started implementing this feature, but it wasn’t finished. You could check the [rz-solver](https://github.com/rizinorg/rz-solver) repository for more details.\n\nAlso, the `rz-gg`\n\ntool while has the ability to create a custom shellcode but there is still [a lot of work](https://github.com/rizinorg/rizin/issues?q=is%3Aissue+is%3Aopen+label%3Arz-gg) required.\n\n### Task[#](https://rizin.re#task-6)\n\n- Fix\n`rz-gg`\n\nissues - Write a compiler which uses SMT solver (like Z3 for example) to produce the ropchain:\n[#4563](https://github.com/rizinorg/rizin/issues/4563). - Support main architectures - x86, ARM, MIPS, PowerPC at the very least\n\n### Skills[#](https://rizin.re#skills-7)\n\nThe participant should be comfortable with the C language, know some assembly and a high-level language. Also, knowing a little bit of automatic binary analysis wouldn’t hurt.\n\n### Difficulty[#](https://rizin.re#difficulty-7)\n\nAdvanced\n\n### Benefits for the participant[#](https://rizin.re#benefits-for-the-participant-7)\n\nThe participant will improve their skills in software exploitation and solvers.\n\n### Benefits for the project[#](https://rizin.re#benefits-for-the-project-7)\n\nThis feature would greatly help during exploits development, and people would be able to ditch mona.py for Rizin ;)\n\n### Assess requirements for evaluation[#](https://rizin.re#assess-requirements-for-evaluation)\n\n- 1st term: Creating the language for defining the ROP chain semantics and integrating it with SMT solver\n- Final term: Working ropchain compiler, covered by tests and documented in the Rizin book.\n\n### Mentors[#](https://rizin.re#mentors-8)\n\n- xvilka\n- Rot127\n\n### Links/Resources[#](https://rizin.re#linksresources-5)\n\n[ROPGadget](http://shell-storm.org/project/ROPgadget/)[Ropper](https://github.com/sashs/Ropper)[Angrop](https://github.com/salls/angrop)[ROPC](https://github.com/pakt/ropc)[exrop](https://github.com/d4em0n/exrop)[roper2](https://github.com/oblivia-simplex/roper2)[mona.py](https://www.corelan.be/index.php/2012/12/31/jingle-bofs-jingle-rops-sploiting-all-the-things-with-mona-v2/)from corelan[Hunting for ROP Gadgets in Style](https://media.blackhat.com/us-13/US-13-Quynh-OptiROP-Hunting-for-ROP-Gadgets-in-Style-WP.pdf)(2012)[dropper](https://github.com/rizlik/dropper)a BARF-based rop chain generator[Materials](http://dustri.org/b/files/hacklu2014_r2_exploitation.tar.xz)about the exloitation workshop at Hack.lu 2014[Slides](https://github.com/XVilka/hacklu)for the exploitation part of workshop at Hack.lu 2015[RzEgg related bugs](https://github.com/rizinorg/rizin/labels/RzEgg)\n\n## Binary case reduce tool (175 hours project)[#](https://rizin.re#binary-case-reduce-tool-175-hours-project)\n\nSimilar to [Csmith/Creduce](https://github.com/csmith-project/creduce) but operating on the binary files, to reduce the size of the test and to avoid sharing proprietary/classified files.\n\nIt can perform these operations:\n\n- cut bytes\n- shift\n- zero/0xFF/mask bytes\n- remove section\n\nSince it requires some knowledge of the file format, existing libraries like [LIEF](https://lief.re/) could be used.\n\n### Task[#](https://rizin.re#task-7)\n\n- Make a tool to reduce the size of ELF using specified operations\n- Extend it to other formats - PE, MachO\n- Create tests for this tool\n- Research the possibility of minimizing some testcases that are already in the Rizin repository.\n\n### Skills[#](https://rizin.re#skills-8)\n\nThe participant should be comfortable with the C language, as well as the high-level language of a choice (Python or Rust).\n\n### Difficulty[#](https://rizin.re#difficulty-8)\n\nAdvanced\n\n### Benefits for the participant[#](https://rizin.re#benefits-for-the-participant-8)\n\nThe participant will improve their understanding in file formats and their mutation.\n\n### Benefits for the project[#](https://rizin.re#benefits-for-the-project-8)\n\nThis feature would greatly help in minimizing and anonimizing testcases for the Rizin and any other binary analysis tool.\n\n### Assess requirements for evaluation[#](https://rizin.re#assess-requirements-for-evaluation-1)\n\n- 1st term: Create the simple tool to reduce the ELF size\n- Final term: Extend it to other formats, improve the “compression” rate, cover with tests.\n\n### Mentors[#](https://rizin.re#mentors-9)\n\n- xvilka\n- deroad\n\n### Links/Resources[#](https://rizin.re#linksresources-6)\n\n## Function prelude detection plugin (175 hours project)[#](https://rizin.re#function-prelude-detection-plugin-175-hours-project)\n\nA common problem in binary analysis is function detection.\n\nOne method is searching for function preludes. Preludes are a sequence of instructions commonly found at the beginning of a function. These preludes perform tasks like setting up the stack, or initializing registers to values as defined in the architecture’s ABI.\n\nIt is very common to hard-code these prelude patters and match instructions against them. These patterns get outdated, are tedious to update, and have to be written for each architecture.\n\nInstead an algorithm to detect function preludes, based on bytes from known functions, should be implemented.\n\n### Task[#](https://rizin.re#task-8)\n\nThe student implements the prelude detection algorithm in form of a plugin.\n\nThe plugin collects bytes found at call targets, compares their similarity and generates possible prelude patterns from byte sequences with a high similarity.\n\nLastly, a stand-alone version of the algorithm should be implemented, by writing a simple wrapper around the plugin.\n\n### Skills[#](https://rizin.re#skills-9)\n\nThe participant should be comfortable with the C language. Being strong in statistics is a plus.\n\n### Difficulty[#](https://rizin.re#difficulty-9)\n\nBeginner/Advanced\n\n### Benefits for the participant[#](https://rizin.re#benefits-for-the-participant-9)\n\nThe participant will improve their understanding in basic binary analysis and algorithm design.\n\n### Benefits for the project[#](https://rizin.re#benefits-for-the-project-9)\n\nThis feature would greatly help in detecting functions independent of the binary’s architecture and give a ready to be used tool to the reverse engineering community.\n\n### Assess requirements for evaluation[#](https://rizin.re#assess-requirements-for-evaluation-2)\n\n- Design the matching algorithm and implement in a plugin.\n\n### Mentors[#](https://rizin.re#mentors-10)\n\n- xvilka\n- deroad\n- Rot127\n\n# Microtasks[#](https://rizin.re#microtasks)\n\nWhen taking any of microtasks please be sure someone isn’t already working on them, and let us know if you are going to work on a particular one.\n\n## Cutter UX improvements[#](https://rizin.re#cutter-ux-improvements)\n\nThere are many small issues and missing features that when implemented will improve the user experience significantly:\n\n[Variables and values popup widgets on mouse hover](https://github.com/rizinorg/cutter/issues/2532)[Unified dialogue to set debug symbols servers](https://github.com/rizinorg/cutter/issues/3202)[X-Refs Widget Improvements: lack of filtering & sorting in refs lists](https://github.com/rizinorg/cutter/issues/1366)[Make sure all the filter-supported widgets are searching with case insensitivity](https://github.com/rizinorg/cutter/issues/2230)\n\nSee full list at our [User Experience](https://github.com/orgs/rizinorg/projects/4/views/1) project covering all parts of RizinOrg: Rizin, Cutter, RzGhidra, rz-pm.\n\n## File formats[#](https://rizin.re#file-formats)\n\nImplementing the support for any new file format counts as a microtask. See [New File-Format](https://github.com/rizinorg/ideas/labels/New%20File%20Format) label for pending issues.\n\nNotable good task is extending OMF file format to support more of its variations: [OMF51 and OMF96](https://github.com/rizinorg/rizin/issues/5418).\n\nOne more format that is COFF-based and is good to have in Rizin is [TI-COFF](https://github.com/rizinorg/rizin/issues/4299).\n\nAnother important improvement of the existing format is [parsing __cstring section of Mach-O files](https://github.com/rizinorg/rizin/issues/5409).\n\n## Disassemblers and assemblers[#](https://rizin.re#disassemblers-and-assemblers)\n\nImplementing the support for any new architecture counts as a microtask. See [New-Architecture](https://github.com/rizinorg/ideas/labels/New%20Architecture) label for pending issues.\n\nNotable example is the [BPF dissembly and analysis support](https://github.com/rizinorg/rizin/issues/4757).\n\n## Analysis[#](https://rizin.re#analysis)\n\nThe current code analysis has many caveats and issues which need addressing. Fixing them and writing more tests is important to stabilize and enhance rizin’s analysis engine.\n\n[See these issues](https://github.com/rizinorg/rizin/labels/RzAnalysis) on our GitHub dashboard.\n\n### Heap analysis[#](https://rizin.re#heap-analysis)\n\nCurrently Rizin has support for heap exploration and analysis, but the feature is still basic and can be improved. Additionally, [other allocators can be added](https://github.com/rizinorg/rizin/issues/208) (MacOS, tmalloc, etc.), [musl](https://github.com/rizinorg/rizin/issues/5238), [uClibc](https://github.com/rizinorg/rizin/issues/5239).\n\n## Debugging[#](https://rizin.re#debugging)\n\n## Miscellaneous[#](https://rizin.re#miscellaneous)\n\n`rz-find`\n\nmultiple directories support[#](https://rizin.re#rz-find-multiple-directories-support)\n\nSimply allow `rz-find`\n\n[searching among multiple paths](https://github.com/rizinorg/rizin/issues/5253), just like coreutils `find`\n\ntool.\n\n`rz-ar`\n\n- code archives unpacking tool[#](https://rizin.re#rz-ar---code-archives-unpacking-tool)\n\n[https://github.com/rizinorg/rizin/issues/4866](https://github.com/rizinorg/rizin/issues/4866)\n\n### Improving regression suite and testing[#](https://rizin.re#improving-regression-suite-and-testing)\n\nIt is required to solve [numerous issues](https://github.com/rizinorg/rizin/labels/rz-test), along with improving parallel execution and performance.\nThe next interesting idea is to setup and reuse Godbolt compilation engine for generating tests for different compilers and compilation options. There is even a command line tool for interacting with Godbolt - [cce](https://github.com/ethanhs/cce).\n\n### Unbreaking broken tests[#](https://rizin.re#unbreaking-broken-tests)\n\nAlmost one thousand of tests marked as “broken” in our testsuite. The task is to take any of those, investigate why it fails, if the test makes sense now or already irrelevant today. Then to try to fix some of the broken tests.\n\n## RzGhidra[#](https://rizin.re#rzghidra)\n\nThere are many small issues in the decompiler output:\n\n`pdgsd`\n\ncommands showing incorrect P-code[Improvements in recovering jump tables](https://github.com/rizinorg/rz-ghidra/issues/236)[rz-ghidra can’t detect string](https://github.com/rizinorg/rz-ghidra/issues/85)[Ghidra Decompiler Error: Could not finish collapsing block structure](https://github.com/rizinorg/rz-ghidra/issues/203)[Prioritize keeping vars with lower addresses](https://github.com/rizinorg/rz-ghidra/issues/167)[Minor improvements for the SLEIGH plugin](https://github.com/rizinorg/rz-ghidra/issues/133)\n\nSome of these issues might be related on how Rizin and RzGhidra integrate and might require changes in the Rizin side.\n\nAlso note that most of these issues should be paired with the test to verify it will not break in the future."
  },
  {
    "name": "GNU Image Manipulation Program",
    "slug": "gnu-image-manipulation-program",
    "tagline": "GIMP is a cross-platform image editor",
    "description": "GIMP is a cross-platform image editor available for GNU/Linux, macOS, Windows and more operating systems. It is free software, you can change its source code and distribute your changes.\n\nWhether you are a graphic designer, photographer, illustrator, or scientist, GIMP provides you with sophisticated tools to get your job done. You can further enhance your productivity with GIMP thanks to many customization options and 3rd party plugins.",
    "ideas_url": "https://developer.gimp.org/core/internship/ideas/",
    "website_url": "https://www.gimp.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "GEGL"
    ],
    "topic_tags": [
      "graphics",
      "design",
      "photography",
      "illustration"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/gnu-image-manipulation-program",
    "ideas_content": "# Project ideas for internship programs\n\nThis page is shared for events such as Google Summer of Code or similar\ninternship programs which GIMP might participate in, as a list of project ideas\nfor participants.\nYou may choose to implement exactly one of the proposed ideas, propose new ideas\ninspired from this list, or suggest completely new projects (which is perfectly\nfine if your proposition makes sense). Our\n[roadmaps](https://developer.gimp.org/core/roadmap/) may also be a good source\nof inspiration.\n\nYou will be selected on the quality of the proposal and on your attitude within the context of a Free Software Community. Also we prefer smaller projects which end up in our main codebase, rather than over-ambitious projects which you won’t have time to finish and might end bitrotting for years.\n\nPlease also read the [main page on internship programs with\nGIMP](https://developer.gimp.org/core/internship/).\n\n##\n[Implement a Shape Tool\n](https://developer.gimp.org#implement-a-shape-tool)\n\n- Category\n- Tools, Core\n- Project size (GSoC)\n- Large (350 hours)\n- Skills\n- C, GTK\n- Possible mentors\n- Jehan, CmykStudent\n- Difficulty\n- Intermediate\n- Outcome\n- Initial implementation of a Shape tool\n\nA long running request for GIMP has been to have a simple Shape tool.\nWhile we have had the [GFig filter](https://docs.gimp.org/3.0/en/plug-in-gfig.html),\nit has several drawbacks and limitations. With the implementation of vector layers\nin GIMP 3.2, we now have the backend to implement a vector Shape tool.\n\nPeople interested in this project can begin by reading the\n[history of the issue report](https://gitlab.gnome.org/Teams/GIMP/Design/gimp-ux/-/issues/715),\nwith special attention to [recent comments](https://gitlab.gnome.org/Teams/GIMP/Design/gimp-ux/-/issues/715#note_2586018).\nCurrent ideas are to either build an entirely separate tool or to modify the existing Path tool\nto have shape presets - though you are always welcome to suggest your own ideas!\n\nThis is a project involving UX considerations, so you would\nbe expected to work with our community of designers on the `gimp-ux`\n\ntracker, and experiment with various implementations via back-and-forth\ntesting.\n\n##\n[New Shortcuts Editing Dialog\n](https://developer.gimp.org#new-shortcuts-editing-dialog)\n\n- Category\n- User Interface, Core\n- Project size (GSoC)\n- Large (350 hours)\n- Skills\n- C, GTK\n- Possible mentors\n- Jehan, CmykStudent, Aryeom\n- Difficulty\n- Intermediate\n- Outcome\n- replacement of exiting GUI in GIMP codebase\n\nGIMP has a dialog to edit your shortcuts. It is globally working but has issues:\n\n- It is based on\n`GtkTreeView`\n\nwhich is deprecated in GTK4. - It does not allow assigning several shortcuts for a single action (which is a new core feature of GIMP 3, except we don’t have a proper GUI to allow creators make their own multiple shortcuts).\n- Many things are confusing in this dialog.\n- The search is quite basic and not always so useful.\n- Etc.\n\nThis is a project involving quite some UX considerations, so you would\nbe expected to work with our community of designers on the `gimp-ux`\n\ntracker, and experiments various implementations with back-and-forth\ntesting.\n\n##\n[Improve Text-along-a-Path features\n](https://developer.gimp.org#improve-text-along-a-path-features)\n\n- Category\n- Text, User Interface, Core, tools\n- Project size (GSoC)\n- Large (350 hours)\n- Skills\n- C, GTK, GEGL\n- Possible mentors\n- Liam, Jehan, CmykStudent\n- Difficulty\n- Intermediate\n- Outcome\n- implementation of the updated feature in GIMP codebase\n\nGIMP supports bending and shaping text layers along user defined paths.\nHowever, this is currently a destructive process with a number of limitations.\nWe would like to improve the user experience for this feature and add more\nnice, modern abilities to it\n([such as non-destructive editing](https://gitlab.gnome.org/GNOME/gimp/-/issues/136))\n\nFor a successful project, you will need to do the following:\n\n- Study the current implementation as well as implementations in other software\n- Propose a project scope with milestones\n- Collaborate with our community and UX designers to test out differnt interactions\n- Implement an initial version in our codebase\n\n##\n[New UI to quickly list, search and preview filters\n](https://developer.gimp.org#new-ui-to-quickly-list-search-and-preview-filters)\n\n- Category\n- User Interface, Core, Tools, GEGL\n- Project size (GSoC)\n- Large (350 hours)\n- Skills\n- C, GTK, GEGL\n- Possible mentors\n- Jehan, CmykStudent, Aryeom\n- Difficulty\n- Intermediate\n- Outcome\n- implementation of the tool in GIMP codebase\n\nNon-destructive filters can currently be started from menus (mixed with all sorts of other items, which may not be filters), or from the action search. Some people have discussed the idea of a more centralized interface where filters usable non-destructively could be listed, show some kind of preview of the filter (though it could just be pre-rendered images showing a typical use case). This would more likely be implemented as a dockable dialog.\n\nAdditional features which would make sense would include categorization, proper tagging, search by keyword, etc.\n\nSuch project would require a lot of UX discussions with our designers and various people on our tracker, back and forth implementations for testing and so on.\n\nRelevant UX report: [https://gitlab.gnome.org/Teams/GIMP/Design/gimp-ux/-/issues/106](https://gitlab.gnome.org/Teams/GIMP/Design/gimp-ux/-/issues/106)\n\n##\n[Better math expressions UI/UX\n](https://developer.gimp.org#better-math-expressions-uiux)\n\n- Category\n- User Interface, Core\n- Project size (GSoC)\n- Small (90 hours)\n- Skills\n- C, GTK\n- Possible mentors\n- Aryeom, Jehan, CmykStudent\n- Difficulty\n- Intermediate\n- Outcome\n- make maths expressions feature more discoverable and usable\n\nSome widgets in GIMP have the ability to process math operations in\ntheir input fields. For instance, in the “Create a New Image” dialog,\nyou could write `1920*2`\n\nin “Width” field and it would be transformed to\n`3840`\n\n. The mathematics parser code currently resides in\n`libgimpwidgets/gimpeevl.[ch]`\n\n.\n\nThough very powerful, the feature could be made more discoverable, understandable and why not even more powerful!\n\nReference UX discussions:\n\n[https://gitlab.gnome.org/Teams/GIMP/Design/gimp-ux/-/issues/476](https://gitlab.gnome.org/Teams/GIMP/Design/gimp-ux/-/issues/476)[https://gitlab.gnome.org/Teams/Design/whiteboards/-/issues/328](https://gitlab.gnome.org/Teams/Design/whiteboards/-/issues/328)\n\nYou would work with our community of designers to implement a visual interface for the feature. This could mean implementing several versions for wider testing and decision.\n\nThe end implementation would be cleanly contained in code which could be easily reused in several widgets, if needed. You would then research the various widgets where this would be useful, as well as the various fields where it would be worth enabling.\n\nIt could be interesting to also contribute this to upstream GTK.\n\nIf time allows, the internal feature could also be improved where needed.\n\n##\n[Implement In-Painting Tool\n](https://developer.gimp.org#implement-in-painting-tool)\n\n- Category\n- User Interface, Core, Tools, GEGL\n- Project size (GSoC)\n- Large (350 hours)\n- Skills\n- C\n- Possible mentors\n- Jehan, CmykStudent\n- Difficulty\n- Intermediate\n- Outcome\n- implementation of the tool in GIMP codebase\n\nGIMP has had support for in-painting (filling in an area based on the\nsurrounding image) for many years with the third-party\n[Resythesizer plug-in](https://github.com/bootchk/resynthesizer).\nThere have been many requests to implement the feature as a tool directly in\ncore GIMP. In addition to this algorithm, there is also the GEGL operation\n[alpha-inpaint](https://gitlab.gnome.org/GNOME/gegl/-/blob/master/operations/workshop/alpha-inpaint.c)\nwhich works similarly.\n\nRelevant discussions that would assist with implementing this feature can be found\n[here](https://gitlab.gnome.org/GNOME/gimp/-/issues/8692) and\n[here](https://gitlab.gnome.org/GNOME/gimp/-/issues/4762).\n\n- Study the Resynthesizer plug-in,\n`gegl:alpha-inpaint`\n\noperation, and other implementations - Design a potential implementation and UI\n- Improve the implementation of the algorithms as needed\n- Implement the tool\n\n##\n[Image Segmentation Improvements\n](https://developer.gimp.org#image-segmentation-improvements)\n\n- Category\n- Core, Tools\n- Project size (GSoC)\n- Large (350 hours)\n- Skills\n- C\n- Possible mentors\n- Jehan, CmykStudent\n- Difficulty\n- Intermediate\n- Outcome\n- New and/or improved algorithms for selecting parts of images\n\nGIMP has many different tools and algorithms for selecting specific sections of an image - from the standard Rectangle and Ellipse Select tools to the more advanced Paint Select and Foreground Select tools. Yet there are always new algorithms and methods for segmenting images.\n\n- Find an existing algorithm or propose a new one\n- Implement, optimize and test for real image processing work on a variety of images\n- Design how it should be used in GIMP\n- An additional mode in an existing tool\n- A new tool entirely\n\n\n##\n[Update Windows Scanner and Printer API\n](https://developer.gimp.org#update-windows-scanner-and-printer-api)\n\n- Category\n- Plug-ins\n- Project size (GSoC)\n- Large (350 hours)\n- Skills\n- C\n- Possible mentors\n- Jacob, CmykStudent\n- Difficulty\n- Intermediate\n- Outcome\n- Updated Scanner and Printer features on modern Windows platforms\n\nGIMP is a cross-platform program that supports Linux, macOS, and Windows. In some cases, we have to add platform-specific code to access system features like printing and scanning. Currently, our Windows integration for these are out of date:\n\n-\nOur Windows scanner plug-in uses\n\n[32-bit TWAIN rather than WIA API](https://gitlab.gnome.org/GNOME/gimp/-/issues/10930), and soon will no longer be supported on modern 64-bit systems. -\nThe Printer API for Windows 11 is different than earlier versions, and our printer plug-in currently has\n\n[missing features on that OS](https://gitlab.gnome.org/GNOME/gimp/-/issues/7299).\n\nA successful project to update these plug-ins would include:\n\n- Study the current implementation and the newer APIs\n- Design any new UI components required by the API update\n- Implement and test the updated plug-ins for printing and/or scanning\n\n##\n[Improving unit testing\n](https://developer.gimp.org#improving-unit-testing)\n\n- Category\n- Unit testing\n- Project size (GSoC)\n- Large (350 hours)\n- Skills\n- C\n- Possible mentors\n- Jehan, Jacob\n- Difficulty\n- Intermediate\n- Outcome\n- Improved unit testing infrastructure and new unit tests\n\nCurrently GIMP unit testing framework is really outdated, adding new tests is complex and therefore never happens. We should specify and code a proper framework for testing GIMP features.\n\nThis implies automated tests we can run in our Continuous Integration in Gitlab and not interactive tools (though such tools can be interesting too, as additional process, if someone has something nice to propose).\n\n- Port existing tests to the new framework;\n- Testing all libgimp functions;\n- Testing GEGL operations implemented within GIMP codebase;\n- Testing plug-ins (in priority the file import/export ones, but not only);\n- Testing core code;\n- Testing GUI code if possible;\n- Writing down the procedure to add unit tests to make it a mandatory process in future development.\n\n##\n[Fuzz testing integration\n](https://developer.gimp.org#fuzz-testing-integration)\n\n- Category\n- Unit testing, Security\n- Project size (GSoC)\n- Large (350 hours)\n- Skills\n- C\n- Possible mentors\n- Jehan, Jacob\n- Difficulty\n- Intermediate\n\nIn addition to unit testing, we would also like to build a robust automated fuzz testing suite. Integrating a fuzzer would help us better detect when new code could lead to a security vulnerability or incorrect behavior in GIMP. This project would cover many aspects of GIMP, from core code to plug-ins to public API.\n\n- Study GIMP and determine what areas to cover in initial implementation\n- Review fuzzing techniques and tools\n- Design a test suite and process\n- Implement fuzz testing suite\n\n##\n[Implement sandboxing for plug-ins\n](https://developer.gimp.org#implement-sandboxing-for-plug-ins)\n\n- Category\n- Security, Plug-ins\n- Project size (GSoC)\n- Large (350 hours)\n- Skills\n- C\n- Possible mentors\n- Jehan, Jacob\n- Difficulty\n- Complicated\n\nMany features of GIMP such as image import and export are implemented with separate plug-ins. For this project, we would like to run them in a sandbox environment for safety and security.\n\nThis is a complex project, and requires knowledge of both GIMP’s\narchitecture as well as extensive research into security. Mentors\nwould be learning alongside the student, so any interested individual\nwould need to be able to work well independently. Please\n[contact us](https://www.gimp.org/discuss.html#irc-matrix) to\ndiscuss your proposal for this project.\n\n##\n[Improving the text tool\n](https://developer.gimp.org#improving-the-text-tool)\n\n- Category\n- GEGL, color science\n- Project size (GSoC)\n- Large (350 hours)\n- Skills\n- C\n- Possible mentors\n- Liam Quin\n- Difficulty\n- Intermediate\n- Outcome\n- Improvement of the text tool\n\n**This is a project following up a few previous GSoC projects, which\ndeserves further work as this is a complicated topic.**\n\nOur text tool is a bit of a UI and UX mess and deserves a proper rewrite/enhancement project:\n\n- Re-specify text editing and formating as well as the tool option, for existing\nfeatures, but also adding new features for modern text editing (see also this\n[draft](https://gui.gimp.org/index.php?title=OnCanvasTextEditing)); - Add\n[OpenType support](https://gui.gimp.org/index.php?title=OpenTypeSupport). - Continue previous years experiments on a new text layout library.\n\n##\n[Implement GEGL operations for GIMP\n](https://developer.gimp.org#implement-gegl-operations-for-gimp)\n\n- Category\n- GEGL, image processing\n- Project size (GSoC)\n- Large (350 hours)\n- Skills\n- C\n- Possible mentors\n- Jehan, Øyvind\n- Difficulty\n- Intermediate\n- Outcome\n- implementation or improvements of GEGL operations in GIMP or GEGL codebase\n\nThe migration of GIMP to use GEGL has accelerated - for some GIMP functionality the main hurdle to migrate is having GEGL ops that can act as drop in replacement for the core processing functionality (some ops would be desired directly in GIMP others could likely go directly into GEGL).\n\nFor most code involved, porting to GEGL involves understanding what the current code does; and port or reimplement it as a floating point processing operation (floating point math often ends up shorter and more readable than the 8bit equivalents.\n\nThere are also some filters which were ported to GEGL, but some people prefer the old one (e.g. the Sharpen filter). It would be worth investigating the difference and either implement the old one or improve the new one.\n\n[Talk to us](https://www.gimp.org/discuss.html#irc-matrix) for specifics on\nwhich operations would be a good project`.\n\n##\n[Implement OpenColorIO Color Management\n](https://developer.gimp.org#implement-opencolorio-color-management)\n\n- Category\n- User Interface, Core, Tools, GEGL\n- Project size (GSoC)\n- Large (350 hours)\n- Skills\n- C\n- Possible mentors\n- drc, CmykStudent\n- Difficulty\n- Intermediate\n- Outcome\n- implementation of the OCIO color management system in GIMP codebase\n\nGIMP uses industry standard [ICC Color profiles](https://www.color.org/profiles2.xalter)\nto allow users to match and maintain colors for image editing and printing.\nThe film industry utilizes a separate standard, [OpenColorIO](https://opencolorio.org/),\nwhich focuses more on manipulating colors in a space rather than trying to keep them\nconsistent across multiple devices.\n\nThis project would involve adding support for OCIO color management in addition to the existing system. This addition would improve user workflows for motion picture and animation work, as well as improve compatibility with other OCIO-supporting software like Blender and Krita. The project would involve the following:\n\n- Research OCIO and color management systems in general\n- The Krita manual has an\n[excellent overview of the subject](https://docs.krita.org/en/general_concepts/colors/color_managed_workflow.html)\n\n- The Krita manual has an\n- Design and test a user interface\n- Implement the code\n\n##\n[Improve Non-Destructive Editing\n](https://developer.gimp.org#improve-non-destructive-editing)\n\n- Category\n- GEGL, User Interface\n- Project size (GSoC)\n- Large (350 hours)\n- Skills\n- C\n- Possible mentors\n- Jehan, CmykStudent\n- Difficulty\n- Intermediate\n- Outcome\n- implementation of the feature in GIMP codebase\n\nAs of version 3.0, GIMP now has initial support for non-destructive\nediting with layer effects. Yet there is much more work to be done.\nOur [roadmap](https://developer.gimp.org/core/roadmap/#non-destructive-filters)\nprovides some ideas for the next areas to improve, or you can propose your own:\n\n- Studying the current implementation\n- Design improvements to UI or functionality\n- Implement the improvements\n\n##\n[Improving off-canvas editing\n](https://developer.gimp.org#improving-off-canvas-editing)\n\n- Category\n- User Interface, Core\n- Project size (GSoC)\n- Large (350 hours)\n- Skills\n- C\n- Possible mentors\n- Jehan\n- Difficulty\n- Intermediate\n- Outcome\n- implementation of the feature in GIMP codebase\n\nGIMP recently got the ability to view the image out of the canvas. This is still incomplete. Among the many possible improvements:\n\n- Being able to select off-canvas.\n- Being able to see off-canvas but with an effect (e.g. dimming).\n- Having various tools and features working differently when “Show All” is enabled.\n\n##\n[Improve Metadata Editor and Viewer\n](https://developer.gimp.org#improve-metadata-editor-and-viewer)\n\n- Category\n- Metadata, Plug-in, User Interface\n- Project size (GSoC)\n- Large (350 hours)\n- Skills\n- C\n- Possible mentors\n- Jehan, Jacob\n- Difficulty\n- Intermediate\n- Outcome\n- Improved metadata UI and codebase\n\nOur image metadata viewer and editor could use some code review and improvements.\nIt currently supports only a subset of all valid metadata, and the UI could be\nimproved to allow easier editing and viewing of metadata.\nThere may a better, more logical, division in categories than the current one.\nYou could check what are the most used tags and which ones are considered\ndeprecated. Some discussion about this can be found\n[here](https://gitlab.gnome.org/Teams/GIMP/Design/gimp-ux/-/issues/521).\n\nAdditionally, some image formats such as HEIC, FITs, and DICOM have custom metadata. Another aspect of this project might be considering how to handle these in a way that is easily extensible and maintainable.\n\nFor further inspiration, you can review open issues\n[tagged with the Metadata label](https://gitlab.gnome.org/GNOME/gimp/-/issues/?label_name%5B%5D=5.%20Metadata)\nin our tracker. See also relevant issues in our GIMP UX tracker, e.g. the\nfollowing:\n\n-\nReview metadata related issues\n\n-\nDiscuss designs with the UX team at an early stage\n\n-\nDevelop a plan what exactly you want to work on\n\n-\nDesign user interface and code structure\n\n-\nImplement planned changes in the metadata plug-in\n\n\n##\n[Extension website\n](https://developer.gimp.org#extension-website)\n\n- Category\n- Web\n- Project size (GSoC)\n- Large (350 hours)\n- Skills\n- Python, HTML, Javascript and other web technologies\n- Possible mentors\n- Jehan\n- Difficulty\n- Intermediate\n- Outcome\n- New website and build scripts for continuous integration\n\nWe would want a website for our future extension platform, with very specific\ncriteria.\nApart from some necessary dynamic parts, we want a website as static as\npossible, with generated pages when possible. GIMP is a software project, which\nrelies on community. We don’t want to spend all our time having to maintain and\nmanage a website with a lot of moving parts. So we need simplicity first,\nsecurity first, with just the right amount of dynamicity. The static\nwebsite framework which we seem to want to go with the most in our\nproject right now is [Hugo](https://gohugo.io/).\n\nEven though it has a “web” component, this project is also about\nbuilding a proper backend, which includes processing XML metadata\n([AppStream](https://www.freedesktop.org/software/appstream/docs/)) in a\nsecure way (considering third-party received data as unsafe and possibly\nmalicious), generic static web and repository data from these\nrepositories, and more.\n\nSee [this\ndocument](https://gitlab.gnome.org/Infrastructure/gimp-extensions-web/-/blob/master/docs/README.md)\nfor an early overview of what we are looking for."
  },
  {
    "name": "OpenAFS",
    "slug": "openafs",
    "tagline": "An open source distributed filesystem.",
    "description": "OpenAFS is a distributed filesystem originally developed at Carnegie Mellon University and IBM. It offers a client-server architecture for federated file sharing and replicated read-only content distribution, providing location independence, scalability, security, and transparent migration capabilities. OpenAFS is available for a broad range of systems including UNIX, Linux,  MacOS X, and Microsoft Windows.",
    "ideas_url": "https://www.openafs.org/gsoc/project-ideas.html",
    "website_url": "https://www.openafs.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "python",
      "javascript",
      "git",
      "tcp/udp"
    ],
    "topic_tags": [
      "testing",
      "kernel",
      "network",
      "storage",
      "filesystems"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/openafs",
    "ideas_content": "OpenAFS"
  },
  {
    "name": "GNU Mailman",
    "slug": "gnu-mailman",
    "tagline": "GNU Mailman manages your mailing lists.",
    "description": "The Mailman project develops the GNU Mailman mailing list manager. Our goals are RFC conformance and powerful convenient tools for subscribers, moderators, list owners, domain administrators, and site adminstrators of mailing lists.",
    "ideas_url": "https://wiki.list.org/DEV/Google%20Summer%20of%20Code%202026",
    "website_url": "https://www.list.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "django",
      "rest",
      "sqlalchemy",
      "zope"
    ],
    "topic_tags": [
      "email",
      "archives",
      "list management"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/gnu-mailman",
    "ideas_content": "# Google Summer of Code 2026 Ideas Page\n\n**Take me straight to the ideas!**\n\n\n## What is Mailman?\n\nMailman is free software for managing electronic mail discussion and e-newsletter lists. Mailman is integrated with the web, making it easy for users to manage their accounts and for list owners to administer their lists. Mailman supports built-in archiving, automatic bounce processing, content filtering, digest delivery, spam filters, and more. Many open source denizens will be familiar with Mailman 2.1, which is used to manage many project mailing lists. All of our current work is on Mailman 3, which was released in 2015, but there's still lots of room for new features and ideas!\n\nNot sure about how GSoC works? Check out the resources at [Summer of Code Home](https://summerofcode.withgoogle.com/)\n\nContents\n\n-\n[Google Summer of Code 2026 Ideas Page](https://wiki.list.org#Google_Summer_of_Code_2026_Ideas_Page) -\n[Project Ideas](https://wiki.list.org#Project_Ideas)-\n[Mentors](https://wiki.list.org#Mentors) -\n[User Profile Tool](https://wiki.list.org#User_Profile_Tool) -\n[Moderating Emails and Threads in Hyperkitty](https://wiki.list.org#Moderating_Emails_and_Threads_in_Hyperkitty) -\n[Support for Encrypted Lists](https://wiki.list.org#Support_for_Encrypted_Lists) -\n[Improved UI for Subscription Management](https://wiki.list.org#Improved_UI_for_Subscription_Management) -\n[Dynamic Sublists (aka Conversations)](https://wiki.list.org#Dynamic_Sublists_.28aka_Conversations.29) -\n[Topics](https://wiki.list.org#Topics) -\n[HTML Digests](https://wiki.list.org#HTML_Digests) -\n[Configurable Mail Footers](https://wiki.list.org#Configurable_Mail_Footers) -\n[Per-list backup](https://wiki.list.org#Per-list_backup) -\n[Shell Completions](https://wiki.list.org#Shell_Completions) -\n[Log Access from the Web UI](https://wiki.list.org#Log_Access_from_the_Web_UI) -\n[Implement Domain Administration](https://wiki.list.org#Implement_Domain_Administration) -\n[The Generic Project Template](https://wiki.list.org#The_Generic_Project_Template)\n\n-\n\n\n## Getting Started\n\nThe [GSoC Contributor Guide](https://google.github.io/gsocguides/student/) has some great general GSoC information. Read it first!\n\nBefore you ask any questions about how to do anything in git or initialize your repository please read through the [git howto](https://wiki.list.org/DEV/HowToContributeGit) and see if that answers your questions.\n\n\n## Recommended Skills\n\nHere's a few skills that will make it easier for you to get started as a Mailman developer:\n\n**Python programming.**You can be fairly new to[Python](https://www.python.org), but you're going to have to be comfortable reading the Mailman code and asking questions if you aren't sure how it works. SQL is another useful language to know. Mailman core makes heavy use of third-party modules such as[lazr-config](https://lazrconfig.readthedocs.io/en/stable/),[Zope interfaces](https://zopeinterface.readthedocs.io/en/latest/README.html), and[SQLAlchemy](https://docs.sqlalchemy.org/en/20/). Postorius and HyperKitty are[Django](https://wiki.list.org/%EF%BB%BF%EF%BB%BFhttps%3A//docs.djangoproject.com/en/4.0/)applications, which even experienced Python programmers may find to be as unfamiliar as a foreign language. Ask us about anything!**Familiarity with any version control.**We use git on Gitlab (and you will too), but any experience will help you here.**Ability to setup a development environment for Mailman.**You'll need access to a Linux machine or VM, and we will help you to set it up. (Mailman also works well on macos and BSD systems, but the core developers are not as familiar with them. Windows-based POSIX environments are going to be difficult, not recommended unless you're wizardly with them. Windows itself is known*not*to support Mailman.)**Ability to communicate with the Mailman developers.**You'll be expected to keep a blog, post to the public mailing lists, ask questions, and describe the work you're doing. We don't*require*English, but we have very little ability to work in other languages.\n\nSpecific projects may have additional desired skills listed along with them.\n\n\n## What is Mailman Suite?\n\nIn Mailman 3, we've divided up the code into a number of sub-projects. We refer to the whole package as \"Mailman Suite\" and there's a few really important pieces you should know:\n\n[Mailman Core](https://gitlab.com/mailman/mailman)- This is the part that actually sends and receives mail and handles subscriber and list information.[Postorius](https://gitlab.com/mailman/postorius)- A web interface for managing Mailman lists (e.g. subscribing, changing preferences), a WSGI application based on Django.[Hyperkitty](https://gitlab.com/mailman/hyperkitty)- A web interface to access GNU Mailman v3 archives, another WSGI application based on Django.\n\nThere's also a number of smaller projects that provide the glue to make these pieces work well together, or allow them to be used separately.\n\n[All the Mailman 3 source is on GitLab](https://gitlab.com/groups/mailman).\n\n\n## Documentation & Installation\n\nHere are some useful links to get you started with Mailman Development:\n\n\nMailman is written in Python. Mailman supports Python 3.5+. Each individual projects may have their own restrictions on the Python versions you can use depending on the support of the their dependencies.\n\nDevelopment work on Mailman 2.1 has been frozen for some time, so **all new project ideas must be related to Mailman 3**.\n\n\n## GSoC Application Process\n\nTo be considered as an applicant for Google Summer of Code 2026, we need you to contribute at least one Merge Request (not merely a typographical error in a comment, but an actual defect including semantically incorrect documentation), and have that accepted.\n\nThe best way to get started is to set up a local development environment, documentation for which is [available here](http://docs.mailman3.org/en/latest/devsetup.html).\n\nYou can then find issues tagged with \"beginner-friendly\" and \"easy\" on [our Gitlab Page](https://gitlab.com/groups/mailman/-/issues?sort=created_date). Or ask us on the mailing lists (but showing you've checked the [GitLab](https://wiki.list.org/GitLab) issues first is something we consider anencouraging sign!) Feel free to open more issues when you find them.\n\n\n## Contacting us\n\n**The most successful GSoC students are the ones who work closely with the Mailman team.** As you might expect from a group that makes mailing list software, our preferred method of communication is our mailing list, but we also have an IRC channel. Please do not send private messages or emails unless asked to do so or the subject is personal rather than technical, since we get a lot of similar questions and would rather the questions and answers happen in public so everyone can benefit.\n\nMailing list to use for GSoC discussions:\n\n[Mailman developers mailing list](https://mail.python.org/mailman3/lists/mailman-developers.python.org/)Mailing list to consult users about their experiences and requirements:\n\n[Mailman Users mailing list](https://lists.mailman3.org/mailman3/lists/mailman-users.mailman3.org/)IRC channel: #mailman on irc.libera.chat. You need to have a\n\n[registered nickname](https://libera.chat/guides/registration)to participate. Many people prefer specialized clients, but you can also participate using[Libera's Kiwi webchat](https://web.libera.chat/)site. For help in connecting, see[Connecting to Libera.Chat](https://libera.chat/guides/connect).\n\n\n## Writing Your Application\n\nThe\n\n[GSoC student Guide](https://google.github.io/gsocguides/student/)has some great information[Tips for Prospective Google Summer of Code Students](https://wiki.list.org/DEV/Tips%20for%20Prospective%20Google%20Summer%20of%20Code%20Students)(general good advice)[Tips for writing a good GSoC proposal](https://wiki.list.org/DEV/SPAM)(advice on structuring and composing the document; now several years old but mostly valid)\n\n\n\n## FAQ\n\n- I am interested to contribute to Mailman and participate in GSOC, how do I start?\n\n[This page](http://wiki.list.org/DEV/Tips%20for%20Prospective%20Google%20Summer%20of%20Code%20Students) might be of some help.\n\nThis question has been asked tons of times on the mailing list (mentioned above) and IRC Channel (again, mentioned above). Both of them are logged publicly and are searchable. It would be really nice to go through them once before you ask the same question again. More specific questions are encouraged and receive more attention than \"How do I start?\". Mentors do try hard to reply to each and every email to the developers list, but in case you don't get any replies on trivial questions, don't be discouraged. Also, in case you are a student, helping others with small problems for which you know answers is also a great way to get noticed. Don't worry too much about giving wrong answers, list is constantly monitored by the core developers and any mistakes would be corrected.\n\n- I am a beginner, what is the best way for me to contribute?\n\nIssues, bugs and tests are obviously a good way to contribute. But, writing/improving documentation is another great way to contribute for beginners. It doesn't have to be a real commit or patch, write up a detailed blog post about what problems you faced while setting up mailman for development. What parts of mailman you find are difficult to understand? What are awesome things about mailman?\n\n**Note:** To qualify for Google Summer of Code, your proposed project must be a coding project. That's Google's rule. Documentation and tests help to make a substantial contribution, but only count toward GSoC to the extent that they apply to your *new or changed* code. Additional work on documentation or testing is considered a community contribution, which is a consideration in deciding who to accept.\n\n- My MR has been pending for a long time, what should I do?\n\nIn most of the cases the reason for a MR to be pending is that there is either something missing or something incorrect. In either of those cases, first check the MR itself and any issues associated with it, to see if there are comment you have missed. If it's not obvious what you need to do next, contact any mentor or the org admin (Steve = yaseppochi@IRC) and we'll look into it, or ask the relevant person. I don't mean that you do that for each one, just the ones that haven't been noticed by anyone for a *long time*. (Use your judgment as to what is \"long\" when there's a deadline coming up.)\n\n\n# Project Ideas\n\nThis is the list of project ideas. Do communicate with the developers before writing a proposal based on any of these ideas. The developers work individually on issues that catch their eye either as a feature they want, or at a user's request. So somebody may already be working on an idea, and you may be wasting your time to propose it.\n\nIf you have an idea not listed here that you'd like to propose , please send it to [mailman-developers@python.org](mailto:mailman-developers@python.org) for discussion! You can also look at the to-do lists for Mailman 3 [here](https://wiki.list.org/DEV#Version-specific_resources), and see if anything is interesting enough that you would like to work on it through the summer.\n\nIf you saw an idea on an earlier year's page and thought it would be a good project, but it isn't here, most likely it has been implemented and is in the current distribution. Sorry!\n\n\n## Mentors\n\nThe mentor assignments below are tentative. During the application and community bonding phases, your primary contact with the mentors about projects should be through the Mailman Developers mailing list <[mailman-developers@python.org](mailto:mailman-developers@python.org)> for technical questions about the source code and implmentation, the Mailman 3 Users mailing list <[mailman-users@mailman3.org](mailto:mailman-users@mailman3.org)> for questions that touch on user-visible features, or IRC for interactive conversations. Once you have been assigned a project and mentors, you can make alternative arrangements. For *personal* questions, such as known scheduling issues that make it difficult for you to work to the \"standard\" schedule, contact the organization administrator(s) directly. (GSoC does allow a certain amount of flexibility, but you will need to justify nonstandard schedules.)\n\nHere are the current mentors:\n\nAbhilash Raj (UTC+5.5, maxking on IRC,\n\n[maxking@asynchronous.in](mailto:maxking@asynchronous.in))Stephen J. (Steve) Turnbull (UTC+9, yaseppochi on IRC, yaseppochi.bsky.social on\n\n[BlueSky](https://wiki.list.org/BlueSky),[steve@turnbull.jp](mailto:steve@turnbull.jp))Mark Sapiro (UTC-7,\n\n[mark@msapiro.net](mailto:mark@msapiro.net))- Daniel Toe (UTC)\n- Victoriano Giralt (UTC)\n\nOrganization administrators:\n\nStephen J. (Steve) Turnbull (yaseppochi on IRC, yaseppochi.bsky.social on\n\n[BlueSky](https://wiki.list.org/BlueSky),[steve@turnbull.jp](mailto:steve@turnbull.jp))Abhilash Raj (maxking on IRC,\n\n[maxking@asynchronous.in](mailto:maxking@asynchronous.in))\n\n\n## User Profile Tool\n\nMailman 3 allows users to set some profile information at several scopes: user-wide, per-address, or per-subscription. While \"power users\" enjoy the flexibility, others find it inconvenient and confusing that settings at subscription scope don't propagate to the address or user scopes. This is especially annoying when they ask a list administrator to help them, because the list administrator normally doesn't have access to the user profile object, although they do have access to their list roster (including user preferences). For example, here's a [short thread](https://lists.mailman3.org/archives/list/mailman-users@mailman3.org/message/PRYP6ZVFKKOLXWGJBPKDCXPPFOUIKR2N/) on such a problem.\n\nThe object of this task is to create and integrate into Postorius a tool which allows the user to easily modify their preferences in any scope, and which helps them to propagate changes where appropriate, and not do so when not. It should probably present initially at user scope, even if invoked from subscription level. It should offer the ability to show a \"map\" of the scopes in which preferences are set to non-default values. List administrators should be warned about the limitations on their own access. A possible feature (but I haven't thought about it carefully, and don't know if users would want it) would be to send a one-time key to the list admin allowing them to access the user's profile as the user. (This needs careful thought -- should the admin be able to change credentials? other lists' preferences?)\n\n\n### Requirements\n\n- Level: moderate\n- Estimated effort: 175 hours\n\n\n### Mentors\n\n- Abhilash Raj\n- Stephen J. Turnbull\n\n\n## Moderating Emails and Threads in Hyperkitty\n\nHyperkitty is GNU Mailman's official archiver. However, it also supports some advanced functionality which allows users to send messages/emails through its web interface.\n\nModeration of topics being discussed in a Mailing List has been one of the biggest complaints on Mailman Users. Email is a very distributed and open protocol, which makes it hard to restrict users from following up on threads that have been going on for a long time and need to be shut down.\n\nWith Hyperkitty, we can tackle this problem by adding moderation actions to specific Email Headers. This allows us to moderate all the replies to a message (In-Reply-To: and References: header fields).\n\n\n### Requirements\n\n- Level: moderate\n- Estimated effort: 175 hours\n\n\n### Mentors\n\n- Abhilash Raj\n- Stephen J. Turnbull\n\n\n## Support for Encrypted Lists\n\nThis is an idea that has been around for a while and there are a number of custom implementations in the wild, we hear. The problem as usual is key distribution and management. The obvious distributed implementation using PGP requires everyone on the list to know everyone else's public key, and to encrypt using *all of them*. The basic idea is to add each subscriber's public key to their profile, so that subscribers only need to know the list's public key. Then the list would do the reencryption. That way subscribers only need to manage two keys: their own and the list's. The devil is in the details. For example, the list is by definition a person in the middle. To what extent can Mailman help to improve site security? A naive implementation would put plaintext on disk. Can that be avoided? What about archives? Some of these questions are design questions, and (for the purpose of GSoC) it doesn't matter how you answer them. But they do need to be answered and *documented*.\n\nThe simplest, *low functionality*, model would involve disabling archives, and poster to server and server to subscriber encryption.\n\nA *high functionality* model would offer archives, with some degree of forward security as well as security in transit.\n\nTags: *core* (securing the core), *postorius* (configuring an encrypted list), *hyperkitty* (archive management)\n\n\n### Requirements\n\n- Level: hard\n- Estimated effort: 175 hours (low functionality) or 350 (high functionality)\n\n\n### Mentors\n\n- Abhilash Raj\n- Stephen J. Turnbull\n- Victoriano Giralt\n\n\n## Improved UI for Subscription Management\n\nThis is a collection of small improvements. For example, Postorius currently presents minimal information on the subscriber list page, with a link to each subscription's options page. There should at least be an option to view the most important options as a table, and a link to the subscriber's profile only for verbose or rarely used fields. At present, the list of lists view does not present \"private\" lists to the logged user, even if they are a subscriber. There should be a option between public and private making lists visible to subscribers but not nonsubscribers.\n\nTags: *postorius*\n\n\n### Requirements\n\n- Level: moderate\n- Estimated effort: 175 hours\n\n\n### Mentors\n\n- Abhilash Raj\n- Stephen J. Turnbull\n\n\n## Dynamic Sublists (aka Conversations)\n\nDynamic sublists are a feature of the Systers fork of Mailman which was never integrated upstream due to entanglement with other, very Systers-specific, features of their fork. The idea is that only the thread root is distributed to all users, and by replying to a special address, a reader can \"subscribe\" to that thread. Because of divergence of the code bases integration will likely involve some amount of new code. Also, the original feature was controlled entirely by email, but integration with Postorius and [HyperKitty](https://wiki.list.org/HyperKitty) is desirable. Also see [Topics](https://wiki.list.org/DEV/Google%20Summer%20of%20Code%202026#Topics) for a similar feature, but user-controlled.\n\nTags: *core*\n\n\n### Requirements\n\n- Level: hard\n- Estimated effort: 175 hours (as described above) or 350 hours (for additional functionality, ask us)\n\n\n### Mentors\n\n- Abhilash Raj\n- Stephen J. Turnbull\n\n\n## Topics\n\nTopics are a feature of Mailman 2 which was never integrated into Mailman 3. The idea is that the list administrator creates a tag for the topic, and a reader can \"subscribe\" to that topic in the web interface or by email. If a post has an explicit topic and you're not subscribed, you don't get it. Finally there is special \"not a topic\" tag that you can \"subscribe\" to, to get posts that are classified as being related to a topic. Because of divergence of the code bases integration and a Python 2 to Python 3 port will likely involve quite a lot of new code. The original feature was controlled entirely by the web interface, but integration with email commands is also desirable. Also see [Dynamic Sublists](https://wiki.list.org/DEV/Google%20Summer%20of%20Code%202026#Dynamic_Sublists_.28aka_Conversations.29) for a similar feature, but user-controlled.\n\nTags: *core* *topics*\n\n\n### Requirements\n\n- Level: hard\n- Estimated effort: 175 hours (as described above)\n\n\n### Mentors\n\n- Abhilash Raj\n- Stephen J. Turnbull\n\n\n## HTML Digests\n\n*Thanks to Jay Hamilton-Roth for the suggestion.*\n\nBackground: For the non-technical users of MM3, the Mime digest format is only useful on a small subset of email readers (e.g., Outlook and iPad/iPhone Email). The majority of \"average\" users cannot easily parse nor reply to messages in the digest, making the digest not very useful.\n\nThe current digest format is:\n\n1. The masthead from the list:member:digest:masthead template. 2. The digest header if any from the list:member:digest:header template. 3. The table of contents. 4. The individual messages. 5. The digest footer from the list:member:digest:footer template.\n\nFor the MIME digest, these are all separate MIME parts and the individual messages are message/rfc822 parts within a multipart/digest part.\n\nFor the plain text digest, the digest is one text/plain part containing the above formatted par RFC 1153\n\nGoal: A simple HTML customizable digest format could help to make digests more usable.\n\nSuggestion: Create new html template files (that could live in list:member:htmldigest): masthead, header, footer, tocheader, tocfooter, msgheader, msgfooter. These would allow for customized ornamentation. The masthead would also include the following digest classes by default: .digest_msg_start, .digest_msg_number, .digest_msg_reply, .digest_msg_reply_all, .digest_msg_archive, and .digest_msg_end. List owners could configure any of these classes to set the visibility property to hidden.\n\nThis would create a proposed HTML digest format as:\n\n1. The masthead from the list:member:htmldigest:masthead template.\n\n2. The digest header if any from the list:member:htmldigest:header template.\n\n3. The toc header if any from the list:member:htmldigest:tocheader template\n\n4. The table of contents.\n\n5. The toc footer if any from the list:member:htmldigest:tocheader template\n\n6. Foreach message\n\n- The msg header if any from the list:member:htmldigest:msgheader template followed by\n\n<div class=\"digest_msg_number\">message number</div> <div class=\"digest_msg_title\">message subject</div>\n\n- b. message body\n\n<div class=\"digest_msg_reply\"><a href=\"mailto:SenderURL?subject=message subject\">Reply to sender</a> </div> <div class=\"digest_msg_reply_all\"><a href=\"mailto:ListURL?subject=message subject\">Reply to group</a> </div> <div class=\"digest_msg_archive\"><a href=\"archiveURL\">Thread</a></div>\n\n- c. The msg footer if any from the list:member:htmldigest:msgfooter template\n\n7. The digest footer from the list:member:htmldigest:footer template.\n\nFor example, the default for htmldigest:msgheader could be <hr>\n\nAn HTML digest is probably only greatly useful if you're going to prohibit HTML mail or convert it to plain text in digests. The HTML produced by commercial MUAs is complex, and it's hard to predict how it will interact with the digest formatting.\n\nIf HTML mail will be allowed, we would need to examples of what at least the most common mail composers on your lists are going to throw at us. (Somebody else can do the followup work for composers you've never seen. The problem is that we may have to \"unwrap\" the HTML document and parse the HEAD element to integrate them into a digest correctly and provide a convenient UI.\n\n- I think the high-level structure for the digest itself should be extremely simple, right? A few paragraphs with lists for the table of contents and the messages themselves mixed in.\n\nTag: core\n\n\n### Requirements\n\n- Level: moderate (HTML mail prohibited version) or hard (HTML mail allowed)\n- Estimated effort: 175 hours (HTML mail prohibited version) or 350 hours (HTML mail allowed)\n\n\n### Mentors\n\n- Abhilash Raj\n- Stephen J. Turnbull\n\n\n## Configurable Mail Footers\n\nWhile generally a good idea to have the existing mail footers on mailing list, there exist some mailing lists where having the footers is basically a non-starter. This can currently be achieved by editing the templates directly, but this is obvious cumbersome. This project is intended to focus on piping through Postorius the UI elements needed to configure those footers on a per-list, or per-site basis. (basically give an editor in postorious for the respective `var/templates/domains/<domain>/<lang>/` files)\n\n\n### Requirements\n\n- Level: moderate\n- Estimated effort: to be determined\n\n\n### Mentors\n\n- Stephen J. Turnbull\n- Victoriano Giralt\n\n\n## Per-list backup\n\nIn Mailman 2, the list configurations were stored in list-specific structures as Python *pickles*. Backup of a single list was just a matter of copying the pickle file. Currently there is no way to extract and restore the configuration and membership of a single list from a Mailman 3 installation. This project would involve picking a format such as a Python pickle or a JSON object, extracting the list-specific data from the backing database, and storing it to a file, as well as reversing the process.\n\nTags: *core*, *postorius*\n\n\n### Requirements\n\n- Level: medium\n- Estimated effort: 175 hours\n\n\n### Mentors\n\n- Stephen J. Turnbull\nVictoriano Giralt\n\n\n\n## Shell Completions\n\nMailman has (at least) two command-line utilities: *mailman*, for list creation, deletion, and querying, as well as starting and stopping the core daemon, and *mailmanweb*, which handles configuration and maintenance of the Django applications Postorius and [HyperKitty](https://wiki.list.org/HyperKitty), as well as starting and stopping them. Both have long, complex lists of subcommands, so it is desirable to have shell completion for these commands. Completion functions for at least *bash* and *zsh* are required, *csh* is desirable, and other shells with completion hooks may be added.\n\n**Note:** *This task may not require a full summer's effort, so additional subtasks may be added.*\n\n\n### Requirements\n\n- Level: medium\n- Estimated effort: 175 hours\n- Special skills: shell programming and configuration\n\n\n### Mentors\n\n- Stephen J. Turnbull\n- Victoriano Giralt\n\n\n## Log Access from the Web UI\n\nSometimes it would be useful for admins who do not have shell access to the host (domain admins for hosted instances as well as list admins) to view logs through the web UI. This task is rated \"hard\" not because the filtering problem is complex (it's complex enough to be interesting!), but because of the privacy and security implications of access to the logs. Site admins in particular would often like to get information from the MTA or web server. This would need to be extremely well-done to convince a hosting provider to enable those features.\n\nTag: Postorius\n\n\n### Requirements\n\n- Level: hard\n- Estimated effort: 175 hours\n\n\n### Mentors\n\n- Stephen J. Turnbull\n- Mark Sapiro\n\n\n## Implement Domain Administration\n\nMailman 3 has a hierarchy of administrative privileges, currently:\n\n*site admin*(aka*superuser*, who maintains the software and creates domains and lists)*list owner*(who can see all subscriptions and delegate moderation to other users)*list moderator*(who can approve or disapprove subscriptions and posts)\n\nThis task is to implement the *domain owner* role, which allows a domain owner to create lists in a specific domain, as well as exercise the privileges of a list owner for lists in that domain.\n\nTag: Postorius\n\n\n### Requirements\n\n- Level: moderate\n- Estimated effort: 175 hours\n\n\n### Mentors\n\n- Stephen J. Turnbull\n- Abhilash Raj\n\n\n## The Generic Project Template\n\nWe're open to original proposals from candidates. Trawl the [mailman-users@mailman3.org](https://lists.mailman3.org/mailman3/lists/mailman-users.mailman3.org/) and [Mailman developers mailing list](https://mail.python.org/mailman/listinfo/mailman-developers) mailing list archives and the [GitLab issue trackers](https://gitlab.com/mailman) for user feature requests and proposals. Be careful and consult with us before doing much work on a proposal, though: Google requires a certain *minimum amount of work* (approximately full-time for 10 weeks) and that the work produce *code* (not tests, UI styling, or documentation).\n\nTag: as appropriate\n\n\n### Requirements\n\n- Level: to be determined\n- Estimated effort: to be determined\n\n\n### Mentors\n\n- to be determined"
  },
  {
    "name": "SymPy",
    "slug": "sympy",
    "tagline": "SymPy is a Python library for symbolic mathematics",
    "description": "SymPy is a Python library for symbolic mathematics. It aims to become a full-featured computer algebra system (CAS) while keeping the code as simple as possible in order to be comprehensible and easily extensible. SymPy is written entirely in Python.",
    "ideas_url": "https://github.com/sympy/sympy/wiki/GSoC-Ideas",
    "website_url": "https://www.sympy.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "numpy",
      "jupyter"
    ],
    "topic_tags": [
      "mathematics",
      "physics",
      "symbolic mathematics"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/sympy",
    "ideas_content": "# Introduction\n\nThis is the list of ideas for students wishing to apply for Google Summer of\nCode. For more information on how to apply, see the [GSoC Student\nInstructions](GSoC-Student-Instructions). This list is here for inspiration and to give students an idea\nof what directions may be good for SymPy.\n\nIf you want to pursue an idea listed here, you should contact us on our\n[mailing list](http://groups.google.com/group/sympy) and discuss it. **Be sure\nto always ask about these ideas to get the latest information about what is\nimplemented and what exactly has to be done.**\n\nThe order of ideas in this list has no bearing to the chances of an idea to be\naccepted. All of them are equally good and your chances depend on the quality\nof your application. Also do not worry if there are no mentors assigned to a given idea. If the application is good, we will find a mentor. As already said, you can very well submit your own idea\nnot listed here.\n\n## Project length\n\nGSoC allows three different project lengths, 90 hours, 175,\nhours and 350 hours. The ideas below specify which project length is the best fit.\n\nIn some cases, it may be possible to extend a smaller project into a larger one by extending the ideas of what can be done in the project.\nSimilarly, in some cases a larger project can be shortened by only implementing part of the full idea and leaving the rest for a\nfuture project. In either case, if you want to do this, please discuss it with\nus first.\n\n# Submitting Your Own Idea\n\nYou can apply with something completely different if you like. The best project\nfor you is one you are interested in, and are knowledgeable about. That way,\nyou will be the most successful in your project and have the most fun doing it,\nwhile we will be the most confident in your commitment and your ability to\ncomplete it.\n\nIf you do want to suggest your own idea, please [discuss\nit](http://groups.google.com/group/sympy) with us first, so we can determine if\nit is already been implemented, if it is enough work to constitute a summer's\nworth of coding, if it is not too much work, and if it is within the scope of\nour project.\n\nPlease be aware that some ideas are specifically [out of scope for\nSymPy](#non-ideas) and may be a better fit for other GSoC organizations. Also\nbe aware that ideas that propose completely new modules to SymPy are less\nlikely to be accepted, unless they have already been mentioned on this page or\nsomewhere in the SymPy issue tracker. This is because most of the things that\nare in-scope for SymPy already have at least a partial implementation in a\nsubmodule in SymPy. However, many of these things are not fleshed out very\nwell yet and doing so can often make a good project. If you are unsure, it\ndoesn't hurt to ask us.\n\n# Potential Mentors\n\nIf you are willing to mentor, please add yourself here. Also please register at\nhttps://summerofcode.withgoogle.com and add your email that you registered\nwith. Finally, list your name with any\nprojects below that you would be willing to mentor.\n\n(Note from Aaron, the org admin: if your name is on this list, I'm assuming\nyou're willing to either mentor or at least help review applications. If you\naren't able to help this year, please remove your name from the list. If you\nhave any questions about mentoring feel free to email me.)\n\n* Aaron Meurer - asmeurer@gmail.com\n* Advait Pote - apote2050@gmail.com (for `sympy.physics.continuum_mechanics`)\n* Akshansh Bhatt - qaz.akshansh@gmail.com (for `sympy.physics.control`)\n* Amit Kumar - dtu.amit@gmail.com (for `sympy.solvers`)\n* Anurag Bhat - anuragbhatgsoc23@gmail.com\n* Anutosh Bhat - anutosh.bhat.21@gmail.com (for `sympy.series`, `sympy.concrete`)\n* Faisal Riyaz - faisalriyaz011@gmail.com\n* Francesco Bonazzi - franz.bonazzi@gmail.com\n* Hwayeon Kang - hwayeonniii@gmail.com (for `sympy.physics.mechanics`)\n* Ishan Joshi - ishanaj98@gmail.com\n* Ishan Pandhare - ishan9096137017@gmail.com\n* Jason Moore - moorepants@gmail.com (physics.vector/mechanics/biomechanics, parsing.autolev, utilities.autowrap/codegen/lambdify)\n* Mohit Balwani - mohitbalwani.ict17@gmail.com (for `sympy.solvers.ode`)\n* Mohit Gupta - mohitgupta6678@gmail.com\n* Naman Gera - namangera15@gmail.com (for `sympy.physics`)\n* Naveen Sai - naveensaisreenivas@gmail.com\n* Nijso Beishuizen - nijso.beishuizen@gmail.com (for ode and pde solvers)\n* Nikhil Maan - nikhilmaan22@gmail.com\n* Oscar Benjamin - oscar.j.benjamin@gmail.com\n* Peter Stahlecker - peter.stahlecker@gmail.com (for `sympy.physics.mechanics` (Kane's method)`)\n* Prakhar Saxena - prakharrsaxena@gmail.com (for `sympy.physics.continuum_mechanics`)\n* Sachin Agarwal - sachinagarwal0499@gmail.com (for `sympy.series`)\n* Sidharth Mundhra - sidharthmundhra16@gmail.com (for 'sympy.series')\n* Smit Lunagariya - smitplunagariya@gmail.com\n* Sudeep Sidhu - sudeepmanilsidhu@gmail.com (physics.vector/mechanics)\n* Timo Stienstra - timostienstra00@gmail.com (for `sympy.physics.mechanics`/`vector`/`biomechanics`)\n* Tom van Woudenberg - tom.van.woudenberg@gmail.com (for `sympy.physics.continuum_mechanics`)\n* Yathartha Joshi - yathartha32@gmail.com\n* Rushabh Mehta - mehtarushabh2005@gmail.com (for `sympy.physics.mechanics` (Wrapping Geometries))\n* Sai Udayagiri - saibabu.udayagiri@gmail.com (for `sympy.physics.continuum_mechanics`)\n* Leonardo Mangani - leomangani4@gmail.com (for `sympy.physics.control`)\n\n# Table of Contents\n\n<!-- Generate the TOC below with (https://github.com/thlorenz/doctoc):\n\ndoctoc --title \" \" GSoC-Ideas.md\n\n-->\n\n<!-- START doctoc generated TOC please keep comment here to allow auto update -->\n<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->\n\n- [High Priority](#high-priority)\n  - [Polynomial GCD](#polynomial-gcd)\n  - [Benchmarks and performance](#benchmarks-and-performance)\n  - [Assumptions](#assumptions)\n- [Mathematics Projects](#mathematics-projects)\n  - [Solvers](#solvers)\n  - [Optimize floating point expressions](#optimize-floating-point-expressions)\n  - [Group theory](#group-theory)\n  - [Risch algorithm for symbolic integration](#risch-algorithm-for-symbolic-integration)\n  - [Rule-based symbolic integration](#rule-based-symbolic-integration)\n  - [ODE ideas](#ode-ideas)\n  - [Improving Series Expansions & Limit Computations](#improving-series-expansions--limit-computations)\n  - [Cylindrical algebraic decomposition](#cylindrical-algebraic-decomposition)\n  - [Efficient Groebner bases and their applications](#efficient-groebner-bases-and-their-applications)\n  - [Multivariate polynomials and factorization](#multivariate-polynomials-and-factorization)\n  - [Univariate polynomials over algebraic domains](#univariate-polynomials-over-algebraic-domains)\n  - [Concrete module: Implement Karr algorithm, a decision procedure for symbolic summation](#concrete-module-implement-karr-algorithm-a-decision-procedure-for-symbolic-summation)\n- [Physics Projects](#physics-projects)\n  - [Symbolic Control Systems (`sympy.physics.control`)](#symbolic-control-systems-sympyphysicscontrol)\n  - [Symbolic quantum mechanics (`sympy.physics.quantum`)](#symbolic-quantum-mechanics-sympyphysicsquantum)\n  - [Continuum Mechanics: Create a Rich 2D Beam Solving System](#continuum-mechanics-create-a-rich-2d-beam-solving-system)\n  - [Classical Mechanics](#classical-mechanics)\n  - [Classical Mechanics: Generalize the Equations of Motion System Output](#classical-mechanics-generalize-the-equations-of-motion-system-output)\n  - [Classical Mechanics: Implement and Benchmark Equations of Motion Methods](#classical-mechanics-implement-and-benchmark-equations-of-motion-methods)\n  - [Classical Mechanics: Efficient Equations of Motion Generation](#classical-mechanics-efficient-equations-of-motion-generation)\n  - [Classical Mechanics: Implement Wrapping Geometry and Pathways for Musculoskeletal Modeling](#classical-mechanics-implement-wrapping-geometry-and-pathways-for-musculoskeletal-modeling)\n  - [Classical Mechanics: Implement Specific Forces and Torques](#classical-mechanics-implement-specific-forces-and-torques)\n  - [Classical Mechanics: Constructing Systems From Bodies and Joints](#classical-mechanics-constructing-systems-from-bodies-and-joints)\n  - [Classical Mechanics: Implement an O(N) Equations of Motion Method](#classical-mechanics-implement-an-on-equations-of-motion-method)\n- [Computer Science, Graphics, and Infrastructure Projects](#computer-science-graphics-and-infrastructure-projects)\n  - [Enhancing the flexibility of MatchPy](#enhancing-the-flexibility-of-matchpy)\n  - [Code Generation](#code-generation)\n  - [Code Generation: Efficient Jacobian and Hessian Evaluation for Optimization and ODE Integration](#code-generation-efficient-jacobian-and-hessian-evaluation-for-optimization-and-ode-integration)\n  - [Improve the LaTeX Parser for SymPy](https://github.com/sympy/sympy/wiki/GSoC-Ideas#improve-the-lark-based-latex-parser)\n  - [Parsing](#parsing)\n  - [Improve the plotting module](#improve-the-plotting-module)\n  - [Documentation tooling](#documentation-tooling)\n  - [Hypothesis testing](#hypothesis-testing)\n- [User Application Projects](#user-application-projects)\n- [LFortran SymPy Project Ideas](#lfortran-sympy-project-ideas)\n  - [SymPy -> Fortran Code Generation and JIT](#sympy---fortran-code-generation-and-jit)\n  - [Parsing Fortran code to SymPy](#parsing-fortran-code-to-sympy)\n- [Idea Prompts](#idea-prompts)\n- [Other Related Projects](#other-related-projects)\n- [Non-Ideas](#non-ideas)\n\n<!-- END doctoc generated TOC please keep comment here to allow auto update -->\n\n\n**Mentors, please use the following template to add ideas to this page:**\n\n```\n## Title\n\n**Idea**\n\n(Specify your idea with proper explanation)\n\n**Status**\n\n(What is the Status of this Idea in the Sympy Community currently, previous\nwork done and Issues)\n\n**Involved Software**\n\n(Any other Software Involved that would be required to implement your idea)\n\n**Difficulty**\n\n(Advanced, Intermediate, or Beginner and any specific comments on the\ndifficulty)\n\n**Prerequisite Knowledge**\n\n(Any prerequisite knowledge or approach needed)\n\n**Project Length**\n\nWhether this project is appropriate for a 90, 175, or 350 hours GSoC project.\nThe same idea can have different project length sub-ideas.\n\nNOTE: This section is required by Google. Be sure to include it for\nany idea!\n```\n\n# High Priority\n\n## Polynomial GCD\n\n**Idea**\n\nAdd new algorithms for computing the greatest common divisor (GCD) of polynomials in the sparse representation. This would improve the speed of many parts of sympy such as matrices, solvers, integration and so on.\n\nThe issues and potential solutions along with many references are discussed in this issue:\nhttps://github.com/sympy/sympy/issues/23131\n\n**Status**\n\nThere is plenty of work that can be done in this area so this is effectively an open-ended area for improvement in sympy.\n\n**Involved Software**\n\n**Difficulty**\n\nMedium to high difficulty\n\n**Prerequisite Knowledge**\n\nPython, some understanding of abstract algebra and of algorithms.\n\n**Project Length**\n\n175 or 350 hours, depending on the scope of the project.\n\n## Benchmarks and performance\n\n**Idea**\n\nSpeed is important for SymPy. One issue is that it's difficult to tell what is\ntoo slow, and, more importantly, if a given change makes things faster or\nslower.\n\nSymPy needs more benchmarks. It also needs an automated system to run them.\nThat way, when someone adds some code that slows things down in an unexpected\nway, we will know about it.\n\nThere are already some benchmarks at\nhttps://github.com/sympy/sympy_benchmarks, and some others in the main SymPy\nrepo. But not all benchmarks are in the sympy_benchmarks repo. Also, the repo\nuses asv, but the results are run and hosted *ad hoc*, as we don't have a\ndedicated machine to run the benchmarks.\n\nThis project should do the following:\n\n- Move benchmarks from the sympy repo to the sympy_benchmarks repo.\n- Add new benchmarks as needed.\n- Work with the community to set up a dedicated machine that can constantly\n  run asv to warn about benchmarks. It would also be nice if this could be set\n  up to warn for performance regressions on PRs.\n- Make improvements to SymPy to improve performance issues found\n  throughout the project.\n- Improve the usability of the current GitHub Actions bot that adds benchmarks outputs to pull requests.\n\nSome prior art:\n\n- ASV (what we are using now)\n- PyPy benchmarks page\n- See https://www.youtube.com/watch?v=d65dCD3VH9Q for some ideas/warnings\n  about setting up benchmarking.\n- See this issue for ways to run benchmarks on GitHub Actions https://github.com/sympy/sympy/issues/21374.\n\n**Status**\n\nWe currently have a benchmarking suite and run the benchmarks on GitHub\nActions, but this is limited and is often buggy.\n\n**Involved Software**\n\n**Difficulty**\n\nMedium to low difficulty\n\n**Prerequisite Knowledge**\n\nPython\n\n**Project Length**\n\n175 hours or 350 hours, depending on the scope of the project.\n\n## Assumptions\n\n**Idea**\n\nThe project is to completely remove our old assumptions system, replacing it\nwith the new one. The difference between the two systems is outlined in the\nfirst two sections of [this blog\npost](http://matthewrocklin.com/blog/work/2013/02/05/Assuming).\n\nThis project is challenging. It requires deep understanding of the core of\nSymPy, basic logical inference, excellent code organization, and attention to\nperformance.  It is also very important and of high value to the SymPy\ncommunity.\n\nNumerous related tasks are mentioned in the \"Ideas\" section.\n\n**Status**\n\nThere has been a significant amount of merged and unmerged work on this topic. A\nlist of detailed issues can be found at [this\nissue](https://github.com/sympy/sympy/issues/6730). You should take\na look at the work started at https://github.com/sympy/sympy/pull/2508.\n\n[This mailing list post](https://groups.google.com/d/msg/sympy/PHR136kdxc4/eW4pKFcWmzIJ) by Aaron Meurer outlines the status of the project and some ideas of what to do. It is from 2015 but most of what is written there is still true. The main thing that is new is that the new assumptions call the old assumptions (`ask(Q.real(Symbol('x', real=True)))`). See also the prior GSoC projects on assumptions, including [this one](https://github.com/sympy/sympy/wiki/GSoC-2015-Application-Sudhanshu-Mishra:-Assumptions), which was accepted, but there may be parts of it that were not completed, and https://github.com/sympy/sympy/wiki/GSoC-2013-Application-Tom-Bachmann:-Removing-the-old-assumptions-module, which was not accepted (the student chose to do another project), but contains some good ideas.\n\n**Involved Software**\n\nNone\n\n**Difficulty**\n\nAdvanced\n\n**Prerequisite Knowledge**\n\nNumber theory, Boolean algebra, etc.\n\n**Project Length**\n\n350 hours\n\n# Mathematics Projects\n\n## Solvers\n\n**Idea**\n\nSymPy already has a pretty powerful `solve` function. But it has a lot of major\nissues\n\n1. It doesn't have a consistent output for various types of solutions\n   It needs to return a lot of types of solutions consistently:\n   * single solution : ` x == 1`\n   * Multiple solutions: `x**2 == 1`\n   * No Solution: `x**2 + 1 == 0; x is real`\n   * Interval of solution: `floor(x) == 0`\n   * Infinitely many solutions: `sin(x) == 0`\n   * Multivariate functions with point solutions `x**2 + y**2 == 0`\n   * Multivariate functions with non point solution `x**2 + y**2 == 1`\n   * System of equations `x + y == 1` and `x - y == 0`\n   * Relational `x > 0`\n   * And the most important case \"We don't Know\"\n\n2. The input API is also a mess, there are a lot of parameter. Many of them\n   are not needed and they makes it hard for the user and the developers to\n   work on solvers.\n\n3. There are cases like finding the maxima and minima of function using\n   critical points where it is important to know if it has returned all the\n   solutions. `solve` does not guarantee this.\n\n**Salient Features of `solveset`**\n\n* `solveset` has a cleaner input and output interface: `solveset` returns a set\n  object and a set object take care of all the types of the output. For cases\n  where it doesn't \"know\" all the solutions a `NotImplementedError` is raised.\n  For input only takes the equation and the variables for which the equations\n  has to be solved.\n\n* `solveset` can return infinitely many solutions. For example solving for\n  `sin(x) = 0` returns {2⋅n⋅π | n ∊ ℤ} ∪ {2⋅n⋅π + π | n ∊ ℤ} Whereas `solve`\n  only returns [0, π]\n\n* There is a clear code level and interface level separation between solvers\n  for equations in complex domain and equations in real domain. For example\n  solving `exp(x) = 1` when x is complex returns the set of all solutions that\n  is {2⋅n⋅ⅈ⋅π | n ∊ ℤ} . Whereas if x is a real symbol then only {0} is\n  returned.\n\n* `solveset` returns a solution only when it can guarantee that it is returning\n  all the solutions.\n\n**Status**\n\n**[GSoC 2014 Project: Harsh Gupta](https://github.com/sympy/sympy/wiki/GSoC-2014-Application-Harsh-Gupta:-Solvers)**\nDuring the summer of 2014 Harsh Gupta worked to improve solvers as part of his\nGSoC project. Instead of making changes in the current `solve` function a new\nsubmodule named `solveset` was written.\n\n**[GSoC 2015 Project: Amit Kumar](https://github.com/sympy/sympy/wiki/GSoC-2015-Application-AMiT-Kumar--Solvers-:-Extending-Solveset)**\nIn the summer of 2015 Amit Kumar worked on this project to improve solveset, implement complex sets as a part of his GSoC project.\n\n**[GSoC 2016 Project: Kshitij SaraogiKshitij Saraogi](https://docs.google.com/document/d/1GljN3hj_qDzMvTAUW2X7idcsoDPhJ0uAqmMrqykSGGg/edit?usp=sharing) | [GSoC 2016 Project: Shekhar Rajak](https://github.com/sympy/sympy/wiki/GSoC-2016-Shekhar-Prasad-Rajak-Application:-Solvers:-Completing-Solveset)**\nIn the summer of 2016, two projects were selected to participate in Google Summer of Code to work on the Solvers.\nNew solver helper functions such as `solve_decomposition` and `nonlinsolve` were implemented to facilitate the porting from `solve` to `solveset`. Also, the inequality solver `solve_univariate_inequality` was refactored and added to `solveset`. Several methods related to functional analysis, such as `periodicty`, `continuous_domain` and `function_range` were implemented.\n\n**[GSoC 2018 Project: Yathartha Joshi](https://docs.google.com/document/d/1kcZCdQuY3XxgHPuSA8vvwc6O8AbVZ-nYskMuXIia9hA/edit#)**\nIn the summer of 2018, Yathartha worked on the project to implement transcendental equation solver for `solveset`. `transolve` alongwith its helper solvers was implemented as a result of it.\n\n**TODOs**\n\n* Extending `transolve`:\nAs part of the work done in the summer of 2018, `transolve` is fully designed and is now able to handle logarithmic and exponential equations for `solveset`. To make `solveset` fully fledged and replace `solve` completely we expect it to handle equations like:\n     * Lambert type equations (PR [#14972](https://github.com/sympy/sympy/pull/14972))\n     * Handling modular equations ([#13178](https://github.com/sympy/sympy/issues/13178))\n     * Solving transcendental equations in complex domain.\n\n     There may be other types of equations that `transolve` can be made to handle. It's still under development!! Feel free to propose any of your ideas.\n\n* Integrating helper solvers with `solveset`:\nCurrently, `solveset` only solves a single equation for a single variable. In the future, we expect it to be capable of solving a system of equations and for more than one variable.\n`linsolve`: Solves a system of linear equations\n`nonlinsolve`: Solves a system of non-linear equations\n`solve_decomposition`: Solves a varied class of equations using the concept of Rewriting and Decomposition\nThese are the helper functions that have been implemented in `solveset` during the past few years. We would like to have all these solvers(including `transolve`) to be integrating in `solveset` so as to increase its power.\n\n* Build the set infrastructure: This includes implementing functions to handle\n  multidimensional ImageSet etc., This part must go hand in hand with the\n  improvements in the solvers as set module can be a universe in itself. Also\n  there can be fundamental limits on the things you can do.\n\n* `nonlinsolve` is not able to handle system having trigonometric/transcendental equations correctly all the time. Improve solveset's trigonometric solver and handle trig system of equations separately in `nonlinsolve`.\n\n\n**References**\nThere had been a lot of discussion during and before the project and you should\nknow why we did what we did. Here are some links:\n\n* [Discussion on the mailing list](https://groups.google.com/forum/#!searchin/sympy/solvers/sympy/Oyz8SkR2fRk/RMpooqwu3oMJ)\n* [Action Plan on solvers](https://github.com/sympy/sympy/pull/2948)\n* [Harsh Gupta's proposal for GSoC 2014](https://github.com/sympy/sympy/wiki/GSoC-2014-Application-Harsh-Gupta:-Solvers)\n* [Harsh's blog for GSoC](http://hargup.github.io/categories/sympy.html)\n* [solveset pull request](https://github.com/sympy/sympy/pull/7523)\n* [Amit's blog for GSoC](http://iamit.in/blog/)\n* [Solveset Documentation](https://github.com/sympy/sympy/blob/master/doc/src/modules/solvers/solveset.rst)\n* [GSoC 2016 Solvers Progress and blog links](https://github.com/sympy/sympy/wiki/GSoC-2016-Solvers-Progress)\n* [Yathartha's blog for GSoC](https://yathartha22.github.io)\n* [transolve pull request](https://github.com/sympy/sympy/pull/14736)\n* [GSoC 2018 Solvers Progress](https://github.com/sympy/sympy/wiki/GSoC-2018-Solvers-Progress)\n\n**Involved Software**\n\nSymPy\n\n**Difficulty**\n\nThis project is difficult because it requires a good deal of thought in the\napplication period. You should have a clear plan of most of what you plan to do\nin your application: waiting until the Summer to do the designing will not\nwork.\n\n[#10006](https://github.com/sympy/sympy/issues/10006) and\n[#8711](https://github.com/sympy/sympy/issues/8711) can be good entry points.\n\n**Prerequisite Knowledge**\n\nAlgebraic and differential equations\n\nPotential mentor - Co-mentor: Shekhar (@Shekharrajak)\n\n**Project Length**\n\n350 hours.\n\n## Optimize floating point expressions\n\n**Idea**\n\nOptimize floating point expressions (à la https://herbie.uwplse.org/).\nThe user will supply a SymPy expression and an optional\nrange of \"x\" (and other variables) and the module would determine\nwhich symbolic simplifications make sense to make things more\naccurate and/or faster.\n\nPart of this project would also be to provide faster implementations of special\nfunctions, say if it is determined that \"x\" in sin(x) is in the range [0,\n1e-3], then there are much faster polynomial approximations that give the same\naccuracy (the same is possible for other finite ranges, e.g., [1.5, 1.7]).\n\nOne mode is to concentrate on accuracy (possibly with larger/slower\nexpression). Another mode is to concentrate on speed, and this mode can have a\nuser prescribed accuracy, say 1e-16 for machine precision, or 1e-3 for lower\naccuracy. For lower accuracies one can replace functions like sin(x) with a\nmuch faster polynomial approximation.\n\n**Difficulty**\n\nIntermediate, Advanced\n\n**Project Length**\n\n350 hours, although you may propose a 175 hour project with a more limited\nscope.\n\n## Group theory\n\n**Idea**\n\nContinue developing the group theory functionality of the combinatorics module. You should take a look at the GAP\nlibrary, as this is the canonical group theory computation system right now.\n\nAlgorithms to think about implementing:\n\n- Computation of various subgroups of infinite finitely presented groups\n- Computation of Galois groups for a given polynomial\n- Finding kernels of homomorphisms with infinite domains\n- Extend functionalities of polycyclic groups\n- Quotient groups\n- Automorphism groups\n\n**Status**\n\nPrevious projects on the topic include:\n\n- [GSoC 2012 Aleksandar Makelov: Computational Group Theory](https://github.com/sympy/sympy/wiki/GSoC-2012-Report-Aleksandar-Makelov:-Computational-Group-Theory)\n- [GSoC 2016 Gaurav Dhingra: Computational Group Theory](https://gxyd.github.io/blogs/Gsoc2016-project/)\n- [GSoC 2017 Valeriia Gladkova: Computational Group Theory](https://github.com/sympy/sympy/wiki/GSoC-2017-Report-Valeriia-Gladkova:-Group-Theory)\n- [GSoC 2018 Ravi Charan: Computational Group Theory](https://ravicharann.github.io/blog//final-report/)\n- [GSoC 2019 Divyanshu Thakur: Computational Group Theory](https://github.com/sympy/sympy/wiki/GSoC-2019-Report-Divyanshu-Thakur:-Group-Theory)\n\nA good amount of work has been done on polycyclic groups, polycyclic presentation with the base class collector were introduced in 2019 GSoC project but still there are a lot of things to be added for e.g. polycyclic orbit stabilizer and canonical polycyclic sequence to check if two polycylic subgroups are equal or not could be implemented. In addition, few other algorithms like abelian invariants and composition series implemented in 2019 GSoC project can be extended for infinite groups.\n\nSome major algorithms for finitely presented groups include coset enumeration (there's been work on modified Todd-Coxeter in the 2018 GSoC project: see [this PR](https://github.com/sympy/sympy/pull/14830)), low index subgroup search and Reidemeister-Schreier algorithm for subgroup presentation. Rewriting systems together with the Knuth-Bendix completion algorithm are available but could be made more efficient.\n\nAdditionally, the 2017 project implemented group homomorphisms and the 2018 project implemented the computation of the isomorphism between 2 groups, an automaton for word reduction and a few additional algorithms. Find the complete work done during 2018 in the project report in the link below.\n\nSee the [2016](https://gxyd.github.io/blogs/Gsoc2016-project/), [2017](https://github.com/sympy/sympy/wiki/GSoC-2017-Report-Valeriia-Gladkova:-Group-Theory) and [2019](https://github.com/sympy/sympy/wiki/GSoC-2019-Report-Divyanshu-Thakur:-Group-Theory) reports for suggestions on where the work could continue.\n\nQuite a lot of work has been done on permutation groups, but still, some things remain (some of those mentioned in [GSoC 2012 Report by Aleksandar Makelov](https://github.com/sympy/sympy/wiki/GSoC-2012-Report-Aleksandar-Makelov:-Computational-Group-Theory#after-gsoc) are still relevant, e.g. subgroup intersection). Some work is already done on discrete groups. Nonetheless, there is still much that can be done both for discrete groups and for Lie groups.\n\n**Difficulty**: Medium/Difficult\n\n**Resources**: *Handbook of Computational Group Theory* by *Derek F. Holt*, *Bettina Eick* and *Eamonn A. O'Brien*\n\n**Prerequisite Knowledge**: Basic knowledge of Abstract Algebra\n\nPotential mentor - Co-mentor: Divyanshu Thakur (@divyanshu132)\n\n**Project Length**\n\n350 hours.\n\n## Risch algorithm for symbolic integration\n\n**Idea**\n\nThe Risch algorithm is a complete algorithm to integrate any elementary\nfunction.  Given an elementary function, it will either produce an\nantiderivative, or prove that none exists.  The algorithm described in\nBronstein's book deals with transcendental functions (functions that do not\nhave algebraic functions, so ``log(x)`` is transcendental, but ``sqrt(x)`` and\n``sqrt(log(x))`` are not).\n\n**Status**\n\nThe project is to continue where Aaron Meurer left off in his 2010 GSoC\nproject, implementing the algorithm from Manuel Bronstein's book, _Symbolic\nIntegration I:  Transcendental Functions_.  If you want to do this project, be\nsure to ask on the mailing list or our IRC channel to get the status of the\ncurrent project.\n\nThe algorithm has already been partially implemented, but there is plenty of\nwork remaining to do.  Contact Aaron Meurer for more information. There was\nalso work done in 2013, which hasn't been completely merged yet. A good place\nto start would be to look at finishing this work:\nhttps://github.com/sympy/sympy/pulls/cheatiiit. See\nhttps://groups.google.com/forum/#!msg/sympy/bYHtVOmKEFs/UZoyDX81eP4J for some\nmore details on this project (nothing has changed since that email thread).\n\n**Involved Software**\n\n**Difficulty**\n\n**Prerequisite Knowledge**\n\nYou should have at least a semester's worth of knowledge in abstract algebra.\nKnowing more, especially about differential algebra, will be beneficial, as you\nwill be starting from the middle of a project. Take a look at the first chapter\nof Bronstein's book (you should be able to read it for free via Google Books)\nand see how much of that you already know. If you are unsure, discuss this\nwith Aaron Meurer (asmeurer).\n\n**Project Length**\n\n350 hours.\n\n## Rule-based symbolic integration\n\n**Idea**\n\nSymbolic integration can also be performed with a \"rule-based\" system, which\npattern matches the integrand against a set of known integrals uses them to\nreturn a result. This is a different approach to the Risch algorithm discussed\nin the previous approach, and is generally seen as complementary to it. For\ninstance, the Risch algorithm can handle very complex expressions but it can\nonly work with elementary integrals. Rule-based systems are limited to\nexpressions that can match the given set or rules, but it can work with a\nlarge set of special functions.\n\n**Status**\n\nThe main work here is a software called [RUBI](https://rulebasedintegration.org/), which is a rule-based\nintegration system written in Wolfram Language. Several previous GSoC projects\nhave worked on integrating RUBI in SymPy, but this work has not yet been\nsuccessfully completed.\n\nSee\n\n- [[GSoC-2017-Report-Abdullah-Javed-Nesar:-Rule-based-Integrator]]\n- [GSoC 2018 Rubi Final Report](https://github.com/ashishkg0022/Gsoc-proposal-Rubi/wiki/GSoC-2018-Rubi-Final-Report)\n- [[Improving-Rule-Based-Integrator]]\n- Tracking issue [#12233](https://github.com/sympy/sympy/issues/12233)\n\nThe RUBI code that has been written is now at https://github.com/sympy/rubi.\nThe primary issue with it is that RUBI is very large and the Python\ntranslation is too slow to be useful.\n\nRUBI also involves using MatchPy (see [Enhancing the flexibility of\nMatchPy](#enhancing-the-flexibility-of-matchpy)), which enables the sort of\nMathematica-style pattern matching needed for integration.\n\nBecause previous projects have failed to integrate the entirety of RUBI due to\nits size, a project working on RUBI should focus on integrating parts of it at\na time.\n\nSymPy also has a separate module called\n[manualintegrate](https://github.com/sympy/sympy/blob/master/sympy/integrals/manualintegrate.py)\nwhich implements a pattern-based integration system. It only has a limited of\npatterns right now, but could be extended. A potential project could just be\nto extend manualintegrate and not involve RUBI.\n\n**Involved Software**\n\n- MatchPy\n- RUBI\n\n**Difficulty**\n\nIntermediate to difficult\n\n**Prerequisite Knowledge**\n\nIf working on RUBI knowledge of Mathematica code will be useful, but not\nrequired. Prior knowledge of special functions will be useful, but can also\nquite easily be learned.\n\n**Project Length**\n\nFor anything involving RUBI, this should be 350 hours.\n\nSmaller 175 or even 90 hour projects to just improve manualintegrate are\npossible. Discuss with us.\n\n## ODE ideas\n\nYou also might want to look at [Manuel Bronstein's sumit](http://www-sop.inria.fr/cafe/Manuel.Bronstein/sumit/index.html).\n\n  * \"Solving Differential Equations in Terms of Bessel Functions\" by Ruben Debeerst.\n(basic idea is [already implemented](https://github.com/sympy/sympy/pull/16581).)\n      * Webpage: http://rubendebeerst.de/master/\n      * Master Thesis: http://rubendebeerst.de/master/master.pdf\n      * Corresponding ISSAC 08 paper: http://rubendebeerst.de/master/paper_issac2008.pdf\n\n  * Lie groups and symmetry related:\n\n      * [\"Integrating factors for second order ODEs\" by E.S. Cheb-Terrab and A.D. Roche](https://drive.google.com/file/d/1-XktJVEzpRK9nOlaMjE7arEgMgGlV_sN/view?usp=sharing)\n      * [\"Abel ODEs: Equivalence and Integrable Classes\" by E.S. Cheb-Terrab and A.D. Roche](https://drive.google.com/file/d/1XpGRJc6ZQ_ReTgRSBc3_tnToZ-hjCNgS/view?usp=sharing)\n        Note: Original version (12 pages): July 1999. Revised version (31 pages): January 2000\n\n**Status**\n\n**Involved Software**\n\n**Difficulty**\n\nMedium\n\n**Prerequisite Knowledge**\n\nDifferential equations\n\n**Project Length**\n\n175 hours or 350 hours, depending on the project details (discuss with us).\n\n## Improving Series Expansions & Limit Computations\n\n**Idea**\n\nThis includes numerous smaller subprojects and is more of a bug burn down project than implementing things from scratch. Hence we should aim at solving as many bugs and possible issues having the label series or limits on them. There are around **146** open issues with the series label & around **26** open issues with the limits label with some overlap and the proposal should have a comprehensive list of ideas to fix a significant portion of these issues.\n\n  * improve series expansions\n    * [relevant issues](https://github.com/sympy/sympy/labels/series)\n  * improve limit computations\n    * [relevant issues](https://github.com/sympy/sympy/labels/limits)\n  * improve formal power series\n  * asymptotic series (for instance aseries for gamma, bessel, error type functions)\n    * [issue 1](https://github.com/sympy/sympy/issues/26207), [issue 2](https://github.com/sympy/sympy/issues/26208), [issue 3](https://github.com/sympy/sympy/issues/26210), [issue 4](https://github.com/sympy/sympy/issues/26096)\n  * Better support for Order term arithmetic (for example, expression of the\n    order term of the series around a point that is not 0, like O((x - a)**3)).\n    * [issue 1](https://github.com/sympy/sympy/issues/22836)\n    * Read through [discussion](https://github.com/sympy/sympy/pull/22247#issuecomment-977811355) & comments for fixing [issue](https://github.com/sympy/sympy/issues/21315)\n    * Fix _eval_subs method to hanlde [issue 1](https://github.com/sympy/sympy/issues/19120), [issue 2](https://github.com/sympy/sympy/issues/10290), [issue 3](https://github.com/sympy/sympy/issues/7872), [issue 4](https://github.com/sympy/sympy/issues/15915)\n  * Fix limit computations for piecewise functions\n    * revamp work on [PR](https://github.com/sympy/sympy/pull/22339) and test properly, [relevant issue](https://github.com/sympy/sympy/issues/24127)\n  * All other problems, which are described in wiki page about [series](UD-series) and\n    [current situation](UD-series-situation)\n\n\n**Status**\n\nThere is already a fast implementation called `rs_series` in SymPy. This\nproject would extend it to work for all functions and then make it the default\nseries expansion in SymPy.\n\nSymPy now has support for Formal Power Series (series.formal). The algorithm is more or less\ncomplete. The module should be made faster. There are also a lot of XFAIL tests that can be made to pass.\n\nA new algorithm for computing limits of sequences has also been added (series.limitseq). There are still XFAIL tests that can be made to pass.\n\n**Some references**\n\n1. \"Formal Power Series\" by Dominik Gruntz and Wolfram Koepf\n2. \"A New Algorithm Computing for Asymptotic Series\" by Dominik Gruntz\n3. \"Computing limits of Sequences\" by Manuel Kauers\n4. \"Symbolic Asymptotics: Functions of Two Variables, Implicit Functions\"\n    by Bruno Savly and John Shackell\n5. \"Symbolic Asymptotics: Multiseries of Inverse Functions\" by Bruno Savly\n    and John Shackell\n\n**Involved Software**\n\nSymPy\n\n**Difficulty**\n\nMedium\n\n**Prerequisite Knowledge**\n\nCalculus\n\n**Project Length**\n\n175 hours or 350 hours, depending on the project details (discuss with us).\n\n\n## Cylindrical algebraic decomposition\n\n**Idea**\n\n* Implement the Cylindrical algebraic decomposition algorithm\n* Use CAD to do quantifier elimination\n* Provide an interface for solving systems of polynomial inequalities\n\n* Some references:\n  * Cylindrical Algebraic Decomposition\n    [[http://mathworld.wolfram.com/CylindricalAlgebraicDecomposition.html]]\n  * \"Algorithms in Real Algebraic Geometry\"\n    [[http://perso.univ-rennes1.fr/marie-francoise.roy/bpr-ed2-posted1.html]]\n    (useful background resource, but contains much more information)\n  * \"Cylindrical Algebraic Decomposition I: The Basic Algorithm\" by Dennis\n    S. Arnon, George E. Collins, Scot McCallum\n  * \"Computing Cylindrical Algebraic Decomposition via Triangular\n    Decomposition\" by Marc Moreno Maza, Changbo Chen, Bican Xia, Lu Yang\n  * \"Simple CAD Construction and its Applications\" by Christopher W. Brown\n  * \"Improved Projection for Cylindrical Algebraic Decomposition\" by Christopher W. Brown\n  * \"Symbolic Computation for Inequalities\" by Manuel Kauers\n    [[http://www.sfb013.uni-linz.ac.at/uploads/media/SymCompIneq.pdf]]\n  * \"How To Use Cylindrical Algebraic Decomposition\" by Manuel Kauers\n\n**Status**\n\n**Involved Software**\n\n**Difficulty**\n\n**Prerequisite Knowledge**\n\n**Project Length**\n\n350 hours\n\n## Efficient Groebner bases and their applications\n\n**Idea**\n\nGroebner bases computation is one of the most important tools in computer\nalgebra, which can be used for computing multivariate polynomial LCM and GCD,\nsolving systems of polynomial equations, symbolic integration, simplification\nof rational expressions, etc. Currently there is an efficient version of\nBuchberger algorithm implemented and of the F5B algorithm, along with naive\nmultivariate polynomial arithmetic in monomial form. There is also the FGLM\nalgorithm converting reduced Groebner bases of zero-dimensional ideals from one\nordering to another.\n\nImprove efficiency of Groebner basis algorithm by using better selection\nstrategy (e.g. sugar method) and implement Faugere F4 algorithm and analyze\nwhich approach is better in what contexts.  Implement the generic Groebner walk\nconverting between Groebner basis of finite-dimensional ideals; there are\nefficient algorithms for it, by Tran (2000) and Fukuda et al. (2005).\n\nApply Groebner bases in integration of rational and transcendental functions\nand simplification of rational expressions modulo a polynomial ideal (e.g.\ntrigonometric functions).\n\n**Status**\n\nThere was a project last year relating to Groebner bases. Please take a look a\nthe source and discuss things with us to see what remains to be done.\n\nSome Groebner bases algorithms, in particular F4, require strong linear\nalgebra.  Thus, if you want to do that, you may have to first improve our\nmatrices (see the ideas relating to this above).\n\n**Involved Software**\n\n**Difficulty**\n\n**Prerequisite Knowledge**\n\n**Project Length**\n\n350 hours\n\n## Multivariate polynomials and factorization\n\n**Idea**\n\nFactorization of multivariate polynomials is an important tool in algebra\nsystems, very useful by its own, also used in symbolic integration algorithms,\nsimplification of expressions, partial fractions, etc. Currently multivariate\nfactorization algorithm is based on Kronecker's method, which is impractical\nfor real life problems. Undergo there is implementation of Wang's algorithm,\nthe most widely used method for the task.\n\nStart with implementing efficient multivariate polynomial arithmetic and GCD\nalgorithm. You do this by improving existing code, which is based on recursive\ndense representation or implement new methods based on your research in the\nfield. There are many interesting methods, like Yan's geobuckets or heap based\nalgorithms (Monagan & Pearce). Having this, implement efficient GCD algorithm\nover integers, which is not a heuristic, e.g. Zippel's SPMOD, Musser's EZ-GCD,\nWang's EEZ-GCD. Help with implementing Wang's EEZ factorization algorithm or\nimplement your favorite method, e.g. Gao's partial differential equations\napproach. You can go further and extend all this to polynomials with\ncoefficients in algebraic domains or implement efficient multivariate\nfactorization over finite fields.\n\n**Status**\n\nSome work on this may already be done. Take a look at\n`sympy/polys/factortools.py` in the SymPy source code.\n\n**Involved Software**\n\n**Difficulty**\n\nAdvanced\n\n**Prerequisite Knowledge**\n\n**Project Length**\n\n350 hours\n\n## Univariate polynomials over algebraic domains\n\n**Idea**\n\nChoose a univariate polynomial representation in which elements of algebraic\ndomains will be efficiently encoded. By algebraic domains we mean algebraic\nnumbers and algebraic function fields. Having a good representation, implement\nefficient arithmetic and GCD algorithm. You should refer to work due to\nMonagan, Pearce, van Hoeij et. al. Having this, implement your favorite\nalgorithm for factorization over discussed domains. This will require\nalgorithms for computing minimal polynomials (this can be done by using LLL or\nGroebner bases). You can also go ahead and do all this in multivariate case.\n\n**Status**\n\nCurrently SymPy features efficient univariate polynomial arithmetic, GCD and\nfactorization over modular rings and integers (rationals). This is, however,\ninsufficient in solving real life problems, and has limited use for symbolic\nintegration and simplification algorithms. For example, the support for finite\nfields GF(p^n) is missing.\n\n**Involved Software**\n\n**Difficulty**\n\nAdvanced\n\n**Prerequisite Knowledge**\n\n**Project Length**\n\n350 hours\n\n## Concrete module: Implement Karr algorithm, a decision procedure for symbolic summation\n\n**Idea**\n\nAlgorithm due to Karr is the most powerful tool in the field of symbolic\nsummation, which you will implement in SymPy. There are strong similarities\nbetween this method and Risch algorithm for the integration problem. You will\nstart with implementing the indefinite case and later can extend it to support\ndefinite summation (see work due to Schneider and Kauers). Possibly you will\nalso need to work on solving difference equations.\n\n* Some references:\n  * \"A=B\" by Marko Petkovsek, Herbert S. Wilf, Doron Zeilberger\n  * \"Symbolic Summation with Radical Expressions\" by Manuel Kauers and Carsten\n    Schneider\n  * \"An Implementation of Karr's Summation Algorithm in Mathematica\" by\n    Carsten Schneider\n  * Manuel Kauers, webpage: [[http://www.risc.jku.at/home/mkauers]]\n  * Carsten Schneider, webpage: [[http://www.risc.jku.at/people/cschneid]]\n  * \"Algorithmen für mehrfache Summen\", by Torsten Sprenger\n\n**Status**\n\nSymPy currently features Gosper algorithm and some heuristics for computing\nsums of expressions. Special preference is for summations of hypergeometric\ntype. It would be very convenient to support more classes of expressions, like\n(generalized) harmonic numbers etc. There is already an complete algorithm\nrational expression summation.\n\n**Involved Software**\n\n**Difficulty**\n\nAdvanced\n\n**Prerequisite Knowledge**\n\n**Project Length**\n\n350 hours\n\n# Physics Projects\n\n## Symbolic Control Systems (`sympy.physics.control`)\n\n**Idea**\n\nA Control Systems subpackage\n([`sympy.physics.control`](https://github.com/sympy/sympy/tree/master/sympy/physics/control))\nwas added to SymPy in the summer of 2020, by Naman Gera. This was built upon\nfurther by Akshansh Bhatt in 2021 and Anurag Bhat in 2023. It would be great\nto continue its development and make it more accessible to the public. Since\nthe users are mostly students and researchers in the field of Control theory, a\nset of problems from a textbook can be solved in the documentation, as the\ndevelopment proceeds.\n\nhttps://www.cds.caltech.edu/~murray/amwiki/Second_Edition.html can be used as a reference.\n\n**Status**\n\nThe functionalities of the project can be viewed here:\n\nhttps://docs.sympy.org/latest/modules/physics/control/lti.html#module-sympy.physics.control.lti\n\nFuture Work (can be modified after discussion):\n\n* Refactor and complete plots:\n    1. The plots namely **Pole Zero**, **Step Response**, **Impulse Response**, **Ramp Response**, **Bode Magnitude** and **Bode Phase** plots need to be refactored since they use `numpy` and `matplotlib`. The numerical methods were used for speed but they sacrifice on precision. Sympy's symbolic methods are used in the first place for the precision they provide, hence these numerical methods should be replaced by algebraic methods. \\\n[Davide](https://github.com/Davide-sd), a fellow contributor has been revamping the plotting module. Check this [roadmap](https://github.com/sympy/sympy/issues/19263#issuecomment-1685859671), according to which `SymPy` will soon have its own `plot_list` function after which this refactoring could be done with ease.\n    2. The plots namely **Root Locus**, **Nichols** and **Nyquist** plots are draft pull requests and need to be completed. They have clear ideas to follow and some comments which can be addressed once `SymPy` no longer depends upon `matplotlib` and `numpy`.\n\n* Implementations for the `StateSpace` class:\n    1. Solve examples mentioned in [#25502](https://github.com/sympy/sympy/issues/25502) and add them to the `control_problems` file . The required functionality is already supported in the pull request.\n\n* Make the classes more feature rich:\n    1. Read about Laub's or Horner's method to evaluate system transfer function at complex frequency. This will be the equivalent of `eval_frequency` for Transfer Functions.\n    2. Other features can be picked up on comparison with `MATLAB` and `python-control`.\n    3. Implement the Z-Transform and its inverse. See [#28347](https://github.com/sympy/sympy/issues/28347#issuecomment-3225522105) for more information.\n    4. Implement the DiscretePIDController.\n    \n* Refactoring:\n    1. Simplify the code to improve clarity.\n    2. Add type annotations.\n\n**Involved Software**\n\nPython, Git\n\n**Difficulty**\n\nIntermediate\n\n**Prerequisite Knowledge**\n\nUndergraduate level Control Systems knowledge will suffice. Otherwise, one _can_ complete the project if they self-learn required topics and then contribute voraciously.\n\n**Project Length**\n\n150 or 350 hours.\n\n## Symbolic quantum mechanics (`sympy.physics.quantum`)\n\nIn the past, Brian Granger was the maintainer of the `sympy.physics.quantum`\nsubpackage. He has stepped down from this position. Until someone takes over\nthe maintenance of this subpackage, we will not be able to mentor any GSoC projects\nin this area. If you have questions about this, please contact Ondřej Čertík.\n\n## Continuum Mechanics: Create a Rich 2D Beam Solving System\n\n**Idea**\n\nSingularity functions are a popular tool for solving beam bending stress and\ndeflection problems in mechanical design. This is traditionally done by hand\ncalculations and can be very tedious and error prone. This process could be\nimproved greatly by a CAS implementation of the functions and some high level\nabstractions for constructing beam loading profiles.\n\nThe deliverable would be a unit tested and documented sub-package for SymPy 2D\nand 3D beams that can solve many beam problems, add in arbitrary cross\nsections, plotting, be robust, and add any other relevant features.\n\n**Status**\n\nSampad Saha implemented Singularity Functions in 2016. The 2017 and 2018 GSoC\nprojects created the functionality shown here:\n\nhttps://docs.sympy.org/dev/modules/physics/continuum_mechanics/beam_problems.html\n\nSome students at Delft Univeristy of Technology expanded both the theoretical\nand coding capabilities (https://oit.tudelft.nl/Macaulays-method/overview.html).\n\nThe next steps involve making it easier to define complex cross sectional\ngeometry via the geometry package, developing the 3D Beam into a well tested\nand robust class, and polishing to the plotting for 2D and 3D beams. Adding a\nlarge set of example problems that exercise the functionally.\n\nOther next steps focus on extending capabilities to frames.\n\n**Involved Software**\n\nPython, Git\n\n**Difficulty**\n\nIntermediate\n\n**Prerequisite Knowledge**\n\nNo specific prerequisite knowledge is necessary but it would help if the\nstudent had some knowledge of beam stress/strain analysis methods.\n\n**Project Length**\n\n350 hours.\n\n## Classical Mechanics\n\nThe following project ideas are in approximate order of priority.\n\n## Classical Mechanics: Generalize the Equations of Motion System Output\n\n**Idea**\n\nWe would like an ecosystem in which you can define/create your mechanical\nsystem in a general way using joints, bodies, forces, torques, etc., compute\nthe equations of motion based on different methods like `LagrangesMethod` and\n`KanesMethod`, to be used in numerical purposes, like simulations and\noptimizations.\n\nThe above is the general picture for which a lot of work has been done over the\nyears on the different parts. However, some parts are disjoint while other\nparts are still missing or should almost be entirely replaced.\n\nNote that defining/creating the mechanical system falls into two other projects,\nnamely:\n- [Classical Mechanics: Constructing Systems From Bodies and Joints](#classical-mechanics-constructing-systems-from-bodies-and-joints)\n- [Classical Mechanics: Implement Specific Forces and Torques](#classical-mechanics-implement-specific-forces-and-torques)\n- [Classical Mechanics: Implement and Benchmark Equations of Motion Methods](#classical-mechanics-implement-and-benchmark-equations-of-motion-methods)\n\n**Status**\n\nPrevious work covers quite a few different parts, which can be improved and\nextended, but mostly require to be tied together more properly:\n- An abstract base class as an interface to the different equations of motion\n  generation methods has been introduced in\n  [#21778](https://github.com/sympy/sympy/pull/21778).\n- Refer to the project\n  [Classical Mechanics: Constructing Systems From Bodies and Joints](#classical-mechanics-constructing-systems-from-bodies-and-joints)\n  for the status of bodies and joints.\n- Refer to the project\n  [Classical Mechanics: Implement Specific Forces and Torques](#classical-mechanics-implement-specific-forces-and-torques)\n  for the status of implementing specific loads.\n- In [#25560](https://github.com/sympy/sympy/pull/25560) a `System` class was\n  introduced as a general frontend to define a mechanical system and generate\n  the equations of motion using either of the implemented methods, i.e.\n  `LagrangesMethod` and `KanesMethod`.\n- In [#11431](https://github.com/sympy/sympy/pull/11431) as `SymbolicSystem` was\n  introduced as a data class to store all information about a system and its\n  equations of motion in a general format.\n- In [PyDy](https://github.com/pydy/pydy) there also exists a\n  [`System` class](https://github.com/pydy/pydy/blob/master/pydy/system.py),\n  which can be used to simulate a system that was solved using `KanesMethod`.\n\nThe goal of this project is to implement a class to function as a general\ninterface of a system from which the equations of motion can be used for\nnumerical purposes. This class would be an extension or replacement of\n`sympy.physics.mechanics.system.SymbolicSystem`. Some of the features it should\noffer are:\n- A general representation of the equations of motion and the algebraic\n  constraints.\n- Methods to code generate the functions to be used in simulation purposes, like\n  with `scipy.integrate.solve_ivp` and `scikits.odes.dae`.\n- It should use `sympy.physics.mechanics.system.System` for the basic system\n  information. It could possibly have multiple methods to be instantiated, like\n  a normal `__init__` where all equations and things need to be provided as is\n  currently the case with `SymbolicSystem`, and a classmethod `from_system`,\n  where it extracts most information from the `System` instance.\n\n**Involved Software**\n\nPython, Git\n\n**Difficulty**\n\nAdvanced\n\n**Prerequisite Knowledge**\n\nThis project requires basic understanding of dynamical systems and at least\nunderstanding of one method of generating the equations of motion for a\nmulti-body system.\n\n**Project Length**\n\n350 hours.\n\n## Classical Mechanics: Implement and Benchmark Equations of Motion Methods\n\n**Idea**\n\nThere are many methods to derive the equations of motion. Each method has its\nadvantageous and disadvantageous when modeling different systems. SymPy\ncurrently contains only two methods: `KanesMethod` and `LagrangesMethod`. The\nidea of this project is to develop more methods to form the equations of motion\nand to benchmark them for different models to also give users more insight what\nmodel they should use for their application.\n\n**Status**\n\n- An abstract base class as an interface to the different equations of motion\n  generation methods has been introduced in\n  [#21778](https://github.com/sympy/sympy/pull/21778).\n\nThis project could roughly entail the following steps:\n- Improve the abstract base class, `sympy.physics.mechanics.method._Methods` of\n  the equations of motion generation methods, e.g. `KanesMethod`.\n- Improve the implementation of `KanesMethod` and `LagrangesMethod`.\n- Implementing more methods to generate the equations of motion, like\n  `NetwonEulersMethod` or `HamiltonsMethod`.\n- Develop a benchmark suite deriving the equations of motion using the different\n  methods and measure their performance. Examples could include a 5-DoF planar\n  kinematic chain, a four-bar linkage, and the Carvallo-Whipple bicycle model.\n\n**Involved Software**\n\nPython, Git\n\n**Difficulty**\n\nIntermediate\n\n**Prerequisite Knowledge**\n\nThis project requires basic understanding of dynamical systems and at least\nunderstanding of one method of generating the equations of motion for a\nmulti-body system.\n\n**Project Length**\n\n175 or 350 hours.\n\n## Classical Mechanics: Efficient Equations of Motion Generation\n\n**Idea**\n\nCurrently we have basic equation of motion generation with automated Kane's and\nLagrange's methods. These methods work well but can take many minutes to\ncomplete for hard problems. The algorithms that derive these equations of\nmotion can be improved in both speed of computation and the resulting\nsimplification of the equations of motion. This project would involve profiling\nto find the slow functions and speeding up the slow parts. This may involve\ndigging into the SymPy codebase for trigonometric simplification and other\nrelevant function calls to speed up the EoM generation. These modification will\nhelp speed up both the entire SymPy codebase and the Mechanics package.\n\n**Status**\n\nThere is no previous work on this topic.\n\n**Involved Software**\n\nPython, Git\n\n**Difficulty**\n\nBeginner\n\n**Prerequisite Knowledge**\n\nThere are no prequisites to this project.\n\n**Project Length**\n\n175 or 350 hours.\n\n## Classical Mechanics: Implement Wrapping Geometry and Pathways for Musculoskeletal Modeling\n\n**Idea**\n\nSymPy Mechanics includes classes to manage how forces and torques act on\nconnected bodies when the path of action is a complex pathway that wraps over\ngeometric features. This is critical for accurate musculotendon force\ngeneration. The [Biomechanical Model\nExample](https://docs.sympy.org/dev/tutorials/physics/biomechanics/biomechanical-model-example.html)\nshows a simple cylindrical wrapping of a muscle around the elbow. This idea\ninvolves adding more wrapping surfaces and pathways that are useful for\nmusculoskeletal modeling.\nThe work can include implementing new wrapping geometry classes, such as an ellipsoid or torus. In addition, the APIs of wrapping geometry objects can be expanded to expose new useful convenience methods (for example, computing tangent or contact points). More end to end example models can also be added to the documentation.\n\n**Status**\n\n- [Cylindrical, sphereical and conical wrapping geometry\n  exist](https://docs.sympy.org/dev/modules/physics/mechanics/api/wrapping_geometry.html)\n- [Example models for cylindrical, spherical and conical geometries exist in the dev documentation](https://docs.sympy.org/dev/tutorials/physics/mechanics/atwoods_machine_example.html)\n- [Linear and obstacle pathway\n  exist](https://docs.sympy.org/dev/modules/physics/mechanics/api/pathway.html#sympy.physics.mechanics.pathway.WrappingPathway)\n\n**Involved Software**\n\nPython, Git\n\n**Difficulty**\n\nBeginner to intermediate\n\n**Prerequisite Knowledge**\n\nThis project requires basic understanding geometry, forces, anatomy and basic familiarity with Kane's/Lagrange's method.\n\n**Project Length**\n\n90, 175, or 350 hours (depends on how many features you'd like to implement)\n\n## Classical Mechanics: Implement Specific Forces and Torques\n\n**Idea**\n\nMany forces and torques still have to be manually created by the user. It would\nbe helpful if we had a set of typical and common forces and torques. Some\npossible examples:\n\n- Actuator forces and torques\n- Aerodynamic forces\n- Contact force models\n- Friction force models\n- Linear and nonlinear springs and dampers\n- Musculotendon models, like the Hill type muscle model\n- Controller forces (like PID or full state feedback)\n- [Eardrum model](https://www.cfm.brown.edu/people/dobrush/am33/Mathematica/ch4/nspring.html)\n\nSome kind of force and torque objects will likely be needed as well as symbolic\nmathematical descriptions of the force and torque models. The forces and\ntorques should work with SymPy's code generation to generate efficient and\nrobust numerical codes. Here is a [soft introduction to forces and\ntorques](https://moorepants.github.io/learn-multibody-dynamics/loads.html).\n\n**Status**\n\n- Timo Stienstra introduced a `Force` and `Torque` class, refer to\n  [#24258](https://github.com/sympy/sympy/issues/24240) and\n  [#24641](https://github.com/sympy/sympy/pull/24641).\n- Sam Brockie implemented an abstract base class to define actuators and\n  implemented several types of actuators, like a `LinearSpring` and\n  `LinearDamper`, refer to [#25518](https://github.com/sympy/sympy/pull/25518).\n- Sam Brockie implemented base classes for Musculotendon force generators,\n  refer to the [musculotendon\n  API](https://docs.sympy.org/dev/modules/physics/biomechanics/api/musculotendon.html)\n- Hwayeon Kang implemented [CoulombKineticFriction](https://docs.sympy.org/dev/modules/physics/mechanics/api/actuator.html#sympy.physics.mechanics.actuator.CoulombKineticFriction) and\n  [DuffingSpring](https://docs.sympy.org/dev/modules/physics/mechanics/api/actuator.html#sympy.physics.mechanics.actuator.DuffingSpring) classes, refer to [#26438](https://github.com/sympy/sympy/pull/26438) and [#26412](https://github.com/sympy/sympy/pull/26412).\n- Initial idea for the Hill muscle model is introduced in [#26443](https://github.com/sympy/sympy/pull/26443) -- it will be helpful to refer to the `DeGroote2016` classes in `sympy.physics.biomechanics.activation` together.\n\nSome load types that could be worked on are:\n- Contact force models\n- Aerodynamic forces\n- Nonlinear springs and dampers\n- Models involving biomechanics, refer to\n  [#24240](https://github.com/sympy/sympy/issues/24240) for ideas.\n\n**Involved Software**\n\nPython, Git\n\n**Difficulty**\n\nBeginner to intermediate\n\n**Prerequisite Knowledge**\n\nThis project requires basic understanding of dynamics and numerical methods.\n\n**Project Length**\n\n90, 175, or 350 hours (depends on how many features you'd like to implement)\n\n## Classical Mechanics: Constructing Systems From Bodies and Joints\n\n**Idea**\n\nWe'd like to be able to construct multibody systems by specifying descriptions\nof rigid bodies and the joints and constraints that connect them.\n\n**Status**\n\n- Sahil Shekewat worked on implementing a joint-based descriptor for systems:\n  https://github.com/sympy/sympy/pulls/sahilshekhawat\n- Sudeep Sidhu completed Sahil's work and merged a functioning joint-based\n  system that can solve open-chain problems. See his report:\n  https://github.com/sympy/sympy/wiki/GSoC-2021-Report-Sudeep-Sidhu-:-Implement-JointsMethod\n- Timo Steinstra furthered the work by enhancing the joint definition, adding\n  new joints, and developing examples of using the joints framework.\n\nThe next steps are, in order of priority:\n\n- Fix any existing bugs with the joints.\n- Add many different example problems to test the robustness of the\n  implementation.\n- Allow parsing constants as generalized coordinates to `Joint`, such as\n  `pi / 2` to the `PinJoint`, as if it is just a fixed pin.\n- Implement and test quaternion rotations.\n- Implement a `Mobilizer` joint or `CustomJoint` for describing complex motions,\n  refer to ([#23920 comment](https://github.com/sympy/sympy/pull/23920#issue-1337665929)).\n- Implement an option to choose the generalized speeds efficiently, refer to\n  [#24053 comment](https://github.com/sympy/sympy/pull/24053#issuecomment-1262468801).\n\n**Involved Software**\n\nPython, Git\n\n**Difficulty**\n\nIntermediate to Advanced\n\n**Prerequisite Knowledge**\n\nThis project requires familiarity with multibody dynamics. At the least, one\nshould know how to form the equations of motion of complex systems with one\nmethod.\n\n**Project Length**\n\n90, 175, or 350 hours\n\n## Classical Mechanics: Implement an O(N) Equations of Motion Method\n\n**Idea**\n\nRoy Featherstone, Abhi Jain, and others developed recursive methods of forming\nthe right-hand side of the differential equations for complex multibody systems\nthat have an evaluation time of O(N) instead of O(N^3). This project would be\ndedicated to implementing a symbolic O(N) method to complement the\n`LagrangesMethod` and `KanesMethod` classes. This project would involve\nimplementing 6D vectors and spatial operators, as well as the recursive\nmethods. This would give a significant speed boost in numerical evaluation for\nsystems with bodies greater than 20 or so.\n\n**Status**\n\nBrandom Milam made significant headway in this project in 2016. See:\n\n- https://github.com/sympy/sympy/wiki/GSoC-2016-Application-James-Brandon-Milam:-Base-Class-and-Increased-Efficiency-for-Equation-of-Motion-Generators\n- https://github.com/sympy/sympy/pulls/jbm950\n\n**Involved Software**\n\nPython, Git\n\n**Difficulty**\n\nExtremely Advanced\n\n**Prerequisite Knowledge**\n\nThis project requires proficiency with multibody dynamics. At the least, one\nshould know how to form the equations of motion of complex systems with one\nmethod. The ideal candidate will have experience forming the equations of\nmotion with the aforementioned Featherstone or Jain methods.\n\n**Project Length**\n\n350 hours.\n\n# Computer Science, Graphics, and Infrastructure Projects\n\n## Enhancing the flexibility of MatchPy\n\n**Idea**\n\nMatchPy, a Python library, provides associative-commutative pattern matching and replacement rules for expression trees. This functionality enhances the usability of computer algebra systems, simplifying the formulation of transformation rules for mathematical formulas.\n\nIn essence, MatchPy expressions can be likened to \"regular expressions with an awareness of commutative and associative properties”. MatchPy also supports the simultaneous execution of multiple matches, contributing to its exceptional efficiency.\n\nHowever, the current requirement for expression trees and wildcards to be subclasses of MatchPy objects presents a significant inflexibility. This constraint forces SymPy to delve into metaclass intricacies to function, limiting the ability to work with expression trees whose node type lacks identification by an object.\n\nThis proposal seeks to enhance MatchPy by restructuring its node type identification, the iteration criteria and wildcard definitions. This involves replacing type checks with custom node identification and iteration rules, fostering greater flexibility in working with various expression tree structures.\n\nSince MatchPy is currently under a separate project and has experienced a period of inactivity, forking MatchPy becomes necessary for the progress of this project.\n\nAdditionally, if time allows it, this project also envisions exploring the possibility of a Rust implementation of MatchPy, aiming to enhance its speed and efficiency.\n\n**Status**\n\nAn experimental connector to MatchPy has been successfully implemented and can be found in sympy.utilities.matchpy_connector. For a comprehensive understanding of the algorithm that drives MatchPy, refer to the paper authored by its creators, available at https://arxiv.org/abs/1710.06915.\nFurthermore, it's worth noting that MatchPyCpp, an integral submodule of SymEngine, features a translation of the main MatchPy algorithms into C++. However, its performance is presently constrained by the absence of support for coroutines.\n\n**Involved software**\n\nPython, MatchPy\n\n**Difficulty**\n\nAdvanced.\n\nThis project very likely requires the MatchPy library to be forked.\n\nThis project necessitates proficiency in executing tree-visiting algorithms.\n\n**Project Length**\n\n350 hours.\n\n\n## Code Generation\n\n**Idea**\n\nThere are quite a few potential projects for codegen.\n\nThe code generation system in SymPy has been overhauled to use AST nodes\nfrom ``sympy.codegen.ast``, there are however lot of more nodes that can be added\nfor e.g. Fortran in ``sympy.codegen.fnodes``. It could also be useful if the code\nprinters could output parallel code using OpenMP directives (e.g. parallel for loops\nfor C and Fortran, including use of reduction). Most printers do not yet support the\nnew AST nodes, it would be useful if those were extended so that they can express ASTs\ncreated e.g. by functions in ``sympy.codegen.algorithms``.\n\nAnother idea for codegen is to add more support for directly working with matrices. For instance, matrix expressions (sympy.matrices.expressions objects) should print LAPACK calls.\n\n**Status**\n\nWe have support for a number of backends and basic code gen classes in place.\nThere is work on updating the system ongoing. Please ask on the mailing list.\n\nYou can check out the work done by Ankit Pandey to extend codegen to support matrix operations at [Extending Codegen GSoC 2019](https://github.com/sympy/sympy/wiki/GSoC-2019-Report-Ankit-Pandey:-Extending-Codegen)\n\n**Involved Software**\n\nFortran, C, C++, Julia, Rust, Python, LLVM, Javascript, Octave, Matlab, etc.\n\n**Difficulty**\n\nIntermediate to Advanced\n\n**Prerequisite Knowledge**\n\n**Project Length**\n\n175 hours or 350 hours, depending on the project details (discuss with us).\n\n## Code Generation: Efficient Jacobian and Hessian Evaluation for Optimization and ODE Integration\n\n**Idea**\n\nWhen solving optimization problems with gradient based solutions, you typically\nneed to evaluate the function to optimize along with its Jacobian and/or\nHessian (or the Lagrangian of the Hessian). SciPy offers many optimization\nroutines, many which accept three functions for evaluating the function, the\nJacobian, and the Hessian. If you create a function in SymPy, then having the\nability to do something like:\n\n```python\nrosenbrock_expr = (a - x)**2 + b*(y - x**2)**2\neval_f, eval_j, eval_h = generate_minimize_derivative_funcs(expr, (x, y), extra_args=(a, b))\nresult = minimize(eval_f, x0, jac=eval_j, hess=eval_h)\n```\n\nwould make it very easy to solve optimization problems from functions defined in\nSymPy. If the expression is very large, the computational cost of evaluating\nthose three functions needs to be minimized. With careful use of lambdify,\nautorwrap, and shared common sub expressions, SymPy can generate very efficient\nversions of these functions.\n\nSimilarly, when numerically integrating ordinary differential equations, the\nJacobian of the integrand  (and its sparsity information) can be useful for the\nintegration algorithms.\n\n```python\nrhs = [\n    v(t),\n    (-sign(v(t))*B*v(t)**2 - k*x(t) - c*v(t) + A*sin(w*t))/m\n]\neval_f, eval_j, sparsity = generate_ode_derivative_funcs(rhs, (x(t), v(t)), extra_args=(A, B, m, c, k))\nresult = solve_ivp(eval_f, (0.0, 1.0), y0, jac=eval_j, jac_sparsity=sparsity)\n```\n\nOnce again, for very large expressions, generating computationally efficient\ncode becomes very important for fast integration performance.\n\n**Status**\n\nThere are existing tools where these basic ideas have been implemented outside\nof SymPy. For example:\n\n- [pyodesys](https://github.com/bjodah/pyodesys): integrates ODEs defined with\n  SymPy\n- [symopt](https://github.com/spcornelius/symopt): optimizes functions defined\n  with SymPy\n- [opty](https://github.com/csu-hmc/opty): generates a numerical function and\n  its sparse jacobian\n- [simple stackoverflow\n  question](https://stackoverflow.com/questions/34115233/python-optimization-using-sympy-lambdify-and-scipy)\n- [optimization problem that doesn't quite connect sympy to\n  scipy](https://gist.github.com/XavierMBP/5b783b4b03100483c107d7425070a15b)\n- [symjit](https://github.com/siravan/symjit) has a simple API for generated\n  numerical functions on-the-fly.\n\nRiccardo added a new Jacobian function in 2024 that efficiently computes\nJacobians of very large expressions in\n[#26773](https://github.com/sympy/sympy/pull/26773). We should be able to use\nthis, at least optionally, for computing derivatives.\n\nSee the SciPy documentation:\n\n- [SciPy Optimization](https://docs.scipy.org/doc/scipy/tutorial/optimize.html)\n- [solve_ivp](https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.solve_ivp.html)\n\n**Involved Software**\n\nNone\n\n**Difficulty**\n\nIntermediate to Advanced\n\n**Prerequisite Knowledge**\n\nKnowledge of optimization and ODE integration and their associated numerical\nmethods.\n\n**Project Length**\n\n175 or 350\n\n## Improve the Lark-based LaTeX parser\n\n**Idea**\n\nThere are a lot of issues with the old ANTLR-based parser. Motivations for why we need a new LaTeX parser\ncan be found [here](https://wermos.github.io/blog/gsoc/sympy/gsoc-2-the-sympy-boogaloo/), where it is discussed\nin great detail.\n\n**Status**\n\nThere was some work done in 2023: [Rewrite the LaTeX parser (GSoC 2023)](https://summerofcode.withgoogle.com/archive/2023/projects/apj3AeJL),\nwherein a new parser was designed and implemented from the ground up. It supports a lot of the features of the existing ANTLR-based parser,\nbut is not a full drop-in replacement yet.\n\nBut the Lark-based parser is not complete, as it is not a drop-in replacement for the ANTLR-based parser. The current state of the parser can\nbe found in [this blog post](https://wermos.github.io/blog/gsoc/sympy/gsoc-2-the-final-status-report/) that was written during the 2023 GSoC, and\nSymPy Issue [#25365](https://github.com/sympy/sympy/issues/25365).\n\n**Involved Software**\n\nPython, [Lark](https://lark-parser.readthedocs.io/en/latest/)\n\n**Difficulty**\n\nIntermediate\n\n**Prerequisite Knowledge**\n\nSome knowledge of LaTeX would be helpful\n\n**Project Length**\n\n175 hours or 350 hours, depending on the details (discuss with us).\n\n## Parsing\n\n**Idea**\n\nSymPy has the ability to generate Python, C, and Fortran code from\nSymPy expressions.\n\nIt would be very interesting to go the other way, to be able to parse Python,\nC, and Fortran code and produce SymPy expressions. This would allow SymPy to\neasily read in, alter, and write out computational code. This project would enable\nmany other projects in the future. Ideally, this project would create a general\nframework for parsers and then use this system to implement parsers for a few\nof the languages listed above. See the other parsing ideas on this page, as\nwell as [[Parsing]].\n\n**Status**\n\nSymPy currently has a parsing module that supports parsing LaTeX and\n[autolev](GSoC-2018:-Autolev-Parser-(using-ANTLRv4):-Final-Report) using\nANTLR, C, and Fortran. The parsing module also supports a Python parser,\nwith special extensions to support things like implicit multiplication (`2a` -> `2*a`)\nand implicit function application (`sin x` -> `sin(x)`), which uses the Python `tokenize` module.\n\nYou can check out the work done on the C and Fortran parsers at [Creating a C and Fortran Parser GSoC 2019](https://github.com/sympy/sympy/wiki/GSoC-2019-Report-Nikhil-Maan:-Creating-a-C-and-Fortran-parser-for-SymPy)\n\nThe existing parsers could be improved by adding support for more features of the programming languages, or new parsers could be added for other languages like Julia, Octave, MATLAB, etc.\n\n**Involved Software**\n\nFortran, C, C++, Julia, Rust, Python, LLVM, Octave, Matlab, etc.\n\n**Difficulty**\n\nIntermediate to Advanced\n\n**Prerequisite Knowledge**\n\n**Project Length**\n\n175 hours or 350 hours, depending on the project details (discuss with us).\n\n## Improve the plotting module\n\n**Idea**\n\nA new plotting module\n[sympy-plot-backends](https://github.com/Davide-sd/sympy-plot-backends) has\nbeen written, which is planned to replace the existing `sympy.plot` module\n(see https://github.com/sympy/sympy/issues/23036).\n\nThe idea is to merge this module into SymPy, also implementing substantial\nimprovements and possibly new functionalities.\n\nA very approximate guesstimate is given.\n\n  * medium/hard: Refactoring of *Series classes in order to reduce code repetition\n    and allow the implementation of new features.\n  * easy/medium: Improve numerical evaluation.\n  * medium/hard: implement custom theming for interactive applications and fix a\n    behaviour affecting the current interactive module.\n  * easy/medium: Implement new functionalities:\n      * 2D and 3D linear operators (the effect of a matrix on a plane/3D space)\n      * Phase portrait for Ordinary Differential Equations.\n      * Improve plot_parametric_region to better visualize complex maps.\n      * Animations.\n  * easy/medium: Packaging: while the main plotting functionalities work just with\n    sympy, numpy and matplotlib, the full plotting module relies on several other\n    packages. It has been observed that building a conda package with the full\n    dependencies is difficult: most of the time the build succeed but the installation\n    fails. Debug and fix it.\n  * easy/medium: Implement a intelligent routine that automatically determines\n    the regions of interest for plotting.\n  * Fix related things/bugs in SymPy\n\nMore detailed information can be found on [this page](https://github.com/Davide-sd/sympy-plot-backends/wiki/Roadmap-to-version-2).\n\n**Status**\n\nCurrently, the new plotting module lives on an external repository: [sympy-plot-backends](https://github.com/Davide-sd/sympy-plot-backends)\n\n**Involved Software**\n\nPython, HTML, Javascript, CSS\n\n**Difficulty**\n\nIntermediate to Advanced: working with several different packages can be overwhelming.\n\n**Prerequisite Knowledge**\n\n**Project Length**\n\n350 hours.\n\n## Documentation tooling\n\n**Idea**\n\nSymPy's documentation makes use of Sphinx and several Sphinx extensions. The\nidea here is to improve the tooling around the docs by developing some Sphinx\nextensions. Some ideas here\n\n- Write a Sphinx extension that improves the way autodoc cross references work (see\n  https://github.com/sympy/sympy/issues/23081)\n- Add autosummary to our docs so that each function is on a separate page.\n  This may require writing a Sphinx extension or some other tooling. See\n  https://github.com/sympy/sympy/pull/22589 for why default autosummary does\n  not work.\n- Implement linters for various parts of markup so that people can avoid\n  common mistakes. Mistakes include:\n  - Using the wrong type of markup for math, code, and cross-references (see\n    also https://github.com/sympy/sympy/issues/13519)\n  - Common mistakes in LaTeX $math$ (see for instance https://github.com/sympy/sympy/issues/17803)\n  - Various things outlined in the [documentation style\n    guide](https://docs.sympy.org/dev/guides/contributing/docstring.html)\n- Improved tooling to make sure every docstring is included in Sphinx and\n  every docstring has a doctest (see the `bin/coverage_doctest` script in the\n  SymPy repo, which needs improvement)\n- Some way to make it so that headers in docstrings can be easily linked to\n  and cross-referenced https://github.com/sympy/sympy/issues/17599\n- Allow subheaders in docstrings https://github.com/sympy/sympy/issues/17618\n- Several other small issues, mostly relating to the way autodoc generates\n  documentation. See these issues for some additional ideas\n  https://github.com/sympy/sympy/labels/GSoD.\n\n\n**NOTE: Google requires that any GSoC project be primarily coding. This\nproject is *not* primarily about writing documentation, as such a project is\nnot allowed. It is instead about developing tooling to improve the SymPy\ndocumentation system.**\n\n**Status**\n\nSome things are already implemented, for instance, we have an extension that\nlets us use dollar signs for math in RST\nhttps://github.com/sympy/sphinx-math-dollar. See the above issues for the\nstatus of any specific item.\n\n**Involved Software**\n\nThis would primarily involve working with Sphinx and building Sphinx\nextensions or modifying existing ones. If relevant, we may prefer to upstream\nchanges to Sphinx itself (although the Sphinx developers will not be mentors\non this project, so we should not rely on this happening).\n\n**Difficulty**\n\nIntermediate to advanced (working with Sphinx can often be difficult)\n\n**Prerequisite Knowledge**\n\nPrior experience with RST and using autodoc is recommended.\n\n**Project Length**\n\nA project to implement all or the majority of the above ideas would require a\n350 hours project, but a 175 hours or even 90 hours project can also be done that only\nimplements a subset of the above ideas.\n\n## Hypothesis testing\n\n**Idea**\n\n[Hypothesis](https://hypothesis.readthedocs.io/en/latest/) is a Python library\nfor property-based testing. Hypothesis tests work by specifying properties\nthat a function should satisfy, and automatically generating inputs to test\nit. There are more details of the idea of adding hypothesis to SymPy in [this\nissue](https://github.com/sympy/sympy/issues/20914).\n\nThe idea is to explore adding hypothesis testing to SymPy. We should start\nsmall, ideally with a function that is already well tested and has relatively\neasy to generate inputs. From there we can expand the testing.\n\nSome work has begun on this but hypothesis is currently only used in a couple\nof tests (search the sympy codebase for \"hypothesis\" to see where it is\ncurrently used). However, we would like for much larger fractions of the tests\nto use hypothesis.\n\nWork on this project will involve adding tests to more functions, adding more\nhypothesis strategies for different kinds of inputs, and reporting and\npotentially fixing any SymPy bugs that you find along the way.\n\nIt's expected that throughout this process you will find many bugs in SymPy.\nYou may end up spending a lot of time in this project debugging failures,\nfixing bugs, or working around bugs that are not so easily fixed.\n\n**Status**\n\nSymPy has some basic hypothesis tests, which demonstrate a proof-of-concept of using it. However, the usage could be expanded significantly, as only a handful of functions currently have hypothesis tests.\n\n**Involved Software**\n\nThe hypothesis testing library.\n\n**Difficulty**\n\nIntermediate to Advanced.\n\nHypothesis testing is simple in principle, but using it in practice can be\ndifficult because it will uncover many bugs in SymPy. It will also not be\nstraightforward to use hypothesis to test symbolic expressions (there are some\nideas on how to do this outlined in the issue).\n\n**Prerequisite Knowledge**\n\nPrior experience with using hypothesis would be a huge plus, but it is not a\nhard requirement. If you have not used hypothesis before it is recommended\nthat you play around with it and perhaps try adding some simple tests for\nsomething (in SymPy or somewhere else) to get familiar with it.\n\n**Project Length**\n\n350 hours (175 hours is possible, but the longer is preferred since there will\nbe many things to do for this project).\n\n# User Application Projects\n\n# LFortran SymPy Project Ideas\n\n[LFortran](https://gitlab.com/lfortran/lfortran) is a modern open-source (BSD licensed) interactive Fortran compiler\nbuilt on top of LLVM. It can execute user's code interactively to allow\nexploratory work (much like Python, MATLAB or Julia) as well as compile to\nbinaries with the goal to run user's code on modern architectures such as\nmulti-core CPUs and GPUs.\n\nThe basic idea of LFortran is to provide the infrastructure that can be used as a foundation to do anything related to Fortran (tools that need any of: parsing, source code generation, code transformation, machine code generation, etc.)\n\nLFortran is currently written in Python. Down the line it will get rewritten into C++ for speed and robustness, but even then it will have Python wrappers, so the Python API should not change much.\n\nThere are many potential projects regarding Fortran in general and . Please see the two ideas here first for background information:\n\nhttps://github.com/sympy/sympy/wiki/GSoC-Ideas#code-generation\nhttps://github.com/sympy/sympy/wiki/GSoC-Ideas#parsing\n\nAnd then read through LFortran's documentation, mainly the [Developer Tutorial](https://docs.lfortran.org/developer_tutorial/) to understand LFortran's AST and ASR.\n\nThis page contains a few well developed ideas.\n\n## SymPy -> Fortran Code Generation and JIT\n\n**Idea**\n\nCode generation from SymPy -> ASR, and then have two options: ASR -> AST -> source code, or ASR -> LLVM -> JIT and load it from Python to test it out.\n\nDown the road the LLVM route might even be producing better (faster) code than using SymEngine->LLVM, because one can do optimizations on the ASR itself and before it is lowered to LLVM (as part of LFortran down the road), especially if one starts using do loops and arrays, because one knows more semantic information at the Fortran level than the LLVM level. And one can at least see the high level Fortran code (for debugging), as opposed to the relatively low level LLVM IR.\n\nCurrently SymPy represents Fortran code as a SymPy AST which is a combination of `sympy.codegen.ast` and `sympy.codegen.fnodes`. The `sympy.printing.fcode` module then has a visitor pattern that transforms this `ast`/`fnodes` AST into Fortran source code.\n\nAs a first step, one would change `fcode()` to transform this SymPy AST to LFortran's ASR. That will greatly simplify the printing, as LFortran will take care of transforming ASR -> AST (adding variable definitions mostly) and AST->source code. So SymPy code will get simplified. But also this will enable to then use LFortran to just in time compile this ASR and execute it from Python, thus allowing to interactively test the generated code.\n\nOne would port all the features from `fcode()` into LFortran, where it makes sense. SymPy should only do things which are SymPy specific.\n\nAfter this is done, one can implement more features. For example it could be useful if the code\nprinters could output parallel code using OpenMP directives (e.g. parallel for loops\nfor C and Fortran, including use of reduction). Most printers do not yet support the\nnew AST nodes, it would be useful if those were extended so that they can express ASTs\ncreated e.g. by functions in `sympy.codegen.algorithms`.\n\nAnother idea for codegen is to add more support for directly working with matrices. For instance, matrix expressions (`sympy.matrices.expressions` objects) should print LAPACK calls.\n\n**Project Length**\n\n350 hours.\n\n## Parsing Fortran code to SymPy\n\n**Idea**\n\nLFortran can parse Fortran source code to AST and then convert AST to ASR.\nThis ASR will then get inspected and Fortran expressions identified and converted to SymPy expressions.\nThis would allow SymPy to easily read in, alter, and write out computational Fortran code. This project would enable\nmany other projects in the future.\n\nThis would be a general framework, some applications of this (some of which can\nbe part of this project):\n\n* load the right hand side expressions and generate manufactured solution\n* check that a special function (e.g., spherical harmonics) Fortran\n  implementation has the right expressions in it\n\nPart of this project can also be to implement a capability in LFortran\nto track the values of variables (\"x\") that go into an expression when you\nactually run the code on production data.\n\nA separate project idea is to:\n\n* optimize floating point expressions (à la https://herbie.uwplse.org/)\n* Based on the range of \"x\" (and other variables), determine which\nsymbolic simplifications make sense to make things more accurate --- and to\nprovide faster implementations of special functions, say if it is determined\nthat \"x\" in sin(x) is in the range [0, 1e-3], then there are much faster\npolynomial approximations that give the same accuracy (the same might be\npossible if the range is say [1.5, 1.7], or any other finite range).\n\nSee https://github.com/sympy/sympy/wiki/GSoC-Ideas#optimize-floating-point-expressions for the expansion of this idea, as this capability is independent of\nLFortran.\n\n**Project Length**\n\n350 hours.\n\n# Idea Prompts\n\n* Linear algebra\n  * Improve the matrices module documentation\n  * Refactor the ``MatrixBase`` class.\n  * Add more special matrices to the matrix expressions module, and migrate some special matrices from the quantum physics\n    module.\n  * Add more matrix decomposition methods: Schur Decomposition, Polar Decomposition,\n    Hermite Decomposition, ...\n  * Make the matrices use the specialized data types (Modular Integers, Gaussian Rationals, Polynomial Ring, ...) from the\n    ``polys`` module.\n\n* improve the integration algorithm\n  * integration of functions on domains of maximum extent, etc.\n  * Interesting idea: \"SYMBOLIC COMPUTATION OF INTEGRALS BY RECURRENCE\" by\n    MICHAEL P. BARNETT\n  * A Simple Method for Computing Some Pseudo-Elliptic Integrals in Terms of Elementary Functions,\n    https://arxiv.org/pdf/2004.04910.pdf\n\n* definite integration & integration on complex plane using residues.  Note\n  that we already have a strong algorithm that uses Meijer G-Functions\n  implemented.  So we need to first determine if such an algorithm would be\n  worthwhile, or if it would be better to extend the current algorithm.  Note\n  that there are many integrals that are easy to compute using residues that\n  cannot be computed by the current engine.  Other possibilities:  the ability\n  to closed path integrals in the complex plane, which is not possible with\n  the Meijer G algorithm.\n  * https://www.researchgate.net/publication/312366307_Contour_Integration_or_what_is_still_missing_in_Mathematica_Part_1_Residues_and_Contour_Integration\n  * https://www.researchgate.net/publication/312343785_Contour_Integration_or_what_is_still_missing_in_Mathematica_Part_2_Construction_of_sophisticated_Contour_Paths_Location_of_Poles_insideoutside_Closed_Contours_Special_Functions_Representations_by_Cont\n  * https://www.researchgate.net/publication/319554309_Contour_Integration_or_what_is_still_missing_in_Mathematica_Part_3_Contour_Integrals_of_Functions_with_Branch_Cuts\n  * http://www.cs.kent.edu/~pwang/Paul-phd-dissertation.pdf\n  *\n\n* Groebner bases and their applications in geometry, simplification and\n  integration\n  * improve Buchberger's algorithm and implement Faugere F4 (compare their\n    speed) _Note: This has already been implemented by a previous GSoC\n    student.  Please check with us to see the current state of Groebner bases\n    in SymPy_\n* improve polynomial algorithms (gcd, factorization) by allowing coefficients\n  in algebraic extensions of the ground domain\n* implement efficient multivariate polynomials (arithmetic, gcd,\n  factorization)\n  * Implement a sparse representation for polynomials (see the dummy files in\n    sympy/polys/ starting with \"sparse\" in the SymPy source code for a start\n    to this project).\n  * Figure out which representations to use where (sparse vs. dense).\n  * implement efficient arithmetic (e.g. using geobuckets (Yan) or heaps\n    (Monagan & Pearce))\n* improve SymPy's pattern matching abilities (efficiency and generality)\n  * implement similarity measure between expression trees\n  * expression complexity measures (e.g. Kolmogorov's complexity)\n  * implement expressions signatures and heuristic equivalence testing\n  * implement semantic matching (e.g. expression: cos(x), pattern: sin(a*x) +\n    b)\n    * e.g by using power series for this purpose (improve series speed)\n  * Expand the capabilities of Wild() and match() to support regular\n    expression-like quantifiers.\n* improve simplification and term rewriting algorithms\n  * add (improve) verbatim and semi-verbatim modes (more control on expression\n    rewriting)\n  * implement more expression rewrite functions (to an exact form that user\n    specifies).  This may involve rewriting the rewrite framework to be more\n    expressive.  For example, should cos(x).rewrite(sin) return sqrt(1 -\n    sin(x)**2) or sin(pi/2 - x)?\n  * maybe put transformation rules in an external database (e.g. prolog), what\n    about speed?\n  * improve context (e.g. input) depended simplification steps in different\n    algorithms\n      * e.g. the integrator needs different sets of rules to return \"better\"\n        output for different input\n      * but there are more: recurrences, summations, solvers, polynomials with\n        arbitrary coefficients\n  * what about information carried by expressions?\n      * what is simpler: chebyshevt(1, x) or x ?\n      * what is simpler: chebyshevt(1000, x) or (...) ?\n  * improve trigonometric simplification. See for example the paper by fu et. al.\n* implement symbolic (formal) logic and set theory\n  * implement predicate (e.g. first-order), modal, temporal, description\n    logic\n  * implement multivalued logic; fuzzy and uncertain logic and variables\n  * implement rewriting, minimization, normalization (e.g. Skolem) of\n    expressions\n  * implement set theory, cardinal numbers, relations etc.\n  * This task is heavily tied to the assumptions system.\n* implement symbolic global optimization (value, argument) with/without\n  constraints, use assumptions\n* continue work on objects with indices (tensors)\n  * include the index simplification algorithms used in\n    [xAct](http://www.xact.es/) and [cadabra](http://cadabra.phi-sci.com/).\n* generalized functions - Dirac delta, P(1/x), etc... Convolution, Fourier\n  and Laplace transforms\n  * Fourier and Laplace transforms are implemented but we can not do many\n    cases involving distributions _Is this enough alone for a project though? -Aaron_\n* vector calculus, differential fields, maybe Lie algebras & groups\n* parametric integrals asymptotic expansion (integral series)\n* Integral equations.  See for example the work started at\n  http://code.google.com/p/sympy/issues/detail?id=2344.  This could be part of\n  a project on ODEs, for example.\n* partial differential equations. Currently, SymPy can't solve any PDEs,\n  though a few tools related to separation of variables are implemented. The\n  PDE module should be structured similarly to the ODE module (see the source\n  code of sympy/solvers/ode.py).\n* improve SymPy's Common Subexpression Elimination (CSE) abilities.\n  * Poly factorization http://cseweb.ucsd.edu/~kastner/papers/tcad06-poly_factorization_cse.pdf\n* Singular analysis and test continuous.\n  * find singularities of the function and classify them.\n  * test the function whether it is continuous at some point or not. And in the interval.\n    Note: Please discuss this idea with us if you are interested, as as it currently presented,\n    it is somewhat vague.\n* Control theory. systems for Maple and Mathematica might provide insight\n  here. http://www.mcs.anl.gov/~wozniak/papers/wozniak_mmath.pdf might be useful.\n* Diophantine Equations: SymPy does have substantial support for solving\n  these, nevertheless there is more work possible to improve the solver.\n\n# Other Related Projects\n\n# Non-Ideas\n\nEvery year, people ask about implementing various things that we have already\ndecided do not belong in SymPy. Among these are:\n\n- Out-of-scope ideas. SymPy is primarily a symbolic mathematics software.\n  Ideas that are not related to **symbolic** mathematics are generally out of\n  scope (with the exception of related topics like plotting or code\n  generation, which are already mentioned here).\n- Graph theory. The [NetworkX](http://networkx.github.com/) package already\n  does a great job of graph theory in Python. If you are interested in working\n  in graph theory, you should contact them.\n- Numerical solvers. SymPy is a symbolic library, so the code should focus on\n  solving things symbolically. There are already many libraries for solving\n  problems numerically ([NumPy](http://www.numpy.org/),\n  [SciPy](http://www.scipy.org/), ...).\n\n<!--  LocalWords:  GSoC GUIs iOS Andriod sqrt sumit José Debeerst Cheb Terrab\n -->\n<!--  LocalWords:  Duarte da Mota Kolokolnikov Onur Kiymaz Seref Karr Dominik\n -->\n<!--  LocalWords:  Mirasyedioglu Gruntz Koepf Kauers Savly Shackell Arnon Xia\n -->\n<!--  LocalWords:  McCallum Maza Changbo Bican GCD Buchberger FGLM Faugere et\n -->\n<!--  LocalWords:  Fukuda al Yan's geobuckets Monagan Pearce Zippel's SPMOD\n -->\n<!--  LocalWords:  Musser's EZ EEZ Gao's Hoeij LLL Gosper Marko Petkovsek für\n -->\n<!--  LocalWords:  Wilf Doron Zeilberger Carsten Karr's Algorithmen mehrfache\n -->\n<!--  LocalWords:  Summen Torsten Sprenger Granger Schroedinger Coulombic cse\n -->\n<!--  LocalWords:  Solovay Kitaev Bosons Hartree Fock Bogoliubov KanesMethod\n -->\n<!--  LocalWords:  LagrangesMethod pyglet PyOpenGL vtk mayavi mprint mlatex\n -->\n<!--  LocalWords:  NDSovle InterpolatingFunction Mathics autowrap matplotlib\n -->\n<!--  LocalWords:  asciart js openGL textplot Buchberger's gcd Yan prolog fu\n -->\n<!--  LocalWords:  Kolmogorov's chebyshevt Skolem xAct cadabra asmeurer Vig\n -->\n<!--  LocalWords:  Krastanov certik seanv wdjoyner Mateusz Paprocki mattpap\n -->\n<!--  LocalWords:  Lukas hazelnusse moorepants Gede gilbertgede\n -->"
  },
  {
    "name": "Ruby",
    "slug": "ruby",
    "tagline": "Ruby is an object-oriented programming language",
    "description": "The Ruby organization collects mentors and students working on the Ruby language (MRI), the Ruby packaging system (Bundler, RubyGems, and RubyGems.org), and other Ruby projects. Any Ruby OSS project is eligible to be included in the Ruby GSOC organization.",
    "ideas_url": "https://github.com/rubygsoc/rubygsoc/wiki/Ideas-List-(2026)",
    "website_url": "https://www.ruby-lang.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "java",
      "ruby on rails",
      "ruby",
      "rubygems"
    ],
    "topic_tags": [
      "security",
      "web",
      "cloud",
      "server",
      "application"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/ruby",
    "ideas_content": "Welcome! This is the central hub for project ideas for the **Ruby Organization** in [Google Summer of Code (GSoC) 2026](https://opensource.googleblog.com/2025/12/shape-future-with-google-summer-of-code.html).\n\nWe are looking for mentors and sub-projects from across the Ruby ecosystem (including Rails, Hanami, SciRuby, etc.) to submit project proposals. This year, Google is placing a special emphasis on projects within the **AI, Security, and Machine Learning** domains. We highly encourage ideas that help Ruby stay at the forefront of these fields.\n\n### 📢 Call for Mentors & Projects\n\nIf you are a maintainer or a regular contributor to a Ruby-related project, we invite you to add your project ideas below.\n\n**Deadline for Idea Submission:** Please finalize your entries by **February 1, 2026**, to give us time to review before the Organization Application deadline on Feb 3.\n\n### 📝 Submission Guidelines\n\nTo ensure our application is successful, every project idea **must** follow the template below. Google requires clear outcomes and defined scopes.\n\n* **No \"Bug Trackers\":** Do not simply link to a list of issues. Each idea must be a cohesive project.\n* **Mentor Commitment:** Every project should ideally have two mentors identified to ensure redundancy.\n* **Scope:** Ensure the project size (90, 175, or 350 hours) is realistic for a summer timeframe.\n\n---\n\n### 🛠 How to add your idea\n\nFollow the format layout while [Defining a Project Idea List](https://google.github.io/gsocguides/mentor/defining-a-project-ideas-list) specified in the [Mentor guide](https://google.github.io/gsocguides/mentor/), please provide the following information for each idea:\n\nPlease copy the template below, create a new section under the appropriate category (AI/ML, Security, or General Ruby), and fill in the details.\n\n#### [Copy-Paste Template]\n\n```markdown\n### [Project Title: e.g., Enhancing Ruby-Tensorflow integration]\n* **Description**: A 2-5 sentence summary of the problem and the proposed solution.\n* **Expected Outcome**: What will the contributor have accomplished by the end of the program? (e.g., \"A new gem for X,\" \"Integration of Y into Z\").\n* **Skills Required**: List specific skills (e.g., Ruby, C, Linear Algebra, OpenSSL knowledge).\n* **Difficulty**: Easy / Medium / Hard\n* **Project Size**: Small (90h) / Medium (175h) / Large (350h)\n* **Mentors**: [Name/GitHub Handle], [Second Mentor Name/GitHub Handle]\n* **Domain**: AI / Security / Machine Learning / Core Ruby\n\n```\n\n---\n\n## 🤖 AI & Machine Learning Ideas\n\n*Focus: Libraries for LLMs, data processing, tensor manipulation, and AI-driven automation.*\n\n## 🛡 Security & Infrastructure Ideas\n\n*Focus: Cryptography, vulnerability scanning, secure Gem management, and Ruby core security improvements.*\n\n## 💎 General Ruby & Ecosystem Ideas\n\n*Focus: Performance improvements, developer tooling, and community-driven features.*\n\n---\n\n## RubyGems.org \n\n### Event Transparency Logs\n\n* **Description**: RubyGems.org currently lacks transparency into critical package registry events such as gem publications, ownership changes, and deletions, making it difficult to detect supply chain compromises or unauthorized modifications. This project proposes implementing a Merkle tree–based transparency log that records these events in an immutable, append-only structure. The log will provide cryptographically verifiable records that allow maintainers to detect unexpected changes and enable security researchers to audit the Ruby ecosystem.\n* **Expected Outcome**: A working proof-of-concept transparency log system integrated into RubyGems.org that captures and cryptographically logs critical registry events, with verification APIs and a basic interface for maintainers to monitor their packages.\n* **Skills Required**: Ruby, Ruby on Rails, Cryptography fundamentals\n* **Difficulty**: Hard\n* **Project Size**: Large (350h)\n* **Mentors**: Colby Swandale (@colby-swandale), Jenny Shen (@jenshenny), Josef Šimánek (@simi)\n* **Domain**: Security\n\n### Bundle Audit\n\n* **Description**: Ruby developers currently lack official tooling to automatically detect known vulnerabilities in their dependencies, leaving many unaware of security risks. Although the community-maintained bundler-audit tool exists, it requires separate installation and manual execution, resulting in inconsistent adoption. This project aims to integrate ruby-advisory-db directly into Bundler to provide automatic vulnerability scanning as part of the standard workflow.\n* **Expected Outcome**: Bundler ships with built-in `bundle audit` functionality that checks dependencies against ruby-advisory-db and optionally warns users during `bundle install` when vulnerable gems are detected.\n* **Skills Required**: Ruby, Bundler internals\n* **Difficulty**: Medium\n* **Project Size**: Medium (175h)\n* **Mentors**: Colby Swandale (@colby-swandale), Jenny Shen (@jenshenny), Josef Šimánek (@simi)\n* **Domain**: Security\n\n---\n\n## Rage Framework\n\n[Rage Homepage](https://rage-rb.dev) | [Rage GitHub](https://github.com/rage-rb/rage)\n\n### Observability: Metrics & Context Propagation\n* **Description**: To run Rage in production at scale, it needs robust observability. This project addresses two critical gaps in running Rage at scale: Context Propagation and Runtime Metrics. This project aims to close these gaps, making Rage fully observable out of the box.\n  * **Context Loss:** Many Rage applications use `ActiveSupport::CurrentAttributes` to track global request data (e.g., `Current.user`). However, because Rage's background tasks are executed in separate fibers, this context is lost when execution moves to the background. This project involves introducing Active Support integration to ensure Current attributes automatically travel with a task when it is enqueued.\n  * **Missing Metrics:** Users cannot see how hard the engine is working. Critical indicators like \"Event Loop Lag\" or \"Socket Backlog\" are currently invisible.\n* **Expected Outcome**: An updated `Rage::Telemetry` interface that allows developers to export low-level reactor metrics (loop lag, queue depth) to OpenTelemetry, and a context-propagation patch ensuring `ActiveSupport::CurrentAttributes` persist across background task boundaries.\n* **Skills Required**:\n  * **Ruby Internals:** Understanding Active Support internals and Fiber storage.\n  * **Systems Programming:** Understanding event loops and sockets.\n  * **OpenTelemetry:** Understanding tracing and metrics.\n* **Difficulty**: Medium\n* **Project Size**: Medium (175h)\n* **Mentors**: @cuneyter @daz-codes \n* **Domain**: Core Ruby\n\n### HTTP Streaming\n* **Description**: Modern applications (like ChatGPT) rely heavily on HTTP Streaming to deliver content incrementally. Rage is built on fibers, making it a perfect candidate for handling long-running requests. Currently, Rage buffers responses, which prevents this behavior. This project aims to unlock real-time capabilities in Rage by implementing support for Chunked Transfer Encoding and, potentially, Server-Sent Events (SSE). Crucially, the API must be designed to be protocol agnostic: while the underlying transport will initially be HTTP/1.1, the interface must be abstract enough to support HTTP/2 streams in the future.\n* **Expected Outcome**: Core support for Chunked Transfer Encoding within the Rage engine, and a developer-friendly public API for streaming data (including a helper for Server-Sent Events) that abstracts away the underlying transport protocol.\n* **Skills Required**:\n  * **Networking:** Understanding HTTP/1.1 and HTTP/2 protocols, buffering, and sockets.\n  * **Rack:** Understanding the Rack interface and body proxies.\n* **Difficulty**: Hard\n* **Project Size**: Medium (175h)\n* **Mentors**: @tonekk @rsamoilov\n* **Domain**: Core Ruby\n\n### SQL Adapter for Background Tasks\n* **Description**: Rage's background system ([Rage::Deferred](https://rage-rb.dev/docs/deferred)) currently relies on a disk-based Write-Ahead Log (WAL) for durability. While it introduces no dependencies and requires no setup, this approach is problematic for modern cloud deployments (like Heroku, K8S, or serverless containers), where disk storage is ephemeral. If a container restarts or is redeployed, the local file is wiped, and pending background tasks are lost. To make Rage cloud-native, we need to allow users to store pending tasks in a database (PostgreSQL/MySQL) instead of a local file.\n  * **Important Note:** This project is not about creating a distributed queue like Sidekiq. The execution model of `Rage::Deferred` will remain local (tasks are processed by the same process that enqueued them). The goal of the project is purely data durability in stateless environments.\n* **Expected Outcome**: A production-ready database adapter that persists background tasks to a SQL database to ensure durability in containerized environments.\n* **Skills Required**:\n  * **Software Architecture:** Designing clean interfaces.\n  * **Cloud Concepts:** Understanding ephemeral storage vs. persistent storage.\n  * **Relational Databases:** Integrating with SQL databases.\n* **Difficulty**: Hard\n* **Project Size**: Medium (175h)\n* **Mentors**: @cuneyter @rsamoilov\n* **Domain**: Core Ruby\n\n### Extension System (Railtie Equivalent)\n* **Description**: As Rage grows, external libraries need a standard way to hook into the framework's lifecycle. Currently, integrating third-party gems requires manual setup. In Rails, this is solved by \"Railties\" - a system that allows gems to automatically configure themselves, add initializers, or extend core classes when the application boots. We need a similar extension architecture for Rage. This will allow the Ruby ecosystem to build drop-in integrations for Rage (e.g., `rage-sentry`, `rage-devise`, etc.).\n* **Expected Outcome**: A defined `Rage::Extension` (or similar) architecture allowing external gems to hook into the application boot process and configuration, validated by creating a proof-of-concept integration for a standard library (e.g., Sentry or Honeybadger).\n* **Skills Required**:\n  * **Ruby Metaprogramming:** Understanding how gems are loaded and how to modify classes at runtime.\n  * **Framework Architecture:** Understanding boot sequences and dependency injection.\n* **Difficulty**: Medium\n* **Project Size**: Medium (175h)\n* **Mentors**: @daz-codes @cuneyter\n* **Domain**: Core Ruby\n\n### Blueprinter Integration for OpenAPI\n* **Description**: [Rage::OpenAPI](https://rage-rb.dev/docs/openapi) is a tool that automatically generates OpenAPI documentation by statically analyzing your code. Currently, it supports the `Alba` serializer for defining response structures. [Blueprinter](https://github.com/procore-oss/blueprinter) is another highly popular serializer in the Ruby ecosystem. Because Rage generates docs via static analysis, this project involves parsing Blueprinter classes to extract their schema without loading the entire application environment.\n* **Expected Outcome**: A static analysis extension for `Rage::OpenAPI` capable of parsing `Blueprinter` serializer definitions via Prism/AST and converting them into accurate OpenAPI schemas without requiring the application to run.\n* **Skills Required**:\n  * **Ruby Metaprogramming & Parsing:** Understanding Abstract Syntax Trees (AST) and Static Analysys (`Prism`) .\n  * **API Specifications:** Understanding OpenAPI specifications.\n* **Difficulty**: Hard\n* **Project Size**: Medium (175h)\n* **Mentors**: @tonekk @daz-codes\n* **Domain**: Core Ruby\n\n---\n\n## LowType\n\nLowType provides optional inline type annotations and type checking in Ruby, all without a build step. Simply include LowType in a class and types are checked per environment, or ignored and just treated as type annotations, depending on user configuration.\n\n[LowType GitHub](https://github.com/low-rb/low_type)\n\n### 1. Support boolean and enum types\n\n* **Description**: LowType supports Ruby's standard types (String, Array, Integer, etc.) as well as \"complex types\" that are defined by LowType itself (Tuple, Status, Headers) which allow more complex behaviour from a type. For example `Status` type is a subclass of `Integer` and will check that the number provided is a valid HTTP Status Code. Complex types are defined in `lib/types/complex_types.rb` and can be added to using the existing types as a guide.\n\n* **Expected Outcome**:\nA boolean type in a method definition will look like:\n```ruby\ndef my_method(my_var: Boolean | false)\n```\nWhere `Boolean` is the type and `false` is the default value if the arg is not supplied.\n\nAn enum type in a method defintion will look like:\n```ruby\ndef my_method(my_var: Enum[\"red\", \"orange\", \"yellow\"] | \"blue\")\n```\nWhere `\"blue\"` is the default value and `\"red\", \"orange\", \"yellow\"` are the allowed values for the enum.\n\nAn enum type in a `type()` method will look like:\n```ruby\ncolor = type Enum[\"red\", \"orange\", \"yellow\"] | arg\n```\nWhere `arg` is the name of the variable representing the value or argument that we are validating and `\"red\", \"orange\", \"yellow\"` are the allowed values for the enum.\n\n* **Skills Required**: Ruby, understanding of [Type Expressions](https://github.com/low-rb/low_type?tab=readme-ov-file#lowtype)\n* **Difficulty**: Easy\n* **Project Size**: Small (90h)\n* **Mentors**: @maedi\n* **Domain**: Core Ruby\n\n### 2. Evaluate constants in their original binding\n\n* **Description**: Currently types are evaluated in the binding of LowType, which uses refinements (avoids monkey patching) to implement Array/Hash types with a collection style Array[T]/Hash[T] syntax. We need to evaluate user supplied types like `CustomClass` in the binding of the class from where the type was originally defined. This can be done by getting the constant's full namespace via `FileParser` and evaluating that (`::CustomModule::CustomClass`) or evaluating the type in its original binding/context:\n\n> \"Ruby constants can be evaluated in another namespace by utilizing module_eval or const_get on the target module, or by passing a binding to eval. To access TargetModule::CONST from a different scope, use TargetModule.const_get(:CONST) or TargetModule::CONST\"\n\nSee [Scope](https://github.com/low-rb/low_type?tab=readme-ov-file#scope) and research \"ruby refinements\" and \"ruby execution context\" for more information.\n\n* **Expected Outcome**: Use `const_get` and `class_eval` to evaluate user-defined constants in their original binding.\n* **Skills Required**: Ruby, Ruby modules/namespaces, Ruby bindings (execution context)\n* **Difficulty**: Medium\n* **Project Size**: Small (90h)\n* **Mentors**: @maedi\n* **Domain**: Core Ruby\n\n### 3. Re-evaluate typed arguments without types\n\n* **Description**:  When `config.type_checking` is disabled we currently prepend a \"shim\" method that ignores validating the types in the user's code. So when calling a previously typed method there is always a guard method to go through. This impacts performance by adding additional method calls in the prepended \"shim\" method. Instead let's rewrite the method to contain no types at all.\n\nBenefits:\n- Improve performance (no \"shim\" method)\n- Simplify debugging (one less step)\n- Shorten stack traces (one less line)\n\n* **Expected Outcome**: Rewrite the method's params to be \"untyped\". We would likely use eval() to do this, which allows us override the method in memory on class load. We can also mirror the line numbers of the original method by suppling them to eval(). Use `low_methods` available on the class to find metadata on the method params and their types, and/or use `FileParser` to access the original method definition as a string and rewrite this string to be without types.\n\n* **Skills Required**: Ruby, Ruby's PRISM, Ruby's eval()\n* **Difficulty**: Medium\n* **Project Size**: Medium (175h)\n* **Mentors**: @maedi\n* **Domain**: Core Ruby\n\n### 4. Integrate LowType with RBS\n\n* **Description**: Ruby Signature files are the standard Ruby way to define the types of your class, via a corresponding file that just contains type definitions. These files are traditionally generated manually or inferred via certain tools to varying degrees of accuracy. Exporting LowType's inline type annotations to RBS sig files will allow LowType to be integrated into the core Ruby ecosystem and be integrated with other type checking tools such as Steep.\n\nWhat makes this project hard is the familiarity needed with RBS, and the skillset needed to generate sig files using PRISM, from the metadata supplied by LowType.\n\n* **Expected Outcome**: A very simple command line tool (CLI) that when called generates the mirrored sig versions of our typed files when run. Ruby Gems provide a way to easily install a CLI command for your gem when the gem is installed. Call this command `lowtype`.\n* **Skills Required**: Ruby, RBS, PRISM, CLI\n* **Difficulty**: Hard\n* **Project Size**: Large (350h)\n* **Mentors**: @maedi\n* **Domain**: Core Ruby\n\n---\n\n### 💡 Pro-Tip for Mentors:\n\nWhen drafting your ideas, think about the \"First 5 Minutes\" for a contributor. Providing a small \"warm-up\" task or a link to relevant documentation in your description helps attract the best candidates early on!\n\nFor any questions, please reach out via our [Discord Channel](https://discord.gg/W2YeZ3sE) or DM [zoras](https://www.linkedin.com/in/zoras/)."
  },
  {
    "name": "MariaDB",
    "slug": "mariadb",
    "tagline": "The fastest growing Open Source Database",
    "description": "MariaDB Foundation is the non-profit organization behind MariaDB Server, the fastest growing open source databases. MariaDB Foundation's mission is to ensure the continuity of the MariaDB Server code as well as foster and facilitated collaboration within the MariaDB ecosystem. As part of GSoC, MariaDB Foundation seeks to bring more developers into the MariaDB Server (and related projects) code base.",
    "ideas_url": "https://mariadb.com/docs/general-resources/community/contributing-participating/google-summers-of-code/google-summer-of-code-2026",
    "website_url": "https://mariadb.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "c/c++",
      "perl",
      "databases"
    ],
    "topic_tags": [
      "Database Engines",
      "SQL Features"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/mariadb",
    "ideas_content": "# Google Summer of Code 2026\n\nIn 2026, we are again participating in the [Google Summer of Code](https://summerofcode.withgoogle.com/). We, joined with the [MariaDB Foundation](https://www.mariadb.org), believe we are making a better database that remains application-compatible with MySQL. We also work on making LGPL connectors (currently [C](https://mariadb.com/docs/connectors/mariadb-connector-c), [C++](https://mariadb.com/docs/connectors/mariadb-connector-cpp), [ODBC](https://mariadb.com/docs/connectors/mariadb-connector-odbc), [Java](https://mariadb.com/docs/connectors/mariadb-connector-j), [Node.js](https://mariadb.com/docs/connectors/mariadb-connector-nodejs)) and on [MariaDB Galera Cluster](https://mariadb.com/docs/galera-cluster/), which allows you to scale your reads & writes. And we have [MariaDB ColumnStore](https://mariadb.com/docs/analytics/mariadb-columnstore), which is a columnar storage engine, designed to process petabytes of data with real-time response to analytical queries.\n\n## Where to Start\n\nPlease join us on [Zulip](https://mariadb.zulipchat.com/#narrow/channel/118760-New-Members/topic/GSoC.202026.3A.20welcome.20here!/) to mingle with the community. You should also subscribe to the [developers mailing list](https://lists.mariadb.org/postorius/lists/developers.lists.mariadb.org) (this is the main list where we discuss development - there are also [other mailing lists](https://mariadb.com/docs/general-resources/community/joining-the-community#mailing-lists)).\n\nTo improve your chances of being accepted, it is a good idea to submit a pull request with a bug fix to the server.\n\nAlso see the [List of beginner friendly issues](https://jira.mariadb.org/issues/?jql=status%20%3D%20Confirmed%20AND%20labels%20%3D%20beginner-friendly%20ORDER%20BY%20updated%20DESC) from the MariaDB Issue Tracker.\n\n## List of Tasks (work in progress, check again tomorrow)\n\n### MariaDB Server\n\n[MDEV-28395](https://jira.mariadb.org/browse/MDEV-28395) LOAD DATA plugins\n\n[MDEV-28395](https://jira.mariadb.org/browse/MDEV-28395)LOAD DATA plugins\n\n**Full-time project 350h**\n\n`LOAD DATA INFILE`\n\ncan flexibly load data into a table from CSV-like files accessible by the mariadbdb process. `LOAD XML INFILE`\n\ncan do it for XML files. `LOAD DATA LOCAL INFILE`\n\nand `LOAD XML LOCAL INFILE`\n\ncan do it with files accessible by the client, but not by the server. But there are requests to support loading more file formats and from other locations, for example, from S3.\n\nThis project is to implement support for LOAD plugins and refactor the current LOAD code accordingly. There are two kind of plugins — data parser plugin (CSV-like and XML) and transfer plugin (file and LOCAL). Implementing new plugins is not in the scope of this task, this task is mainly about moving existing code around, creating a *possibility* for new plugins (like JSON or S3).\n\n**Skills needed:** C++, bison\n**Mentors:** Sergei Golubchik\n\n[MDEV-7924](https://jira.mariadb.org/browse/MDEV-7924) START SLAVE UNTIL to Support Timestamps\n\n[MDEV-7924](https://jira.mariadb.org/browse/MDEV-7924)START SLAVE UNTIL to Support Timestamps\n\n**Part-time project 175h**\n\nUsers can control a point at which a replica will automatically stop applying events from the primary via [START REPLICA UNTIL](https://mariadb.com/docs/server/reference/sql-statements/administrative-sql-statements/replication-statements/start-replica#start-replica-until). Currently, this only allows [GTIDs](https://mariadb.com/docs/server/ha-and-performance/standard-replication/gtid) and log-offsets (file-name, binlog offset), which usually requires users to manually examine the binary log on the master to find the exact transaction one wants to stop at. Often, users won't care about the specifics on the exact transaction to stop at, but rather the goal is to create a known/consistent state, e.g. across multiple different slaves (possibly of different masters). That is, it currently requires users to use [mariadb-binlog](https://mariadb.com/docs/server/clients-and-utilities/logging-tools/mariadb-binlog/using-mariadb-binlog) to manually analyze the binary log files in the master server's binlog directory, find the transaction identifier (GTID or log-offset) of some transaction at the timestamp they want to stop the slaves at, and input that into their `STOP SLAVE UNTIL`\n\nstatement. With multiple masters, this process would need to be repeated for each master.\n\nThis project is to implement support for timestamps in `START SLAVE UNTIL`\n\n, to simplify the aforementioned process. To define inclusive/exclusive behaviors, it would be good to be consistent with the existing GTID-based keywords `SQL_BEFORE_GTIDS`\n\nand `SQL_AFTER_GTIDS`\n\n, i.e. to define `SQL_BEFORE_TIMESTAMP`\n\nand `SQL_AFTER_TIMESTAMP`\n\n, respectively.\n\n**Skills needed:** C++, Lex/Yacc\n**Mentors:** Brandon Nesterenko\n\n[MDEV-38721](https://jira.mariadb.org/browse/MDEV-38721) one-pass HNSW search\n\n[MDEV-38721](https://jira.mariadb.org/browse/MDEV-38721)one-pass HNSW search\n\n**Full-time project 350h**\n\nThe idea here is to treat HNSW graph as a flat one-level non-hierarchical graph and search on all layers at once. Without actual flattening, so let's call it VF-HNSW, Virtually Flattened Hierarchical Navigable Small World.\n\nThis project is to implement this algorithm and benchmark it using ann-benchmarks.\n\n**Skills needed:** C++, Python\n**Mentors:** Sergei Golubchik\n\n[MDEV-33411](https://jira.mariadb.org/browse/MDEV-33411) OPTIMIZE TABLE for graph indexes\n\n[MDEV-33411](https://jira.mariadb.org/browse/MDEV-33411)OPTIMIZE TABLE for graph indexes\n\n**Full-time project 350h**\n\nBulk insert into mHNSW index. There are various optimizations we can implement when all vectors are available in advance.\n\n**Skills needed:** C++\n**Mentors:** Sergei Golubchik\n\n[MDEV-31342](https://jira.mariadb.org/browse/MDEV-31342) I_S optimization: avoid temp table\n\n[MDEV-31342](https://jira.mariadb.org/browse/MDEV-31342)I_S optimization: avoid temp table\n\n**Part-time project 175h** or can be combined with MDEV-31535 for a Full-time project 350h\n\nCurrently information_schema tables work like:\n\nprepare information_schema table\n\nthis creates a temporary table\n\n\ncall the information_schema implementation code\n\nit sets values using\n\n`Field::store()`\n\nand calls`schema_table_store_record()`\n\nper row`schema_table_store_record()`\n\nuses`handler::ha_write_row()`\n\nto store the row in he temporary table\n\nwhen the temporary table is filled with data, it's used in the query.\n\n\nFor queries like `SELECT f1, f2, ... FROM INFORMATION_SCHEMA.tbl`\n\nthe above adds a lot of overhead. The server can recognize that case, not create a temporary table in the step 1. And modify `schema_table_store_record()`\n\nto send results directly to the client.\n\n**Skills needed:** C++\n**Mentors:** Oleksandr Byelkin\n\n[MDEV-31535](https://jira.mariadb.org/browse/MDEV-31535) optimize directory listing for information_schema tables based on privileges\n\n[MDEV-31535](https://jira.mariadb.org/browse/MDEV-31535)optimize directory listing for information_schema tables based on privileges\n\n**Part-time project 175h** or can be combined with MDEV-31342 for a Full-time project 350h\n\nUsually when `INFORMATION_SCHEMA.TABLES`\n\n(or any other table that is implemented via `get_all_tables()`\n\nfunction) is queried, it creates a list of all schemas first, then for every schema it creates a list of all files in that schema.\n\nIn certain cases the above is optimized:\n\nwhen a specific table is requested via\n\n`TABLE_SCHEMA=xxx AND TABLE_NAME=yyy`\n\nin the`WHERE`\n\nclase — in this case only that one table is openedwhen a specific schema is requested via\n\n`TABLE_SCHEMA=xxx`\n\n— tables for only that schema are listed, the list of all schemas is not createdwhen privileges only allow access to certain schemas — the list of all schemas is created, but tables are listed only for those schemas that pass the privilege check\n\n\nNote that in the last case the server still creates a list of all schemas. This can be expensive, if there're thousands of them and the privileges only allow access to one specific schema. It makes sense to treat this case as if the schema name was explicitly specified on the `WHERE`\n\nclause. Almost, because the user will also have access to the `INFORMATION_SCHEMA`\n\nitself, but it's already treated specially anyway.\n\nThat is:\n\nif the user does not have global grants that allow to see all schemas, then\n\nfor every schema-level (and table-level?) grant:\n\nif the schema name is not a pattern (does not contain wildcards), directly append this schema name to the list, if the schema exists\n\n\nappend \"INFORMATION_SCHEMA\"\n\n\nif the above isn't true — fallback to the directory listing.\n\n**Skills needed:** C++\n**Mentors:** Oleksandr Byelkin\n\n[MDEV-38329](https://jira.mariadb.org/browse/MDEV-38329) Named parameters in invocation of stored routines\n\n[MDEV-38329](https://jira.mariadb.org/browse/MDEV-38329)Named parameters in invocation of stored routines\n\n**Full-time project 350h**\n\nAdd support for the syntax like\n\nnot explicitly mentioned parameters get their default values.\n\n**Skills needed:** C++\n**Mentors:** Alexander Barkov\n\n[MDEV-12320](https://jira.mariadb.org/browse/MDEV-12320) configurable default authentication plugin for the server\n\n[MDEV-12320](https://jira.mariadb.org/browse/MDEV-12320)configurable default authentication plugin for the server\n\n**Full-time project 350h**\n\nconfigurable default authentication plugin for the server.\n\n\"default\" applies to the plugin name that the server uses for the first handshake packet, what plugin the server uses when no username is yet known.\n\n**Skills needed:** C, C++\n**Mentors:** Nikita Malyavin\n\n[MDEV-13594](https://jira.mariadb.org/browse/MDEV-13594) Support for JSON operators column->path and column->>path\n\n[MDEV-13594](https://jira.mariadb.org/browse/MDEV-13594)Support for JSON operators column->path and column->>path\n\n**Part-time project 175h** or can be combined with MDEV-38591 for a Full-time project 350h\n\nImplement this syntax sugar in MariaDB for MySQL compatibility\n\n**Skills needed:** C++\n**Mentors:** Rucha Deodhar\n\n[MDEV-38591](https://jira.mariadb.org/browse/MDEV-38591) MEMBER OF json operator\n\n[MDEV-38591](https://jira.mariadb.org/browse/MDEV-38591)MEMBER OF json operator\n\n**Part-time project 175h** or can be combined with MDEV-13594 for a Full-time project 350h\n\nImplement {{MEMBER OF}} operator for MySQL compatibility.\n\n**Skills needed:** C++\n**Mentors:** Rucha Deodhar\n\n[MDEV-37591](https://jira.mariadb.org/browse/MDEV-37591) Binlog Table Map Event to be a Sequential Index\n\n[MDEV-37591](https://jira.mariadb.org/browse/MDEV-37591)Binlog Table Map Event to be a Sequential Index\n\n**Part-time project 175h**\n\nThe mapping defined by a binary log `Table_map_log_event`\n\ncan be revamped to improve slave efficiency. Currently, when a transaction is binlogged using `binlog_format=ROW`\n\n, a `Table_map`\n\nevent is written in the binary log to declare a table that the transaction is updating, and includes information to identify this table on the slave. In particular, this information includes an identification number (`table_id`\n\n) that is used by a `Rows log event`\n\nin this transactions, which specifies that the given row event is targeting that given table. This `table_id`\n\nis only applicable for the server which actually logged the event, and is meaningless to the slave for execution, outside of its use to identify the table to target. However, when the slave uses this `table_id`\n\nto identify a table, it does so by searching/iterating through a list of all tables targeted by the transaction.\n\nThis search for a table can be optimized by changing the assignment strategy of the `table_id`\n\nto effectively work as an index into the list of tables targeted by the transaction. That is, instead of using the actual `table_id`\n\nof the given table on the master server, the value can be filled in using some 0-indexed counter. Then when the slave needs to find the table that a given row event is targeting, it would use this index to simply access the table directly (rather than iteratively search).\n\n**Skills needed:** C++\n**Mentors:** Brandon Nesterenko\n\n## Suggest a Task\n\nDo you have an idea of your own, not listed above? Do let us know in the comments below (Click 'Login' on the top of the page first)!\n\n*This page is licensed: CC BY-SA / Gnu FDL*\n\nLast updated\n\nWas this helpful?"
  },
  {
    "name": "The Rust Foundation",
    "slug": "the-rust-foundation",
    "tagline": "A language empowering everyone",
    "description": "The Rust Project is a group of developers and maintainers who build and support the Rust programming language. Organised into teams, they develop new features and mantain the Rust language, its compiler and standard library, and also all kinds of infrastructure that supports Rust. This application is being made by the Rust Foundation, the legal entity for the Rust Programming language, working in close association with representatives from the Rust Project.",
    "ideas_url": "https://github.com/rust-lang/google-summer-of-code",
    "website_url": "https://www.rust-lang.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "rust"
    ],
    "topic_tags": [
      "compilers",
      "programming languages"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/the-rust-foundation",
    "ideas_content": "This page contains a list of ideas for various projects that could help improve the Rust Project and potentially also the wider Rust community.\n\nThese project ideas can be used as inspiration for various OSS contribution programs,\nsuch as [Google Summer of Code](https://summerofcode.withgoogle.com/) or [OSPP](https://summer-ospp.ac.cn/).\n\nIn the list below, you can find projects from past GSoC runs:\n\n**This README contains ideas that are actual for Google Summer of Code 2026.**\n\nWe invite contributors that would like to participate in projects such as GSoC or that would just want to find a Rust project that they would like to work on to examine the project list and use it as an inspiration. Another source of inspiration can be the [Rust Project Goals](https://rust-lang.github.io/rust-project-goals/index.html), particularly the orphaned goals. However, you can also work on these projects outside GSoC or other similar projects! We welcome all contributions.\n\nIf you would like to participate in GSoC, please read [this](https://github.com/rust-lang/google-summer-of-code/blob/main/gsoc/README.md), **in particular the guidance around AI usage!**\nIf you would like to discuss project ideas or anything related to them, you can do so on our [Zulip](https://rust-lang.zulipchat.com/#narrow/channel/421156-gsoc).\n\nWe use the GSoC project size parameters for estimating the expected time complexity of the project ideas. The individual project sizes have the following expected amounts of hours:\n\n- Small: 90 hours\n- Medium: 175 hours\n- Large: 350 hours\n\n**Rust Compiler****Infrastructure****Cargo****Rustup****Crate ecosystem****Rust Analyzer****Rust Embedded**\n\nThe list of ideas is divided into several categories.\n\n**Description**\n\nThe Rust compiler debuginfo test suite should test how Rust programs interact with debuggers, such as GDB, LLDB and CDB. However, it is currently not fully exercised on CI, because it suffers from several issues:\n\n- It is not easily possible to bless the expected output, which makes it quite difficult to maintain the test suite.\n- It uses whatever version of a debugger is discovered (through inconsistent and varying means) on the system where the tests run.\n- It does not allow specifying different expected outputs per different debugger versions.\n- It is difficult (in part) to comprehend test failure, in part because debugger output is captured then fed to LLVM FileCheck, and the FileCheck failures in turn are hard to figure out what's wrong.\n- There is a significant lack of docs surrounding the design intention and actual usage of the debuginfo test infra.\n\nWe would like to rewrite the test suite to make it more maintainable and thus increase our confidence in the Rust compiler debugger visualizers, and maintain the quality of debuginfo emitted (and detect if there are regressions).\n\n**Expected result**\n\nThe Rust compiler debuginfo test suite is running fully on CI and is easier to maintain and bless.\n\nA stretch goal is to also use the new debuginfo test suite to improve Rust debugger visualizers.\n\n**Desirable skills**\n\nIntermediate knowledge of Rust. Knowledge of debuggers and their APIs is a big plus.\n\n**Project size**\n\nMedium to large.\n\n**Difficulty**\n\nHard.\n\n**Mentors**\n\n**Zulip streams**\n\n**Related links**\n\n[TPDE](https://docs.tpde.org/index.html) is a compiler framework that can act as a LLVM backend with very high build performance. Since slow build times are a constant issue for Rust developers, we would like to experiment with a TPDE-based backend for `rustc`\n\n, to see how much faster could compilation times get.\n\nThere are essentially two approaches that could be chosen here. Either use the [TPDE-LLVM](https://docs.tpde.org/tpde-llvm-main.html) LLVM backend to generate assembly from LLVM IR emitted by `rustc`\n\n, or create a completely separate `rustc`\n\nbackend that will work on TPDE IR (intermediate representation) directly and avoid going through LLVM.\n\nThe TPDE-LLVM-based approach is preferred since it should achieve most of the performance benefits, allows reusing LLVM plugins and infrastructure where desired, and is more likely to succeed. However, we will consider both approaches if the applicant can make good arguments in favor of a completely separate TPDE backend.\n\nNote that this would be experimental work that would most likely have to live out-of-tree, at least at the beginning of the project.\n\n**Expected result**\n\nWe have a new `rustc`\n\nexperimental backend that can be used to compile non-trivial Rust programs (it does not have to be complete though, e.g. inline assembly support will probably not make the cut), and we can evaluate its performance e.g. on the Rust Compiler Benchmark Suite.\n\n**Desirable skills**\n\nKnowledge of Rust, basic familiarity with compiler functionality or LLVM is a bonus.\n\n**Project size**\n\nLarge.\n\n**Difficulty**\n\nMedium to hard.\n\n**Mentor**\n\n**Zulip streams**\n\n**Description**\n\nRecent OSS attacks such as the [XZ backdoor](https://en.wikipedia.org/wiki/XZ_Utils_backdoor)\nhave shown the importance of having reproducible builds.\n\nCurrently, the Rust toolchain distributed to Rust developers is not very reproducible.\nOur source code archives should be reproducible as of [this pull request](https://github.com/rust-lang/rust/pull/123246),\nhowever making the actual binary artifacts reproducible is a much more difficult effort.\n\nThe goal of this project is to investigate what exactly makes Rust builds not reproducible, and try to resolve as many such issues as possible.\n\nWhile the main motivation is to make the Rust toolchain (compiler, standard library, etc.) releases reproducible, any improvements on this front should benefit the reproducibility of all Rust programs.\n\nSee [Tracking Issue for Reproducible Build bugs and challenges](https://github.com/rust-lang/rust/issues/129080)\nfor a non-exhaustive list of reproducibility challenges.\n\n**Expected result**\n\nRust builds are more reproducible, ideally the Rust toolchain can be compiled in a reproducible manner.\n\n**Desirable skills**\n\nKnowledge of Rust and ideally also build systems.\n\n**Project size**\n\nMedium.\n\n**Difficulty**\n\nHard.\n\n**Mentor**\n\n**Zulip streams**\n\n**Related links**\n\n**Description**\n\n[ rustc_codegen_gcc](https://github.com/rust-lang/rustc_codegen_gcc) uses\n\n[and implements the traits in this crate in order to have a codegen that plugs in](https://rustc-dev-guide.rust-lang.org/backend/backend-agnostic.html)\n\n`rustc_codegen_ssa`\n\n`rustc`\n\nseamlessly.\nSince `rustc_codegen_ssa`\n\nwas created based on `rustc_codegen_llvm`\n\n, they are somewhat similar, which sometimes makes it awkward for the GCC codegen.\nIndeed, some hacks were needed to be able to implement the GCC codegen with this API:- Usage of unsafe\n`transmute`\n\n: for instance,[this](https://github.com/rust-lang/rustc_codegen_gcc/blob/8037b6139fea50894978509744f00484150e6816/src/context.rs#L322)or[this](https://github.com/rust-lang/rustc_codegen_gcc/blob/8037b6139fea50894978509744f00484150e6816/src/context.rs#L412). Fixing this might require separatinginto`Value`\n\n`RValue`\n\nand`LValue`\n\nor usingin place of`Function`\n\n`Value`\n\nin some places to better fit the GCC API. - Usage of mappings to workaround the API: for instance,\n[this](https://github.com/rust-lang/rustc_codegen_gcc/blob/8037b6139fea50894978509744f00484150e6816/src/context.rs#L123-L128)or[this](https://github.com/rust-lang/rustc_codegen_gcc/blob/8037b6139fea50894978509744f00484150e6816/src/context.rs#L95-L99).\n\nSome other improvement ideas include:\n\n- Separate the aggregate operations (structs, arrays): methods like\nare generic over structures and arrays because it's the same operation in LLVM, but it is different operations in GCC, so it might make sense to have multiple methods like`extract_value`\n\n`extract_field`\n\nand`extract_array_element`\n\n. - Remove duplications between\n`rustc_codegen_gcc`\n\nand`rustc_codegen_llvm`\n\nby moving more stuff into`rustc_codegen_ssa`\n\n. For instance:[some debuginfo code is exactly the same](https://github.com/rust-lang/rustc_codegen_gcc/blob/8037b6139fea50894978509744f00484150e6816/src/debuginfo.rs#L63)[ABI code](https://github.com/rust-lang/rustc_codegen_gcc/blob/8037b6139fea50894978509744f00484150e6816/src/intrinsic/mod.rs#L509-L569)[the allocator code](https://github.com/rust-lang/rustc_codegen_gcc/blob/8037b6139fea50894978509744f00484150e6816/src/allocator.rs#L16-L91)[the dummy output type for inline assembly](https://github.com/rust-lang/rustc_codegen_gcc/blob/8037b6139fea50894978509744f00484150e6816/src/asm.rs#L704-L793)- perhaps we could add a\n`set_alignment`\n\nmethod in`rustc_codegen_ssa`\n\nthat asks the backend to set the alignment and is called in`rustc_codegen_ssa`\n\nin strategic places so that we don't have to worry as much about alignment in the codegens (not sure if this is possible).\n\n\nThe goal of this project is to improve `rustc_codegen_gcc`\n\nby removing hacks, unnecessary unsafe code and/or code duplication with `rustc_codegen_llvm`\n\nby refactoring `rustc_codegen_ssa`\n\n.\nIt would be important that this refactoring does not result in a performance degradation for `rustc_codegen_llvm`\n\n.\n\n**Expected result**\n\nA `rustc_codegen_gcc`\n\nthat contains less hacks, unsafe code and/or code duplication with `rustc_codegen_llvm`\n\n.\n\n**Desirable skills**\n\nKnowledge of Rust and basic knowledge of `rustc`\n\ninternals, especially the [codegen part](https://rustc-dev-guide.rust-lang.org/backend/backend-agnostic.html).\n\n**Project size**\n\nSmall-Medium depending on the chosen scope.\n\n**Difficulty**\n\nMedium.\n\n**Mentor**\n\n**Zulip streams**\n\n**Description**\n\nThe `tests/ui/issues`\n\ndirectory of the Rust compiler test suite currently contains a large number of miscellaneous tests — approximately 615 in total. These are primarily regression tests that were added after specific issues were fixed. Over time, this directory has become a catch-all, making the test suite harder to navigate and maintain.\n\nOur goal is to keep the UI tests well organised, with each test placed in an appropriate subdirectory based on what it is actually testing. Consolidating such a large number of unrelated tests in a single directory works against this goal.\n\nThis project focuses on systematically reviewing these tests and relocating them to more suitable locations within `tests/ui`\n\n.\n\nHere is an approximate plan to tackle this:\n\n- Inspect each test in\n`tests/ui/issues`\n\n. - Identify the issue it relates to (the issue number is typically part of the file name).\n- Determine a more appropriate subdirectory within\n`tests/ui`\n\n, based on the behaviour or feature being tested. - Add explanatory comments where the purpose of the test is not immediately obvious.\n- Rename the test file to better reflect what it is testing.\n- Add a link to the original issue at the top of the test file.\n- Reformat the test where appropriate, taking care with tests that intentionally rely on unusual formatting.\n- Re-bless tests where necessary (for example, if a test was previously marked as erroneous), and remove any obsolete\n`.stderr`\n\nfiles from the original location.\n\n**Expected result**\n\nComplete removal of the `tests/ui/issues/`\n\ndirectory, with all tests relocated to appropriate subdirectories.\n\n**Desirable skills**\n\nFamiliarity with Rust and compiler tests. Ability to read and understand regression tests. Attention to detail and comfort working with large codebases.\n\n**Project size**\n\nSmall to large. (The size is scalable, depending on how many tests would be ported.)\n\n**Difficulty**\n\nMedium.\n\n**Mentors**\n\n**Zulip streams**\n\n**Related links**\n\n**Description**\n\nThe Rust compiler and its related infrastructure currently include a number of hiccups and roadblocks for Windows users specifically. This can make it more difficult for new contributors using Windows or one of the Unix-to-NT API translation layers (e.g. Cygwin, MSYS2, etc.), to get started with developing the compiler or even using Rust.\n\nIt is easy to stumble into rather weird bugs that are both difficult to debug and fix when compiling and working with Rust on Windows. For example, path normalization being done incorrectly for the host OS is a longtime pain point for Unix translation layers (e.g. MSYS2). Additionally, the \"put libs wherever you want\" strategy Windows has taken with system libraries makes it difficult to configure the build process correctly, especially where linking to external C libraries.\n\nThe standard library also has to work around some pecularities of the Windows API. For example, timing on Windows is based on 100ns increments since Jan 1st 1601, whereas most Unix platforms use milliseconds since Jan 1st 1970. In library code, this difference in API behavior is often not well documented and results in many developer surprises. For example, [Checked arithmetic for adding a Duration smaller than 100ns results in a noop](https://github.com/rust-lang/rust/issues/149995).\n\nYou can find a number of open issues related to Windows in the Rust issue tracker, by filtering for one of the many Windows target categories, for example [O-windows](https://github.com/rust-lang/rust/issues?q=is%3Aissue%20state%3Aopen%20label%3AO-windows).\n\n**Expected result**\n\nAn overall improvement to the number of issues and hiccups/roadblocks a compiler developer or Rust user is expected to face when using Rust on Windows-based platforms.\n\n**Desirable skills**\n\nFamiliarity with Rust, comfort working with large codebases and, depending on project scope, some of the following (non-exhaustive):\n\n- Familiarity with Windows NT API\n- Experience developing on Windows or a translation layer\n- A decent amount of experience within your field(s)r of choice\n\n**Project size**\n\nSmall to large. (Size is scalable, depending on the scope of the project.)\n\n**Difficulty**\n\nMedium to Hard, depending on the issues to be fixed.\n\n**Mentor**\n\n- Teapot (\n[GitHub](https://github.com/Teapot4195),[Zulip](https://rust-lang.zulipchat.com/#narrow/dm/583581-Teapot))- Teapot is happy to mentor projects fixing most compiler and ecosystem components, or any combination of them as the contributor details in their proposal.\n- If you would like to do this project, please reach out so Teapot can tell you if he can mentor the field you would like to work on!\n\n\n**Zulip streams**\n\n**Description**\n\nRust doesn't currently have a way to restrict the implementability of a trait, nor does Rust have a way to restrict the mutability of a field.\n\nThe accepted [RFC3323 - Restrictions](https://rust-lang.github.io/rfcs/3323-restrictions.html) aims to improve our story\naround those two points by bringing:\n\n`impl(..)`\n\nrestrictions:`pub impl(crate) trait Foo {}`\n\n`mut(..)`\n\nrestrictions:`pub struct Foo { pub mut(crate) foo: u8 }`\n\n\n*Previous attempts at implementing the RFC have stalled.*\n\nThe goal of this project is to implement both impl and mut restrictions in the Rust compiler, fix any resulting bugs that may be discovered in the course of the project, and add extensive tests for the feature.\n\n**Expected result**\n\nA working implementation of `impl`\n\nand `mut`\n\nrestrictions in the nightly compiler.\n\n**Desirable skills**\n\nFamiliarity with Rust. Attention to detail and comfort working with large codebases.\n\n**Project size**\n\nSmall to medium.\n\n**Difficulty**\n\nMedium.\n\n**Mentors**\n\n**Zulip streams**\n\n**Related links**\n\n**Description**\n\nThe [ std::arch](https://doc.rust-lang.org/nightly/std/arch/index.html) module in the standard library provides architecture-specific intrinsic functions, which typically directly map to a single machine instruction.\n\nCurrently, it lives in its own [repository](https://github.com/rust-lang/stdarch) outside the main [Rust compiler repository](https://github.com/rust-lang/rust) (`rustc`\n\n). The `rustc`\n\nrepository includes `stdarch`\n\nonly as a submodule, and does not execute its testsuite on the compiler's CI. This sometimes causes contributor friction, because updates to the compiler can break `stdarch`\n\n(and vice versa) and it is not possible to change both the compiler and `stdarch`\n\nat once (in the same pull request).\n\n`stdarch`\n\nhas a comprehensive test suite that tests the intrinsics on several hardware architectures and operating system platforms, and it also includes fuzz tests. It cannot be simply copied over to `rustc`\n\n, because that has its own (much more complex) set of CI workflows. The `stdarch`\n\ntestsuite thus has to be adapted to the way workflows are executed in the compiler repository.\n\nThe ultimate goal is to inline `stdarch`\n\ninto `rustc`\n\ncompletely, and archive the `stdarch`\n\nrepository. This can be incrementally achieved by the following two steps:\n\n- Investigate the CI (continuous integration) test suite of\n`stdarch`\n\n, and port as much of it into`rustc`\n\n. This will involve implementing new testing and documentation steps for working with`stdarch`\n\nin the compiler's build system,[bootstrap](https://rustc-dev-guide.rust-lang.org/building/bootstrapping/how-bootstrap-does-it.html). - Once a sufficient portion of the test suite has been ported,\n`stdarch`\n\nshould be changed from a submodule to either a git or[Josh](https://josh-project.github.io/josh)subtree, so that compiler contributors are able to make changes to`stdarch`\n\nwhen they modify the compiler. This might involve creating some automation tooling to help with performing regular synchronizations from/to`stdarch`\n\n. See[this page](https://rustc-dev-guide.rust-lang.org/external-repos.html#using-external-repositories)for more details.\n\n**Expected result**\n\nThe most important parts of the `stdarch`\n\ntest suite should be running in the CI of the Rust compiler. Ideally, `stdarch`\n\nshould be included as a git/Josh subtree instead of a submodule, or in the best possible scenario moved completely into `rust-lang/rust`\n\n.\n\n**Desirable skills**\n\nIntermediate knowledge of Rust. Experience with GitHub Actions or CI workflows is a benefit.\n\n**Project size**\n\nSmall to Medium.\n\n**Difficulty**\n\nMedium.\n\n**Mentor**\n\n**Zulip streams**\n\n**Description**\n\nCargo's progress reporting is designed for fairly broad terminal support,\nonly allowing one line of progress output.\nSmall steps have been done to take advantage of more terminal features,\nlike unicode support and hyperlinks,\nby providing configuration for these with a terminal allow list.\nSomething similar can be done to allow for experimenting with richer progress\nreporting from Cargo like what [buck2 has](https://crates.io/crates/superconsole).\n\nOne proposed idea is for Cargo to track operational spans (e.g. `Updating`\n\n, `Compiling`\n\n)\nand any non-sticky message within one of those spans is cleared upon span close.\nExamples of non-sticky messages include warnings, errors, and a summary line for the command (e.g. `Finished`\n\n).\nThis would help make Cargo less noisy which would be particularly helpful for\n[cargo script](https://doc.rust-lang.org/nightly/cargo/reference/unstable.html#script).\n\nCargo's internals are tied to the idea of one progress line and will need to be updated to allow for richer progress reporting.\n\nSee also\n\n**Expected result**\n\n- Progress style within Cargo is abstracted away\n- Sticky/non-sticky user notifications\n- New compilation progress style with configuration\n- Initial allow list for terminals to use new style\n\n**Desirable skills**\n\nIntermediate knowledge of Rust.\n\n**Project size**\n\nMedium.\n\n**Difficulty**\n\nMedium.\n\n**Mentor**\n\n**Zulip streams**\n\n**Description**\n\nCargo maintains Bash and Zsh completions, but they are duplicated and limited in features.\n\nA previous GSoC participant added unstable support for completions in Cargo itself,\nso we can have a single implementation with per-shell skins ([rust-lang/cargo#6645](https://github.com/rust-lang/cargo/issues/6645)).\n\nThere are many more arguments that need custom completers as well as polish in the completion system itself before this can be stabilized.\n\nSee\n\n**Expected result**\n\nIdeal:\n\n- A report to clap maintainers on the state of the unstable completions and why its ready for stabilization\n- A report to cargo maintainers on the state of the unstable completions and why its ready for stabilization\n\n**Desirable skills**\n\nIntermediate knowledge of Rust. Shell familiarity is a bonus.\n\n**Project size**\n\nMedium.\n\n**Difficulty**\n\nMedium.\n\n**Mentor**\n\n**Zulip streams**\n\n**Description**\n\nWhen developers need to extend how Cargo builds their package,\nthey can write a [build script](https://doc.rust-lang.org/cargo/reference/build-scripts.html).\nThis gives users quite a bit of flexibility but\n\n- Allows running arbitrary code on the users system, requiring extra auditing\n- Needs to be compiled and run before the relevant package can be built\n- They are all-or-nothing, requiring users to do extra checks to avoid running expensive logic\n- They run counter to the principles of third-party build tools that try to mimic Cargo\n\nA developer could make their build script a thin wrapper around a library\n(e.g. [shadow-rs](https://crates.io/crates/shadow-rs))\nbut a build script still exists to be audited (even if its small) and each individual wrapper build script must be compiled and linked.\nThis is still opaque to third-party build tools.\n\nLeveraging an unstable feature,\n[artifact dependencies](https://doc.rust-lang.org/nightly/cargo/reference/unstable.html#artifact-dependencies),\nwe could allow a developer to say that one or more dependencies should be run as build scripts, passing parameters to them.\n\nThis project would add unstable support for build script delegation that can then be evaluated for proposing as an RFC for approval.\n\nSee [the proposal](https://github.com/rust-lang/cargo/issues/14903#issuecomment-2523803041) for more details.\n\nNote: there was a project with a similar topic in\n\n[GSoC 2025]. But since there is a lot of work to be done, we have published this project idea again. The current idea description reflects the current state.\n\n**Expected result**\n\nMilestones\n\n- An unstable feature for passing parameters to build scripts from\n`Cargo.toml`\n\n- An unstable feature for build script delegation, passing parameters to artifact dependencies\n\nBonus: preparation work to stabilize a subset of artifact dependencies.\n\n**Project size**\n\nLarge.\n\n**Mentor**\n\n**Zulip streams**\n\n**Description**\n\n`cargo fmt`\n\nexists today but only supports formatting Rust code and not also\n\n`Cargo.toml`\n\n`.cargo/config.toml`\n\n`rustfmt.toml`\n\n`rust-toolchain.toml`\n\n`clippy.toml`\n\n\nThere is a [Style Guide entry for Cargo.toml](https://doc.rust-lang.org/nightly/style-guide/cargo.html)\nbut it doesn't reflect expectations for how people use\n\n`Cargo.toml`\n\nand needs updates.[ cargo-cargofmt](https://github.com/crate-ci/cargo-cargofmt) is a concrete way to explore Style Guide ideas for\n\n`Cargo.toml`\n\nto help with the process of updating the style guide and to jump start support for formatting `Cargo.toml`\n\nfiles in `cargo fmt`\n\n.\nSome [basic rules are implemented](https://github.com/crate-ci/cargo-cargofmt/discussions/25)but there is still\n\n[more work to be done](https://github.com/crate-ci/cargo-cargofmt/issues)for it to serve its purpose.\n\nThe goal of this project is to extend `cargo-cargofmt`\n\nwith additional formatting rules.\n\n**Expected result**\n\n`cargo-cargofmt`\n\ncontains additional formatting rules\n\n**Desirable skills**\n\nIntermediate knowledge of Rust.\n\n**Project size**\n\nMedium.\n\n**Difficulty**\n\nEasy to medium.\n\n**Mentor**\n\n**Zulip streams**\n\n**Description**\n\n[Rustup](https://github.com/rust-lang/rustup) is an indispensable part of\nRust's infrastructure, as it provides easy access to a Rust toolchain to\nmillions of Rust users.\n\nHistorically, rustup has been using `$RUSTUP_HOME`\n\n(defaulting to\n`$HOME/.rustup`\n\n) and a part of `$CARGO_HOME`\n\n(defaulting to `$HOME/.cargo`\n\n)\nenvironment variable-configurable paths as its config, state, and data\ndirectories, but there has long been a desire to move to a more fine-grained\nand standardized solution instead.\n\nIt is thus decided by both rustup and cargo teams that, in the future, rustup\nwill default to using [XDG paths](https://specifications.freedesktop.org/basedir/latest/) for its various directories, in collaboration\nwith corresponding cargo support:\n\nOn the one hand, its toolchains, `.env`\n\npresets, settings, and cache files\nshould be placed under the respective XDG paths. An example of this could be\nusing `$XDG_DATA_HOME/rustup/toolchains`\n\ninstead of the current\n`$RUSTUP_HOME/toolchains`\n\n.\n\nOn the other hand, its binary proxies (a.k.a. shims) should also be placed under a reasonable XDG path to be negotiated with the cargo team, so that it behaves as if it were cargo-installed binary.\n\nThe goal of this project is to prepare for the above changes in rustup by:\n\n-\nAnalyzing the dependents of\n\n`$RUSTUP_HOME`\n\nand`$CARGO_HOME`\n\nin rustup (and in cargo when necessary) to logically segment them into finer-grained directories. The defaults will remain unchanged for now, but the relevant code should be refactored to support more flexible directory configuration. -\nEstablishing a protocol to maintain backward compatibility with existing installations of both rustup and cargo and to properly inform users of the potential changes.\n\n\nThe above should be implemented in a way that aligns with both rustup and cargo's progress towards XDG path support, and thus frequent communication with the cargo team might be necessary in addition to that with rustup.\n\n**Expected result**\n\n-\nrustup should support fine-grained directory configurations rather than the current dual-directory approach, with relevant business logic (esp. that of\n\n[self-uninstallation](https://github.com/rust-lang/rustup/issues/285)) and docs adjusted accordingly.- This means, if the early adopters would like, they will be able to manually enforce XDG paths on rustup.\n\n-\nrustup should be able to no longer enforce\n\n`$CARGO_HOME`\n\non cargo to unblock relevant cargo changes towards the same direction.- On the other hand, rustup should try its best to respect\n`$RUSTUP_HOME`\n\nand/or`$CARGO_HOME`\n\noverrides and maintain the old behavior if present.\n\n- On the other hand, rustup should try its best to respect\n\n**Desirable skills**\n\nIntermediate knowledge of Rust.\n\n**Project size**\n\nMedium.\n\n**Difficulty**\n\nMedium.\n\n**Mentor**\n\n**Zulip streams**\n\n**Related Links**\n\n[All hands 2025 joint meeting notes on XDG support](https://blog.rust-lang.org/inside-rust/2025/10/01/this-development-cycle-in-cargo-1.90/#all-hands-xdg-paths)- Rustup issue:\n[platform-specific config directories](https://github.com/rust-lang/rustup/issues/247) - Rustup issue:\n[stop nuking](https://github.com/rust-lang/rustup/issues/285)`$CARGO_HOME`\n\non`self uninstall`\n\n- Pre-RFC:\n[Split](https://internals.rust-lang.org/t/pre-rfc-split-cargo-home/19747)`$CARGO_HOME`\n\n- Rustup issue:\n[stop setting](https://github.com/rust-lang/rustup/issues/4502)`$CARGO_HOME`\n\n\n- Rustup issue:\n[XDG paths](https://specifications.freedesktop.org/basedir/latest/)specification\n\n**Description**\n\nThe [libc](https://github.com/rust-lang/libc) crate is one of the oldest crates of the Rust ecosystem, long predating Rust 1.0. Additionally, it is one of the most widely used crates in the ecosystem (#4 most downloaded on crates.io).\nThis combinations means that the current version of the libc crate (`v0.2`\n\n) is very conservative with breaking changes has accumulated a list of things to do in a 1.0 release. Additionally, some of the infrastructure for `lib`\n\nis rather outdated.\n\nMost of the changes required for 1.0 are under the [1.0 milestone](https://github.com/rust-lang/libc/milestone/1). Some of these come from the evolution of the underlying platforms, some come from a desire to use newer language features, while others are simple mistakes that we cannot correct without breaking existing code.\n\nThe goal of this project is to prepare and release the next major version of the libc crate.\n\nNote: there was a project with a similar topic in\n\n[GSoC 2025]. But since there is a lot of work to be done, we have published this project idea again. The current idea description reflects the current state.\n\n**Expected result**\n\nThe libc crate is cleaned up and modernized, and released as version 0.3.\n\n**Desirable skills**\n\nIntermediate knowledge of Rust.\n\n**Project size**\n\nMedium.\n\n**Difficulty**\n\nMedium.\n\n**Mentor**\n\n**Zulip streams**\n\n**Description**\n\n[ cargo-semver-checks](https://github.com/obi1kenobi/cargo-semver-checks) is a linter for semantic versioning. It ensures\nthat Rust crates adhere to semantic versioning by looking for breaking changes in APIs. It's used by many of Rust's\nmost popular libraries — and even within\n\n`cargo`\n\nitself.`cargo-semver-checks`\n\ncan currently catch ~245 different kinds of breaking changes, meaning there are hundreds of kinds of breaking changes it\nstill cannot catch! Its largest capability gap is the inability to perform type-checking in lints, which is necessary\nto detect the breakage between `pub fn example(x: i64) {}`\n\nand `pub fn example(x: String) {}`\n\n, for example.\n\nThe goal of this project idea is to design and implement the systems required to support the first batch of type-checking lints.\nThis specifically lays the ground work for shipping such lints *by the hundreds* — we're not looking to handle just a few special cases.\n[ cargo-semver-checks has been adding hundreds of new lints per year](https://predr.ag/blog/cargo-semver-checks-2025-year-in-review/),\nand this will be the project that makes that possible for 2026 and beyond!\n\nThis would be a challenging \"high risk, high reward\" type of project: perfect for candidates looking to put forward\na significant amount of effort, determination, and skill toward a difficult problem with serious real world impact,\nof course with support and guidance from a mentor. With luck and (quite a lot of) hard work, the culmination of\nthe project could even be *shipping* the first set of type-checking lints in a new `cargo-semver-checks`\n\nrelease.\n\n**Expected result**\n\n`cargo-semver-checks`\n\nwill be able to catch the breakage in cases like:\n\n```\n- pub fn example(x: i64) {}\n+ pub fn example(x: String) {}\n```\n\nIt will do so by using its declarative query language to notice the API change and capture information regarding it,\nthen plugging that information into a templating system able to generate a \"witness\" crate for the API change.\n`cargo-semver-checks`\n\nwould then automatically run `cargo check`\n\non the witness crate, which will either pass\nwithout errors (indicating no breakage), or error out indicating a breaking change.\n\nA possible witness for the above example is:\n\n```\npub fn witness(x: i64) {\ncrate_being_checked::example(x);\n}\n```\n\n\nwhich will obviously only compile if the `example()`\n\nfunction takes an `i64`\n\n, not a `String`\n\n.\n\nWhile this approach may seem overly complex at first, consider the following change:\n\n```\n- pub fn example(x: i64) {}\n+ pub fn example(x: impl Into<i64>) {}\n```\n\nThis is a case where the type of `x`\n\nchanged, but passing `i64`\n\nstill works fine — so this isn't a SemVer-major change.\nTherefore, merely noticing that a type has changed is *not* sufficient to detect breakage, and we must use witness programs instead.\n(It is highly impractical to use `rustc`\n\nas a library. It's similarly infeasible to reimplement the type-checker and trait solver ourselves.)\n\n**Desirable skills**\n\nIntermediate knowledge of Rust, or better. Familiarity with databases, query engines, code generation, or query language design is welcome but not required. Willingness to dive into a complex problem space and find your way around (with guidance, of course) is a must.\n\nContributors interested in this project idea are strongly encouraged to first familiarize themselves with `cargo-semver-checks`\n\nand its linting system, which expresses lints as queries over a database-like schema ([playground](https://play.predr.ag/rustdoc)).\nThe project will require writing lints, extending the schema, writing code-generation code to create witness crates,\nconsidering ways to improve performance in order to ensure a positive user experience, and designing the entire lint-writing process\nsuch that type-checking lints are not challenging nor bespoke, but as normal and easy to write as any other lint.\n\n**Project size**\n\nLarge\n\n**Difficulty**\n\nHigh\n\n**Mentor**\n\n**Zulip streams**\n\n**Related Links**\n\n[Playground where you can try querying Rust data](https://play.predr.ag/rustdoc)[GitHub issues describing not-yet-implemented lints](https://github.com/obi1kenobi/cargo-semver-checks/issues?q=is%3Aissue+is%3Aopen+label%3AE-mentor+label%3AA-lint+)[Opportunities to add new schema, enabling new lints](https://github.com/obi1kenobi/cargo-semver-checks/issues/241)[Query engine adapter](https://github.com/obi1kenobi/trustfall-rustdoc-adapter)[Study of SemVer breakage in Rust, including more details on \"witness\" programs](https://predr.ag/blog/semver-violations-are-common-better-tooling-is-the-answer/)[cargo-semver-checks 2025 year in review, where the \"path forward\" offers more info about this project idea](https://predr.ag/blog/cargo-semver-checks-2025-year-in-review/)[Last year's GSoC project, which built the foundation for type-checking lints that we'd build upon](https://glitchlesscode.ca/posts/2025-11-05a/)\n\n**Description**\n\nThe [Wild linker](https://github.com/davidlattimore/wild) is a very fast linker written in Rust.\n\nWe'd like for it to be possible to use the Wild linker for as large a range of Rust development as possible. Besides porting to other platforms, which is probably too large a scope for a GSoC project, one gap we currently have on Linux is compiling kernel modules. Linux kernel modules can now be written in Rust, but the Wild linker, despite having some linker script support, doesn't support enough linker script features to be able to link a kernel module.\n\n**Expected result**\n\nImplement more linker-script features. Ideally enough that we can support linking of Linux kernel modules, but even if we can't get that far, getting closer would be awesome. Linker scripts are also used extensively for embedded development, which may be something we could support with Wild in the future.\n\n**Desirable skills**\n\nIntermediate knowledge of Rust and a willingness to learn more. You don't need to have existing experience with implementing linkers, but it'd be good if upon reading the docs for GNU linker scripts, they at least mostly make sense.\n\n**Project size**\n\nMedium or large depending on which linker script features are implemented.\n\n**Difficulty**\n\nDifferent linker script features are likely to range between easy and hard.\n\n**Mentor**\n\n**Zulip streams**\n\n**Related links**\n\n**Description**\n\nrust-analyzer has many assists (code actions) that operate on the syntax tree. Most of them are implemented via mutable syntax tree editing, with `rowan`\n\n, our syntax tree library. Unfortunately, the existence of mutable syntax trees prohibits a lot of optimizations in `rowan`\n\nand makes it a lot more memory-heavy and slower. Therefore we'd like to remove our usage of mutable trees.\n\nWe developed an API called `SyntaxEditor`\n\nthat should be used instead of mutable trees. Currently it is implemented with them under the hood, but it is expected to be easier to get rid of them once all mutation is encapsulated in it.\n\n**Expected result**\n\nrust-analyzer has no assists or diagnostics quickfixes that use mutable tree editing. This will likely also involve further development of the `SyntaxEditor`\n\nAPI, as per the needs.\n\n**Desirable skills**\n\nKnowledge of Rust. Knowledge of the rust-analyzer codebase is an advantage but should not be required.\n\n**Project size**\n\nLarge. However note that the size is scalable; even if the project isn't completed, every assist we migrate is a net benefit.\n\n**Difficulty**\n\nEasy.\n\n**Mentors**\n\n**Zulip streams**\n\n**Related Links**\n\n[An issue explaining why we should get rid of mutable syntax trees architecture-wise](https://github.com/rust-lang/rust-analyzer/issues/15710)[Tracking issue for this effort](https://github.com/rust-lang/rust-analyzer/issues/18285)[A prototype exploring how](https://github.com/ChayimFriedman2/rowan/tree/next-rowan)`rowan`\n\nwithout mutable trees could look like\n\n**Description**\n\nWhile it is not strictly an embedded crate, a lot of the embedded Rust ecosystem uses the [ serialport](https://crates.io/crates/serialport) crate for serial communication.\n\nWe maintain compatibility with the latest long-term support (LTS) release of Yocto for embedded Linux systems of which a new release dropped in 2025. This opens a window of opportunity to include PRs with semver breaking changes and streamline the crate's API for better ergonomics and safety.\n\nAt the same time, we can upgrade our Minimum Supported Rust Version (MSRV) (currently 1.59), which has started to cause dependency issues for crate users, as well as inhibiting use of modern features.\n\n**Expected results**\n\n-\nGetting the next major release 5.0 of serialport ready and published.\n\n-\nSuggesting and implementing serial API improvements for this release, including those that might require breaking changes.\n\n\n**Desirable skills**\n\nStrong familiarity with Rust. Some knowledge of the Rust Embedded ecosystem. At least a basic understanding of serial port operation. Interest in working across multiple (desktop) operating systems. Willingness and ability to do both maintenance and design activities.\n\nWe can ship USB serial adapters for testing, if needed.\n\n**Project size**\n\nSmall to medium. The project is scaleable in the sense that there are a lot of smaller individual tasks and progress on every single one helps.\n\n**Difficulty**\n\nEasy.\n\n**Mentors**\n\n**Matrix channel**\n\n**Related links**"
  },
  {
    "name": "Oppia Foundation",
    "slug": "oppia-foundation",
    "tagline": "Free platform for interactive, tutor-like lessons",
    "description": "The Oppia project aims to empower learners across the globe by providing access to high-quality, engaging education. We envision a world where access to high-quality education is not a privilege but a human right. \n\nThe team works on two platforms: \n\n    (a) Oppia Web, which provides an online learning tool that enables anyone to learn from effective and engaging interactive lessons (called 'explorations'), which simulate a one-on-one conversation with a tutor. This format makes it possible for students to learn by doing while getting feedback. The Oppia Web platform also provides the infrastructure needed to support lesson creation and translation.\n\n    (b) Oppia Android, which provides a way for these lessons to be played offline on an Android app that supports low-end devices and does not require Internet connectivity. \n\nAs a community, we are also aware that millions of students in underserved communities lack access to the educational resources necessary to effectively learn key skills like basic numeracy. Thus, in addition to developing the Oppia platform, the team has launched and continues to develop a set of free and effective lessons on basic mathematics, supplemented by translations and voiceovers. Students using these lessons have shown strong improvements between pre-and post-tests, and we’ve received lots of positive feedback on them. We are planning to extend this offering to other subjects, based on what students (and the nonprofits working with them) tell us would be most useful.",
    "ideas_url": "https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2026",
    "website_url": "https://www.oppia.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "google app engine",
      "angular",
      "typescript",
      "Apache Beam"
    ],
    "topic_tags": [
      "education",
      "web",
      "ai",
      "nonprofit",
      "social impact"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/oppia-foundation",
    "ideas_content": "**Important**: _We are making some changes to how we run GSoC for 2026. Please read this page carefully, since some things have changed from previous years._\n\n## Table of Contents\n\n- [Getting started](#getting-started)\n- [FAQs](#faqs)\n- [Dates and Deadlines](#dates-and-deadlines)\n- [Types of work related to Oppia projects](#types-of-work-related-to-oppia-projects)\n- [GSoC proposal template](#gsoc-proposal-template)\n  - [Tips for writing a good project plan](#tips-for-writing-a-good-project-plan)\n  - [What should applicants expect from mentors in a proposal review?](#what-should-applicants-expect-from-mentors-in-a-proposal-review)\n- [Selection Criteria](#selection-criteria)\n- [Communication](#communication)\n- [Oppia's Project Ideas List](#oppias-project-ideas-list)\n\nThis year marks the 11th year that Oppia will be participating in [Google Summer of Code (GSoC)](https://summerofcode.withgoogle.com/)! GSoC is a global program which offers post-secondary students, as well as newcomers to open source, an opportunity to discover and work with open source organizations. The contributions are supported by a stipend. Contributors work closely with one or more mentors to implement either a project idea by the organization, or a proposal of their own.\n\nIn order to receive updates about GSoC at Oppia, please subscribe to the [Oppia GSoC Announce](https://groups.google.com/g/oppia-gsoc-announce) mailing list, as well as the [Developer Announcements](https://github.com/oppia/oppia/discussions/categories/developer-announcements) category on GitHub Discussions.\n\nThis year, the same as last year, Oppia plans to follow a slightly extended GSoC timeline: projects will have 7 weeks for each milestone, with an additional \"holiday week\" between the milestones. Each milestone includes 5 weeks of coding time, 1 week for evaluations, and 1 week for fixes, as well as a product demo session after the 4th coding week. Please refer to the [Dates and Deadlines](#dates-and-deadlines) section below for more details.\n\nAlso, please note that acceptance into GSoC isn't a prerequisite for becoming an Oppia contributor. The Oppia project is run by a global community dedicated to making meaningful social change, and we warmly welcome anyone who'd like to help out! You can get started by following the instructions here ([Web](https://github.com/oppia/oppia/wiki/Contributing-code-to-Oppia#setting-things-up), [Android](https://github.com/oppia/oppia-android/wiki/Contributing-to-Oppia-android)).\n\n\n## Contributors\n\nGSoC is an excellent opportunity for new contributors to get paid to work on an open source project. If you're interested in applying as a contributor, we strongly recommend reading this entire wiki page, including our [FAQ](#faqs) which answers many of the common questions we receive.\n\nYou should also definitely read the following resources:\n  - [Google Summer of Code contributor guide](https://google.github.io/gsocguides/student/)\n  - [Google's list of resources](https://developers.google.com/open-source/gsoc/resources/)\n  - [Google's GSoC FAQ](https://developers.google.com/open-source/gsoc/faq)\n\nFurthermore, note that GSoC isn't just about code -- it's also about communication and interaction with the open source community! Hear what some of our previous contributors have to say:\n\n  - _I learnt a lot from this organisation -- tackling a huge codebase, writing clean and efficient code and communication._\n  - _I learn a lot of things in Oppia which I didn't learn in my school and college. It's not necessary that only a software engineer can contribute, anyone can contribute to Oppia with his/her skill._\n  - _I like the fact that the maintainers are so sincere in their work and are very responsive._\n  - _Oppia Foundation is really awesome and I get to interact with amazing people and learn a lot. The best part is that everything is organised really well and that makes it easy to solve my issues._\n  - _The Oppia Foundation excelled in fostering a supportive and inclusive environment for contributors. The responsiveness of the mentors and the community was remarkable, making it easy to seek guidance and get help whenever needed. The clear communication, structured processes, and well-documented codebase greatly helped my learning and development throughout GSoC._\n  - _I really enjoyed the process, and the feeling of owning a feature end-to-end is fantastic, even with the challenges. Over the past three months, I've learned a lot about feature testing, release testing, PM demos, and more._\n\nYou might also enjoy the \"weekly journals\" from some of our previous contributors: **[Rd4dev](https://medium.com/@rd4dev)** and **[@hardikgoyal2003](https://medium.com/@hardikgoyal2003)**.\n\n\n## Selected Projects\n\nCheck back later to see the projects selected for GSoC 2026.\n\n## Getting started\n\nWelcome! If you're interested in applying to work with Oppia for GSoC, please follow these steps:\n\n1. Sign up to the [oppia-gsoc-announce@](https://groups.google.com/forum/#!forum/oppia-gsoc-announce) mailing list and the [Developer Announcements](https://github.com/oppia/oppia/discussions/categories/developer-announcements) category on GitHub Discussions, so that you can receive important notifications about Oppia's participation in GSoC. Make sure to set your preferences correctly so that you actually get the emails!\n\n2. Get a better understanding of what Oppia is about:\n    - Read the [user documentation](http://oppia.github.io/#/) to become familiar with important concepts like explorations and interactions.\n    - Play some lessons on [Oppia.org](https://www.oppia.org/learn/math), which hosts a live instance of Oppia.\n\n3. To get started with development, read and follow the instructions in the contributors' guide carefully ([Oppia Web](https://github.com/oppia/oppia/wiki/Contributing-code-to-Oppia#setting-things-up), [Oppia Android](https://github.com/oppia/oppia-android/wiki/Contributing-to-Oppia-android)). If you're interested in Oppia Web, you might also find [these tutorials](https://github.com/oppia/oppia/wiki/Contributing-code-to-Oppia#developing-your-skills) helpful.\n\n4. Do a few starter projects to become familiar with the contribution process. This will help us get an idea of what it's like to work with you. It will also help you get a better understanding of the codebase and our development process, which may help with writing a good project proposal. Once you've merged at least 1-2 pull requests, you will get an invitation to become a collaborator to the Oppia repository and be officially onboarded! **This step is a prerequisite to applying for GSoC.**\n\n> [!NOTE]\n> You must be onboarded to the repository to which you will contribute during GSoC. For example, to work on an Oppia Web GSoC project, you need to be onboarded to the oppia/oppia repository, which means that your pull requests need to be to oppia/oppia.\n\n> [!TIP]\n> Quality is more important than quantity, so try to contribute to high-impact issues where possible. Also, we want to see examples of your best work, so please make sure to read the [[\"getting started\" guide|Contributing-code-to-Oppia]] and [[PR instructions|Rules-for-making-PRs]] carefully, follow the [tips for success](https://github.com/oppia/oppia/wiki/Contributing-code-to-Oppia#tips-for-success), manually test your code before submitting (to ensure it does what you want it to and doesn't break anything else), ensure that your code conforms to the [[style rules|Coding-style-guide]], and pay attention to small details. These are good skills to learn when developing software in general, and they will also help you build credibility as a responsible developer who can be trusted to be a good steward of the Oppia codebase.\n\n5. Select one or more [GSoC project ideas](#oppias-project-ideas-list) that you're most interested in, and write your project proposal! You can get feedback from project mentors when you've completed a sufficient draft -- see the instructions in the [GSoC proposal template](#gsoc-proposal-template) section for details.\n\n   We require that all general discussion about GSoC projects take place in open channels. If you have questions about a project, you can ask in [GitHub Web Discussions](https://github.com/oppia/oppia/discussions/categories/general-gsoc-2026-q-a-web) or [GitHub Android Discussions](https://github.com/oppia/oppia-android/discussions/categories/general-gsoc-q-a). Note that individual projects have their own categories, so please use those if you have project-specific questions. Please also be specific when asking questions, since this makes it easier for us to help you.\n\n> [!TIP]\n> During the application period, your first goal should be to figure out how to become an effective contributor. Start developing your project proposal only once you have experience getting some PRs merged. This will give you a much better idea of what you want to work on, and how much you can accomplish.\n>\n> You might also want to ensure that you have the required skills for your chosen project. For guidance on how to do this, see the relevant section in the [GSoC proposal template](#gsoc-proposal-template) document and our [FAQs](#faqs).\n\nGood luck!\n\n\n## FAQs\n\n**Q: What technical skills do I need to work on Oppia?**\n\nA: Please see the individual project ideas to determine which skills are recommended for the project in question. Also, in general:\n\n   - For Oppia Web, Angular 2+, Python 3.10, Google App Engine and Apache Beam are useful and recommended, and experience with GitHub Actions is useful for developer workflow projects. Also, it is important to be able to write tests for the code you submit (using Karma, Puppeteer and unittest). You might also find this [[page of learning resources|Learning-Resources]] helpful, as well as other pages on our [wiki](https://github.com/oppia/oppia/wiki) that provide guidance on Apache Beam, testing frameworks, etc.\n\n   - For Oppia Android, you will need to know how to program in Kotlin, and have experience with Android development. Knowledge of Bazel may also be helpful for some projects.\n\n   - Note that, although GSoC is aimed at both students and beginner contributors to open source, \"beginner to open source\" is **not** the same as \"beginner to coding\" -- the projects do assume that you have some proficiency with coding. The fact that GSoC projects produce high-quality code that solves real problems for open-source projects does make GSoC challenging, but this is also part of what makes GSoC such a valuable experience for our contributors.\n\n**Q: How can I increase my chances of getting selected?**\n\nA: The most important thing is to ensure that you have the required skills for the project -- see the \"Required Skills\" section of the [proposal template](#gsoc-proposal-template) for more details. Aside from that, writing a good project proposal with a solid solution approach, engaging with the community, helping other contributors, successfully contributing PRs for high-priority issues, and demonstrating that you can work independently can all help you. We've also compiled some notes below on the [selection criteria](#selection-criteria) we'll be using this year.\n\n**Q: Which projects are most important for Oppia? Can you advise which project I should pick?**\n\nA: All the projects we've listed in the [Ideas List](#oppias-project-ideas-list) are treated as equally important during selection, and we'd be very happy to see good progress made on any of them! Note that the relative importance of a project to Oppia is not part of the [selection criteria](#selection-criteria). In general, we recommend that you pick a project based on whether you already have (or will be able to learn) the skills required for it, and that you'd enjoy doing over the summer!\n\n**Q: I do not have any experience in skill XYZ. What should I do?**\n\nA: If you are missing a skill that is needed for a project, we recommend trying to learn it -- in software development, it is common to develop experience and expertise as you take up and complete projects successfully. Some ways to do this include working on issues that give you a chance to develop that skill, referring to our wiki documentation, and following tutorials from elsewhere on the Web. Please note that, in general, we are unlikely to accept applicants who lack the required skills for a project, since this tends to result in significant difficulties during the coding phase.\n\n**Q: How will you assess whether I have the required skills for a project?**\n\nWe will assess your application based on your proposal and the skills that you have demonstrated in your PRs and other interactions with the community. Please see the guidance in the \"Required Skills\" section of the [proposal template](#gsoc-proposal-template), which explains how to demonstrate that you have the required skills for a project, and provides pointers on how to develop those skills.\n\n**Q: Is it okay if I only focus on the frontend or backend?**\n\nA: This probably depends on the project(s) you wish to apply for; check their \"required skills\" sections. However, note that most projects are full-stack and require ability in both the frontend and backend. We recommend becoming familiar with both of these, since this will open up more opportunities for you, as the projects we work on at Oppia often touch multiple layers of the stack.\n\n**Q: What is the minimum number of PRs that one should have?**\n\nA: You should have at least 2 merged PRs. Beyond that, remember that quality is more important than quantity, so consider taking some high-priority or [\"impact: high\"](https://github.com/oppia/oppia/issues?q=is%3Aopen+is%3Aissue+label%3A%22Impact%3A+High%22) issues if you're able to, since those fixes are more valuable. You can find a list of high-priority issues on the respective teams' project boards: [LEAP](https://github.com/orgs/oppia/projects/3/views/8), [Dev Workflow](https://github.com/orgs/oppia/projects/8/views/11), [CORE](https://github.com/orgs/oppia/projects/18/views/4), [Android CLaM](https://github.com/orgs/oppia/projects/4/views/3), [Android Dev Workflow](https://github.com/orgs/oppia/projects/10/views/1). Additionally, you'll also want to demonstrate that you have the required skills to successfully complete your chosen project; please see the guidance in the \"Required Skills\" section of the [proposal template](#gsoc-proposal-template), which explains how to do this.\n\n**Q: Will I be penalized during selection if I ask for help while contributing?**\n\nA: Not at all! Asking for help when you need it is part of the learning process, and the Oppia open-source community is more than happy to help and onboard new members. Please just ensure that your questions are well-formed and that you (a) have read the relevant docs on the wiki, (b) provide the necessary information (such as a [debugging doc](https://github.com/oppia/oppia/wiki/Debugging-Docs)) to help responders understand what you've figured out so far and where you are stuck.\n\n**Q: I only discovered Oppia recently. Does this mean that, during selection, my application would automatically be ranked lower than those by other applicants who have a longer tenure with Oppia?**\n\nA: Definitely not! Here are the [selection criteria](#selection-criteria) we use when selecting contributors for GSoC. Note that tenure with Oppia is explicitly not part of these criteria.\n\n**Q: How early should I start working on the proposal?**\n\nA: We recommend developing your project proposal and engaging with the community via GitHub Discussions as early as possible, so that you have enough time to get feedback from mentors and improve the proposal before the submission deadline. Make sure to follow all instructions in the [proposal template](#gsoc-proposal-template) (especially around sharing and access) to reduce delays in reviewing your proposal. That said, it's important to note that the proposal is only one part of the application process, and it is probably more important to figure out how to become an effective contributor by getting some PRs merged and demonstrating that you have the required skills for the project.\n\n**Q: Can I submit more than one proposal to Oppia?**\n\nA: Yes, you can. However, we strongly recommend picking one project and writing a solid proposal for it. Splitting attention across multiple projects might not be a great idea.\n\n**Q: If I only submit a proposal, without making any code contributions, will my application be considered?**\n\nA: No. See our [selection criteria](#selection-criteria) for more details.\n\n**Q: Can I use content from the project ideas list or PRD in my proposal?**\n\nA: It is fine for proposals to draw from the GSoC idea in the wiki and any linked PRDs. However, please note that if you copy content directly from any source (even if it is an Oppia doc), **you must cite and link to the original source**. Also, remember from our [selection criteria](#selection-criteria) that when we review proposals, one of the things we look for is evidence that the applicant understands the project and existing codebase well. Strong proposals will therefore contain details that are original (e.g. that are not copied from the PRD).\n\n**Q: I'm part of team X in Oppia. Can I submit a proposal for a project idea from a different team?**\n\nA: Yes, you can; there are no issues with that. There is a space in the proposal template to list teams at Oppia you've participated in, and we will get feedback from members of those teams about what their experience of collaborating with you has been like.\n\n**Q: What is the total number of contributors that will be accepted?**\n\nA: We generally request slots for as many projects as we think will succeed. However, the Google GSoC admins may impose limits based on how they decide to distribute contributor slots among the different open-source organizations.\n\n**Q: The [Google GSoC FAQ](https://developers.google.com/open-source/gsoc/faq#can_someone_already_participating_in_open_source_be_a_gsoc_contributor) mentions that the program is only for new contributors. I have already contributed to Oppia and I have write access. Can I still participate?**\n\nA: The GSoC program is open to students, as well as beginner contributors to open source. If you do not qualify as a student, see [this FAQ](https://developers.google.com/open-source/gsoc/faq#how_do_i_know_if_i_am_considered_a_beginner_in_open_source_development) on the GSoC website for whether you would be considered a beginner.\n\n**Q: Can you be flexible around my other summer commitments?**\n\nA: Probably not. We have not had good experiences offering flexibility in previous years, so this year, Oppia will strictly adhere to the Oppia GSoC timeline. Please refer to the [Dates and Deadlines](#dates-and-deadlines) section below, and avoid taking up major commitments alongside GSoC. Experience from previous years suggests that you will be unlikely to successfully balance both.\n\n**Q: I'd love to contribute to open source, but I'm not sure I have enough time during the summer to do a GSoC project. Can I still help out?**\n\nA: Yes, GSoC is probably not the best choice if you don't have enough time during the summer, since it requires focused commitment. However, you can still start contributing to Oppia by following the instructions in the contributors' guide ([Oppia Web](https://github.com/oppia/oppia/wiki/Contributing-code-to-Oppia#setting-things-up), [Oppia Android](https://github.com/oppia/oppia-android/wiki/Contributing-to-Oppia-android)).\n\n**Q: What are Oppia's rules for contributors using artificial intelligence (AI) models?**\n\nA: You are welcome to use AI when contributing to Oppia, but you are still responsible for what you contribute. For example, we expect you to double-check any AI-generated code to make sure that it is correct, high-quality, and complies with our guidelines. If AI generates buggy code, it's your job to fix the bugs before you open a PR. Similarly, if you use AI to craft prose (e.g. comments on PR threads), we still expect you to communicate clearly, effectively, and constructively. In our experience, AI tends to generate prose that is too long and verbose, which can be frustrating for other people to read. You are also responsible for ensuring that you are legally allowed to contribute your work to Oppia (e.g. that AI hasn't copied it from a restrictively-licensed source). Finally, remember that GSoC is about learning, so make sure you don't come to rely on AI in place of developing your own skills.\n\n## Dates and Deadlines\n\nNoteworthy dates for 2026 (see also the [Official GSoC Timeline](https://developers.google.com/open-source/gsoc/timeline)):\n\n- **Jan 19 - Feb 3**: Mentoring organizations apply\n- **Feb 19**: Mentoring organizations are announced\n- **Feb 21 16:00 UTC**: GSoC Q&A session with Oppia\n  - Video call link: https://meet.google.com/ffg-vbts-rqd\n- **Mar 16 - Mar 31**: GSoC contributor application period\n- **Apr 30**: Accepted GSoC contributors are announced\n- **Apr 30 - May 24**: Community bonding (\"greenlight\") period\n  - **TBD**: Briefing for accepted GSoC contributors (mandatory)\n- **May 25 - Jul 10**: Milestone 1 work period for GSoC\n  - **Jun 26**: Milestone 1 work due for internal evaluation\n  - **Jun 27 - Jul 3**: Testing of the milestone 1 work product\n  - **Jul 4 - Jul 10**: Buffer time for Milestone 1 revisions\n  - **Jul 13 - Jul 17**: Official GSoC midpoint evaluation\n- **Jul 18 - Sep 2**: Milestone 2 work period for GSoC\n  - **Aug 19**: Milestone 2 work due for internal evaluation\n  - **Aug 20 - Aug 26**: Testing of the milestone 2 work product\n  - **Aug 27 - Sept 2**: Buffer time for Phase 2 revisions\n  - **Sept 7 - Sept 14**: Official GSoC mentor evaluation due\n- **Sep 15**: GSoC period at Oppia officially ends\n\n**Note!** For Oppia's participation in GSoC 2026, the coding period dates are strict, and we will not be offering extensions. Please ensure that you have sufficient time during the summer to work on your projects.\n\n\n\n## Types of work related to Oppia projects\n\nThe Oppia team is committed to making GSoC an enriching educational experience for contributors. In general, our goal for GSoC is for contributors to have a really meaningful experience, and to do something worthwhile over the summer that they can look back on with pride.\n\nIn order to ensure a well-rounded engineering experience, GSoC contributors will have the opportunity to do some or all of the following, depending on their project:\n\n- Write design documents for technical projects\n- Read and understand parts of the codebase related to their project\n- Receive code reviews for all code they write for their project\n- Develop user-focused, responsive and internationalized UIs.\n- Write automated tests for their projects\n- Meet regularly with other contributors on their Oppia development team (LaCE, Contributor Dashboard, Dev Workflow, Android)\n- Meet 1:1 with their mentors regularly to get developmental feedback\n- Give presentations and demos of their projects\n- Get personalized feedback on their project from the product team or a technical lead\n- Learn how to do code reviews\n\nWe've also asked our previous GSoC contributors what specific things they learned during their GSoC projects. Here are their collated answers:\n\n- Technical ability and domain knowledge\n  - Writing maintainable and readable code.\n  - Building an entirely new feature in a scalable way.\n  - Writing better automated tests.\n  - More confidence working with Angular.\n  - Making better design, UI and technical decisions.\n  - Getting a better understanding of overall full-stack development.\n  - Enhanced ability to debug and resolve technical issues.\n- Technical leadership skills\n  - How to manage my time well, and how to achieve deadlines.\n  - Improved skills in managing and executing projects.\n  - How to give, respond to and understand reviews.\n  - How to effectively convey ideas.\n  - How to write a good project proposal.\n  - Becoming a better developer, not only in terms of technical skills, but also in thinking of actual application of the built product and the edge case scenarios that the user might face.\n- Communication and personal development\n  - How to seek help when needed and overcome challenges.\n  - How to reach out to people, work with them, and help solve each other's problems.\n  - How to get myself unblocked.\n  - Putting forward my thoughts more systematically so that others can understand me well.\n  - Feeling more confident while joining online meetings.\n\nContributors have also told us why they continue to stay engaged with the project after GSoC ends:\n\n- Community\n  - It is really an awesome experience working with some amazing folks from all around the world at Oppia.\n  - The organisation is active and has a strong community bond.\n  - The kind of support the complete community provides is extraordinary.\n- Giving back\n  - The main reason to stay connected is the purpose the community serves. Providing education to those who do not have access to it helps me give back to the society.\n  - It makes me very happy that I'm part of an organization which provides free education and I think the education is the biggest blessing we can give to one to make them stand on their feet.\n  - I would love to be part of this org by knowing that maybe not much but yes I'm trying to make an impact and my contribution in the educational field. I really want to do this because where I come from there is not much of education.\n\n- Growth / learning:\n  - I like working in Oppia since it not only helps me improve my coding skills but also helps me grow as an individual.\n  - Working with Oppia has really helped me grow as a developer and I would really like to stick around to gain even more experience of real world software development.\n  - I feel my exponential growth while contributing in Oppia and got to learn many new things while getting help from mentors and other Oppia team members.\n  - The kind of work that Oppia does is really inspiring and there are a lot of opportunities to improve your skills be it be technical skills or leadership skills and most of all the people at Oppia are really fun to work with :)\n\n\n## GSoC Proposal Template\n\nWhen submitting a proposal, please use the provided [GSoC 2026 proposal template](https://docs.google.com/document/d/1C1ZhKaShWSSIAtiFLd-lcQyjfQbMRNl3bIf-kQv2KNw/edit?tab=t.0). We will only consider proposals submitted using this template. Note that there is a length limit: the proposal's technical \"HOW\" section should not exceed 20 pages at \"Roboto 10\" font size.\n\n> [!IMPORTANT]\n> The 2026 template differs from the 2025 template. Please make sure that you are using the 2026 one. Proposals must follow our template and instructions exactly, or they will be dismissed without review as spam.\n\n**Note:** There's **no** formal minimum length requirement for your proposal. The quality of what you write is much more important than the amount of text you write, and we encourage you to write **shorter** proposals that still convey the main aim of the project.\n\n> [!CAUTION]\n> While large language models have become quite capable recently, we caution you against relying on them too much. In contrast to the verbosity typical of AI-generated text, strong proposals will need to be dense and succinct to convey the deep technical analysis we expect within the proposal length limit.\n\n\n**Some important notes:**\n\n1. Your proposal must be **original** (see section 2.4 of the [Contributor Participation Agreement](https://summerofcode.withgoogle.com/terms/contributor)). During the selection process, proposals that are found to have passed off others' work as their own will automatically be disqualified. If you include any text in your proposal that is copied from the Internet or other sources (even if it is an Oppia doc), you **must** provide a link or reference back to the source. Note that you must attribute sources even if you paraphrase (i.e. re-write their content in your own words). In cases of doubt, we would encourage you to err on the side of citing your sources (since not doing so may be construed as plagiarism).\n\n2. When the necessary criteria for requesting a review are met, add gsoc-2026-mentors@oppia.org as an editor for your proposal doc. (This makes some workflows, like inviting PMs or fixing typos, etc., easier, but if you're concerned about changes to your doc, then you can [turn on notifications for edits](https://support.google.com/docs/answer/91588?hl=en&co=GENIE.Platform%3DDesktop).) After fixing the sharing settings, make a new post in the correct \"proposal reviews\" category in [GitHub Discussions](https://github.com/oppia/oppia/discussions) that is clearly titled with the name of the project that you are requesting a review for, and provide a link to the doc in your post.\n\n   Please use only the above channel for proposal reviews: all proposal-related communication should happen through GitHub Discussions or directly through comments in the proposal doc. **Do not** send proposals directly to individual GSoC mentors.\n\n   You can also request **at most one** \"tech lead review\" for **at most one** of your proposals during the pre-selection phase. To keep things fair, the tech lead will do only a single pass on your proposal and leave comments, but is not required to follow up on replies to those comments. Since you can only request a tech lead review once (per applicant), we recommend doing so after you have gotten feedback from mentors and completed a full draft of your proposal, but at least a week before the due date. Tech leads will process requests in the order they are received. To request a tech lead review, fill in [this Google Form](https://forms.gle/GzQ2sAPPBALhnbRx9).\n\n3. Your final proposal should be self-contained. In particular, to be fair to all applicants, key components of the proposal should not be editable after the deadline. Don't assume that reviewers will follow external links.\n\n\n### Tips for writing a good project plan\n\nHere's some advice about proposals and milestone timeline planning that we collated from previous contributors and mentors:\n\n- **Choose a project you're interested in!** If you have a strong interest in your project, this might make it easier for you to pick up the necessary skills and tackle unforeseen difficulties that may arise during GSoC.\n- **Familiarize yourself with the technologies for your project and the relevant part of the codebase.** Reviewers will want to see that you understand how to integrate your project with the current Oppia structure — don't design in a vacuum.\n- **Define milestones with enough detail to get a proper ETA.** For example, don't just say \"write e2e tests\", otherwise you risk significantly underestimating the timeline.\n- **Communicate and present your ideas clearly.** Your proposal should show that you have a good understanding of the codebase and the final goal of the project. For example, in a user-facing proposal, don't just make a list of files that need to be changed; you should also show detailed mocks and user flow diagrams that demonstrate a clear understanding of the requirements.\n- **Limit proposal length.** A lengthy proposal is not necessarily better. In fact, adding large amounts of unnecessary detail can sometimes obscure the main points you are trying to get across.\n- **Pick a project idea that is within your limits to tackle.** Make sure that what you're proposing is within your capabilities.\n\n### What should applicants expect from mentors in a proposal review?\n\n- Please write your proposal on the assumption that you \"own\" your chosen project. From your perspective, the submitted proposal should be proofread and in as good a condition as possible before you ask for a review. Make sure that you have a sufficiently good understanding of the codebase/project so that you can find and fix flaws in the design; reviewers will give you feedback but not do this for you. Note that your proposal doesn't need to be flawless — we expect that you might make mistakes, and reviewers will be happy to guide you on how to improve. Instead, by \"as good a condition as possible\", we mean that your proposal should demonstrate:\n  - Your ownership of the project\n  - The research you have put into writing it\n  - Your analytical skills\n  - Your independence in making complex decisions\n- Make sure to present solutions and ask for feedback, rather than just asking for solutions. The proposal template contains a \"key decisions\" section which you can use to present the various options you came up with, analyze their advantages & disadvantages using a comparison table, and explain your proposed choice and the reasoning behind it. Note that this doesn't mean that you must always have multiple ideas to solve a problem, but you should instead always explain how you reached a solution, and why is it the best one from the end-user's perspective. Think about how you might gather data to validate your conclusions (e.g. by finding support in the peer-reviewed literature, or by showing your ideas to potential users in the target audience and asking for feedback, etc.).\n- Reviewers' suggestions are _suggestions_, not mandates. We do not expect you to always agree with your reviewers! This means that, as the proposal owner, you are always welcome to decide whether to accept/reject such suggestions. In either case, when accepting/rejecting a suggestion provided by a reviewer, try to explain your reasoning and the research that led to your decision.\n- If you're confused about something, try to identify the point of confusion and ask have specific discussions about it, rather than simply agreeing to whatever is proposed. Don't rely on an \"appeal to authority\" (e.g. \"I am doing it this way because reviewer XXX said so\") — the rational analysis and thought that underlie the decision are what's important, so make sure that you understand and clearly communicate the reasons behind the decisions you make.\n- Note that the process Oppia uses to select GSoC contributors typically includes multiple independent reviewers, most of whom will not have looked at the earlier versions of your submitted proposal. Your initial proposal reviewers may or may not be involved in the final selection process, and it is **not** a requirement that you need to implement all your reviewer's suggestions/requests in order to be selected. Instead, please consider your reviewer as a friendly advisor who is available to help you and provide guidance, rather than the main future evaluator of your proposal.\n\n## Selection Criteria\n\nTo select contributors for GSoC, we will evaluate candidates based on a set of criteria designed to ensure we select individuals who not only possess the necessary skills but also demonstrate the ability to contribute effectively to the project. The criteria are as follows, listed in order of significance::\n\n- **Primary Criterion: Required Skills for the Project** - This is the most critical factor in our selection process. A contributor must have the necessary skills for the project. Lack of these skills is a deal-breaker and can lead to immediate rejection of the proposal.\n\n- **Secondary Criteria** (of equal importance):\n    - **Quality of the Submitted Proposal** - This criterion helps us gauge the applicant's understanding of the project requirements. The proposal should align with project goals, and be clear, thorough, and feasible.\n    - **Prior Experience Working with the Contributor** - We consider our previous interactions with the contributor, focusing on their reliability, communication skills, independence, initiative, responsiveness, and willingness to assist others. This assessment allows us to predict how well the contributor will integrate with the Oppia developer community and contribute to the success of the project.\n \n> [!IMPORTANT]\n> Communication quality is very important to us. We've noticed a number of new contributors leaving irrelevant, unclear, or otherwise low-quality comments that appear to have been generated by AI tools. This kind of behavior will reflect poorly on you during selection. While you are welcome to use AI (see our FAQ for details), you remain responsible for the quality of your communications. In general, we have found AI-generated text to be frustratingly long and verbose, so we encourage you to practice communicating clearly and concisely without relying on AI.\n\nWe believe that strong performance in these dimensions is likely to correlate well with the contributor having an enjoyable, fulfilling and productive experience over the summer, and successfully completing the GSoC program.\n\nFor the proposal, we generally look for a clear indication that the contributor has a good, clear understanding of the project, and has broken it down sufficiently well, in a way that makes it very likely to succeed. Some indicators that could help with this include:\n\n- Clear, unambiguous communication. (This is important; your proposal will be read by many mentors!)\n- A clear analysis of (and good design decisions that build on top of) the original project idea, with a strong focus on creating a simple, intuitive experience for end users.\n- A proposed solution approach which is sufficiently concrete and which demonstrates that the applicant has a good understanding of both the scope of the problem and the existing codebase.\n- A description, if applicable, of how the applicant plans to mitigate risks that could potentially derail the project.\n- A concrete, specific description of each milestone, together with a breakdown of the necessary work.\n\n\n## Communication\n\nIf you have questions pertaining to \"how to get started with Oppia\" or any other queries regarding GSoC at Oppia, please ask them on **[GitHub Discussions](https://github.com/oppia/oppia/discussions)**. Please be specific when asking questions; this makes it easier for us to help you. Also, please make sure to read the relevant \"getting started\" wiki page ([Web](https://github.com/oppia/oppia/wiki/Contributing-code-to-Oppia#setting-things-up), [Android](https://github.com/oppia/oppia-android/wiki/Contributing-to-Oppia-android)) first, since the answer to your question might already exist there!\n\nTo receive important announcements and updates about GSoC at Oppia, please subscribe to the **[Oppia GSoC Announce](https://groups.google.com/g/oppia-gsoc-announce)** mailing list, and the [Developer Announcements](https://github.com/oppia/oppia/discussions/categories/developer-announcements) category on GitHub Discussions.\n\n## Oppia's Project Ideas List\n\n_**Note:** If you're coming to this section from an external link, please make sure to scroll up and read this entire wiki page carefully, not just this section. There's a lot of useful information on the rest of the page, including a FAQ and a section describing selection criteria. Thanks!_\n\nThe following is a list of Oppia's 2026 GSoC project ideas. You are welcome to choose among these ideas, or propose your own! However, if you're planning to propose something original, it's essential to engage with the Oppia community beforehand in order to get feedback and guidance to improve the proposal. We'd also recommend taking a look at [Oppia's mission](https://github.com/oppia/oppia/wiki/Oppia's-Mission) and seeing if there is a natural way to tie your idea to the Oppia project's goals, otherwise it might not be a good fit at this time.\n\nPlease note that the list of project ideas below is not set in stone: more projects may be added later, and some project descriptions may also change a bit, so check back regularly. In addition, the mentor assignments listed below are provisional, and may change depending on which proposals are eventually accepted. (If you want to see what changes have been made to this page since you last viewed it, you can use the [History tab](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2026/_history).)\n\nIf you need clarification on any of these ideas, feel free to open a thread in GitHub Discussions following the process in [this guide](https://docs.google.com/document/d/1jt8_pKcrbsc0xHgUEa0Wh8i6imxYmZiB_2QjDmH7ODg/edit?tab=t.0).\n\n### Learners, Educators, Allies, and Parents (LEAP) team\n\n- [1.1. Web user feedback](#11-web-user-feedback)\n- [1.2. Learner assessments](#12-learner-assessments)\n- [1.3. Re-design the topic page](#13-re-design-the-topic-page)\n\n### Creators, Operations, Reviewers, and Editors (CORE) team\n\n- [2.1. Automatic translation suggestions](#21-automatic-translation-suggestions)\n- [2.2. Extend translation infrastructure to exploration metadata and skills](#22-extend-translation-infrastructure-to-exploration-metadata-and-skills)\n\n### Developer Workflow team\n\n- [3.1. Improve acceptance test infrastructure](#31-improve-acceptance-test-infrastructure)\n- [3.2. Consolidate entity migration jobs](#32-consolidate-entity-migration-jobs)\n- [3.3. Standardize and validate domain objects and storage models](#33-standardize-and-validate-domain-objects-and-storage-models)\n\n### Android team\n\n- [4.1 Support for Study Guides & Worked Examples, and Modernizing HTML Handling](#41-support-for-study-guides--worked-examples-and-modernizing-html-handling)\n- [4.2 Streamlining Release Automation](#42-streamlining-release-automation)\n\n## Learners, Educators, Allies, and Parents (LEAP) team\n\n### 1.1. Web user feedback\n\n**Project Description:** Learners (and other relevant users) should have an easy way to report issues with the platform so that we can quickly catch and resolve these issues in a scalable manner.\n\nLinks to PRD and mocks:\n\n- PRD: https://docs.google.com/document/d/1ZUD7nktZrl5ZyxcXfLAqJqb6wI40U9rdg-2vHHWUZ1g/edit?usp=sharing\n\n**Tracking issues**:\n\n- https://github.com/oppia/oppia/issues/24716\n\n**Not in scope:**\n\n- Feedback Recategorization: Workflows for admins to move feedback between categories (e.g., changing \"Lesson\" to \"Platform\").\n- Auto-Translation: Automatic translation of non-English feedback.\n\n**Size:** Large (\\~350 hours)\n\n**Difficulty**: Moderate\n\n**Potential mentors:** @mon4our\n\n**Product/technical clarifiers:** @U8NWXD (product), @mon4our (technical)\n\n**Discussion forum:** https://github.com/oppia/oppia/discussions/categories/gsoc-q-a-1-leap-projects\n\n**Required knowledge/skills:**\n\n- Figure out the root cause of an issue and communicate it well using a debugging doc.\n- Debug and fix CI failures/flakes.\n- Write Python code with unit tests.\n- Write TS + Angular code with unit tests.\n- Write or modify e2e/acceptance tests.\n- Write or modify Beam jobs.\n\n**Related issues:** We don't have a set of particularly related issues for you to start with since this will be a brand new feature. To gain experience with the required knowledge and skills, look for relevant issues with the [LEAP](https://github.com/orgs/oppia/projects/3), [CORE](https://github.com/orgs/oppia/projects/18), and [dev workflow](https://github.com/orgs/oppia/projects/8) teams depending on which skills you need to practice or demonstrate.\n\n**Suggested Milestones:**\n\n- **Milestone 1**: Implement the feedback entry point and modal using the pre-existing image uploader component for screenshots. Develop the logic to programmatically capture user session data (logs, metadata) upon opt-in and persist all data to the backend. **Important steps**: Integrating the existing image uploader, implementing a method to share user’s session data, CAPTCHA integration (to prevent spam feedback by bots, might not be necessary), implementing the acceptance tests for the user flows and backend schema design.\n\n- **Milestone 2**: Create the admin-facing dashboard to retrieve and view feedback. **Important steps**: Creating the Dashboard UI, implementing fetching from the backend data, writing the acceptance tests for the admin flows.\n\n<details>\n<summary>Org-admin/tech-lead commentary/advice</summary>\n\nIn this project, you will be building a new, fairly self-contained feature from the ground up, including some creative design work. If you are excited by the prospect of owning a feature from start to finish and the challenge of overcoming unexpected problems, then this might be a good project for you. Strong debugging, technical design, and planning skills will be essential.\n</details>\n\n<details>\n<summary>What we are looking for in proposals</summary>\n\nThe proposal must explain technically how you intend to capture \"session data\". What will be the database schema for the new Feedback Models that will store the feedback in the database? How will the frontend fetch the feedback data from the backend? How will you integrate the existing image uploader modal into the feedback form? Consider how to protect the feedback submitter’s privacy. Include mocks for the new admin dashboard (for viewing the submitted feedback). Since these are not external-facing, the design can be a little rougher.\n</details>\n\n<details>\n<summary>Technical hints / guidance</summary>\n\n- Frontend-backend communication: You will need to implement a new API endpoint (e.g., /api/feedback_dashboard) to serve the admin dashboard. This endpoint should support server-side pagination and filtering (e.g., fetching feedback by category or date range) to handle potential future scale.\n- On the frontend, create a dedicated FeedbackBackendApiService to handle these requests and manage the type definitions for the feedback objects.\n- Image uploader: Check the current implementation for the Image Upload RTE component in the topic/subtopic modals to get an idea of how to use the image uploader modal in the feedback form.\n- Would we need to differentiate between logged in and logged out users? Explain why. How would we implement the system in either case?\n- To protect the privacy of those submitting feedback, create a cron job (search for `cron` in our codebase to see examples) to automatically erase feedback after 6 months. Viewing feedback should be restricted to admins, and admins should also be able to delete particular pieces of feedback early in case they see something sensitive.\n\n</details>\n\n<details>\n<summary>Suggested PM demo points</summary>\n\nMilestone 1:\n\n- User is able to open the feedback modal from any page on the site\n- User is able to rate the experience and provide text feedback.\n- Demonstrate the integration of the image uploader component.\n- Show the \"Include session info\" checkbox (unchecked by default).\n- The feedback is stored as expected on the backend\n- CAPTCHA integration\n- All applicable frontend, backend, and acceptance tests have been written and pass robustly.\n\nMilestone 2:\n\n- User submitted feedback shows up on the admin dashboard\n- Dashboard is legible and easy to use\n- Admins can dismiss feedback\n- Admins can delete feedback\n- Feedback is automatically deleted every 6 months\n- All applicable frontend, backend, and acceptance tests have been written and pass robustly.\n\n</details>\n\n### 1.2. Learner assessments\n\n**Project Description:** We want to celebrate and recognize learners’ achievements as they progress through our curriculum to help motivate them. We currently do this at the exploration (also known as a “lesson”) level, but we want to also celebrate longer-term learning across multiple lessons. To do so, this project introduces assessments that cover groups of skills. At any time, learners can choose to take the assessment to test what they’ve learned. In the future (out of scope for this project), we plan to give learners certificates for passing assessments so they can share the certificate with others. Even without this certificate feature, learners will be able to show their passing score page to others to celebrate their achievement.\n\nThis project includes:\n\n- Creating the backend infrastructure needed to:\n  - Store the certificate assessment offerings available for learners to take\n  - Given a certificate assessment offering, generate an assessment by randomly selecting from a pool of questions\n  - Record the results from a learner’s certificate assessment attempt\n- Building the frontend experience for learners to:\n  - Discover the available assessment offerings\n  - Take an assessment\n  - See the results of their assessment attempt\n  - See their history of assessment attempts\n- Building the frontend experience for our lessons team to create and configure assessment offerings\n\nOur product team has put a lot of work into specifying the learner’s experience, so the frontend for learners and the backend infrastructure are pretty well-defined. You will have more freedom (and responsibility) to design the frontend experience for the lessons team.\n\nLinks to PRD and mocks:\n\n- PRD: [Assessment Construction and Mastery for Certificates](https://docs.google.com/document/d/19Qm6YPInNMFgqihJP-zL1qtW1BsLRDdLgWHuRr7XtRE/edit?usp=sharing)\n- PRD: [Certificates #28 (Logged-in Student Experience, Web)](https://docs.google.com/document/d/1j5hHvh_WrEngnty5I2RR3EMGBsUHHARJWqnC_ABwYUo/edit)\n\n**Tracking issues**:\n\n- https://github.com/oppia/oppia/issues/24717\n\n**Not in scope:**\n\n- The Skill Mastery PRD (linked-to from the Certification Assessment PRD)\n- Mastery measures that aggregate across multiple certification assessments\n- Generating the certificate document. For now, we will let learners take assessments and screenshot their score page to share their achievement with others.\n- Translations. The questions surfaced in the assessment are currently un-translated, so to keep the scope of this project manageable, we will add translation support in a later project.\n\n**Size:** Large (\\~350 hours)\n\n**Difficulty**: Hard\n\n**Potential mentors:** @brianrodri @masterboy376\n\n**Product/technical clarifiers:** @U8NWXD (product), @brianrodri (technical)\n\n**Discussion forum:** https://github.com/oppia/oppia/discussions/categories/gsoc-q-a-1-leap-projects\n\n**Required knowledge/skills:**\n\n- Figure out the root cause of an issue and communicate it well using a debugging doc.\n- Debug and fix CI failures/flakes.\n- Write Python code with unit tests.\n- Write TS + Angular code with unit tests.\n- Write or modify e2e/acceptance tests.\n- Basic user interface design skills will be important for creating the lesson team’s interface for creating certificate assessment offerings. Note that the functionality and usability of this interface is more important than its aesthetics since it is not exposed to external users.\n  - To demonstrate this skill, you can include in your proposal draft mocks for the asessment creation interface.\n- Creating user interfaces that follow provided mocks. In particular, you should be comfortable using HTML, CSS, and Angular to create new user interface elements to match mocks.\n  - To demonstrate this skill, take a look at feature requests for the [CORE](https://github.com/orgs/oppia/projects/18/views/4) and [LEAP](https://github.com/orgs/oppia/projects/3) teams.\n- Working with Oppia’s full-stack infrastructure. You should be familiar with how data flows between the layers of Oppia’s stack from the frontend all the way through to storage models and back to the frontend.\n  - To demonstrate this skill, take a look at full-stack feature requests or bug fixes for the [CORE](https://github.com/orgs/oppia/projects/18/views/4) and [LEAP](https://github.com/orgs/oppia/projects/3) teams.\n\n**Related issues:** Take a look at issues for the [CORE](https://github.com/orgs/oppia/projects/18/views/4) and [LEAP](https://github.com/orgs/oppia/projects/3) teams, particularly but not exclusively [those related to questions](https://github.com/orgs/oppia/projects/18/views/4?sliceBy%5Bvalue%5D=%5BProject%5D+Fix+issues+affecting+question+submitter+workflows).\n\n**Suggested Milestones:**\n\n- **Milestone 1**: The frontend experience for the lessons team has been created, allowing them to create, edit, view, and delete certificate assessment offerings. This interface enforces validation checks to prevent the creation of invalid assessment offerings (e.g. attaching skills that don’t have enough questions, leaving the description blank) and gives the user feedback about whether changes were successfully saved. The associated backend infrastructure has also been created to store the configured offerings.\n\n- **Milestone 2**: The frontend experience for learners has been created, allowing them to discover, take, and see results of assessments. Learners can also see their history of assessment attempts. The associated backend infrastructure has been built to support this experience, including the generation of new assessments and recording the results of assessments taken.\n\n<details>\n<summary>Org-admin/tech-lead commentary/advice</summary>\n\nThis is a complex, full-stack project that develops a new feature and includes some design work. You should have good familiarity with Oppia’s full-stack infrastructure and be prepared to tackle unexpected issues. Debugging skills will be essential! If the challenge of implementing a whole feature end-to-end excites you, then this is a great project to consider.\n</details>\n\n<details>\n<summary>What we are looking for in proposals</summary>\n\n- Mocks for the frontend experience for the lessons team\n- Detailed plans for the backend infrastructure you will build. What endpoints will you create or change? What storage models will you create, and what will each model look like? Be specific.\n- Sketch out the logic (for example with pseudocode) you will use generate assessments, store assessment attempt results, and compute the metrics to display on the assessment results page.\n- How will you use feature flags to stage the release of the feature?\n- How will you compute the metrics requested in the PRDs? Note that while we need to be able to get these metrics, they don’t need to be surfaced in a dashboard. For example, a beam job that we can run to calculate metrics is acceptable (though if you go this route you need to show you can write beam jobs).\n- Make sure to account for writing frontend, backend, and acceptance tests for your project! These should be included in your timeline, and you should provide evidence that you know how to write them.\n\n</details>\n\n<details>\n<summary>Technical hints / guidance</summary>\n\nThere are substantial technical details in the PRDs, particularly with regards to storing assessment attempt results, so please review those carefully. In brief, we envision you creating the backend storage models for the following:\n\n- Certificate assessment offerings. Should store configuration parameters like attached skills, time limit, name, description, and associated classroom. This needs to be versioned so that if an assessment offering is changed, we can recover the assessment offering version that the learner actually attempted.\n- Assessment attempts. Should store a versioned reference to the offering attempted, the start and end times, references to response objects for each question in the attempt (including questions not answered), and a learner identifier.\n- Assessment question responses. Should store a version reference to the associated assessment attempt object, a versioned reference to the question presented, the user’s selected answer (or an indication that the question wasn’t answered), whether the learner got the answer correct, and a versioned reference to the skill tested.\n\nWe already have backend storage models for questions, topics, skills, and classrooms. You should plan to use those existing models and describe in your proposal any changes you will need to make to them. For example, we will need to modify the classroom model to store references to certificate offerings so that we can control the order in which offerinigs are displayed to the user.\n\nThere is also prior work in the codebase that you can learn from. For example, at the end of a practice session, users are currently shown a breakdown of their score that is similar to what we want to show at the end of an assessment in this project.\n\n</details>\n\n<details>\n<summary>Suggested PM demo points</summary>\n\nMilestone 1:\n\n- Certificate assessment offerings can be created, viewed, edited, and deleted.\n- Validation checks prevent the creation of invalid assessment offerings.\n- Changes made through the frontend are persisted to storage models in the backend.\n- All applicable frontend, backend, and acceptance tests have been written and pass robustly.\n\nMilestone 2:\n\n- Learners can discover, take, and see results from assessments.\n- Learners can see their history of assessment attempts.\n- Learner assessment results are persisted to the backend.\n- Assessments are correctly generated.\n- All applicable frontend, backend, and acceptance tests have been written and pass robustly.\n\n</details>\n\n### 1.3. Re-design the topic page\n\n**Project Description:** Based on user feedback, on the current topic page, users often overlook the Practice and Revision tabs completely. Additionally, the functionality in those tabs is not correlated with the available lessons, making it unclear to learners when they should review or practice those skills.\n\nThe aim of this project is to update the design of the topic page to present a more integrated view of the lessons, practice sessions, and links to revision cards (subtopic pages), so that learners can practice the skills they learned in the relevant lesson. Additionally, it is disappointing for learners to find that the languages that they would want to use for translations and voiceovers are missing only after they start the lesson, so the new design incorporates these selections within the topic page itself and follows the overall site language as a default.\n\nLinks to PRD and mocks:\n\n- [PRD: Practice Sessions Experience and Topic Page](https://docs.google.com/document/d/1r9IEQ5z_t-eu9XAWN3eRA7iKdKuYsOQbVUjO2ZH1qKg/edit?tab=t.0)\n  - Note that this PRD describes a redesign of both the topic page and the practice session experience. This GSoC project only covers redesigning the topic page. The PRD’s mocks are also out of date; please refer to [these mocks](https://www.figma.com/design/1wjdVilWcZs9znEj6tFyFC/Project--107-Add-visual-cues-to-guide-learners-to-their-next-steps-on-the-topic-page?node-id=1-51&p=f) instead. You may find it useful to start by reviewing the mocks, since they only cover the parts of the PRD relevant to this GSoC project.\n\n**Tracking issues**:\n\n- https://github.com/oppia/oppia/issues/19614\n\n**Not in scope:** Changes in the linked PRD that relate solely to the practice questions player.\n\n**Size:** Medium (\\~175 hours)\n\n**Difficulty**: Moderate\n\n**Potential mentors:** @HardikGoyal2003\n\n**Product/technical clarifiers:** @HardikGoyal2003 (product), @HardikGoyal2003 (technical)\n\n**Discussion forum:** https://github.com/oppia/oppia/discussions/categories/gsoc-q-a-1-leap-projects\n\n**Required knowledge/skills:**\n\n- Figure out the root cause of an issue and communicate it well using a debugging doc.\n- Debug and fix CI failures/flakes.\n- Write Python code with unit tests.\n- Write TS + Angular code with unit tests.\n- Write or modify e2e/acceptance tests.\n- User interface creation, particularly familiarity with CSS and screen-size-responsive design\n\n**Related issues:**\n\n- https://github.com/orgs/oppia/projects/3/views/8?sliceBy%5Bvalue%5D=%5BProject%5D+Fix+issues+relating+to+the+topic%2Fclassroom+pages\n- https://github.com/orgs/oppia/projects/3/views/8?sliceBy%5Bvalue%5D=%5BProject%5D+Fix+all+acceptance+test+failures\n- https://github.com/orgs/oppia/projects/3/views/8?sliceBy%5Bvalue%5D=%5BProject%5D+Fix+issues+with+checkpoints%2Fprogress\n- https://github.com/orgs/oppia/projects/3/views/8?sliceBy%5Bvalue%5D=%5BProject%5D+Fix+issues+with+RTL+support\n\n**Suggested Milestones:**\n\n- **Milestone 1**: Implement a basic version of the updated topic player page (based on these mocks), and ensure that it is fully responsive for desktop and mobile portrait views. This involves the following steps:\n  - Use the feature flag introduced in this PR: https://github.com/oppia/oppia/pull/20406, and also verify that the feature flag has been properly introduced in that PR.\n  - Display the topic name and description prominently, along with the associated story name and description.\n  - Include a link to the study skills page from the topic page, ensuring the page is accessible and properly styled.\n  - Filterable, scrollable sequence of lessons and practices.\n    - Displayed the count of lessons and practices\n    - Practices should be interspersed in the correct order\n    - Correctly suggest what item to work on next. This suggestion should be the default when the page loads and indicated with a green arrow.\n    - Dynamic scroll arrow visibility\n    - Correct scroll distance\n    - Selecting a lesson or practice shows details and links to start, resume, study, or practice, as appropriate\n    - Filter status is remembered the next time the user loads the page\n  - Maintain a uniform UI consistent with the topic editor page and ensure full responsiveness for both desktop and mobile portrait views.\n\n- **Milestone 2**:\n  - Show progress indicators on lessons and practice sessions\n  - Show pop-ups when a user returns to an in-progress or completed lesson\n  - Implement the “Representation of Chapter Availability” section in the mocks by updating the existing \"coming soon\" UI and new tag on the chapters.\n  - Support secondary language selection, enforced with pop-ups when necessary\n  - Persist secondary language choices. At this point, the full language selection algorithm should be implemented\n\n<details>\n<summary>Org-admin/tech-lead commentary/advice</summary>\n\nThis project is primarily a frontend project, so contributors should be comfortable with Oppia’s frontend stack. This project is a good fit for contributors interested in building a full, user-facing frontend that will directly impact the learner experience.\n</details>\n\n<details>\n<summary>What we are looking for in proposals</summary>\n\nConsider: \n\n- How will you support showing multiple stories in the topic page?\n- How will you build the new topic page while keeping the old design intact, and how will you make it easy to deprecate the old design and switch over to the new design when needed? Hint: use feature flags!\n\nSome questions to check that you understand the tech stack:\n\n- How will you load the lesson in the preferred language once the user clicks on the Start button?\n- Explain how you will ensure that the implemented/updated pages are (a) fully-responsive for all device sizes, (b) reach a Lighthouse score of 100 for accessibility, (c) support RTL layouts, and (d) are fully internationalizable. If possible, link to PRs that demonstrate that you have a good understanding of these areas.\n\nAdditional things to discuss in your proposal:\n\n- What are the APIs for the components that you will create (e.g., modal, lesson card, progress bar, practice card, and possibly others)? For each of these, provide a definition of the API interface and an example usage of the component that is associated with a screenshot of one of its instances in the mocks.\n- Show a screenshot of the existing \"serial chapter launch\" functionality running on your local machine, and explain the changes you would make to it to bring it into alignment with the mocks.\n- When auditing the mocks and thinking about implementation, you might find that you need to get clarifications on various aspects of the mocks. Include, in your proposal, a list of questions that you have asked / would ask, how they affect the implementation, and the answers to those questions.\n\n</details>\n\n<details>\n<summary>Technical hints / guidance</summary>\n\n- For implementing the language and audio on the lesson card, check the approach used in the new lesson player.\n- For implementing the progress bar for the lesson card, check the new lesson player’s checkpoint bar.\n- To implement the skill progress circle or to determine whether the skill has been completed or not, check the new learner dashboard’s progress tab. In that, skills are implemented that show the progress.\n- When fetching multiple entities, do a single GET-MULTI call. Avoid executing a single GET call N times in a for loop.\n- To turn on the \"coming soon\" functionality, you’ll need to flip the \"serial chapter launch\" feature flag in the /release-coordinator page (you can give yourself permissions for that in /admin > Roles). See Rishi Kejriwal’s project in GSoC 2023 for more details about how this feature works.\n\n</details>\n\n<details>\n<summary>Suggested PM demo points</summary>\n\nMilestone 1:\n\n- The overall topic page design has been implemented\n- Clicking the study skills link, either from the story header or from a practice, leads to the study skills page. From there, selecting a concept leads to the concept revision page.\n- Lessons and practices are shown in the correct order. The user can scroll through them. Check that scroll distances and scrolling availability are correct, given the number of items and screen size.\n- Lessons and practices can be selected to show more details.\n- Lessons and practices can be filtered, and the state of this filter is remembered the next time the user loads the page.\n- All applicable frontend, backend, and acceptance tests have been written and pass robustly.\n\nMilestone 2:\n\n- Progress indicators are displayed, and progress is calculated correctly, for both lessons and practices.\n- Users are shown pop-ups when loading in-progress or completed lessons.\n- Languages are selected correctly for lessons. This includes secondary language selection and pop-ups.\n- All applicable frontend, backend, and acceptance tests have been written and pass robustly.\n\n</details>\n\n## Creators, Operations, Reviewers, and Editors (CORE) team\n\n### 2.1. Automatic translation suggestions\n\n**Project Description:** The lesson content in Oppia is primarily written in English, and the current translation workflow follows a review-and-approval model. Contributors who are familiar with their native language can submit translation suggestions through the contributor dashboard. These suggestions are then reviewed and approved by a translator admin, after which the translated content is stored in the datastore for the respective entities.\n\nThis project aims to simplify the contribution process by automatically providing AI-based translation suggestions. Contributors will have the option to accept the suggested translation (and edit it if needed) or reject it. If the AI suggestion is rejected, contributors can add the translation manually, following the existing workflow.\n\nLinks to PRD and mocks:\n* [Mocks](https://www.figma.com/design/l5CN6GOxtqlZYKrOYBK88p/Automatic-translation-UI?node-id=0-1&t=mKCsNeEwEK1SOsev-1) with the following tweaks:\n  * You don't need to highlight the parts of the auto-generated translation that the user changes.\n  * To submit the translation, require that the user have looked at the translated alt text for each image. Currently we require this by forcing translators to click on images, which opens a modal showing the alt text, to copy the images into the translation, but that mechanism won't work for automated translations.\n\n**Tracking issues**:\n\n- https://github.com/oppia/oppia/issues/24714\n\n**Not in scope:** This project does not aim to automate the entire translation pipeline. Specifically, when the main content of an entity is modified, translations will not be regenerated automatically. This is intentional, as we want to retain the review-and-approval model in the translation infrastructure so that only approved translations are shown to end users.\n\nAutomating the translation pipeline could be explored as a future project, depending on how effective and successful this project proves to be.\n\n**Size:** Medium (\\~175 hours)\n\n**Difficulty**: Moderate\n\n**Potential mentors:** @Nik-09\n\n**Product/technical clarifiers:** @U8NWXD (product), @Nik-09 (technical)\n\n**Discussion forum:** https://github.com/oppia/oppia/discussions/categories/gsoc-q-a-2-core-projects\n\n**Required knowledge/skills:**\n\n- Figure out the root cause of an issue and communicate it well using a debugging doc.\n- Debug and fix CI failures/flakes.\n- Write Python code with unit tests.\n- Write TS + Angular code with unit tests.\n- Write or modify e2e/acceptance tests.\n- (maybe, depending on your technical approach) Write or modify Beam jobs.\n\n**Related issues:**\n\n- Contributors can work on something from this list to understand the translation workflow: https://github.com/orgs/oppia/projects/18/views/4?sliceBy%5Bvalue%5D=%5BProject%5D+Fix+issues+in+the+main+translator%2Fquestion+opportunities+dashboard\n- Full-stack related issues: https://github.com/oppia/oppia/issues?q=state%3Aopen%20label%3Afull-stack\n- https://github.com/oppia/oppia/issues/16837\n\n**Suggested Milestones:**\n\n- **Milestone 1**:\n  - Build backend infrastructure to generate automatic translations for entities. The infrastructure should be flexible enough to support adding or removing languages used for translation generation.\n  - Build the backend infrastructure to store the generated translations in a cache model to avoid multiple translation generations of the same content in a language.\n  - The translations should be generated on the fly while contributors add translation suggestions from the Contributor Dashboard. Please have a look at the Figma mocks for more clarity.\n  - Use the Azure Translator SDK ([reference](https://learn.microsoft.com/en-us/azure/ai-services/translator/text-translation/quickstart/client-library-sdk?pivots=programming-language-python)) to generate translations for Oppia content. The translation configuration should be flexible and language-specific, allowing us to define which service is used for each supported language.\n  - This design should make it easy to onboard additional third-party translation providers in the future (for example, GCP), with minimal code changes. A JSON-based configuration can be used to map languages to translation platforms such as Azure or GCP.\n  - Develop full-stack functionality to enable the addition and removal of languages from the translator admin page (the UI will be very similar to the existing voiceover admin page), supporting automatic translation generation.\n\n\n- **Milestone 2**: Contributors should be able to view AI-based translation suggestions in the Contributor Dashboard. They should be able to submit translations by fully accepting the suggested AI translation, accepting it after making edits, or rejecting it entirely and providing a manual translation instead. If translators don't click the \"Auto-Translate\" button, everything should work as it did before the auto-translation project.\n\n<details>\n<summary>Org-admin/tech-lead commentary/advice</summary>\n\nThis project implements a full-stack, largely self-contained feature that has the potential to immediately improve the translator experience. The selected contributor will likely work with the translation team to get feedback, so this project is great for those who value seeing the impact of their work quickly. This project has a little of everything, from backend architecture design to frontend UI work.\n\n</details>\n\n<details>\n<summary>What we are looking for in proposals</summary>\n\n- A structured and extensible design that supports multiple translation services in the future, beyond the current Azure-based implementation, with the ability to configure translation providers on a per-language basis.\n- Comprehensive examples demonstrating successful translations using Azure for Oppia content, including math, images, and other Oppia interactions.\n- A detailed end-to-end implementation plan, covering the process from generating translations using the Azure Translator SDK to surfacing translation suggestions in the frontend UI.\n\n</details>\n\n<details>\n<summary>Technical hints / guidance</summary>\n\nCaching automatic translation: \n- Each piece of content is translated in the backend and displayed on the CD dashboard when the user submits a translation. Instead of calling the third-party service (Azure, in this case) every time, we can store the generated translations in the datastore.\n- This way, if another exploration — or even the same exploration — contains identical content, we can reuse the previously generated translation instead of sending a new request to the external service. This approach reduces both processing time and cost.\n- To implement this, we can:\n  - Generate a hash of the original English content.\n  - Store the hash along with the original content, target language code, and the generated translation in the datastore.\n  - When a new translation request is received, first check whether a matching hash entry already exists.\n  - If a match is found, reuse the stored translation instead of calling the third-party API.\n  - Ensure proper handling of potential hash collisions.\n- This optimization improves efficiency, reduces redundant API calls, and lowers overall operational costs.\n\n\nHow to make changing third-party translation provider easy\n- There are multiple ways to implement this. The simplest approach would be to maintain a JSON configuration file in the codebase that maps each language to the third-party provider used for automatic translation regeneration. Then create backend objects or functions that handle querying the third-party provider and present a common interface to the rest of our backend code so we can easily swap them out.\n- A similar approach has already been implemented for automatic voiceover regeneration. You can refer to the autogeneratable_language_accent_list.json file in the assets directory of the codebase as a reference.\n\n</details>\n\n<details>\n<summary>Suggested PM demo points</summary>\n\nMilestone 1:\n\n- The translation admin page should successfully support adding and removing languages for automatic translations, enabling/disabling the overall translation suggestions functionality.\n- The translation admin page should support changing the automatic translation service used for any language. \n- Should be able to show the generated translations for selected entities and log the output either in the console or terminal. \n- Additionally, the quality of the generated translations must be reviewed and approved by the translation team to ensure they meet the standards of the existing content translation in the respective language.\n- All applicable frontend, backend, and acceptance tests have been written and pass robustly.\n\nMilestone 2:\n\n- Demonstrate the complete end-to-end workflow, showing how AI-based translation suggestions are generated, modified, and accepted by contributors, followed by how translator reviewers approve the suggested translations without altering the existing review flow.\n- All applicable frontend, backend, and acceptance tests have been written and pass robustly.\n\n</details>\n\n### 2.2. Extend translation infrastructure to exploration metadata and skills\n\n**Project Description:** Currently, we have two main mechanisms for translating content at Oppia: translatewiki and the contributor dashboard. Translatewiki handles content that is not user-generated, for example the text on the homepage at oppia.org. The goal of this project is to extend the contributor dashboard to handle other kinds of user-generated content in our curated curriculum, specifically the following:\n\n- exploration metadata (e.g. titles and tags)\n- skill (concept card) content\n\nThe finished product should also be easily extended to other kinds of content in the future, for example:\n\n- topic metadata\n- story metadata\n- study guide content\n\nAt a high level, this project consists of:\n\n- Displaying all translatable opportunities of the new entities in the contributor dashboard.\n- Displaying all reviewable translated suggestions in the reviewer dashboard.\n- Displaying translated contents to learners when a language other than English is selected.\n\nLinks to PRD and mocks: We have a full TDD instead of a PRD: docs.google.com/document/d/1cFJ6weoOWPopLFpRf2lw4RRPPNFVJ4QVLqdxb_WsLyY/edit. You are welcome to draw inspiration from the TDD, but you should not assume that its suggested approach is best. We expect you to critically evaluate it and suggest deviations when appropriate.\n\n**Tracking issues**:\n\n- https://github.com/oppia/oppia/issues/22793\n- https://github.com/oppia/oppia/issues/24933\n\n**Not in scope:** \n\n- Supporting translation of content outside our curated curriculum, for example user profiles or explorations that aren’t connected to a topic.\n- Supporting translation of entities besides exploration metadata and skill content.\n- Actually doing the translations. This project is just about creating the infrastructure and interface that will support the translation team in doing the actual translations.\n\n**Size:** Large (\\~350 hours)\n\n**Difficulty**: Hard\n\n**Potential mentors:** @chris7716 and @masterboy376\n\n**Product/technical clarifiers:** @chris7716 (product), @chris7716 (technical)\n\n**Discussion forum:** https://github.com/oppia/oppia/discussions/categories/gsoc-q-a-2-core-projects\n\n**Required knowledge/skills:**\n\n- Figure out the root cause of an issue and communicate it well using a debugging doc.\n- Debug and fix CI failures/flakes.\n- Write Python code with unit tests.\n- Write TS + Angular code with unit tests.\n- Write or modify e2e/acceptance tests.\n- Write or modify Beam jobs.\n- Architecting extensible code infrastructure\n\n**Related issues:**\n\n- Bugs in https://github.com/orgs/oppia/projects/18/views/4?sliceBy%5Bvalue%5D=%5BProject%5D+Expand+translation%2Fvoiceover+opportunities+to+include+all+user-created+content\n- Translation issues in https://github.com/orgs/oppia/projects/18/views/4?sliceBy%5Bvalue%5D=%5BProject%5D+Fix+issues+for+translation%2Fquestion+coordinators\nhttps://github.com/orgs/oppia/projects/18/views/4?sliceBy%5Bvalue%5D=%5BProject%5D+Fix+issues+affecting+translation+reviewer+workflows\n\n**Suggested Milestones:**\n\n- **Milestone 1**: Build the extensible translation infrastructure and migrate the translations currently supported by the contributor dashboard (i.e. exploration non-metadata content) to use it.\n\n- **Milestone 2**: Exploration metadata and skill content can be translated through the contributor dashboard, and all legacy code related to the old translation system has been removed.\n\n<details>\n<summary>Org-admin/tech-lead commentary/advice</summary>\n\nThis is a complicated project that primarily consists of backend changes, plus some changes to the frontend code to keep it compatible with the new backend. We expect minimal changes to the user interface. Contributors skilled in the creation of modular, extensible frameworks will likely be particularly well-suited for this project. The first milestone, implementing the extensible framework, is the most critical and the trickiest. Mistakes here will lead to problems extending the framework to other entity types in the second milestone. We think most of the technical issues have been thought through and solved already, which both reduces the amount of planning and design work required of the contributor, and also may help avoid technical issues derailing the project.\n\n</details>\n\n<details>\n<summary>What we are looking for in proposals</summary>\n\nA TDD has already been drafted for this project, so we’ll be looking for evidence that applicants deeply understand the proposed approach and have critically evaluated it. Read the TDD closely, consider whether you think the approach makes sense, and reach out to us with questions and alternative ideas. The solution in the TDD might not actually be the best, and pointing out issues with the TDD is a great way to show you really understand it. Further, the TDD gives a rather high-level explanation of some parts of the project, for example what changes will be required to show translations of the newly-translated entities to users. Your proposal should delve into the details of these parts. We've also had a number of issues with keeping translation counts up-to-date (see https://github.com/oppia/oppia/issues/21878), so you should address how you plan to avoid similar issues in your project.\n\n</details>\n\n<details>\n<summary>Technical hints / guidance</summary>\n\nWe’ve already put a good amount of thought into the technical details. See the TDD for our proposed plan.\n\n</details>\n\n<details>\n<summary>Suggested PM demo points</summary>\n\nMilestone 1:\n\n- The contributor dashboard works like it did before. Opportunities are surfaced for translators, translators can submit translations, reviewers can review them, and accepted translations are displayed to users.\n- Topic filtering for translators and reviewers works.\n- While the contributor dashboard user experience hasn’t changed, it is now implemented using an extensible infrastructure that we can easily extend to the rest of the user-generated content in our curated curriculum.\n- All applicable frontend, backend, and acceptance (unlikely to change much) tests have been written and pass robustly.\n\nMilestone 2:\n\n- Opportunities for user-generated content in the curated curriculum are surfaced for translators, translators can submit translations, reviewers can review them, and accepted translations are displayed to users. Check that the following kinds of content can be translated:\n  - exploration metadata (e.g. titles and tags)\n  - skill (concept card) content\n- Translators and reviewers can filter by topic\n- All applicable frontend, backend, and acceptance (unlikely to change much) tests have been written and pass robustly.\n- The translation infrastructure is extensible to easily support new kinds of content.\n\n</details>\n\n## Developer Workflow Team\n\n### 3.1. Improve acceptance test infrastructure\n\n**Project Description:** [Acceptance tests](https://github.com/oppia/oppia/wiki/Acceptance-Tests) are end-to-end tests organized by Critical User Journeys (CUJs). However, these tests are not as stable as we are expecting them to be. This project aims to improve the infrastructure of the acceptance tests to make it more stable and easy to manage. This includes but is not limited to migrating to Playwright from Puppeteer to reduce test flakiness, adding workflows to easily update snapshots, and documentation updates. Further, we expect using Playwright to reduce test flakiness, but some flakes will likely persist. This project includes fixing these persistent flakes. To limit the scope of this part of the project, you won't be expected to fix more than 10 persistent flakes (i.e. flakes that aren't fixed by the migration and weren't introduced by your changes). All of the acceptance test infrastructure issues can be found [here](https://github.com/orgs/oppia/projects/8/views/11?sliceBy[value]=[Project]+Fix+infrastructure+issues+in+the+acceptance+tests).\n\n**Tracking issues**:\n\n- Finish removing webdriverio tests: https://github.com/oppia/oppia/issues/23871\n- Migrate to Playwright: https://github.com/oppia/oppia/issues/24715\n- Document how to debug acceptance tests:\n  - https://github.com/oppia/oppia/issues/16136\n  - https://github.com/oppia/oppia/issues/22319\n  - https://github.com/oppia/oppia-web-developer-docs/issues/422\n- Infrastructure issues:\n  - Jest not exiting on time: https://github.com/oppia/oppia/issues/22251\n  - Assert expected console errors are present: https://github.com/oppia/oppia/issues/12770\n  - Give better error message when an element isn't clickable: https://github.com/oppia/oppia/issues/20142\n  - Method overriding issue in UserFactory: https://github.com/oppia/oppia/issues/22539\n  - Detect server errors: https://github.com/oppia/oppia/issues/21644\n  - Browser disconnecting: https://github.com/oppia/oppia/issues/22193\n  - We should not fast-fail on snapshot mismatches: https://github.com/oppia/oppia/issues/23776\n  - Capture screen recordings on CI for mobile tests: https://github.com/oppia/oppia/issues/23155\n- Flakes (which flakes are problematic may change over time):\n  - https://github.com/oppia/oppia/issues/22174\n  - https://github.com/oppia/oppia/issues/23106\n\n**Not in scope:** Writing new acceptance tests to increase coverage.\n\n**Size:** Medium (\\~175 hours)\n\n**Difficulty**: Easy\n\n**Potential mentors:** @jayam04\n\n**Product/technical clarifiers:** @U8NWXD (product), @jayam04 (technical)\n\n**Discussion forum:** https://github.com/oppia/oppia/discussions/categories/gsoc-q-a-3-dev-workflow-projects\n\n**Required knowledge/skills:**\n\n- Figure out the root cause of an issue and communicate it well using a debugging doc.\n- Debug and fix CI failures/flakes.\n- Make changes to GitHub Actions workflows.\n- Write Python code with unit tests.\n- Write or modify e2e/acceptance tests.\n- Fixing acceptance test flakes.\n\n**Related issues:**\n\n- https://github.com/oppia/oppia/issues/23871\n\n**Suggested Milestones:**\n\n- **Milestone 1**: Initialize and set up Playwright infrastructure to work in parallel with Puppeteer tests. Migrate all acceptance tests (described in our CUJ trackers for [internal](https://docs.google.com/spreadsheets/d/1DIZ0_Gmf9uhjTbhuDpA495PTjYZW9ZE97r6urS-iXwg/edit) and [external](https://docs.google.com/spreadsheets/d/1IrxN13IC5xwWdAFnGMu_4p3FU1ADL4QO-eLZIuTowIA/edit) users) to the Playwright framework. You may find the [Playwright team's official migration guide](https://playwright.dev/docs/puppeteer) helpful. Remove puppeteer infrastructure by ensuring python scripts and CI run every test using Playwright, and remove unused dependencies. Fix method overriding issue in UserFactory. Additionally, if webdriverio tests are not removed by GSoC start date, contributors will need to migrate webdriverio tests to Playwright in place of some infrastructure issues.\n\n- **Milestone 2**: Update test to not fast-fail on snapshot mismatch but complete the test steps before failing. Fix screen-recording failing in mobile tests. Add a guide for debugging flaky acceptance tests. Fix 10 acceptance test flakes.\n\n<details>\n<summary>Org-admin/tech-lead commentary/advice</summary>\n\nThis project is straightforward, however some level of CI understanding is required. Thus, folks with experience in Acceptance tests (writing and/or debugging) will be a good fit. There are a lot of tests, so folks taking shorter time in repetitive tasks will benefit.\n</details>\n\n<details>\n<summary>What we are looking for in proposals</summary>\n\nFor this particular GSoC project, the proposal is less important and we are more interested in your previous PRs. In particular, each of the following can significantly enhance your application:\n\n- Tackling at least one PR that solves a part of #23871.\n- Fixing some issues on acceptance tests infrastructure in the [Improve workflow for updating acceptance test screenshots](https://github.com/orgs/oppia/projects/8/views/11?sliceBy[value]=[Project]+Improve+workflow+for+updating+acceptance+test+screenshots) and [Fix infrastructure issues in acceptance tests](https://github.com/orgs/oppia/projects/8/views/11?sliceBy%5Bvalue%5D=%5BProject%5D+Fix+infrastructure+issues+in+the+acceptance+tests) themes on the dev workflow project board.\n- Showing at least one debugging doc that correctly diagnoses the root cause of an e2e/acceptance flake.\n- Making at least one PR that resolves at least one E2E/acceptance flakiness issue (many of these are collected here).\n\nSome things you should address in your proposal:\n\n- How will you support the Playwright and Puppeteer framework simultaneously? Explain changes you will make in python scripts and the config file ([`acceptance.json`](https://github.com/oppia/oppia/blob/develop/core/tests/ci-test-suite-configs/acceptance.json)).\n- Important parts of code that you need to take care of while migrating from Puppeteer to Playwright. E.g., Changing usage of ElementHandle to Locator.\n- How will you break down this project into individual sub-milestones? Provide a clear timeline for this.\n- How will you set up your debugging cycle so that you can easily figure out what is going wrong with a test, or fix a flake in it? Explain this for both (a) local development, and (b) getting a test to pass in the CI environment.\n</details>\n\n<details>\n<summary>Technical hints / guidance</summary>\n\n- Create a separate directory for Playwright tests, then migrate tests from Puppeteer to Playwright. In doing so, the contributor needs to make sure that the common code is always in sync. There can be conflicts - for instance when a function is used by tests in both Puppeteer and Playwright frameworks, changes to the function in any will create conflicts when we migrate remaining tests. This can be prevented by simply not allowing any function modification once we start migrating.\n- Update and use “Stress test (Acceptance test)” workflow to ensure that every new test is flake free.\n- Contributors should migrate to Playwright with as few changes as possible first. Then, once Puppeteer is completely removed, they can work on critical parts such as replacing all `ElementHandle` instances with `Locator`.\n- Initially, edit the `acceptance.json` config file to specify whether each test should be run under Puppeteer or Playwright. This will allow CI to run smoothly without requiring extensive changes as everything will be handled by Python script.\n</details>\n\n<details>\n<summary>Suggested PM demo points</summary>\n\nMilestone 1:\n\n- Running an acceptance test using python -m scripts.run_acceptance_tests should run acceptance tests in the Playwright framework. No acceptance test should use Puppeteer framework, and all the unused Puppeteer dependencies must be removed (i.e. Puppeteer Video Recording package).\n- CI should run all acceptance tests using Playwright framework and Internal User journeys using Puppeteer framework\n- Method overriding in UserFactory should throw an error.\n\nMilestone 2:\n\n- Every mobile acceptance test should record a complete test. (Can be verified by stress testing an acceptance test).\n- Running a test with snapshot mismatch, the test should take all steps after comparison and throw a snapshot mismatch error at the end. Test should also upload new snapshot taken as artifact.\n- We should have complete documentation on acceptance tests including updating screenshots, etc.\n- 10 acceptance test flakes have been resolved, and their tests now pass robustly.\n\n</details>\n\n### 3.2. Consolidate entity migration jobs\n\n**Project Description:**\n\nThe Oppia codebase includes several different versioned entities which store learning material: explorations, skills, stories, subtopic pages, questions, topics, and collections. The infrastructure to maintain each of these versioned entities has been developed separately, and is a bit patchy (for example, migrations of old snapshots have not been implemented for some of the entities). This is making it difficult to remove some of the old version upgrade functions in the codebase which are no longer needed.\n\nThe aim of this project is to standardize these migration jobs so that there is a single, standard way to migrate and upgrade versioned models. This will (a) ensure that all the versioned models can be easily updated on a periodic basis, (b) let us delete the code for upgrading from old versions once all the entities of that version have been upgraded, and (c) simplify the remaining version upgrade code.\n\n**Tracking issues**: [#22023](https://github.com/oppia/oppia/issues/22023)\n\n**Size:** Medium (\\~175 hours)\n\n**Difficulty**: Moderate\n\n**Potential mentors:** @kevintab95\n\n**Product/technical clarifiers:** @U8NWXD (product), @kevintab95 (technical)\n\n**Discussion forum:** https://github.com/oppia/oppia/discussions/categories/gsoc-q-a-3-dev-workflow-projects\n\n**Required knowledge/skills:**\n- Figure out the root cause of an issue and communicate it well using a [debugging doc](https://github.com/oppia/oppia/wiki/Debugging-Docs).\n- Write Python code with unit tests.\n- Write or modify Beam jobs, with tests.\n\nAdditionally, strong technical design skills and a good sense of code architecture are helpful.\n\n**Related issues:**\n\n- [#16556](https://github.com/oppia/oppia/issues/16556) is a good issue to look into, since it will help you become familiar with the migration job infrastructure.\n- [Issues related to Beam jobs](https://github.com/oppia/oppia/labels/Beam%20jobs) are also good ones to look at.\n\n\n**Suggested Milestones:**\n- **Milestone 1**: Create a BaseVersionedDomainObject which specifies object member mappings to storage model properties in a declarative way, and also specifies the \"schema version field\" corresponding to each JsonProperty-related field. Add tests to ensure that all JsonProperties are accounted for. Then, replace all existing domain objects for versioned models with subclasses of BaseVersionedDomainObject. Additionally, ensure that all functions that convert storage models to domain objects also migrate domain objects to the latest schema version.\n\n- **Milestone 2**: Create BaseMigrateVersionedModelJob and BaseMigrateVersionedModelSnapshotsJob classes with the core logic for upgrading models and snapshots to the latest schema versions, respectively. Use these to build both job and audit job subclasses for all versioned models (explorations, skills, stories, subtopic pages, questions, topics, collections) with proper logging and error reporting (e.g. if a migration fails, the model that could not be migrated should be logged for debugging). Test these jobs on production data to ensure that they work correctly, and fix any issues that arise. Finally, run all the jobs in all our production environments, so that all the models and snapshots on the server are upgraded to the latest schema versions, then remove the old jobs and the old conversion functions for all 7 versioned models, as well as the methods they call (similar to what was done in https://github.com/oppia/oppia/pull/12256/files).\n\n\n<details>\n<summary>Org-admin/tech-lead commentary/advice</summary>\n\nThis project requires a very good understanding of how our migration pipeline works, and a solid grasp of technical architecture so that you can make good design decisions for how the base classes and their subclasses are structured. However, once that is well-understood, it should not be too difficult to implement. You will probably find deleting all the old code at the end quite satisfying!\n</details>\n\n<details>\n<summary>What we are looking for in proposals</summary>\n\nIn addition to your implementation approach, please also:\n\n  - Analyze the jobs for the existing entities to understand and catalogue their differences. Then, for each of those differences, make a proposal for how you plan to standardize it, and explain the implementation of each of the resulting base job and audit job classes for migrating entities and entity snapshots.\n  - Describe what error reporting or logging you would add to the Beam job to make it easy for you or server admins to detect/debug issues when it is run.\n  - Describe how you would name the new jobs. Try to use a standard naming convention that is easily extended to versioned models that are introduced in the future.\n  - For each entity type, list the functions/constants that you plan to delete (in addition to the conversion methods) after you have confirmed that all models are using the latest schema versions. Describe how you determined that this is the complete list of orphaned functions/constants.\n  - Provide a full example of how you would set up the BaseVersionedDomainObject with declarative definitions for at least one of the existing versioned models. Clarify what goes into the base domain object and what goes into the subclasses.\n  - List the validation checks that the versioned domain object classes must satisfy, and describe how your backend tests will automatically pick up all the versioned domain object classes in the codebase when new ones are added.\n\n</details>\n\n<details>\n<summary>Technical hints / guidance</summary>\n\n- There are existing jobs and audit jobs in the codebase for migrating models and snapshots (e.g. MigrateExplorationJob, ExpSnapshotsMigrationAuditJob, etc.). All these should be deleted at the end of the project. This old wiki page with instructions for writing schema migrations might also provide some useful background: https://github.com/oppia/oppia/wiki/Writing-state-migrations\n\n- The bulk of the logic for all the new jobs should be in the two base classes, BaseMigrateVersionedModelJob and BaseMigrateVersionedModelSnapshotsJob. In general, if some functionality is common to all versioned models, it should be included in the base class, otherwise it should be defined in the relevant subclass(es). Ideally, the subclasses would just point to the relevant storage models / domain object classes and not include any custom logic – see `SNAPSHOT_METADATA_CLASS` in `ExplorationModel` for an example of this. The corresponding audit jobs for these two jobs should be trivial subclasses of the main jobs with `DATASTORE_UPDATES_ALLOWED = False`. (Look at the usage of `DATASTORE_UPDATES_ALLOWED` in the codebase for more information.)\n\n- Part of this project includes standardizing the infrastructure for migrating JSON properties. Here is a more detailed technical sketch for how this could be done:\n\n  - Create a BaseVersionedDomainObject whose subclasses declaratively specify a mapping from any versioned field to its corresponding schema version field. (These fields correspond to `JsonProperty` in the datastore's storage model.) Un-versioned fields of type `Dict` or `List[Dict]`` should be explicitly declared as un-versioned. Subclasses must also reference constants in feconf.py that specify the minimum and maximum version of each field.\n\n  - Write backend tests that:\n    - Identify all subclasses of BaseVersionedDomainObject in the codebase and verify that every `Dict` or `List[Dict]`` field contained in the object is either included in the mapping mentioned above or included in a list of un-versioned fields. This ensures that all versioned domain objects have the necessary infrastructure for performing schema upgrades for their respective JsonProperties.\n    - Ensure that the relevant migration functions for each upgradable field are present in the corresponding domain object class with the function signatures (including type hints). Specifically, each conversion function should accept one parameter of the same type as the versioned field and should return one value of the same type. The migration functions can be named using a standard scheme, e.g. `_convert_{{field_name}}_v{{x}}_dict_to_v{{x+1}}_dict`, and the backend test can check for that. This test should also use the minimum and maximum schema versions to check that upgrade functions from the minimum up to the maximum version are present.\n\n  - Add a `migrate_to_latest_schema_versions` function to BaseVersionedDomainObject to handle schema upgrades in a generalized way across all domain objects.\n  - Ensure that all the different getter functions in the _services/fetchers.py files that convert storage models to domain objects also use `migrate_to_latest_schema_versions` to translate that object’s fields to use the latest schema versions.\n  - Replace all domain objects corresponding to VersionedModels with the new BaseVersionedDomainObject.\n\n- Here's a schematic depiction of a possible end state for versioned domain models:\n\n  ```\n  class BaseVersionedDomainObject:\n    - Class Variables:\n       - schema_versioned_attributes = {}\n    - Methods:\n      - def migrate_to_latest_schema_versions():\n        - Use the versioned_attributes map to find versioned fields. Then call update functions on each of those until the entire domain object is fully upgraded.\n\n  class Exploration(BaseVersionedDomainObject:\n    - Class Variables:\n      -  schema_versioned_attributes: {\n          \"states_dict\": {\n            \"version_field\": \"states_schema_version\",\n            \"version_min\": feconf.MIN_STATE_SCHEMA_VERSION (e.g. 5),\n            \"version_max\": feconf.CURRENT_STATE_SCHEMA_VERSION (e.g. 10)\n          }\n        }\n    - Methods:\n      - def _convert_states_v5_dict_to_v6_dict\n      - ...\n      - def _convert_states_v9_dict_to_v10_dict\n  ```\n</details>\n\n<details>\n<summary>Suggested PM demo points</summary>\n\n- Milestone 1: At least one domain object is using BaseVersionedDomainObject, and all the get/save functionality works correctly. All applicable frontend, backend, and acceptance tests have been written and pass robustly.\n\n- Milestone 2: All jobs run correctly on the backup server. All applicable frontend, backend, and acceptance tests have been written and pass robustly.\n</details>\n\n\n### 3.3. Standardize and validate domain objects and storage models\n\n**Project Description:**\n\nOppia's production data is organized using [NDB storage models](https://github.com/oppia/oppia/wiki/Storage-models#storage-model-concepts), which in simple terms can be thought of as objects having different properties. For instance, data related to a user can be stored in a UserSettingsModel with properties like username, user ID, etc.\n\nDifferent inter-model relationships exist as well, corresponding to relationships between prod data. For instance, a story includes a list of explorations. So, a StoryModel might include the IDs of all the ExplorationModels it is composed of.\n\nFor proper functioning of the Oppia application, it is important to ensure that all the models are internally consistent and that the relationships between models are valid. The aim of this project is therefore to ensure that all production data is valid by:\n\n  - Ensuring that domain objects exist for all prod models, and that they have full `validate()` functions.\n\n  - Implementing Beam jobs that audit production data and flag any errors. These jobs should validate the model properties as well as inter-model relationships. After these jobs are run, any errors should be investigated, and checks should be implemented to ensure that such problems don’t reoccur in the future with new data.\n\n**Tracking issues**:\n- [#21970](https://github.com/oppia/oppia/issues/21970)\n- [#21905](https://github.com/oppia/oppia/issues/21905)\n- [#21869](https://github.com/oppia/oppia/issues/21869)\n\n**Not in scope:** Migrating existing datastore data to address the validation issues found in the first milestone.\n\n**Size:** Large (\\~350 hours)\n\n**Difficulty**: Moderate\n\n**Potential mentors:** @ankita240796\n\n**Product/technical clarifiers:** @U8NWXD (product), @ankita240796 (technical)\n\n**Discussion forum:** https://github.com/oppia/oppia/discussions/categories/gsoc-q-a-3-dev-workflow-projects\n\n**Required knowledge/skills:**\n- Figure out the root cause of an issue and communicate it well using a [debugging doc](https://github.com/oppia/oppia/wiki/Debugging-Docs).\n- Write Python code with unit tests.\n- Write or modify Beam jobs, with tests.\n\n\n**Related issues:**\n\n- https://github.com/oppia/oppia/issues/21970\n- https://github.com/oppia/oppia/issues/21905\n- https://github.com/oppia/oppia/issues/21869\n- The first checkbox item from any of the following:\n  - https://github.com/oppia/oppia/issues/14968\n  - https://github.com/oppia/oppia/issues/14967\n  - https://github.com/oppia/oppia/issues/14969\n  - https://github.com/oppia/oppia/issues/14971\n  - https://github.com/oppia/oppia/issues/14972\n\n\n**Suggested Milestones:**\n\n- **Milestone 1**: Domain objects exist for all storage models, and include validate() methods that fully validate the domain object's internal consistency and correctness. The usage of storage models in the domain layer is restricted to the interfaces for getting and saving datastore models, and they are not passed further around the codebase. 50% of the validation jobs for the storage models are implemented and run successfully. For each validation error found, an issue is filed with clear action steps for (a) stopping the error from happening for new data, and (b) migrating old data to fix the error.\n\n- **Milestone 2**: All remaining validation jobs for the storage models are implemented and run successfully, and issues are filed for all validation errors as described in Milestone 1. All root causes of the validation issues found in Milestones 1 and 2 are identified and fixed, so that the error no longer happens for new data. (This corresponds to part (a) of each issue in Milestone 1.)\n\n\n<details>\n<summary>Org-admin/tech-lead commentary/advice</summary>\n\nThis project is relatively straightforward if you can identify the validation checks correctly and are able to analyze the codebase to figure out why incorrect data is being written. The [design brief](https://docs.google.com/document/d/1u45oC6igsaTvQl4oNd8VvDiZe3JqeY3m_5n4QZ6d4rA/edit?usp=sharing) provided in the technical hints should help provide a lot of the necessary structure. Note that the validation requirements for the different models can vary greatly in terms of difficulty.\n</details>\n\n<details>\n<summary>What we are looking for in proposals</summary>\n\nFor your proposal, please include the following:\n\n  - A complete list of all storage models, with “validity” clearly defined for (a) the corresponding domain objects, (b) the models themselves (including inter-model relationships).\n\n  - How you would structure the sub-milestones to enable you to run jobs efficiently on the server in batches.\n\n  - A worked example of how you would do each part of the project (domain-object creation, only using storage models in get/put, writing a validation job, filing the GitHub issue, fixing the root cause). You can link to sample PRs if you like. For the purposes of this illustration, we suggest that you pick one or two \"average\" or \"hard\" examples – try not to pick a trivial model.\n\n  - Any complicated cases you identify for any of the above steps, and an explanation of how you would tackle them. (For example, customization arg validation for interactions.)\n\n  - An explanation of how you would ensure/verify that storage models are not used beyond the get and save functions in the `*_services.py` file. (For example, you might come up with a standard pattern for get/save that you can implement universally to make that verification easy to do, or you might analyze import statements that involve to the storage layer, or you might add a backend test to ensure that ndb.Model instances are not passed beyond specific functions.)\n\n\nWe also recommend taking up at least one checkbox item from each of the following, in order to confirm that this project is a good fit for you:\n  - https://github.com/oppia/oppia/issues/21970\n  - https://github.com/oppia/oppia/issues/21869\n  - The first checkbox from any of the following (to demonstrate ability to “identify the root cause of an error and stop it from happening”):\n    - https://github.com/oppia/oppia/issues/14968\n    - https://github.com/oppia/oppia/issues/14967\n    - https://github.com/oppia/oppia/issues/14969\n    - https://github.com/oppia/oppia/issues/14971\n    - https://github.com/oppia/oppia/issues/14972\n\n</details>\n\n<details>\n<summary>Technical hints / guidance</summary>\n\n- Please go through the following guides in the Oppia wiki:\n\n  - [Storage models](https://github.com/oppia/oppia/wiki/Storage-models#storage-model-concepts)\n  - [Testing jobs and other features on production](https://github.com/oppia/oppia/wiki/Testing-jobs-and-other-features-on-production)\n  - [Debugging datastore locally](https://github.com/oppia/oppia/wiki/Debugging-datastore-locally)\n  - [Apache Beam Jobs](https://github.com/oppia/oppia/wiki/Apache-Beam-Jobs) · oppia/oppia Wiki · GitHub\n    - Note that, in general, any Beam jobs you write should be **idempotent**, i.e., running them twice should result in the same outcome as running them once. This allows us to just rerun them if a job fails for some reason (e.g. due to an internal Beam error).\n\n- See [this design brief](https://docs.google.com/document/d/1u45oC6igsaTvQl4oNd8VvDiZe3JqeY3m_5n4QZ6d4rA/edit?usp=sharing) for a design approach that you can follow for the validation jobs.\n\n- To understand how validation jobs work, you might like to take a look at the existing [audit and validation jobs](https://github.com/oppia/oppia/tree/develop/core/jobs/batch_jobs). Some examples:\n  - https://github.com/oppia/oppia/blob/develop/core/jobs/batch_jobs/user_validation_jobs.py\n  - https://github.com/oppia/oppia/blob/develop/core/jobs/batch_jobs/blog_validation_jobs.py\n</details>\n\n<details>\n<summary>Suggested PM demo points</summary>\n\n- Milestone 1: Validation jobs for at least 5 prod models are written & run, and errors arising from those jobs have been filed as issues on GitHub. All applicable frontend, backend, and acceptance tests have been written and pass robustly.\n\n- Milestone 2: A full list of errors is compiled with clear action items. All applicable frontend, backend, and acceptance tests have been written and pass robustly.\n</details>\n\n## Android team\n\n### 4.1 Support for Study Guides & Worked Examples, and Modernizing HTML Handling\n\n**Project Description:**\nThe Oppia web platform introduced support for worked examples (through a custom rich-text tag) and study guides (which are a repurposed section-by-section representation of the old revision cards). We would like to bring this functionality into the Oppia Android app, along with some substantial infrastructural improvements to how HTML handling is done.\n\nThe web version of the Study Guide mocks can be seen in [this Figma project](https://www.figma.com/design/xVkmX0xZdNCpj9CP7ec6pG/Learner-View-of-Revision-Card?node-id=0-1&t=Lt8v5o8bmEg0X1ct-1). This project involves creating basic mocks for how the UI should change to support the new sections, getting these mocks reviewed and finalized by the design team (during the community bonding period), and implementing those mocks.\n\nWorked examples are actually not being directly implemented in the UI as part of this project. This is due to the significant complexity of actually implementing a custom tag handler that can render an interactive drop-down experience like the web platform provides for worked examples. This can't effectively be done with a mere `TextView` without substantially breaking the accessibility Talkback experience. As such, this project actually plans to inline the worked examples to a basic 'question' and 'answer' format (similar to what content creators needed to do before the tag was implemented). That means this is a change only in the lesson download script/import pipeline rather than directly in the app.\n\nFinally, the process of breaking down and considering implementation strategies for worked examples yielded a realization: in order to actually support the full UI experience in the future the app would need to support actually breaking up HTML components into `RecyclerView`-esque lists for proper styling. The exact implementation of this is still not fully known and rather challenging (since nested navigation may be needed for Talkback--this requires user testing). While actually building the correct long-term solution isn't obvious, there's a prerequisite that _can_ be completed now and provides a variety of other stability benefits: replacing the representation of HTML text from actual HTML to a structured proto representation. This requires changes in:\n- The [proto API](https://github.com/oppia/oppia-proto-api).\n- The lesson download script.\n- The existing protos.\n- HTML parsing (which will essentially be fully replaced by a 'span building' systems interpreted from proto structures).\n\nNote that all of this functionality must be gated behind a feature flag on the app side.\n\n**Tracking issues**:\nTo be added soon.\n\n**Not in scope:** Implementing the full box-like UI and collapsible sections that Oppia web has for worked examples.\n\n**Size:** Large (\\~350 hours)\n\n**Difficulty**: Moderate\n\n**Potential mentors:** @MohitGupta121\n\n**Product/technical clarifiers:** @BenHenning (product & technical), @MohitGupta121 (technical)\n\n**Discussion forum:** https://github.com/oppia/oppia-android/discussions/categories/gsoc-q-a-4-android-projects\n\n**Required knowledge/skills:**\n- Figure out the root cause of an issue and communicate it well using a [debugging doc](https://github.com/oppia/oppia/wiki/Debugging-Docs).\n- Build the app and install it on a local device or emulator. Then verify that you can:\n  - (a) build a non-test library target locally\n  - (b) run a unit test locally\n  - (c) play through the app locally\n- Write new Kotlin code with unit tests.\n- Change Android UIs, write tests for them, and manually verify that they work.\n- Familiarity with how the team uses Kotlin scripts (recommended to have actually written or changed one, but this isn't a strong requirement).\n\n**Related issues:**\n- https://github.com/oppia/oppia-android/issues/5963\n- https://github.com/oppia/oppia-android/issues/5844\n\n**Suggested Milestones:**\n\n- **Milestone 1**:\n  - Introduction of a new feature flag to gate the worked examples and study guides functionality.\n  - Support for the new study guides experienced, gated behind the feature flag.\n  - Support for worked examples, gated behind the feature flag.\n\n- **Milestone 2**:\n  - Updates to app, script, and API protos to support the new structure.\n  - Introduction of a new feature flag to gate the HTML-alternative text representation.\n  - New string builder utility introduced with interoperability with the existing handlers to parse the new representation and build the necessary string to bind.\n  - Updates to the lesson download script and import pipeline to parse HTML and convert it to the new structure. Specific requirements:\n    - The script should output both the HTML & new representation for each structure (duplicated). The app should support loading from both depending on the flag being enabled.\n    - The following enforcement checks are added:\n      - Hard fail if any unexpected tags or tag attributes are encountered.\n      - Hard fail if the JSON structure for math tags are missing any properties.\n      - Hard fail if any expected \"block\" tags have other nested \"block\" tags (such as worked examples not containing other worked examples).\n\n<details>\n<summary>Org-admin/tech-lead commentary/advice</summary>\n\nComing soon.\n\n</details>\n\n<details>\n<summary>What we are looking for in proposals</summary>\n\nComing soon.\n\n</details>\n\n<details>\n<summary>Technical hints / guidance</summary>\n\nComing soon.\n\n</details>\n\n<details>\n<summary>Suggested PM demo points</summary>\n\n- Milestone 1: That worked examples and study guides are supported, and only show when the corresponding feature flag is enabled.\n\n- Milestone 2: That the app correctly renders the new proto representation of text when the corresponding feature flag is enabled. This may require some real-time hacking to demonstrate that the app is actually using the proto rather than HTML representation, and some code and textproto walkthrough to demonstrate that the lesson script is actually converting the HTML correctly.\n</details>\n\n### 4.2 Streamlining Release Automation\n\n**Project Description:**\nThe Oppia Android team currently needs to follow a manual, 17-page release process that is both incomplete and has out-of-date instructions, for each release of the app. This highly error-prone and complex manual process leads to multiple hours needing to be spent every time the team wants to ship a new release to end users. This project aims to significantly reduce the burden on the development team to conduct releases by:\n- Cleaning up and modernizing the release process to be a wiki page rather than a private Google document.\n- Introducing a variety of scripts and GitHub Actions tooling to reduce most of the steps of the process to simple \"one-click\" deployments to eliminate most of the complexity and time-consuming nature of the existing release process.\n\nOne important note for this project is that the team currently only deploys to the Google Play Store. This project will include, as part of its deployment scripts, introducing support for deploying testable builds to [Firebase App Distribution](https://firebase.google.com/docs/app-distribution) to solve a very big headache that currently exists for the QA team: actually installing the correct version of the app. There's well-known synchronization issue wih Play Store that makes it difficult to actually guarantee testers get the correct build at the correct time, and it has caused multiple testers in the past to outright not be able to help with QA for past releases. Firebase App Distribution is expected to fully mitigate this problem and provide QA even more control over testing (such as by being able to switch between multiple release flavors rather than only being limited to a single flavor as is the case for the Play Store's Internal Testing release channel).\n\nPlease also note the difficulty of this project. We are assuming most of the deployment steps will require small, custom Kotlin scripts (in-line with other scripts in the codebase) and are not solvable with existing deployment solutions. It may be the case that there are such solutions possible, but the team's own research suggests that we almost certainly have to build out this tooling from scratch due to the prerequisite for Bazel integration. We do expect existing libraries and tooling to be used for directly integrating with Play Store and Firebase.\n\n**Tracking issues**:\nComing soon.\n\n**Not in scope:** Cron jobs to fully automate the beta & GA launches, or changelog translations (since the team plans to rely on automated translations for these). The steps for archiving releases, creating the release on GitHub, emailing the marketing team, and creating a GitHub discussion are all also not part of the project.\n\n**Size:** Large (\\~350 hours)\n\n**Difficulty**: Hard\n\n**Potential mentors:** @adhiamboperes\n\n**Product/technical clarifiers:** @BenHenning (product & technical), @adhiamboperes (technical)\n\n**Discussion forum:** https://github.com/oppia/oppia-android/discussions/categories/gsoc-q-a-4-android-projects\n\n**Required knowledge/skills:**\n- Figure out the root cause of an issue and communicate it well using a [debugging doc](https://github.com/oppia/oppia/wiki/Debugging-Docs).\n- Build the app and install it on a local device or emulator. Then verify that you can:\n  - (a) build a non-test library target locally\n  - (b) run a unit test locally\n  - (c) play through the app locally\n  - (d) build _each_ flavor of the app: dev, alpha, beta, GA.\n- Write new Kotlin code with unit tests.\n- Strong understanding of all the steps of the Oppia Android release process, and why each step is needed.\n- Familiarity with how the team uses Kotlin scripts (recommended to have actually written or changed one, but this isn't a strong requirement).\n- Familiarity with GitHub Actions and a strong concept of how cron jobs work.\n\n**Related issues:**\n- https://github.com/oppia/oppia-android/issues/5033\n- https://github.com/oppia/oppia-android/issues/5984\n- https://github.com/oppia/oppia-android/issues/3923\n- https://github.com/oppia/oppia-android/issues/5394\n- Related documentation:\n  - https://github.com/oppia/oppia-android/wiki/Platform-Parameters-&-Feature-Flags will relate to the feature release process.\n  - [Oppia Android release process](https://docs.google.com/document/d/1XAoXnQkn2oIAFkd6vY90tn_SSW3J9Eia0_4RhXhJSxQ/edit?tab=t.0). Note: this is almost 4 years out-of-date, so it will have some steps wrong. It will be updated soon to cover the latest steps.\n  - [GSoC project 6.1 from 2022](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2022#61-android-release-automation) included some of the same goals, but 2026's version is much more streamlined and targetd on specific pieces of automation.\n\n**Suggested Milestones:**\n\n- **Milestone 1**:\n  - Introduce support for maintaining a check-in version of the app changelog. Specifically, this changelog should:\n    - Provide a historical record of changes that goes into each release, mapped to major.minor release version.\n    - Be used as default for every flavor of the app unless that flavor has an override and a custom changelog to use (which needs to be supported).\n  - Support for the following new GitHub actions that can be manually triggered through the GitHub web interface:\n    - Deploy to Firebase App Distribution.\n    - Deploy to Play Store.\n    - Upload the changelog to Play Store.\n  - Note that each of the new actions above needs to:\n    - Work for each of the alpha, beta, and GA flavors of the app, and upload to the correct corresponding track.\n    - Be one action for all of the flavors (selecting the flavor should be an input).\n    - Work correctly for the changelog, meaning the correct changelog (version & flavor) is selected and is uploaded to the correct release track.\n\n- **Milestone 2**:\n  - Rewrite the existing release documentation and publish it as multiple wiki pages, also accounting for release features. The following pages should be added as a new 'Releasing' top-level section:\n    - An overview of the binary & feature release process.\n    - A high-level playbook for release coordinators detailing the steps they need to take for creating a new release and releasing it. These will mostly be using the new automation introduced in milestone 1. It also will need to account for the new release process that happens once https://github.com/oppia/oppia-android/issues/5033 is addressed.\n    - A more detailed playbook that provides detailed steps for manually performing each step necessary (for cases when GitHub Actions is broken or unavailable). Parts of this page will be linked to from the previous page so that it's easy to jump to manual instructions if needed.\n    - A playbook for developers adding new features and guiding them through the release process.\n  - Introduction of automatic generation for the following release artifacts:\n    - Changelogs: each time the minor version of the app is updated (a la [version.bzl](https://github.com/oppia/oppia-android/blob/develop/version.bzl)), a script should kick off to generate a new changelog for that version and automatically propose a PR to make the change. Specific requirements:\n      - The branch must be directly on the repository so that team members can edit it.\n      - The changelog should be sourced from all merged PRs and referenced issues since the last release (which is how GitHub generates its automated changelog for new releases).\n      - An LLM should be invoked using the above source material to provide a suggested, brief description of changes geared towards end users.\n      - The PR description for the proposed changelog should contain links to all of the reference material so that team members can choose to alter the context provided by the LLM.\n      - **Important**: The changelog is always for the _previous_ version (i.e. if we update the version from 1.1 to 1.2, then 1.1's changelog is what needs to be generated since 1.2 is now the unreleased developer build and 1.1 is soon to be released). Note that this is a difference from the past when the major/minor version represented the previous release.\n    - Lesson pinning: the lesson download script relies on a generated textproto file that contains all of the lesson IDs and versions to download. This file will soon be checked into `develop`, so a new cron job should be introduced that periodically (weekly to start) re-runs the download script that produces the pinned version file and introduces a PR for it. Specific requirements:\n      - Every week, run the script to generate a new pinned lesson textproto and propose a PR to update it.\n      - The same branch is used each time, similar to the Translatewiki model.\n      - If the branch already has an open PR, force push the changes (in general, always run against latest `develop` and force push the proposed changes into the branch).\n  - Introduce automated release cron for alpha: a new cron job that automatically pushes new alpha flavors of the app to their corresponding channels. Specific requirements:\n    - The cron should run weekly (i.e. we never push alpha more than once per week).\n    - The cron finds the most recent commit to `develop` with passing CI checks and compares it against the rolling alpha version of the app (which is denoted using the tag `latest-alpha`).\n    - If the commits are different, `latest-alpha` is updated to the latest passing CI `develop` commit and that version of the app is built and automatically deployed to both Firebase and Play Console.\n    - Note that this should be done in two steps: a workflow that performs all of the alpha detection and build kick-off work, and a cron that runs it. The former should be able to be manually started, as well.\n\n<details>\n<summary>Org-admin/tech-lead commentary/advice</summary>\n\nComing soon.\n\n</details>\n\n<details>\n<summary>What we are looking for in proposals</summary>\n\nComing soon.\n\n</details>\n\n<details>\n<summary>Technical hints / guidance</summary>\n\nComing soon.\n\n</details>\n\n<details>\n<summary>Suggested PM demo points</summary>\n\n- Milestone 1: Demonstrating each of the new actions works with a test-only version of the app.\n\n- Milestone 2: Walk through the new wiki pages to demonstrate their content. Demonstration of the automatic changelog and lesson pinning crons running. Demonstration of the alpha cron automatically running.\n</details>"
  },
  {
    "name": "FOSSASIA",
    "slug": "fossasia-bg",
    "tagline": "Free and Open Source Software in Asia",
    "description": "FOSSASIA is an organization developing Open Source software applications and Open Hardware together with a global community from its base in Asia. It is our goal to provide access to open technologies, science applications and knowledge that improve people's lives. We want to enable people to adapt and change technology according to their own ideas and needs and validate science and knowledge through an Open Access approach. FOSSASIA was established 2009 by Hong Phuc Dang and Mario Behling. We organize and participate in conferences, meetups and code camps. The annual FOSSASIA Summit is one of the top tech events in Asia. Other summits take place in Vietnam, Cambodia, Thailand and India. FOSSASIA also runs a number of coding programs such as Codeheat. Please join us and start contributing to our projects, participate as a coder, designer, hardware developer or event organizer.",
    "ideas_url": "https://docs.google.com/document/d/1Tz1KxYefreKzBr98C4vbCv9UwnchZoyTwO8rBrz_lmg/edit?tab=t.0#heading=h.9sjk3ie7l2o2",
    "website_url": "https://fossasia.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "python",
      "javascript",
      "django",
      "android"
    ],
    "topic_tags": [
      "web",
      "hardware",
      "event solutions",
      "android",
      "firmware"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/fossasia-bg",
    "ideas_content": "Die Datei kann in Ihrem Browser nicht geöffnet werden, weil JavaScript nicht aktiviert ist. Aktivieren Sie JavaScript und laden Sie die Seite noch einmal.\nFOSSASIA GSoC 2026 Ideas List\nTab\nExtern\nFreigeben\nAnmelden\nDatei\nBearbeiten\nAnsicht\nTools\nHilfe\nBedienungshilfen\nFehlerbehebung"
  },
  {
    "name": "KDE Community",
    "slug": "kde-community",
    "tagline": "Control your digital life",
    "description": "Community of technologists, designers, writers and advocates who work to ensure freedom for all people through our software.",
    "ideas_url": "https://community.kde.org/GSoC/2026/Ideas",
    "website_url": "https://kde.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c++",
      "qt",
      "qml",
      "data structures"
    ],
    "topic_tags": [
      "education",
      "science",
      "applications",
      "desktop environment"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/kde-community",
    "ideas_content": "# GSoC/2026/Ideas\n\nSee also: [GSoC Instructions](https://community.kde.org/GSoC), [Last year ideas](https://community.kde.org/GSoC/2025/Ideas)\n\n## Guidelines\n\n### Information for Students\n\n**Read https://community.kde.org/GSoC#Instructions_for_potential_contributors**\nIt contains important information about the process and KDE stance on AI.\n\nThese ideas were contributed by our developers and users. They are sometimes vague or incomplete. If you wish to submit a proposal based on these ideas, you are urged to contact the developers and find out more about the particular suggestion you're looking at.\n\nBecoming accepted as a Google Summer of Code student is quite competitive. Accepted students typically have thoroughly researched the technologies of their proposed project and have been in frequent contact with potential mentors. **Simply copying and pasting an idea here will not work. Neither will generating a proposal with ChatGPT or equivalent!** On the other hand, creating a completely new idea without first consulting potential mentors rarely works.\n\nWhen writing your proposal or asking for help from the general KDE community don't assume people are familiar with the ideas here. KDE is really big!\n\nIf there is no specific contact given you can ask questions on the general KDE development list [[email protected]](https://community.kde.org/cdn-cgi/l/email-protection). See [the KDE mailing lists page](http://www.kde.org/mailinglists/) for information on available mailing lists and how to subscribe.\n\n\n\n### Adding a Proposal\n\nWhen adding an idea to this section, please include the following data:\n\n- if the application is not widely known, a description of what it does and where its code lives\n- a\n**brief explanation**(2-5 sentences, do not just put a link to a bug) - the expected size of the project (small-90 hours, medium-175 hours or large-350 hours)\n- the expected results\n- pre-requisites for working on your project (skills required/preferred)\n- if applicable, links to more information or discussions\n- mailing list or IRC channel for your application/library/module\n- your name and email address for contact (if you're willing to be a mentor)\n- if possible, an easy, medium or hard rating of the project\n\n\nIf you are not a developer but have a good idea for a proposal, get in contact with relevant developers first.\n\n\n\n### Project: Something that you're totally excited about\n\n**Brief explanation:** Do you have an awesome idea you want to work on with KDE but that is not among the ideas below? That's cool. We love that! But please do us a favor: Get in touch with a mentor early on and make sure your project is realistic and within the scope of KDE. That will spare you and us a lot of frustration.\n\n**Expected results:** Something you and KDE loves\n\n**Knowledge Prerequisite:** Probably C++ and Qt but depends on your project\n\n**Duration:** Mention one of ~90, ~175 or ~350 hours of effort necessary to finish the project. Use only one of these three project classes and don't come up with other numbers here.\n\n**Difficulty:** Easy, medium or difficult project\n\n**Mentor:** Try to see who in KDE is interested in what you want to work on and approach them. If you are unsure you can always ask in [#kde-soc:kde.org](https://matrix.to/#/#kde-soc:kde.org) on matrix.\n\n\n\n# Ideas\n\n\n\n## Mankala\n\nMancala games are played all over the world and have many variants.\n\n### Add a new Mancala Variant to Mankala Engine\n\n**Project type:** Coding\n\n**Brief explanation:** Add a new variant to Mankala Engine.\n\n**Expected results:** An incomplete list of variants can be found on [[Wikipedia](https://en.wikipedia.org/wiki/List_of_mancala_games)]. Add a variant and test it out with people that play the know how to play the game.\n\n**Knowledge Prerequisite:** C++\n\n**Duration:** 175 hours\n\n**Difficulty:** Medium\n\n**Mentor:** Benson Muite, talk to me at [https://matrix.to/#/#mancala:kde.org](https://matrix.to/#/#mancala:kde.org)\n\n### Enable Tournaments in Mankala\n\n**Project type:** Coding\n\n**Brief explanation:** Add a new variant to Mankala Engine.\n\n**Expected results:** Build upon QXmpp to enable tournaments for mancala games in Mankala engine. The tournaments will be held online and can be run over several days during which people will play against each other or against computer opponents to find a champion. For inspiration see [https://kibao.org/](https://kibao.org/)\n\n**Knowledge Prerequisite:** C++\n\n**Duration:** 175 hours\n\n**Difficulty:** Medium\n\n**Mentor:** Benson Muite, talk to me at [https://matrix.to/#/#mancala:kde.org](https://matrix.to/#/#mancala:kde.org)\n\n## Okular\n\nOkular is a universal document viewer developed by KDE. Okular works on multiple platforms, including but not limited to Linux, Windows, Mac OS X, *BSD. Contact the Okular developers.\n\n### Implement font subsetting when saving PDF files\n\n**Project type:** Coding\n\n**Brief explanation:** PDF files can contain annotations/forms. Users can write arbitrary text on those, meaning we need to embed the font to the PDF so other users on other systems can open those files. At this point we are embedding the full font when saving, which is non optimal space wise since modern fonts can be huge. PDF has this concept of subsetting in which only the characters needed for that particular text are added. We want to implement that. Most of the work will be done in poppler.\n\n**Expected results:** When saving a PDF file with a new annotation that contains 4 characters, instead of embedding the full font to the PDF, only a font with those 4 characters is added to the PDF.\n\n**Knowledge Prerequisite:** C++\n\n**Duration:** 350 hours\n\n**Difficulty:** Medium\n\n**Mentor:** Albert Astals Cid <[[email protected]](https://community.kde.org/cdn-cgi/l/email-protection)>, talk to me at [https://matrix.to/#/#okular:kde.org](https://matrix.to/#/#okular:kde.org)\n\n### PDF Image Alt text support via Structured information\n\n**Project type:** Coding\n\n**Brief explanation:** PDF files can contain structured information about the file. Poppler, the library we use to work with PDF files, reads it (at least partially). But the qt frontend of Poppler does not expose that information. The project would involve exposing that information in poppler-qt and then using it in Okular to be able to use it.\n\n**Expected results:** The pdf file from bug 512838 shows ALT text as a tooltip\n\n**Knowledge Prerequisite:** C++\n\n**Duration:** 350 hours\n\n**Difficulty:** Medium\n\n**Mentor:** Albert Astals Cid <[[email protected]](https://community.kde.org/cdn-cgi/l/email-protection)>, talk to me at [https://matrix.to/#/#okular:kde.org](https://matrix.to/#/#okular:kde.org)\n\n## Marknote\n\n### Project: Implement block editor\n\n**Brief explanation:** Implement a basic block editor where each elements from markdown is transformed into a block which can be drag-and-dropped.\n\nInspiration can be taken from [https://rubymamistvalove.com/block-editor](https://rubymamistvalove.com/block-editor)\n\n**Expected results:** A nice rich text editor which can then be also reused in other apps like Merkuro Mail.\n\n**Knowledge Prerequisite:** C++, Qt, will also involve some Qml\n\n**Duration:** ~350 hours\n\n**Difficulty:** Medium\n\n**Mentor:** Carl Schwan ([https://matrix.to/#/#marknote:kde.org](https://matrix.to/#/#marknote:kde.org))\n\n## digiKam\n\n### Project: Interface the database search engine to an AI based LLM\n\n**Brief explanation:** The digiKam photo management program already allows the user to search items over the collections using a database. Many powerful search tools can find items by many criteria such as metadata, aesthetic contents, face, place, date, hierarchical keywords, etc. The idea is to add a new top-level interface where users can enter a human phrase which describes the contents to search. With this change, the searches can be user-friendly to use without having to pass plenty of settings used to tune the engine. The LLM must be included in the application, without using an external web-service, as it's not permitted to share data over the Internet. All the new implementations must be written in C++, not Python.\n\nRelevant entries in bugzilla:\n- [wish 497938](https://bugs.kde.org/show_bug.cgi?id=497938)\n- [wish 367700](https://bugs.kde.org/show_bug.cgi?id=367700)\n\n**Expected results:** A nice and simple view where users type a human comprehensive phrase to search items over the photo collections.\n\n**Knowledge Prerequisite:** C++, Qt, OpenCV, AI modeling, Large Language Model\n\n**Duration:** ~350 hours\n\n**Difficulty:** Difficult\n\n**Mentor:** Michael Miller ([[email protected]](https://community.kde.org/cdn-cgi/l/email-protection)), Maik Qualmann ([[email protected]](https://community.kde.org/cdn-cgi/l/email-protection)), and Gilles Caulier ([[email protected]](https://community.kde.org/cdn-cgi/l/email-protection))\n\n## Plasma Mobile\n\n**Brief explanation:** Currently, Plasma Mobile has its own Wi-Fi, cellular networking and hotspot settings modules. They are very basic, and lack some features compared to their desktop equivalents (ex. enterprise Wi-Fi security). The desktop has a very functional networking settings module, but it has a large codebase and complex UI that is not easy to adapt to mobile usage.\n\nThe aim of the project is to improve the mobile networking settings so that it is functionally equivalent to the desktop experience. This includes support for enterprise Wi-Fi networks, VPN configuration, and etc. The tasks involves exposing configuration values from C++ to QML and writing some UI code around it (working heavily with NetworkManager and ModemManager). Developing a shared base with the desktop implementation and consolidating code is also a key goal.\n\n**Expected results:** Mobile network KCMs can share more code with the desktop one and are more featureful\n\n**Knowledge Prerequisite:** QML and C++\n\n**Duration:** ~350 hours\n\n**Difficulty:** Difficult\n\n**Mentor:** Carl Schwan and rest of Plasma mobile team. [https://matrix.to/#/#plasmamobile:kde.org](https://matrix.to/#/#plasmamobile:kde.org)\n\n## Drawy\n\n### Implement Rich Text\n\n**Brief explanation:**\nThe current text tool in Drawy is limited to plain text. Formatting applies to the entire text block, and it is not possible to use different styles for different parts of the text. The code is hard to extend and needs refactoring to support richer editing features and better maintainability.\n\nSeveral important features are also missing. The text tool does not support spell checking, text alignment, or proper word wrapping. It also has limited support for international input and should allow different input methods, including dead keys required by many languages.\n\n**Expected results:**\nAn improved rich text tool that allows different styles within the same text, supports text alignment, and integrates Sonnet (KDE's spell checking framework) for spell checking. The tool should support multiple input methods, implement word wrapping, and provide improved keyboard navigation.\n\n**Knowledge Prerequisite:**\nC++ and Qt\n\n**Duration:**\n~350 hours\n\n**Difficulty:**\nDifficult\n\n**Mentor:**\nLaurent Montel <[[email protected]](https://community.kde.org/cdn-cgi/l/email-protection)>\n\n## Kdenlive\n\n### Improve effect widgets\n\n**Brief explanation:** Kdenlive is an advanced video editor. We support several libraries for our effects, but the effects user interface is managed in Kdenlive. Some effects currently don't have a proper user interface, and we would like to improve the situation. for example, libavfilter provides an effect allowing to adjust the color curves for each channel (red, green, blue, etc). We would need a proper widget allowing to edit curves with tabs to handle each channel. Another effect requires creating an arbitrary number of color gradients, so we need a widget to handle this. Speed ramp could also benefit from a nice UI to adjust speed of a video clip. We also use Qml overlays on the monitor which allow tweaking some parameters, so some work is also possible here.\n\n**Expected results:** Nice looking, intuitive and powerful widgets to adjust effect parameters.\n\n**Knowledge Prerequisite:** Qt (mostly QWidgets, some Qml) and C++.\n\n**Duration:** ~350 hours.\n\n**Difficulty:** medium\n\n**Mentor:** Jean-Baptiste Mardelle <[[email protected]](https://community.kde.org/cdn-cgi/l/email-protection)>, helped by other Kdenlive devs. [#kdenlive-dev:kde.org](https://matrix.to/#/#kdenlive-dev:kde.org) on matrix.\n\n## KStars\n\n### AI-Powered Guiding Assistant\n\n**Brief explanation**: Autoguiding is critical for long-exposure astrophotography, compensating for tracking errors by sending corrective pulses to the telescope mount. However, optimal guiding performance requires careful tuning of multiple parameters (aggressiveness, hysteresis, minimum move, declination mode) that vary significantly between mounts due to mechanical differences, periodic error, backlash, and non-linear response characteristics. The goal of this project is to develop an AI Guiding Assistant that learns mount-specific behavior and dynamically optimizes guide corrections in real-time.\n\nThe AI Guiding Assistant will:\n\n**Augment Existing Guide Pulses**: Intercept guide pulses calculated by the EKOS Guide Module and apply learned corrections before sending to the mount via INDI. This preserves all existing guiding physics while adding intelligent optimization.\n\n**Learn Mount Characteristics**: Analyze guide pulse history and mount response to build a model of mount-specific quirks including backlash patterns, periodic error signatures, declination drift behavior, and non-linear response curves.\n\n**Real-time Parameter Optimization**: Dynamically adjust guiding aggressiveness, filtering, and response based on current seeing conditions, mount behavior, and guide star characteristics without requiring manual tuning.\n\n**Training and Inference Modes**: Provide a training mode where the assistant learns mount behavior over multiple sessions, and an inference mode where it applies learned corrections. Users can enable/disable the assistant at any time for testing and comparison.\n\n**Performance Metrics and Visualization**: Display RMS error improvements, correction patterns, and confidence metrics to help users understand the assistant's behavior and effectiveness.\n\nThe implementation will be based on [recent research in this domain](https://arxiv.org/pdf/2407.08046) and will utilize lightweight machine learning frameworks suitable for embedded systems.\n\n**Expected results**:\n\n- AI Guiding Assistant module integrated into EKOS Guide Module with enable/disable toggle\n- Training mode to collect and analyze mount behavior data\n- Real-time guide pulse augmentation with learned corrections\n- Persistent model storage for mount-specific profiles\n- Performance comparison tools showing improvement over standard guiding\n- Documentation and user guide for optimal usage\n\n**Knowledge Prerequisite**: C++, Qt, Machine Learning basics (PyTorch/TensorFlow or C++ ML libraries), Signal Processing, Control Systems\n\n**Duration:** 350 hours\n\n**Difficulty:** Hard\n\n**Mentor**: Jasem Mutlaq ([KDE Web Chat](https://webchat.kde.org/#/room/#kstars:kde.org): Jasem)\n\n## Lokalize\n\n[Lokalize](https://invent.kde.org/sdk/lokalize) is KDE's translation system, enabling the translation of KDE programs as well as other external projects. All Lokalize tasks are mentored by Finley Watson (@fin-w:private.coffee , ask on [https://matrix.to/#/#kde-mentorship:kde.org](https://matrix.to/#/#kde-mentorship:kde.org) and I'll respond).\n\n**WARNING:** I will reject all applications written by LLMs. If you can't be bothered to write it, I can't be bothered to read it. The purpose of contributing to KDE is for you to grow and learn.\n\n### Project 1: Adapt PO file read / write to use libgettextpo\n\n**Description:** The PO file format [is changing slightly](https://lists.gnu.org/archive/html/bug-gettext/2025-06/msg00018.html). Lokalize's PO file parser also has multiple problems with it (see the bug reports below). The mentee should research how viable [libgettextpo](https://www.gnu.org/software/gettext/manual/gettext.html) is to use as a replacement for the current parser, and decide if the library is suitable to integrate with existing PO read / write capability, and be prepared to work on a challenging task.\n\n**Expected Results:** Bugs are fixed, Lokalize uses libgettextpo to read and write PO files, and the existing data structures in Lokalize are adapted to work with libgettextpo. Robust read / write ability, with new tests that cover bug report examples and confirm expected behaviour.\n\n**Knowledge Prerequisite:** C++, QtWidgets, understand PO file format, test-driven development might be useful here\n\n**Duration:** 350 hours\n\n**Difficulty:** Difficult\n\n**Related Bug Reports:**\n\n[https://bugs.kde.org/show_bug.cgi?id=490802](https://bugs.kde.org/show_bug.cgi?id=490802)[https://bugs.kde.org/show_bug.cgi?id=76495](https://bugs.kde.org/show_bug.cgi?id=76495)[https://bugs.kde.org/show_bug.cgi?id=510320](https://bugs.kde.org/show_bug.cgi?id=510320)\n\n### Project 2: Integrate Weblate API\n\n**Description:** Weblate offers [an API](https://docs.weblate.org/en/latest/api.html) to load and save translations. A successful mentee will add a new project type, with the ability to log in to Weblate servers, and *at the very least* load and save translations to and from the remote server, allowing a translator to submit, review and approve translations for a project stored online. Glossary syncing would be a bonus, but not essential. You should consider [whole-file syncing](https://docs.weblate.org/en/latest/api.html#get--api-translations-(string-project)-(string-component)-(string-language)-file-) or per translation unit syncing. Assessment of relevant parts of the API is expected in the mentee's application, linking them to the relevant parts in the current codebase, in addition to examples of successful use of the API (e.g. with *curl* or another command-line tool).\n\n**Knowledge Prerequisites:** C++, QtWidgets, REST APIs\n\n**Duration:** 350 hours\n\n**Difficulty:** Difficult\n\n**Related Bug Reports:**\n\n### Project 3: Redesign the translation memory tab\n\n**Description:** The translation memory tab allows you to pick a TM (saved translation pairs from previous translation jobs / files) to search through, and shows the results in the list below. The UI needs redesigning to enable searching multiple memories at once by selecting the TMs you want to search, rather than picking only one from a drop-down. The selected TMs to search should be saved per-project, so translators can customise their translations per-project (e.g. only use translation memories with formal language for one specific project). Additionally, the \"Manage translation memories\" button opens a TM manager which should be merged into the tab instead of existing separately e.g. by moving TM-specific entries into the right-click menu, and adding more general buttons into the TM tab page, or the toolbar that is specific to the TM tab.\n\n**Stretch Goal(s):** Fix the results list so the selected entry is highlighted with the correct colour from the theme (it seems broken?), and make entry rows only one line tall instead of many lines, when entry text is long.\n\n**Expected Result:** A list of all TMs to pick instead of a drop-down, each entry checkable with a checkbox. Save selected TMs to the project data. Filter searches per TM grouping, searching each TM and sorting results sensibly.\n\n**Knowledge Prerequisites:** C++, QtWidgets, UI design is beneficial\n\n**Duration:** 350 hours\n\n**Difficulty:** Medium\n\n**Related Bug Reports:**"
  },
  {
    "name": "SW360",
    "slug": "sw360",
    "tagline": "Software supply chain management done right !",
    "description": "SW360 is an open source software project licensed under the EPL-2.0 that provides both a web application and a repository to collect, organize and make available information about software components. It establishes a central hub for software components in an organization.",
    "ideas_url": "https://eclipse.dev/sw360/gsoc/gsoc-projects-2026/",
    "website_url": "https://eclipse.dev/sw360/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "java",
      "react",
      "couchdb",
      "SpringBoot"
    ],
    "topic_tags": [
      "license compliance",
      "compliance automation",
      "SBOM",
      "component repository",
      "vulnerabilities management"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/sw360",
    "ideas_content": "Welcome to the idea page for all GSoC 2026 related information.\n\n## Intro\n\nSW360 is applying as a mentoring org again in GSoC 2026 with the ambition to make it as awesome as the GSoC 2025!\n\nPlease see two main resources for finding out more SW360 in general:\n\n- Check\n[https://eclipse.dev/sw360/](https://eclipse.dev/sw360/)and development and deployment section. - Try to install SW360 from source or your can try the\n[Docker](https://github.com/eclipse-sw360/sw360/blob/main/docker-compose.yml)\n\nMeetings: Checkout the [Meetings table](https://eclipse.dev/sw360/gsoc/#meetings-table)\n\n## AI Policy\n\nPlease out our AI Policy documenting our understanding and requirements about\nthe usage of Generative AI with respect to Google Summer of Code program as\nwell as its usage in general [at our policy\npage](https://eclipse.dev/sw360/gsoc/ai-policy/).\n\n## Interested in Application? - Getting Grip\n\nIf you are interested in an application - great! We encourage your application. So the question is how to get started with the topic, just a few points:\n\n- Check\n[https://eclipse.dev/sw360/docs/](https://eclipse.dev/sw360/docs/)for development and operational guides. - Check the frontend project for UI:\n[https://github.com/eclipse-sw360/sw360-frontend](https://github.com/eclipse-sw360/sw360-frontend) - Try to install SW360, either from source or Docker\n- Read the proposed topics\n- Use the mailing list\n[sw360-dev@eclipse.org](mailto:sw360-dev@eclipse.org)or contact proposed mentors for further steps. [Matrix group](https://chat.eclipse.org/#/room/%23technology.sw360-general:matrix.eclipse.org)[GitHub discussion](https://github.com/eclipse-sw360/sw360/discussions/3631)- If you are interested in trying to make contributions, see\n[contribution guidelines](https://github.com/eclipse-sw360/sw360/blob/main/CONTRIBUTING.md). - Check out our new AI Guidelines\n\n## Mentors\n\nInterested in becoming a mentor? Please reach out to us!\n\n#### Volunteers so far:\n\n## Topic Proposals\n\nPlease reach out to us to add more proposals for GSoC 2026.\n\nCurrently, discussion happening on\n[https://github.com/eclipse-sw360/sw360/discussions/3631](https://github.com/eclipse-sw360/sw360/discussions/3631)\n\n## Topic Proposals for 2026\n\nFollowing are the topics proposed by the community (in no particular order):\n\n[Creating Components as a separate service in SW360](https://eclipse.dev/sw360/gsoc/gsoc-projects-2026/#creating-components-as-a-separate-service-in-sw360)[SBOM Validator](https://eclipse.dev/sw360/gsoc/gsoc-projects-2026/#sbom-validator)[CLIXML visualizer for release attachments](https://eclipse.dev/sw360/gsoc/gsoc-projects-2026/#clixml-visualizer-for-release-attachments)[Integration of SW360 and LicenseDB](https://eclipse.dev/sw360/gsoc/gsoc-projects-2026/#integration-of-sw360-and-licensedb)[Remove Apache Thrift and Migrate to Direct Spring Service Calls](https://eclipse.dev/sw360/gsoc/gsoc-projects-2026/#remove-apache-thrift-and-migrate-to-direct-spring-service-calls)[Archival of Components and Projects](https://eclipse.dev/sw360/gsoc/gsoc-projects-2026/#archival-of-components-and-projects)[Project 360 view](https://eclipse.dev/sw360/gsoc/gsoc-projects-2026/#project-360-view)[Customize Copy Project](https://eclipse.dev/sw360/gsoc/gsoc-projects-2026/#customize-copy-project)\n\n### Creating Components as a separate service in SW360\n\n**Goal:** Idea is to create a Components as a service that can then be used by\nmultiple Org to reuse common component repository.\n\nDecompose SW360 backend and extract out the Component and related modules like Releases, Packages. This new service should be capable of running with its own DB and as a standalone service.\n\n| Category | Rating |\n|---|---|\n| Low Hanging Fruit | * |\n| Risk/Exploratory | ** |\n| Fun/Peripheral | ** |\n| Core Development | * |\n| Project Infrastructure | *** |\n| Project size | Lage |\n| Preferred contributor | Student/professional |\n| Skills needed | Java, Spring, Microservice |\n| Contact | @GMishx @bibhuti230185 @amritkv @rudra-superrr |\n\n### SBOM Validator\n\n**Goal:** Design and implement an SBOM Validator that ensures uploaded SBOMs\nmeet organizational and regulatory requirements by validating completeness,\nconsistency, and structure\n\nThe SBOM Validator processes SBOMs generated by different tools and provided in various standard formats (such as SPDX and CycloneDX). It validates that all mandated fields are present and correctly populated according to defined policies and compliance requirements.\n\nThe validator may optionally convert incoming SBOMs into a standardized internal representation. When enabled, this internal format is used to simplify validation logic, ensure consistent behaviour across SBOM sources, and reduce format-specific handling. When not enabled, validation can be performed directly against the original SBOM structure.\n\nDuring processing, the validator consolidates duplicate or overlapping packages and components, resolving inconsistencies such as multiple representations of the same dependency. Additionally, the validator supports SBOM enrichment by augmenting existing data with derived or externally sourced information, such as normalized package identifiers or additional metadata.\n\nBefore final import, users are provided with a clear graphical and navigable visualization of the parsed and consolidated SBOM data instead of boaring flat list view, allowing them to review structure, metadata, and detected issues.\n\nIn a summary:\n\n- Validate SBOMs from multiple formats (e.g., SPDX, CycloneDX) and generators for completeness and correctness.\n- Ensure all mandated and policy-required fields are present and properly populated.\n- Optionally normalize uploaded SBOMs into a standardized internal format to simplify validation and ensure consistent processing.\n- Provide a graphical visualization of SBOM data prior to import for user review.\n\n| Category | Rating |\n|---|---|\n| Low Hanging Fruit | - |\n| Risk/Exploratory | * |\n| Fun/Peripheral | *** |\n| Core Development | * |\n| Project Infrastructure | ** |\n| Project size | Large |\n| Preferred contributor | Student/professional |\n| Skills needed | Java, Spring |\n| Contact | @amritkv |\n\n### CLIXML visualizer for release attachments\n\n**Goal:** The idea here is to provide a clearance report visualizer for the\nCLIXML coming from FOSSology.\n\nCurrently, SW360 users must download separate CLIXML files or log into FOSSology to understand the clearance status of a release. This feature would allow SW360 to parse the CLIXML report directly within the browser. The key features to this idea can be pointed out as follows:\n\n- CLIXML Parser and UI Renderer in SW360\n- If FOSSology can provide item ID in the report, provide a hyperlink to file directly. Next to every file listed in the SW360 preview, provide a “View in FOSSology” icon.\n- Compare the CLIXML of the current release with the previous version. Highlight New Licenses or Changed Copyrights in red/green within the UI. This helps the user focus only on what has changed in the latest code drop.\n\n| Category | Rating |\n|---|---|\n| Low Hanging Fruit | * |\n| Risk/Exploratory | * |\n| Fun/Peripheral | *** |\n| Core Development | ** |\n| Project Infrastructure | ** |\n| Project size | Medium |\n| Preferred contributor | Student/professional |\n| Skills needed | Java, XML, NextJS |\n| Contact | @amritkv @rudra-superrr @deo002 |\n\n### Integration of SW360 and LicenseDB\n\n**Goal:** To establish LicenseDB as the sole source for all license and\nobligation data within SW360, streamlining data management and ensuring\nconsistency.\n\nCurrently, SW360 relies on a fragmented approach for managing license and obligation information. Licenses can be imported from external sources like OSADL or SPDX, or created manually. Obligations, which define the requirements associated with each license, can only be created manually within SW360. This decentralized system can lead to inconsistencies, manual overhead, and difficulty in maintaining a single, accurate view of license compliance.\n\nThis project aims to change how SW360 manages this data by integrating it directly with LicenseDB. The successful completion of this project will involve:\n\n- Removing Redundant Data Entry Methods: All existing functionalities within SW360 that allow for manual license creation or direct import from OSADL/SPDX will be deprecated and removed.\n- Integration: Develop a robust integration layer to enable SW360 to fetch\nlicense and obligation data directly from LicenseDB. This will likely\ninvolve:\n- OAuth Integration: Implementing Machine-to-Machine OAuth flow between SW360 and LicenseDB.\n- Data Translation/Mapping: Creating mechanisms to translate and map data structures from LicenseDB’s format to SW360’s internal data model for licenses and obligations.\n- Data Persistence: Ensuring that the fetched data is correctly saved and updated within SW360’s database for ongoing use and reference.\n\n- Adapting Existing Workflows: Review and modify existing SW360 CLI (Command Line Interface) and XML-based workflows. These workflows currently create licenses and obligations if they don’t already exist. They must be updated to leverage the new LicenseDB integration, ensuring they now fetch and sync data from LicenseDB rather than creating it independently.\n\nCheckout LicenseDB at: [https://github.com/fossology/LicenseDb](https://github.com/fossology/LicenseDb)\n\n| Category | Rating |\n|---|---|\n| Low Hanging Fruit | * |\n| Risk/Exploratory | * |\n| Fun/Peripheral | ** |\n| Core Development | *** |\n| Project Infrastructure | ** |\n| Project size | Medium |\n| Preferred contributor | Student/professional |\n| Skills needed | Java, Spring, REST API |\n| Contact | @GMishx @deo002 |\n\n### Remove Apache Thrift and Migrate to Direct Spring Service Calls\n\n**Goal:** Eliminate Apache Thrift dependency from SW360 and replace\ninter-service communication with direct Spring Bean injection and REST APIs.\n\nSW360 currently uses Thrift for backend service communication (ThriftClients, *Service.Iface). This adds complexity, requires .thrift IDL files, and creates tight binary coupling. Migrate to Spring-managed services with direct injection for in-process calls and REST for external integrations.\n\n#### Current state vs Expected state\n\n| Aspect | Current State | Expected State |\n|---|---|---|\n| Service Layer | Thrift IDL (.thrift files) generates interfaces | Plain Java interfaces with Spring @Service |\n| IPC Mechanism | ThriftClients + THttpClient + TCompactProtocol | Direct @Autowired injection (in-process) |\n| External API | Thrift servlets (Sw360ThriftServlet) | REST controllers (existing resource-server) |\n| Dependencies | libthrift, Thrift compiler toolchain | Removedâpure Spring Boot |\n| Code Generation | Required for model classes | POJOs, no generation step |\n\n| Category | Rating |\n|---|---|\n| Low Hanging Fruit | ** |\n| Risk/Exploratory | ** |\n| Fun/Peripheral | ** |\n| Core Development | *** |\n| Project Infrastructure | *** |\n| Project size | Large |\n| Preferred contributor | Student/professional |\n| Skills needed | Java, Spring, Microservices |\n| Contact | @GMishx @bibhuti230185 @amritkv @rudra-superrr |\n\n### Archival of Components and Projects\n\n**Goal:** Creation of an archival and restore functionality to remove\nunnecessary Projects and Components from SW360 server\n\nAs an SW360 instance grows over years of use, the database becomes cluttered with “stale” projects and deprecated component versions that are no longer in active use. This feature introduces an Archival Workflow. The archival workflow should allow complete removal of a Project or Component or Release from the SW360 server (with entire metadata like changelogs, attachments, etc.) into a single compressed package (e.g., a ZIP or TAR containing JSON metadata), and purges them from the active database. At the same time, there should be a Workflow to restore these archived projects/components/releases individually for the purpose of audit, reuse, etc. This archival process will allow usage of cold storage backups and improve upon the performance of application by reducing index size, speeds up UI responsiveness, and saves significant disk space.\n\nFeature points to consider:\n\n- Comprehensive Data Bundling (The “Snapshot”)\n- Database Cleanup & Performance Optimization\n- Seamless Re-Import & Restoration\n- Archival Metadata Registry\n\n| Category | Rating |\n|---|---|\n| Low Hanging Fruit | * |\n| Risk/Exploratory | *** |\n| Fun/Peripheral | ** |\n| Core Development | * |\n| Project Infrastructure | *** |\n| Project size | Large |\n| Preferred contributor | Student/professional |\n| Skills needed | Java, CouchDB/No SQL |\n| Contact | @GMishx @amritkv @rudra-superrr |\n\n### Project 360 view\n\n**Goal:** To empower product owners and compliance teams with a single, trusted\nsource of compliance truth\n\nProject 360Â° View delivers a holistic compliance dashboard for both parent and child projects, offering complete visibility into software usage, security risks, and license obligations.\n\nIt consolidates vulnerability data across the entire project hierarchy, clearly highlighting severity levels, affected components, and overall compliance impact. All license and obligation information is aggregated to identify notice, disclosure, and copyleft requirements, ensuring legal and regulatory adherence.\n\nThe view also presents approved and pending releases, along with clearing request and legal approval status, giving product owners a clear picture of release readiness. Additionally, all compliance-relevant changes since the last releaseâincluding newly introduced components, license changes, new vulnerabilities, and removed itemsâare tracked and visualized.\n\nBy unifying security, legal, and release data into a single interface, Project 360Â° View enables faster audits, reduces compliance risk, and supports confident, data-driven release decisions.\n\n- Provide a good overview of the project to the product owners.\n- Project 360Â° View provides a hierarchical compliance view of parent and child\nprojects, ensuring full traceability of software usage.\n- It consolidates vulnerability data across the project hierarchy, highlighting severity, affected components, and compliance impact.\n- License information and obligation data are aggregated to identify notice, disclosure, and copyleft requirements.\n- The page presents approved and pending releases, including clearing request and legal approval status.\n- Compliance-relevant changes since the last releaseânew components, licenses, vulnerabilities, and removalsâare clearly tracked.\n- This enables faster, audit-ready compliance verification and release approval decisions.\n\n\n| Category | Rating |\n|---|---|\n| Low Hanging Fruit | ** |\n| Risk/Exploratory | ** |\n| Fun/Peripheral | ** |\n| Core Development | * |\n| Project Infrastructure | * |\n| Project size | Medium |\n| Preferred contributor | Student/professional |\n| Skills needed | Java, REST API, NextJS |\n| Contact | @amritkv @rudra-superrr @deo002 |\n\n### Customize Copy Project\n\n**Goal:** Idea is to allow users to provide fields they want to carry over\nwhile using the “Copy Project” feature\n\nCurrently, when a user wants to use duplicate/copy projects to create, lets say a new version, they do not have a choice of fields to be carried over. SW360 copies all and everything to the new Project and the user has to manually make sure everything is up-to-date.\n\nThis new feature will allow users to pick and choose the fields they want to carry over into the new Project and leave the rest. To implement this feature, the changes would have to be done at both front-end and back-end side.\n\n| Category | Rating |\n|---|---|\n| Low Hanging Fruit | *** |\n| Risk/Exploratory | * |\n| Fun/Peripheral | * |\n| Core Development | *** |\n| Project Infrastructure | * |\n| Project size | Small |\n| Preferred contributor | Student |\n| Skills needed | Java, Spring, NextJS |\n| Contact | @GMishx @deo002 |\n\n### Provide alternative Component link\n\n**Goal:** Provide a data structure to deprecate a Component and provide link to\nnew Component.\n\nDepending on how Admins are using the SW360 instance, they want to manage the Component naming/grouping in a different way. There can also be scenarios where an OSS project decided to rename themselves over period. In such cases, you might want to mark a Component as deprecated and provide an alternative to be used instead.\n\nAll this information still needs to be preserved and documented in SW360 but\nneeds to be machine-readable as well. When using automation to generate SBOM\nand import in SW360 like with [capycli](https://github.com/sw360/capycli),\nadding all such customization makes them tool specific and someone using\ndifferent tool might not understand this.\n\nThe main idea of this project is to provide such fields in the Component DataStructure where user can mark a Component (and all its Releases) as deprecated. At the same time, make it easy to provide link to alternatives to be used. Such information, when provided over REST API, can be used by frontend to display information like bellow. At the same time allow tools to use this information to make smart decisions. As an add-on, SW360 can be allowed to completely disallow changes in deprecated Components and use the alternative instead to create new Releases.\n\n| Category | Rating |\n|---|---|\n| Low Hanging Fruit | * |\n| Risk/Exploratory | * |\n| Fun/Peripheral | ** |\n| Core Development | ** |\n| Project Infrastructure | * |\n| Project size | Small |\n| Preferred contributor | Student |\n| Skills needed | Java, Jackson, NextJS (is a Plus) |\n| Contact | @amritkv |"
  },
  {
    "name": "AboutCode",
    "slug": "aboutcode",
    "tagline": "Scan code for origin, license and vulnerabilities",
    "description": "AboutCode.org is a community of open source developers who are trying to make open source easier to use by providing open source tools to discover, identify and track open source components (aka. Software Composition Analysis – SCA). This includes tools, data and standards for code origin, FOSS licenses and security vulnerabilities.",
    "ideas_url": "https://github.com/aboutcode-org/aboutcode/wiki/GSOC-2026-project-ideas",
    "website_url": "https://aboutcode.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "Django+PostgreSQL",
      "C/Rust/Go"
    ],
    "topic_tags": [
      "dependencies",
      "vulnerabilities",
      "SoftwareCompositionAnalysis",
      "License",
      "SBOM"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/aboutcode",
    "ideas_content": "-\n-\n[Notifications](https://github.com/login?return_to=%2Faboutcode-org%2Faboutcode)You must be signed in to change notification settings -\n[Fork 234](https://github.com/login?return_to=%2Faboutcode-org%2Faboutcode)\n\n# GSOC 2026 Project Ideas\n\n[1 revision](https://github.com/aboutcode-org/aboutcode/wiki/GSOC-2026-Project-Ideas/_history)\n\nSee our page on applying for GSoC 2026: [https://github.com/aboutcode-org/aboutcode/wiki/GSOC-2026](https://github.com/aboutcode-org/aboutcode/wiki/GSOC-2026)\n\n[Project Ideas Index](https://github.com#project-ideas-index)[PURLdb project ideas](https://github.com#purldb-project-ideas)[vulnerablecode project ideas](https://github.com#vulnerablecode-project-ideas)[scancode.io projects ideas](https://github.com#scancodeio-project-ideas)[scancode-toolkit project ideas](https://github.com#scancode-toolkit-project-ideas)[About our Project Ideas List](https://github.com#our-project-ideas)\n\nHere is a list of candidate project ideas for your consideration. Your own ideas are welcomed too! Please chat about them to get early feedback!\n\n[scancode-toolkit](https://github.com/aboutcode-org/scancode-toolkit): [project ideas](https://github.com#scancode-toolkit-project-ideas)\n\nArchived Project Ideas: [https://github.com/aboutcode-org/aboutcode/wiki/Archived-GSoC-Project-Ideas](https://github.com/aboutcode-org/aboutcode/wiki/Archived-GSoC-Project-Ideas)\n\nWe use these now and then:\n\n- SCIO: ScanCode.io\n- BOM: Bill of Material, same as SBOM\n- SBOM: Software Bill of Material\n- DJCD: DejaCode\n- SCTK: ScanCode-Toolkit\n- VCIO: VulnerableCode\n- NLP: Natural Language Processing\n- VDR: Vulnerability Disclosure Report\n- VEX: Vulnerability Exploitability Exchange\n\nCode Repositories: [https://github.com/aboutcode-org/purldb](https://github.com/aboutcode-org/purldb)\n\nDescription:\n\nThere are between 100 and 200 million open source projects and repos out there. Not all of them are equal. Some are much more useful than others, and some could be safely ignored. For instance, the linux kernel is more important, used and popular than a 1st year computer student school assignment project. The goal of this project is to determine when a project is popular and what are the most popular projects. If we do not know what code is used, we can spend a lot of resources to index less used code.\n\nThere are some simple approaches to this, using available statistics for downloads or Github stars, but that is not satisfying alone.\n\nAn idea would be to consider multiple factors to rank popularity and usage.\n\n- For instance: create a (current and updated) graph of dependencies and compute something like a pagerank but for packages\n- Then create with a metric on the freshness of the code like when last release and how much downloaded or based on git activity (excluding bots). This would grow for used code and decay for declining packages\n- Then combine this with the dependencies \"connectedness\"\n\nOr, just a use the graph connections and no download stats, just a giant graph on top of purldb\n\nOr something like this:\n\n- Finding strongly connected components\n- Relate packages ignoring versions\n- Find most connected\n- Discount distant connections, boost closest\n- Apply decay based on version freshness or git activity\n\nThe approach would be to start small with a single ecosystem as PoC and then extend this to all packages types.\n\nIdeally, this should be exposed in PurlDB API and integrated in data collection operations.\n\nPriority: High\n\nSize: Large\n\nDifficulty Level: Advanced\n\nTags:\n\n- Python\n- Django\n- PostgreSQL\n- Popularity\n\nMentors:\n\n- @pombredanne\n- @JonoYang\n- @AyanSinhaMahapatra\n\nThere are two main categories of projects for VulnerableCode:\n\n-\nA. COLLECTION: this category is to mine and collect or infer more new and improved data. This includes collecting new data sources, inferring and improving existing data or collecting new primary data (such as finding a fix commit of a vulnerability)\n\n-\nB. USAGE: this category is about using and consuming the vulnerability database and includes the API proper, the GUI, the integrations, and data sharing, feedback and curation.\n\n\nCode Repositories:\n\nDescription:\n\nThe project would be to provide a way to effectively mine unstructured data sources for possible unreported vulnerabilities.\n\nFor a start this should be focused on a few prominent repos. This project could also find Fix Commits.\n\nSome sources are:\n\n- mailing lists\n- changelogs\n- reflogs of commit\n- bug and issue trackers\n\nThis requires systems to \"understand\" vulnerability descriptions: as often security advisories do not provide structured information on which package and package versions are vulnerable. The end goal is creating a system which would infer vulnerable package name and version(s) by parsing the vulnerability description using specialized techniques and heuristics.\n\nThere is no need to train a model from scratch, we can use AI models pre-trained on\ncode repositories (maybe [https://github.com/bigcode-project/starcoder](https://github.com/bigcode-project/starcoder)?) and then\nfine-tune on some prepared datasets of CVEs in code.\n\nWe can either use NLP/machine Learning and automate it all, potentially training data masking algorithms to find these specific data (this also involved creating a dataset) but that's going to be super difficult.\n\nWe could also start to craft a curation queue and parse as much as we can to make it easy to curate by humans and progressively also improve some mini NLP models and classification to help further automate the work.\n\nReferences: [https://github.com/aboutcode-org/vulnerablecode/issues/251](https://github.com/aboutcode-org/vulnerablecode/issues/251)\n\nPriority: Medium\n\nSize: Large\n\nDifficulty Level: Advanced\n\nTags:\n\n- Python\n- Django\n- PostgreSQL\n- Security\n- Vulnerability\n- NLP\n- AI/ML\n\nMentors:\n\n- @pombredanne\n- @tg1999\n- @keshav-space\n- @Hritik14\n- @AyanSinhaMahapatra\n\nRelated Issues:\n\nCode Repositories:\n\nDescription:\n\nWhen large packages/containers are scanned in scancode.io it is useful to have a tree-view to explore thorugh the file-tree for that package/container to look into scan data for a particular subset of the file-tree/directory or to research more into detections and detection issues.\n\nThis would be something similar to what we have at scancode-workbench for example:\n[https://scancode-workbench.readthedocs.io/en/develop/ui-reference/directory-tree.html](https://scancode-workbench.readthedocs.io/en/develop/ui-reference/directory-tree.html)\n\nI.e. we need the following features:\n\n- To be able to toggle showing the directory contents from the directory icon\n- Show nested directory contents in a tree like structure\n- Have this view ideally in a pane left to the table-view of resources\n- Show only info from the selected directory in the table-view of resources\n\nNote that we do have a ProjectCodebaseView in the projects page currently in scancode.io but this is fairly limited as it only lets you browse through the codebase one directory at a time (only shows the files/directories in one directory), and lets you navigate to directories in the current directory or the parent directory from there.\n\nPriority: High\n\nSize: Large\n\nDifficulty Level: Intermediate\n\nTags:\n\n- Python\n- Django\n- UI/UX\n- File-system\n- Navigation\n\nMentors:\n\n- @tdruez\n- @pombredanne\n- @AyanSinhaMahapatra\n\nRelated Issues:\n\nCode Repositories:\n\nDescription:\n\nRequired phrases are present in rules to make sure the rule is not matched to text in a case where the required phrase is not present in the text, which would be a false-positive detection.\n\nWe are marking required phrases automatically based on what\nis present in other rules and license attributes, but this\nstill leaves a lot of rules without them.\nSee [https://github.com/aboutcode-org/scancode-toolkit/pull/3924](https://github.com/aboutcode-org/scancode-toolkit/pull/3924)\nwhere we are also adding a script to add required phrases as\nindividual rules if applicable and also adding required phrases\nadded to other rules.\n\n- research and choose a model pre-trained on code (StarCoder?)\n- use the dataset of current SCTK rules to train a model\n- Mark required phrases in licenses automatically with the model\n- Test required phrase additions, improve and iterate\n- Bonus: Create a minimal UI to review rule updates massively\n\nPriority: Medium\n\nSize: Medium\n\nDifficulty Level: Advanced\n\nTags:\n\n- Python\n- ML/AI\n- Licenses\n\nMentors:\n\n- @AyanSinhaMahapatra\n- @tg1999\n- @pombredanne\n\nRelated Issues:\n\nHere are some project related attributes you need to keep in mind while looking\ninto prospective project ideas, see also: [guidance on finding the right project](https://google.github.io/gsocguides/student/finding-the-right-project):\n\n-\nThe repositories/projects are not sorted in order of importance, instead we have a explicit priority mentioned for each project idea and this can be: Low, Medium or High.\n\n-\nThis doesn't mean we will always consider a project proposal with a higher priority idea over a relatively lower priority one, no matter the merit of the proposal. This is only one metric of selection, mostly to prioritize important projects.\n\n-\nYou can also suggest your own project ideas/discuss changes/updates/enhancements based on the provided ideas, but you need to really know what you are doing here and have lots of discussions with the maintainers.\n\n\nThere are three project lengths:\n\n- Small (~90 hours)\n- Medium (~175 hours)\n- Large (~350 hours)\n\nIf you are proposing an idea from this ideas list, it should match what is listed here,\nand additionally please have a discussion with the mentors about your proposed length\nand timeline. Please also open a discussion about the same, if not already present,\nat [https://github.com/aboutcode-org/aboutcode/discussions/categories/gsoc](https://github.com/aboutcode-org/aboutcode/discussions/categories/gsoc) or discuss this in\nthe respective issues.\n\nWe have marked our ideas with medium/large based on general estimates, but this could vary. In a few cases they are both used to mark a project as it can be both. We have made conscious effort to make sure projects are not too large, have clear deliverables and can be finished successfully, but still note that these are complex projects and you're likely underestimating the complexity (and how much we'll bug you to make sure everything is up to our standards).\n\nYou must discuss your proposal and the size of project you are proposing with a mentor as otherwise we cannot consider your proposal fairly.\n\nWe likely would only select medium/large project ideas only as the small projects are too small to get familiar with and contribute meaningfully to any of our projects.\n\nPlease also note that there is a difference in the stipend based on what you select, and it would not be fair if you're selecting and working on a large project, but getting paid for a medium one (or vice-versa).\n\nHere are all the tags we use for specific projects, feel free to search this page using these if you only want to look into projects with specific technical background.\n\n[Django], [PostgreSQL], [Web], [DataStructures], [Scanning], [Javascript], [UI], [LiveServer] [API], [Metadata], [PackageManagers], [SBOM], [Security], [BinaryAnalysis], [Scraping], [NLP], [Social], [Communication], [Review], [Decentralized/Distributed], [Curation]\n\nWe are generally using three levels of difficulty to characterize the projects:\n\n- Easy\n- Intermediate\n- Advanced\n\nIf it is a difficult project it means there is significant domain knowledge required to be able to tackle this project successfully, and you must have prior verifiable experience on this (in the form of open source contributions, either on the same topic in our repos, or elsewhere). You must also consult with mentors/maintainers early, ask a lot of domain specific questions and must be ready to research and tackle greenfield projects in certain cases if you choose a project in this difficulty category.\n\nMost other intermediate projects do not require this much domain knowledge and can easily be acquired during proposal writing/contributing, if you're familiar with the tech stack used in the project. But these are still not straight-forward and requires lots of feedback from the mentors. Most projects fall in this category.\n\nThere are also easy projects which only require honest time and effort from the participant, and decent knowledge about the tech stack/problem.\n\nPlease feel free to chime in at [https://github.com/aboutcode-org/aboutcode/discussions/133](https://github.com/aboutcode-org/aboutcode/discussions/133)\nor in our GSoC 2026 chatroom at [https://matrix.to/#/#aboutcode-org_gsoc2026:gitter.im](https://matrix.to/#/#aboutcode-org_gsoc2026:gitter.im)\nif you have any questions related to AboutCode's participation in GSoC\nor anything in this page."
  },
  {
    "name": "Haiku",
    "slug": "haiku",
    "tagline": "Operating system that targets personal computing.",
    "description": "Haiku is a fast, efficient, easy to use and lean open source operating system inspired by the BeOS that specifically targets personal computing.\n\nHaiku is not a Linux distribution, nor does it use the Linux kernel. Haiku is the spiritual successor to BeOS and it is derived from the NewOS kernel, which was authored by Travis Geiselbrecht (geist), who was formerly employed by Be Inc. — the developers of BeOS.\n\nLinux-based distributions stack up software – the Linux kernel, the X Window System, and various DEs with disparate toolkits such as GTK+ and Qt – that do not necessarily share the same guidelines and/or goals. This lack of consistency and overall vision manifests itself in increased complexity, insufficient integration, and inefficient solutions, making the use of your computer more complicated than it should actually be.\n\nInstead, Haiku has a single focus on personal computing and is driven by a unified vision for the whole OS. That, we believe, enables Haiku to provide a leaner, cleaner and more efficient system capable of providing a better user experience that is simple and uniform throughout.",
    "ideas_url": "https://www.haiku-os.org/community/gsoc/2026/ideas",
    "website_url": "https://www.haiku-os.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c++",
      "posix",
      "unix"
    ],
    "topic_tags": [
      "desktop",
      "kernel",
      "network",
      "media",
      "gui"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/haiku",
    "ideas_content": "# GSoC project ideas\n\nFor information about Haiku's participation in GSoC this year, please see [this page](https://www.haiku-os.org/community/gsoc/2026).\n\nQualifying students can apply for a Haiku project (see the list of *suggested* projects below).\nFor details about how to apply, please check out [How to Apply for a Haiku Idea](https://www.haiku-os.org/community/gsoc/2026/contributors).\n\nThe most successful *Google Summer of Code* projects are often those proposed by the participants themselves.\nThe following list represents some of our ideas and wishes for the project. However, suggesting your own idea is always encouraged!\n\nBe aware: API design and kernel-related work requires a higher level of skill, and user interface design usually involves a lot more thought than other work. A significantly more convincing proposal is required for tasks involving those. Getting started with the design early (before the application period ends) is recommended, to maximize your chances of being selected, and allow a larger part of the coding period dedicated to coding tasks.\n\nIf you find one of the \"big\"/\"hard\" ideas interesting, but feel that you cannot complete it within the allotted coding time, feel free to suggest splitting it into smaller parts for your proposal.\n\n### Project Areas\n\n### Applications\n\n#### Improving Haiku's WebKit video and audio support\n\n##### Idea description\n\nThe WebPositive browser bundled with Haiku uses the WebKit engine (shared with Apple's Safari and a few other browsers) to render webpages. This engine allows several parts of the work to be implemented using existing system libraries, allowing better integration with the existing operating system and reduced overhead.\n\nIn particular, the audio and video support for Haiku should be implemented by using Haiku's Media Kit, which is a framework designed for such tasks. This would allow WebPositive to play audio and video on websites such as Youtube.\n\nThe current experimental code in WebKit uses the Game Kit and only some parts of the Media Kit, it has problems such as blocking the web browser while downloading the video, out of sync audio and video, and unability to seek inside a video.\n\nOther applications such as [StreamRadio](https://github.com/haikuarchives/streamradio) show that it is possible to use the Media Kit with better\nbuffering techniques to obtain a smoother experience.\n\n- Project size: 175 hours with possible extensions for 350 hours (adding for example fullscreen video support, work on WebRTC, ...)\n- Difficulty: medium\n- Skill set: userland development, multimedia (audio/video) programming\n- Possible mentors/knowledgeable people: PulkoMandy\n- Expected outcome: working video and audio support, including fullscreen video, without freeze of the browser during media loading.\n[Sourcecode of WebKit ported to Haiku](https://github.com/haiku/haikuwebkit/)\n\n#### Improving Haiku's WebKit2 port\n\n##### Idea description\n\nHaiku has a native WebKit port which uses the \"WebKit1\" legacy API to interface with WebKit. This API is now deprecated, and the browser should switch to \"WebKit2\", a new way to interface the browser and its engine. This new system does not run the entire web browser inside a single process, instead, the work is separated between a network process, a web process (doing the page rendering) and the browser itself (which is just a \"shell\" to render the pages on screen).\n\nMajor progress was done during GSoC 2024 to get WebKit2 running on Haiku. This results in a minimal functional browser that can render web pages and process user inputs (mouse and keyboard). However, it is very unstable (many page will trigger assertion failures in WebKit code), and also has glitches and performance issues (scrolling webpages or resizing the browser window results in flickering).\n\nThe goal of this project is to stabilize WebKit2 and fix the remaining problems, making it usable for the WebPositive browser that ships with Haiku.\n\n##### Why we need this\n\nThe web browser is an important part of the operating system today. It is difficult to attract and retain users if we don't provide a good web browser. The WebKitLegacy API is being deprecated by the developers of WebKit, with all new features (ad blockers, for example) only being available for WebKit2. Migration to the new API will provide a better path for the future of the WebPositive browser.\n\n##### Further reading\n\n- Skill set: userland development, exploring a large code-base (WebCore)\n- Possible mentors/knowledgeable people: PulkoMandy\n- Project size: 175 or 350 hours, as there is always more things to do in WebKit\n- Difficulty: medium\n- Expected outcome: stabilization of WebKit2, better web browsing experience with the MiniBrowser test application, more tests passing.\n[Sourcecode of WebKit2 work in progress](https://github.com/haiku/haikuwebkit/tree/haiku-webkit2)[GSoC 2024 blog](https://www.haiku-os.org/blog/zardshard)[Opened tickets](https://dev.haiku-os.org/query?status=assigned&status=in-progress&status=new&status=reopened&component=%5EApplications%2FWebPositive)\n\n#### Better XMPP instant messaging client for Haiku\n\n##### Idea description\n\nXMPP is a modern communication protocol for instant messaging. It has open standards and several free software client and server implementations.\n\nCurrently, the available native clients for Haiku are quite simple and don't even allow to replace all IRC features. The goal of this project is\nto improve [Renga](https://github.com/haikuarchives/renga), one of such clients, to make it possible to migrate Haiku discussion channels over to XMPP instead of IRC.\n\nThe main features to implement are more complete support for multi-user chat (in particular, moderation aspects, allowing to manage channel permissions, kick and ban users, etc) as well as any other feature considered useful: message history browsing, message reactions, activity notification, pictures and file sharing, whiteboard collaboration, …\n\n##### Why we need this\n\nMost of Haiku communication channels are currently hosted on IRC servers. IRC is a simple protocol, but it lacks modern features and is difficult to use from unstable connections or using mobile phones. As a result, IRC is less popular, and a part of the Haiku community doesn't use it anymore.\n\nSince we prefer to support open source software and usage of Haiku, XMPP is a good candidate, if we can have a working native client allowing to use it. We don't want people to instead use closed-source software or undocumented protocols.\n\n##### Further reading\n\n- Skill set: userland development, user interface design\n- Possible mentors/knowledgeable people: PulkoMandy, waddlesplash, KapiX\n- Project size: 175 hours or 350 hours depending on the XMPP feature set being implemented\n- Difficulty: easy\n- Expected outcome: improvements to the Renga XMPP client, implementing the full MUC (Multi-User Chat) XEP including moderation aspects, and/or a selection of XEPs (XMPP extensions specifications) to be determined during the GSoC application period.\n[Renga XMPP client for Haiku](https://pulkomandy.tk/projects/renga)\n\n#### Kexec system feature\n\nKexec permits booting a new kernel at reboot instead of requiring a full reboot cycle. Adding this would allow Haiku developers to shorten build/test cycles.\n\nSome other operating systems like Linux and FreeBSD implement kexec. The architecture specifics should be separated from the generic kernel code. An implementation for x86_64 would suffice.\n\n- Kernel syscall.\n- Skill set: kernel development, userland development, possibly x86 assembly\n- Possible mentors/knowledgeable people: korli, ?\n[Enhancement ticket](https://dev.haiku-os.org/ticket/5342)- Project size: 350 hours\n- Difficulty: medium/hard\n- Expected outcome: Ability to warm reboot with another x86_64 kernel.\n\n#### Devices preferences/Hardware manager\n\nHaiku is meant to be an easy to use graphical operating system. It should provide a GUI to manage devices and drivers. This is currently implemented in the \"Devices\" preferences, however it does little more than listing devices found on the machine.\n\nThe goal of this project is to extend the functionality of Devices preferences to make it a more complete and useful tool. This includes working on the following features:\n\n- Telling wether a driver is loaded for a given device and where the matching /dev entry is\n- Giving user readable information on the device type and subtype\n- Allowing to block/disable the driver for a given device\n- Support for bluetooth devices (currently not listed at all)\n- Improved support for USB devices, allowing to inspect interface descriptors (like listusb -v), HID report formats, ...)\n- Generation of a \"compatibility report\" to help populate a hardware compatibility database for Haiku\n\nNote that a lot of the work may be in making the required information available from the drivers and existing device management infrastructure, and not just in building the GUI itself.\n\n- Skill set: user interface, kernel and drivers interfacing (ioctl, devfs...)\n- Possible mentors: waddlesplash\n- Existing code:\n[\"Devices\"](https://cgit.haiku-os.org/haiku/tree/src/apps/devices) - Project size: 350 hours\n- Difficulty: easy/medium\n- Expected outcome: finalized version of Devices application, showing extra information about devices, including but not limited to the driver in use for each device.\n\n#### Other applications\n\nThere are many open source 3rd party applications for Haiku that could use improvements. Whether it is resolving bugs, adding features, updating the coding style, updating them to use the Locale and Layout Kits, or anything else imaginable! Writing applications from scratch is also possible.\n\n[Chat-O-Matic](https://github.com/JadedCtrl/Chat-O-Matic)(IM client)[Torrentor!](https://github.com/HaikuArchives/Torrentor)(bittorrent P2P client)[Calendar](https://github.com/HaikuArchives/Calendar)[Many applications at HaikuArchives](https://github.com/HaikuArchives)[Lots of abandonned projects for BeOS looking for a maintainer](http://pulkomandy.tk/~beosarchive/)\n\n- Skill set: userland development, user interface design, exploring an existing code base, others depending on the application retained.\n- Possible mentors/knowledgeable people (depends on chosen application): PulkoMandy, Scott McCreary, Sean Healy, waddlesplash, KapiX\n- Project size: 175 or 350 hours depending on the application being worked on\n- Difficulty: easy, depending on the application chosen\n- Expected outcome: new release of the chosen application, including fixes to existing tickets from the respective application bugtracker, and/or other features discussed with mentors and the Haiku community during the application period.\n\n### Drivers\n\n#### eMMC storage support\n\neMMC is a standard for communicating with flash mass storage chips. It is used in cheap laptops where NVMe or SATA are too complex to implement, and sometimes in non-standard hardware like Chromebooks or ARM single board computers.\n\nHaiku currently cannot use these mass storage devices, which limits hardware compatibility. The basic layers (SDHC controller) are already in place, and can be used to access SD cards. eMMC needs a slightly different initialization sequence, and would also benefit from adding support for \"advanced DMA\" and other parts of the SDHC controller that allow for high speed operations.\n\nThe interface for eMMC devices and for SDHC controllers is well documented and standardized. This means just one driver should be able to cover a lot of hardware. However, there may be some \"quirks\" (workaround for specific devices) depending on the hardware you will be testing with.\n\n- Requirements:\n[Some testing can be done with QEMU](https://www.qemu.org/docs/master/system/devices/emmc.html), so no specific hardware is needed. - Skill set: kernel and driver development, C and C++ development\n- Possible mentors: PulkoMandy\n- Project size: 175 hours for basic support, extensible for faster DMA usage\n- Difficulty: medium\n- Expected outcome: Haiku can read (and ideally also write) the user data area on eMMC devices.\n\n#### FreeBSD compatibility layer for FDT attached network devices\n\nHaiku relies on FreeBSD and OpenBSD drivers for most network devices. Currently, this support is\nlimited to devices attached to the PCI bus, with [work in progress support to also allow usage of\nUSB network drivers](https://review.haiku-os.org/c/haiku/+/9598).\n\nOn many ARM based devices, there is no PCI bus, instead the hardware is mapped at fixed addresses\ndirectly in the system-on-chip, and discovered through a *flattened device tree*, that is,\na data structure describing what type of hardware is available and how to access it.\n\nHaiku already handles parsing of the FDT for its own drivers. However, the compatibility layer used for FreeBSD drivers is restricted to PCI and USB, and cannot currently be used for ARM machines relying on FDT. This is especially annoying as these machines tend to use a wide variety of implementations, which means a lot of drivers would benefit from this support.\n\nThe goal of this project is to adjust the FreeBSD compatibility layer for at least one such driver.\n\n- Requirements: access to a device with an FDT mapped Ethernet interface, preferrably already supported by FreeBSD\n- Skill set: kernel and driver development, C and C++ development\n- Possible mentors: PulkoMandy\n- Project size: 175 hours for basic support, extensible for porting more drivers, finalization of USB compatibility layer support, or other tasks related to ARM support\n- Difficulty: medium\n- Expected outcome: Haiku can use an FDT network interface (tested for example by\n[network booting](https://www.haiku-os.org/guides/network_booting)).\n\n#### Universal Flash Storage support\n\nHaiku lacks a driver to support the [Universal Flash Storage Host Controller Interface (UFSHCI)](https://www.jedec.org/standards-documents/docs/jesd223f).\nThe goal of this project is to add a driver between the PCIe UFSHCI device and the SCSI bus interface.\n\n- Requirements:\n[Some testing can be done with QEMU](https://github.com/qemu/qemu/blob/master/hw/ufs/ufs.c) - Skill set: kernel and driver development, C and C++ development\n- Project size: 175 hours\n- Difficulty: medium\n- Possible mentors: korli\n\n#### GPU acceleration support\n\nHaiku does not currently support GPU acceleration, for 3D or otherwise. Reusing most of the DRM drivers from Linux, and Mesa's Gallium userspace components, the goal of this project is to enable the use of GPU-accelerated OpenGL, and eventually also OpenCL and Vulkan.\n\nHaiku's current video drivers are mostly modesetting-only, and split in two parts: the driver itself, which is quite minimal and only provides low level access to the video card, and the \"accelerant\", which runs inside app_server and communicates with the driver in order to configure the card and use its features.\n\nPorting the DRM drivers from Linux will be a rather daunting task, as they use a large subset of the Linux kernel APIs. It may be possible to reuse OpenBSD's or DragonFlyBSD's work rather than writing our own Linux API compatibilty layer; more investigation is needed here.\n\n- Skill set: kernel and driver development, Mesa graphics stack\n- Possible mentors/knowledgeable people: waddlesplash\n- Project size: 350 hours\n- Difficulty: hard\n- Expected outcome: proof of concept running an accelerated 3D rendering application based on the ported driver.\n\n### Kernel\n\n#### Improving the btrfs filesystem\n\nHaiku has great support for its own file system, but most others are only available read-only. It is way better for interoperability with other systems to be able to write to these disks from Haiku.\n\nThe goal of this project is to complete the btrfs filesystem, to allow it to write btrfs volumes (reading works already). During GSoC 2017 and 2018, students got as far as creating directories, but it is not possible yet to write files. The first part of the work is to review the existing code, and report on the current status and the work needed to get everything in place.\n\nAfter completion of this project, it should be possible to read and write files to btrfs volumes, making sure they are interoperable with Linux (mount without errors, file data is accessible, fsck detects no problems). Stress-testing should also be performed using bonnie++, and other test suites may also be used.\n\n- Skill set: kernel, and driver development\n- Possible mentors/knowledgeable people: PulkoMandy, Sean Healy, Hy Che\n[Sourcecode](https://git.haiku-os.org/haiku/tree/src/add-ons/kernel/file_systems/btrfs)[GSoC 2017 log](https://www.haiku-os.org/blog/hyche)[GSoC 2018 log](https://www.haiku-os.org/blog/brj)[Existing btrfs patches to start from](https://review.haiku-os.org/q/status:open+btrfs)- Project size: 175 or 350 hours depending on the number of features planned to implement\n- Difficulty: medium\n- Expected outcome: write support for the btrfs filesystem.\n\n#### Adding write support for more filesystems\n\n##### Idea description\n\nSome filesystems can only be read, but not written, from Haiku. The goal of this idea is to add write support for one of these filesystems (of your choice, from the list below).\n\n[XFS](http://en.wikipedia.org/wiki/Xfs)([Development community](http://xfs.org/index.php/Main_Page),[homepage](http://oss.sgi.com/projects/xfs/index.html)) is a filesystem originally developed for the IRIX operating system. Today it is commonly used by Haiku developers who build Haiku from Linux, because of its better support for extended filesystem attributes (unlike ext4). The read-only support is generally complete but does not use any caching yet. Adjusting the filesystem to use the block and file caches would be a good way to start this project.[UFS2](http://en.wikipedia.org/wiki/Unix_File_System)([FreeBSD implementation](https://github.com/freebsd/freebsd/tree/master/sys/ufs/ufs),[u2fstools for windows](http://sourceforge.net/p/ufs2tools/code/HEAD/tree/trunk/ufs2tools/)) is the default filesystem in FreeBSD, commonly used by some Haiku developers as well. It is closely based on the original Unix filesystem, which is implemented in many other operating system. The original design is quite simple, however the different implementations in various systems make it a bit more complex to handle all cases. Focusing specifically on the FreeBSD variant is acceptable for this project if needed. In its current state, the UFS2 driver works in fs_shell but crashes when used as an actual filesystem in Haiku, investigating and fixing this problem would be a good way to start this project.- ExFAT is an improved version of Microsoft's FAT filesystem. It is designed for removable drives and used on large size USB thumb drives and SD cards. There is not yet any write support in Haiku's ExFAT driver.\n\n##### Why we need this\n\nIn its current state, Haiku is rarely used as the single operating system on a computer. It is common to dual boot it with other systems such as Linux or FreeBSD. In this setup, it is very convenient when each system can access and modify the other's files. Disk partitions and data can then be shared more easily.\n\n##### Further details\n\n- Skill set: data structures, C++\n- Possible mentors/knowledgeable people: PulkoMandy, waddlesplash\n- Project size: 175 or 350 hours (in 175 hours only partial progress will be possible)\n- Difficulty: medium\n- Expected outcome: write support for the selected filesystem\n\n#### Filesystems benchmarking and stress-test\n\nSome of the filesystems (or specific features of them) in Haiku are relatively new, and not considered perfectly tested and stable yet. The goal of this project is to define a procedure for testing the filesystems and identifying bugs (especially leading to on-disk data corruption) and performance bottlenecks.\n\nTools like [bonnie++](https://en.wikipedia.org/wiki/Bonnie%2B%2B), [xfstests](https://github.com/kdave/xfstests),\nand the existing tests in src/tests/add-ons/kernel/file_systems in Haiku sources should be explored to determine their respective usefulness.\nThen, an automated way to run the tests should be defined (unit tests, integration tests on a running system, etc.)\n\nThen, the filesystems should be modified to fix the performance problems and/or bugs that were found in the process.\n\n- Skill set: C++ development, testing\n- Possible mentors/knowledgeable people: PulkoMandy\n- Project size: 175 hours\n- Difficulty: easy\n- Expected outcome: benchmark results, analysis of bottlenecks, implementation of changes to improve the filesystem and related code (VFS, caches, ...) in Haiku.\n\n### Network\n\n#### Bluetooth Stack Improvements\n\nHaiku's Bluetooth stack implements a basic subset of general Bluetooth functionality. This functionality needs to be completed and Bluetooth 2.X and later possibilities explored. This task involves investigating the current state of the Bluetooth code, improving the existing code on newer devices (pairing, etc), and improving the stack to make it more useful by implementing driver(s) for Bluetooth device(s) of your choice (file transfers, audio, HID, networking, etc).\n\n- Requirements: Bluetooth-enabled Haiku system\n- Skill set: C++, kernel development, userland development, global bluetooth stack knowledge (optional)\n- Possible mentors/knowledgeable people: waddlesplash\n- Project size: 175 hours or 350 hours (depending on how much of the stack is added)\n- Difficulty: medium\n- Expected outcome: the Bluetooth stack can be used for more than just pairing devices. For example, bluetooth audio or bluetooth HID drivers can be used.\n\n### User Interface\n\n#### Modular edit view (BIG)\n\nThe current solution for text editing in Haiku is the BTextView. It is a rather simple view providing basic text editing features and limited styling. This is, however, not powerful enough for most serious uses. The goal of this project is to design a complete replacement for BTextView, which should be designed to cover more use cases.\n\nThe edit view design should be modular and extensible to make it easy to implement e.g. following features:\n\n- Advanced text decorations and formatting: wavy underlines, strikethrough, exponents, ...\n- spell checker, line numbers, ruler\n- working on an input stream rather than on an input file, e.g. to be able to open files ~100Mb without loading them into memory in one go\n- Including pictures in the text flow\n- Automatic line breaks using locale specific rules (insertion of word breaks, handling of language with no whitespace between words)\n- Ability to load and save data in different formats such as RTF, ODT, ... (using the Translation Kit)\n\n##### Existing work\n\nThe HaikuDepot application includes [preliminary work on a rich text view](https://cgit.haiku-os.org/haiku/tree/src/apps/haikudepot/textview),\nwhich it uses to provide the description of packages. This could be used as a\nstarting point for this work.\n\n- Skill set: C++, API design, UI development\n- Possible mentors: waddlesplash, Sean Healy, scottmc, KapiX\n- Project size: 350 hours (175 hours if working only on a much smaller subset)\n- Difficulty: hard\n- The edit view is more widely available for Haiku applications, and implement a selection of the items outlined in the list above (to be selected during the application period after discussion with the mentors and community)\n\n### Other\n\n#### Improvements to Haiku-format coding style checker\n\nHaiku has its own [coding guidelines](https://www.haiku-os.org/development/coding-guidelines/)\nwhich describe how the code should be formatted. There is [a tool](https://github.com/owenca/haiku-format) (based on clang-format) for reformatting\nor checking if code follows these guidelines, used in the continuous integration and code review process.\n\nHowever, the tool does not fully implement the coding style and currently suggests many changes that are, in fact, not correct. The goal of this project is to improve the tool to get it closer to Haiku's code style.\n\n- Skill set: REST APIs, code formatting tools\n- Possible mentors: PulkoMandy, KapiX\n\n#### Improve automated test coverage and system documentation\n\n##### Idea description\n\nHaiku's regular CI testing is limited to checking whether the code builds, but not whether it works as expected. There is an existing test suite in Haiku repository but its coverage is limited. Some tests have been created along with new features over the years, but this has been an exception rather than a rule.\n\n##### Why we need this\n\nHaving automated tests will reduce amount of regressions, simplifying release process and improving developer confidence when refactoring code.\n\n##### Further details\n\nFirst part of this project is to identify missing coverage, develop a plan to fill the test gaps, and/or propose tests that would test functionality in new ways.\n\nThe goal is to implement missing tests, improve existing ones if necessary, ensure they are stable and included in regular testing cycles.\n\nStretch goal is to develop a plan and integrate code coverage tools.\n\n- Skill set: C++, userland development, unit testing\n- Possible mentors: KapiX\n\n#### Multiple monitors output in app_server\n\napp_server is Haiku's graphics server and the equivalent of X11 or Wayland on other UNIX systems. It currently supports only one video output, but should be able to do more.\n\nWhile the API already allows this for the most part (with the BScreen class), there is no actual implementation behind it and parts of the code assume only a single screen.\n\nSome drivers implement minimal support for multiple displays, but not all of them. This task may involve updating the video drivers to handle multiple monitors correctly.\n\n- Skill set: C++, graphics development\n- Possible mentors/knowledgeable people: PulkoMandy, KapiX\n- Project size: 350 hours\n- Difficulty: medium/hard\n- Expected outcome: implementation of the needed changes in app_server APIs and accelerant APIs to properly support multiple displays. Reference implementation either in test_app_server or in one of the existing graphics drivers on real or emulated hardware.\n\n#### Complex font rendering in app_server\n\napp_server is the graphics server in Haiku. It handles the rendering and display of application windows, desktop, and everything that is shown on screen.\n\nFreetype (in combination with agg) is used to render text. While it provides good results for latin and cyrillic alphabets, Freetype is not enough on its own to properly render other scripts with more complex rules, such as Devanagari or Arabic.\n\nThe goal of this task is to integrate Harfbuzz into app_server, so that the complex rules for text rendering are properly applied. This would allow rendering of complex languages as mentioned above, as well as mixing different languages (picking appropriate fonts automatically).\n\nThis task can be further extended with investigations of API changes required in the interface kit (and in particular BView and BFont) to properly handle right to left text.\n\n- Skill set: C++\n- Possible mentors: PulkoMandy\n- Project size: 175 hours\n- Difficulty: easy/medium\n- Expected outcome: working font rendering for arabic or devanagari or other script with \"complex\" rendering rules."
  },
  {
    "name": "The Julia Language",
    "slug": "the-julia-language",
    "tagline": "A fresh approach to technical computing",
    "description": "The Julia Language is an open-source, high level, and dynamic language built to be easy to use like Python while having speed near C++. As an umbrella organization, we house projects related to core Julia (the language) as well as packages from the broader Julia ecosystem.",
    "ideas_url": "https://julialang.org/jsoc/project",
    "website_url": "https://julialang.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "machine learning",
      "julia",
      "data science",
      "compilers",
      "garbage-collection"
    ],
    "topic_tags": [
      "math",
      "artificial intelligence",
      "science",
      "data science",
      "graphs"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/the-julia-language",
    "ideas_content": "It appears that you have stumbled upon a page on the Julia website that does not yet exist. You may find it useful to start over at [https://www.julialang.org](https://www.julialang.org), or to navigate the Julia website using the links above.\n\nTo improve this website, please [open an issue](https://github.com/julialang/www.julialang.org/issues) or [create a pull request](https://github.com/julialang/www.julialang.org/pulls)."
  },
  {
    "name": "Dart",
    "slug": "dart",
    "tagline": "Dart is a client language for apps on any platform",
    "description": "The Dart language gives you a fast developer experience and works on any platform. Dart powers hot reload enabling you to make a code change and instantly see results in your running app, and compiles to ARM and x64 machine code enabling quick app startup times for mobile, desktop and the web.\n\nDart powers Flutter, Google’s UI toolkit for building beautiful, natively compiled applications for mobile, web, and desktop from a single codebase.",
    "ideas_url": "https://github.com/dart-lang/sdk/blob/main/docs/gsoc/Dart-GSoC-2026-Project-Ideas.md",
    "website_url": "https://dart.dev",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "flutter",
      "dart"
    ],
    "topic_tags": [
      "programming languages",
      "mobile apps"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/dart",
    "ideas_content": "> [!info]\n> **Google Summer of Code 2026 is currently accepting applications until March 31st, 2026.**\n\nThe list of accepted projects will be announced on [summerofcode.withgoogle.com](https://summerofcode.withgoogle.com/organizations/).\n\n📌 See the [official timeline](https://developers.google.com/open-source/gsoc/timeline) for more details.\n------\n\nA list of Google Summer of Code project ideas for Dart.\n\nFor GSoC related discussions please use the [dart-gsoc group](https://groups.google.com/forum/#!forum/dart-gsoc).\n\n**Potential mentors**\n * Jonas Jensen ([jonasfj](https://github.com/jonasfj)) `jonasfj@google.com`\n * Daco Harkes ([dcharkes](https://github.com/dcharkes)) `dacoharkes@google.com`\n * Liam Appelbe ([liamappelbe](https://github.com/liamappelbe)) `liama@google.com`\n * Brian Quinlan ([bquinlan](https://github.com/brianquinlan)) `bquinlan@google.com`\n * Ben Konyi ([bkonyi](https://github.com/bkonyi)) `bkonyi@google.com`\n * More to come!\n\n## Project Application Process\nAll projects assume familiarity with Dart (and sometimes Flutter). Aspiring applicants are encouraged to [learn Dart](https://dart.dev/guides/language/language-tour) and try to write some code.\n\nApplicants are welcome to find and fix bugs in [Dart](https://github.com/dart-lang/sdk) or some of the [packages written by the Dart team](https://pub.dev/publishers/dart.dev/packages). However, getting reviews can take a long time as code owners may be busy working on new features. So instead of requiring applicants to fix a _good first bug_, we\nsuggest that applicants write a working code sample relevant for the proposed project.\n\nThe code sample can be attached to the application as a [**secret** gist](https://gist.github.com/) (please use _secret gists_, and do not share these with other applicants). Suggested ideas below includes proposed \"Good Sample Projects\".\n\n**Do not spend too much energy on this piece of sample code**, we just want to see\nthat you can code something relevant -- and that this sample code can run and do something non-trivial. Be aware that we have a limited number of\nmentors available, and will only be able to accept a few applicants.\n\nApplications can be submitted through the [summerofcode.withgoogle.com](https://summerofcode.withgoogle.com/) website. Applicants are encouraged to submit draft proposals, linking to Google Docs with permission for mentors to comment. See also the [contributor guide](https://google.github.io/gsocguides/student/writing-a-proposal) on writing a proposal.\n\n**IMPORTANT**: Remember to submit _final proposals_ before [the March 31st deadline](https://developers.google.com/open-source/gsoc/timeline).\n\n## **Idea:** Inspect native memory in Dart DevTools\n\n - **Possible Mentor(s)**: `dacoharkes@google.com`, `bkonyi@google.com`\n - **Difficulty**: Hard\n - **Project size**: Large (350 hours)\n - **Skills**: Dart, C++\n\n**Description**:\nWhen using the Dart debugger on `Pointer<X>` (where `X` extends `Struct` or `Union` or is a native type), the pointer itself is opaque. It would be extremely useful if the debugger could inspect the memory that the `Pointer` points to, effectively making `.ref` available as an inspectable getter.\n\nFor example, when debugging the following code:\n```dart\nimport 'dart:ffi';\nimport 'package:ffi/ffi.dart';\n\nfinal class MyStruct extends Struct {\n  @Int32()\n  external int a;\n  @Double()\n  external double b;\n}\n\nvoid main() {\n  final ptr = malloc<MyStruct>();\n  ptr.ref.a = 42;\n  ptr.ref.b = 3.14;\n  // Inspecting 'ptr' in the debugger should allow seeing 'a' and 'b'\n  // (either via the binary layout or a higher-level abstraction).\n  malloc.free(ptr);\n}\n```\nCurrently, `ptr` only shows its memory address in the debugger.\n\nHowever, dereferencing invalid pointers leads to segmentation faults. While `nullptr` (address 0) is easy to check, user-created pointers might point to invalid memory, and dereferencing them during a debug session should not crash the application.\n\nThis project involves:\n1.  **Exploring UI integration**: We'd want to explore different ways of exposing native memory in the developer tools:\n    *   Updating Dart DevTools and the [Debug Adapter Protocol (DAP)](https://microsoft.github.io/debug-adapter-protocol/) to handle a new `Instance` type for `Pointer` so they are displayed properly across IDEs without an extension.\n    *   Extending the **Object Inspector** (found under the **VM Tools** tab in DevTools).\n2.  **VM Service Protocol**: Extend the protocol to provide access to `Struct`/`Union` layout and annotations if not already available.\n3.  **VM Runtime**: Implement a mechanism in the Dart VM to safely dereference pointers during debugging. This likely means intercepting segmentation faults (signals) during these specific read operations and converting them into a virtual exception or error message that the debugger can display, rather than crashing the process.\n\n**Good Sample Project**:\nCreate a standalone Flutter app that demonstrates a custom view for a `Pointer`.\n*   The view should take a `Pointer` object (or a mock of one), compute the size of the data structure (the `X` in `Pointer<X>`), and display the memory contents. For the sample, you can assume valid pointers or mock the data retrieval to avoid crashes. **Bonus**: Implement this custom view directly in the [DevTools codebase](https://github.com/flutter/devtools) (e.g. in the Object Inspector) rather than as a standalone app.\n*   **Standout**: Add a new method or property to the VM Service Protocol (requires building the Dart SDK) and use this new protocol feature in your sample application.\n\n**Expected outcome**:\nA working feature in Dart DevTools (and underlying VM support) that allows\ndevelopers to inspect the contents of `Pointer`s safely during debugging.\n\n**Further reading**:\n\n* [Dart VM Service Protocol](https://github.com/dart-lang/sdk/blob/main/runtime/vm/service/service.md)\n* [Dart Debug Adapter Protocol](https://github.com/dart-lang/sdk/blob/main/third_party/pkg/dap/tool/README.md)\n* [Dart DevTools source code](https://github.com/flutter/devtools)\n* https://github.com/dart-lang/sdk/issues/48882\n* https://github.com/dart-lang/native/issues/1034\n\n\n\n## **Idea:** C++ in FFIgen\n\n - **Possible Mentor(s)**: Liam Appelbe, Brian Quinlan\n - **Difficulty**: Medium\n - **Project size**: Large (350 hours)\n - **Skills**: Dart, C++\n\n**Description**:\n\nC++ doesn't have a stable ABI (for example, it varies by compiler), so we can't directly interop with it. However, it would be possible to parse a C++ API, code-gen C compatible bindings for the API (using `extern \"C\"`), then generate Dart bindings that look like the C++ API, but actually invoke the C glue code.\n\n```\nInput       Output          Output\nC++ API <-> C glue code <-> Dart bindings\n```\n\nThe goal of this project is to add C++ as a new experimental language in FFIgen. FFIgen already uses libclang to parse C/ObjC APIs, so the parsing logic just needs to be extended to parse C++ APIs. Then the AST needs to be extended to be able to represent C++ language features. Finally, the code generator needs to be extended to support generating C code to wrap the C++ API, and Dart code to interact with the C API.\n\nA good proposal for this project will explore the various language features of C++, describe how that feature can be most closely represented in Dart, and what the C glue code looks like to support that feature. The more language features we can translate, the better the final product will be.\n\nA good sample project would be to add parsing logic to FFIgen to parse some simple C++ feature, such as a class with methods. Don't worry about code gen or representing the class in the AST yet, just write the parsing logic and print out some info about the class and its methods.\n\nTracking bug: [https://github.com/dart-lang/native/issues/2644](https://github.com/dart-lang/native/issues/2644)  \n\n\n## **Idea:** Migrate Intellij Plugins off weberknecht web socket library\n\n - **Possible Mentor(s)**: Phil Quitslund, Helin Shiah\n - **Difficulty**: Medium\n - **Project size**: Medium (175 hours)\n - **Skills**: Kotlin\n\n**Description**:\n\nThe current implementation of websocket connections in Intellij is out of date and conflicts with certain Anti-Virus software on Windows PCs. This needs to be updated to a more modern library and tested on various development platforms.\n\nTracking bug: https://github.com/flutter/dart-intellij-third-party/issues/208\n\n## **Idea:** Prototype New Dart IntelliJ plugin using LSP for Analysis Server Connection\n\n - **Possible Mentor(s)**: Phil Quitslund, Helin Shiah\n - **Difficulty**: Medium\n - **Project size**: Large (350 hours)\n - **Skills**: Kotlin\n\n**Description**:\n\nThe Dart plugin communicates with the analysis server with a legacy custom protocol, but migrating to language server protocol (LSP) would enable more language analysis features for IntelliJ/Android Studio users with less IntelliJ-specific code.\n\nRelated to: https://github.com/flutter/dart-intellij-third-party/issues/207\n\n\n## **Idea:** Add WebSocket/GRPC Support to Flutter DevTools Network panel\n\n - **Possible Mentor(s)**: [Elliott Brooks](https://github.com/elliette), [Samuel Rawlins](https://github.com/srawlins)\n - **Difficulty**: Hard\n - **Project size**: Medium (175 hours) or Large (350 hours)\n - **Skills**: Dart, Flutter\n\n**Description**:\n\nThe Dart & Flutter DevTools Network panel currently only supports HTTP requests, but many developers use other types of connections between their applications and back end services. Adding support for these would dramatically increase the effectiveness of the Network panel for developers.\n\nThis project involves extending `dart:io`, `dart:developer`, and the `VM Service` to record and expose `WebSocket` traffic details, and updating the DevTools Network panel to display that information. Once `WebSocket` support is added, there is an opportunity to add the same support for gRPC traffic (which would likely make this a `Large` and not `Medium` project).\n\nThe expected outcome of the project is for WebSocket traffic details (and potentially gRPC traffic details) to be displayed in the DevTools Network panel.\n\n**Good Sample Projects**:\n\nImplement a `ProfileableWebSocket` wrapper and create a Dart CLI application that uses this wrapper to display real-time traffic logs.\n\nPart 1: Create a `ProfileableWebSocket` wrapper class that implements `dart:io`'s `WebSocket` interface. The wrapper should record network traffic by intercepting every `add` call and `listen` event. It should record the time, size, and type of each frame and store it in a local buffer that can be queried.\n\nPart 2: Create a Dart CLI app that uses `ProfileableWebSocket`. It should connect to a public [WebSocket echo server](https://websocket.org/tools/websocket-echo-server/) and allow users to send messages. After every message sent it should print to the console a formatted table of the last ten socket events captured by the wrapper.\n\n**Further reading**:\n\n* [Design and Sizing for WebSocket Support](https://github.com/flutter/devtools/issues/9507)\n* [`dart:io` documentation](https://dart.dev/libraries/dart-io)\n* [Dart VM Service Protocol](https://github.com/dart-lang/sdk/blob/main/runtime/vm/service/service.md)\n* [DevTools Network Panel documentation](https://docs.flutter.dev/tools/devtools/network)\n* [Dart DevTools source code](https://github.com/flutter/devtools)\n\n\n\n## TODO: More ideas as they come!\n\n# Template:\n\nCopy this template.\n\n## **Idea:** ...\n\n - **Possible Mentor(s)**:\n - **Difficulty**: Easy / Hard\n - **Project size**: Small (90) / Medium (175 hours) / Large (350 hours)\n - **Skills**: ...\n\n**Description**: ...\n\n**Good Sample Project**: ...\n\n**Expected outcome**: ..."
  },
  {
    "name": "Ste||ar group",
    "slug": "stear-group",
    "tagline": "Shaping a Scalable Future",
    "description": "The STE||AR Group is an international team of researchers who understand that a new approach to parallel computation is needed.  Our work is crafted around the idea that we need to invent new ways to more efficiently use the resources that we have and use the knowledge that we gain to help guide the creation of the machines of tomorrow.  This organization aims to support, coordinate, and distribute research done in this area by creating a marketplace of ideas where concepts are debated and solutions are transparently developed.",
    "ideas_url": "https://github.com/STEllAR-GROUP/hpx/wiki/Google-Summer-of-Code-(GSoC)-2026#2026-hpx-project-ideas",
    "website_url": "http://stellar-group.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c++",
      "hpc"
    ],
    "topic_tags": [
      "library",
      "optimization",
      "parallel algorithms",
      "hpx",
      "application"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/stear-group",
    "ideas_content": "## Introduction\nWelcome to the Google Summer of Code (GSoC) page for the HPX project. Here you can find information about student projects, proposal submission templates, advice on writing good proposals, and links to information on getting started with HPX. [The STE||AR Group](http://stellar-group.org \"The STE||AR Group: Systems Technology, Emergent Parallelism, and Algorithm Research\") will apply as an organization and our goal is to have at least five funded students working on HPX related projects.\n\n## Requirements\n\nStudents must submit a proposal. A template for the proposal is available [[here|GSoC Submission Template]]. Find hints for writing a good proposal [[here|Hints for Successful Proposals]].\n\nWe strongly suggest that students interested in developing a proposal for HPX discuss their ideas on the [Discord](https://discord.gg/eh4HTXVuWg) channel or the mailing list to help refine the requirements and goals. Students who actively plan and discuss projects with developers are generally ranked before those that do not.\n\nWe have intentionally left the descriptions of these projects vague and open to interpretation because we expect students to develop their proposals' requirements by doing initial background research on the topic and interacting with the community. **In addition, it is important to note that the suggested projects on this page are not binding** -- if you have an interest in parallel task-based programming and have an idea for a project that would either improve HPX or demonstrate how well it applies to your problem, then feel free to suggest your idea as a project and write a proposal for it. We will be glad to help you with project goals to improve your proposal if you have ideas, so do not leave them until the last minute.\n\nWe will expect students to demonstrate that they have the required level of C++ and CMake knowledge by showing us some of their previous work (e.g., a GitHub repository), or preferably, by them making a small demonstration program using HPX that shows a simple example of something they have created themselves.\n\n## Potential Additional Funding\n\nFor students who perform at or above expectations on both GSoC evaluations, the Center of Computation and Technology (CCT) at Louisiana State University (LSU) may fund up to an additional four weeks' work on the project for no more than the GSoC rate of pay. This funding is not guaranteed and is independent of the GSoC program. Students accepted for additional funding will be paid through LSU for the additional weeks and affiliated with LSU during that time. Additional paperwork through LSU will be required.\n\n## Tips for Prospective Students\n\nSome of our former GSoC students that still contribute to our projects have put together the following list. All of them had to go through the same learning experience. Prospective students most probably face this challenge now, so the list provides pointwise help to get into HPX smoothly.\n\n 1. The first thing we suggest is to build HPX from the source using the CMake build system. An example guide to build HPX is [here](https://hpx-docs.stellar-group.org/latest/html/manual/building_hpx.html). Various ways of building HPX (e.g., memory allocators, OTF2 traces, CUDA support) will enable you to understand the capabilities of HPX as a runtime.\n 2. Once you're acquainted with the build system, we suggest you read our [docs/wiki](https://hpx-docs.stellar-group.org/latest/html/index.html) and try to familiarize yourself with the basic terminology (e.g., _locality_, _LCO_, _futurization_, etc.).\n 3. Next, we suggest you watch talks on [HPX](https://www.youtube.com/results?search_query=HPX+cpp) on YouTube. Doing so should give you a brief overview of the motivations and implementation design of the components within HPX.\n 4. At this point, try building and playing with the [examples](https://github.com/STEllAR-GROUP/hpx/tree/master/examples) in HPX. Furthermore, we have a [basic tutorial](https://hpx-docs.stellar-group.org/latest/html/examples.html) that takes you through the features and their usage with code examples.\n 5. Going through the examples may be an overwhelming experience, so we suggest you become familiar with our way of writing code through our [summer lecture series](https://www.diehlpk.de/blog/cpp-lectures/). (Hint: Pay attention to *Lecture #4*)\n 6. The C++ style used in HPX might not seem intuitive at first, but [this guide](https://wenke-d.github.io/CPP-for-HPX/) will help you build an intuition for why it is used.\n 7. When you're familiar with basic usage, we suggest you try writing demo HPX programs (e.g., matrix-matrix multiplication). Go through our [Issue tracker](https://github.com/STEllAR-GROUP/hpx/issues) and see if you can find an issue you would like to investigate. Working on bugs is the easiest way to dive into the code base and contribute to HPX.\n 8. Dig into our currently active [GSoC issues](https://github.com/STEllAR-GROUP/hpx/issues?q=is%3Aissue+is%3Aopen+label%3A%22project%3A+GSoC%22) and Pull Requests relevant to them. Furthermore, leave comments and discuss with the corresponding authors.\n 9. We **highly recommend** joining our channel, on [Discord](https://discord.gg/eh4HTXVuWg), where you can ask questions, discuss issues, pull requests, and your potential GSoC project. Remember, questions are the key to start contributing!\n\n## Usage of AI tooling\nThe goal of GSoC is to learn and grow through engagement with mentors and the broader community. AI tools can be helpful for brainstorming, providing suggestions, and assisting in learning new concepts. That said, we expect contributors to use AI tools responsibly. Raw AI output that you cannot understand and explain will not be accepted.\n\n## 2026 HPX Project Ideas \nThere are new projects this year, and also ones revamped from previous years (legacy) that are still of interest. These projects have mentors ready and waiting to help students.\n\n## Core HPX Projects\nThese are projects that involve making changes/improvements/extensions to the core HPX library.\n- [Introduction](#introduction)\n- [Requirements](#requirements)\n- [Potential Additional Funding](#potential-additional-funding)\n- [Tips for Prospective Students](#tips-for-prospective-students)\n- [Usage of AI tooling](#usage-of-ai-tooling)\n- [2026 HPX Project Ideas](#2026-hpx-project-ideas)\n- [Core HPX Projects](#core-hpx-projects)\n  - [Annotate HPX with Contracts](#annotate-hpx-with-contracts)\n  - [Expose HPX using C++ Modules](#expose-hpx-using-c-modules)\n  - [Implement the `make_receiver_for` optimization for HPX Senders](#implement-the-make_receiver_for-optimization-for-hpx-senders)\n  - [Implement `hpx::system_scheduler` as described in P2079 (System Execution Context)](#implement-hpxsystem_scheduler-as-described-in-p2079-system-execution-context)\n  - [Integrate HPX with the Tracy profiler](#integrate-hpx-with-the-tracy-profiler)\n  - [Use C++26 reflection for HPX remote operation](#use-c26-reflection-for-hpx-remote-operation)\n  - [Hierarchical Collectives for HPX](#hierarchical-collectives-for-hpx)\n  - [Implement parallel `hpx::uninitialized_relocate_*` algorithms for overlapping ranges](#implement-parallel-hpxuninitialized_relocate_-algorithms-for-overlapping-ranges)\n  - [Add HPX to Compiler Explorer (godbolt.org)](#add-hpx-to-compiler-explorer-godboltorg)\n  - [Improve ChplX - Source to Source Transformer for chapel to C++ using HPX](#improve-chplx---source-to-source-transformer-for-chapel-to-c-using-hpx)\n  - [\"Green out\" our Continuous Integration tests](#green-out-our-continuous-integration-tests)\n  - [Port HPX to iOS and Mac (M1 architecture)](#port-hpx-to-ios-and-mac-m1-architecture)\n  - [Study the performance of Halide applications running on HPX threads.](#study-the-performance-of-halide-applications-running-on-hpx-threads)\n  - [HPX distributed algorithms](#hpx-distributed-algorithms)\n  - [(Re-)Implement executor API on top of sender/receiver infrastructure](#re-implement-executor-api-on-top-of-senderreceiver-infrastructure)\n  - [Explicit Visualization of Accelerators for HPX Trace Visualization](#explicit-visualization-of-accelerators-for-hpx-trace-visualization)\n  - [Improved Scalability for HPX OTF2 Trace Visualization](#improved-scalability-for-hpx-otf2-trace-visualization)\n  - [Multiple File Load in HPX Trace Visualization](#multiple-file-load-in-hpx-trace-visualization)\n- [AI Project Ideas](#ai-project-ideas)\n  - [Spatio-Temporal Extrapolation with Generative AI: Advancing Storm Surge Forecast Accuracy through Bias Correction in Unmonitored Areas](#spatio-temporal-extrapolation-with-generative-ai-advancing-storm-surge-forecast-accuracy-through-bias-correction-in-unmonitored-areas)\n  - [Spatio-Temporal Extrapolation with GNN: Advancing Storm Surge Forecast Accuracy through Bias Correction in Unmonitored Areas](#spatio-temporal-extrapolation-with-gnn-advancing-storm-surge-forecast-accuracy-through-bias-correction-in-unmonitored-areas)\n  - [Transformer-based Image-to-Graph Conversion](#transformer-based-image-to-graph-conversion)\n- [Past Year Projects](#past-year-projects)\n  - [Coroutine-like Interface](#coroutine-like-interface)\n  - [Async I/O using Coroutines and S/R](#async-io-using-coroutines-and-sr)\n  - [Add Vectorization to `par_unseq` Implementations of Parallel Algorithms](#add-vectorization-to-par_unseq-implementations-of-parallel-algorithms)\n  - [Conflict (Range-Based) Locks](#conflict-range-based-locks)\n  - [Standardize and Visualize HPX Benchmarks](#standardize-and-visualize-hpx-benchmarks)\n  - [Rustize HPX!](#rustize-hpx)\n  - [Pythonize HPX!](#pythonize-hpx)\n  - [Create Generic Histogram Performance Counter](#create-generic-histogram-performance-counter)\n  - [Fix libCDS broken dependency](#fix-libcds-broken-dependency)\n- [HPX User Projects](#hpx-user-projects)\n  - [Implement your favorite Computational Algorithm in HPX](#implement-your-favorite-computational-algorithm-in-hpx)\n  - [Conduct a thorough Performance Analysis on HPX Parallel Algorithms (and optimize)](#conduct-a-thorough-performance-analysis-on-hpx-parallel-algorithms-and-optimize)\n- [Legacy Project Ideas](#legacy-project-ideas)\n  - [Implement Your Favorite Parcelport Backend](#implement-your-favorite-parcelport-backend)\n  - [Implement a Faster Associative Container for GIDs](#implement-a-faster-associative-container-for-gids)\n  - [Create A Parcelport Based on WebSockets](#create-a-parcelport-based-on-websockets)\n  - [All to All Communications](#all-to-all-communications)\n  - [Distributed Component Placement](#distributed-component-placement)\n  - [Port Graph500 to HPX](#port-graph500-to-hpx)\n  - [Port Mantevo MiniApps to HPX](#port-mantevo-miniapps-to-hpx)\n  - [Distributed solver and load balancing for Peridynamics using asynchronous parallelism](#distributed-solver-and-load-balancing-for-peridynamics-using-asynchronous-parallelism)\n  - [Port the GAP Benchmark Suite to HPX](#port-the-gap-benchmark-suite-to-hpx)\n  - [HPX backend for OpenMPI](#hpx-backend-for-openmpi)\n  - [Bug Hunter](#bug-hunter)\n  - [Project: Template](#project-template)\n\n### Annotate HPX with Contracts\n- **Abstract:** Recent standardization developments indicate that C++26 will introduce contracts [P2900](https://wg21.link/p2900). Their primary use is to increase language safety by providing developers with ergonomic tools to handle false assertions. They can be used to give defined behavior to pre-condition and post-condition violations of functions. The companion proposal to contracts: [P3471](https://wg21.link/p3471) introduces the notion of a hardened STL, which implements the expected conditions to standard library functions (e.g. vector.front() has a precondition that vector.empty() is false). HPX provides multiple debugging mechanisms, and a rich test suite. Annotating the HPX library functions would further safety and debugging ability.\n* **Additional References:** \n\t- [Proposal P2900 (Contracts)](https://wg21.link/p2900)\n\t- [Proposal P3471 (Hardened STL)](https://wg21.link/p3471)\n* **Difficulty:** Medium/Advanced\n* **Expected result:** Annotate a significant portion of HPX's public facing API with contracts.\n* **Knowledge Prerequisite:** C++, Git\n* **Mentor:** Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png)), Isidoros Tsaousis-Seiras (tsa.isidoros [at]  gmail.com)\n* **Project Size:** 350 hour (large project)\n\n\n### Expose HPX using C++ Modules\n* **Abstract:** [Modules](https://en.cppreference.com/w/cpp/language/modules) were introduced in C++20 as an alternative to header files for sharing declarations and definitions across translation units. C++ Modules can improve compilation times and code isolation. There are several differences when using C++ Modules, mainly they cannot export macros, and declarations have to be explicitly exported using the `export` keyword. We are interested in exposing HPX using C++ Modules (in addition to header files). A lot of work has already been done for this, howver there is quite a bit of work left to expose all of HPX in a convenient way through the C++20 module system.\n* **Additional References:** \nRubén Pérez on bringing C++ Modules to the Boost library: [Part 1](https://anarthal.github.io/cppblog/modules), [Part 2](https://anarthal.github.io/cppblog/modules2), [Part 3](https://anarthal.github.io/cppblog/modules3)\n* **Difficulty:** Medium/Advanced\n* **Expected result:** Make all of HPX available to users through C++ Modules\n* **Knowledge Prerequisite:** C++, Git\n* **Mentor:** Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png)), Panagiotis Syskakis (pansysk75 [at] gmail.com)\n* **Project Size:** 350 hour (large project)\n\n\n### Implement the `make_receiver_for` optimization for HPX Senders\n* **Abstract:** The Senders/Receivers ([P2300](https://wg21.link/P2300)) framework is constantly evolving to become more optimized and user-friendly. One of the papers accelerating this evolution is [P3425](https://wg21.link/p3425) It proposes that since chained operations have a known byte-size and are stacked contiguously in memory, we can avoid holding pointers to each of them, and we can calculate their addresses on the fly based on the offsets. This presents a massive object size reduction and also aids the compiler in optimizing the code. HPX's senders would greatly benefit from implementing the proposed interface to support this feature.\n\n* **Additional References:** \n\t- [Proposal P2300](https://wg21.link/p2300)\n\t- [Proposal P3425](https://wg21.link/p3425)\n* **Difficulty:** Medium/Advanced\n* **Expected result:** Implement the `make_receiver_for` interface for `hpx::bulk` as described in [P3425](https://wg21.link/p3425).\n* **Knowledge Prerequisite:** C++, Git, Concurrency\n* **Mentor:** Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png)), Isidoros Tsaousis-Seiras (tsa.isidoros [at]  gmail.com)\n* **Project Size:** 175 hour (medium project)\n\n\n### Implement `hpx::system_scheduler` as described in P2079 (System Execution Context)\n* **Abstract:** C++26 Has evolved to include a modern API for parallelism and task scheduling ([P2300](https://wg21.link/p2300)). HPX implements the proposed interface, as well as multiple schedulers. Proposal ([P2079](https://wg21.link/p2079)) proposes a generic scheduler to OS-provided threads. `hpx::system_scheduler` is the HPX analogue that maps to `hpx::threads` instead, and an excellent way to expose an HPX scheduler with a Sender/Receiver interface.\n\n* **Additional References:** \n\t- [Proposal P2300](https://wg21.link/p2300)\n\t- [Proposal P2079](https://wg21.link/p2079)\n* **Difficulty:** Medium/Advanced\n* **Expected result:** Implement `system_scheduler` as described in [P2079](https://wg21.link/p2079).\n* **Knowledge Prerequisite:** C++, Git, Concurrency\n* **Mentor:** Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png)), Isidoros Tsaousis-Seiras (tsa.isidoros [at]  gmail.com)\n* **Project Size:** 350 hour (large project)\n\n\n### Integrate HPX with the Tracy profiler\n* **Abstract:** HPX is already integrated with the [Intel VTune](https://www.intel.com/content/www/us/en/developer/tools/oneapi/vtune-profiler-download.html) and [APEX](https://uo-oaciss.github.io/apex/) profilers. HPX has also partial support for integrating with Tracy. Extending and improving support for binding Tracy to HPX will extend the capabilities of introspective and embedded profiling tools for HPX applications. The integration would include annotating key functions, mutexes, thread scheduling, distributed operation, etc. The work would also require extending the CMake based build system integration simplifying using Tracy with HPX and its applications. Part of the project could also be setting up a web-serivice that can be used to visualize collected Tracy data.\n* **Additional References:** \n    * [Tracy](https://github.com/wolfpld/tracy)\n* **Difficulty:** Medium/Advanced\n* **Expected result:** Integrate the Tracy profiler with HPX.\n* **Knowledge Prerequisite:** C++, Git, CMake\n* **Mentor:** Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png), Panagiotis Syskakis (pansysk75 [at] gmail.com))\n* **Project Size:** 350 hour (large project)\n\n\n### Use C++26 reflection for HPX remote operation\n* **Abstract:** HPX has already a remote function invocation (RPC) framework that allows to invoke C++ functions on a different locality. The current implementation of the  RPC mechanisms in the general case relies on the user providing explicit macros that expand to the necessary code blocks that enable the remote invocation of an function. With C++26 reflection becoming available, we should add support for automatically generating this code that relies on using these new language facilities.\n* **Additional References:** \n    * [C++ 26 Reflecton](http://wg21.link/P2996)\n* **Difficulty:** Medium/Advanced\n* **Expected result:** Arbitrary C++ functions can be invoked remotely.\n* **Knowledge Prerequisite:** C++, Git, CMake\n* **Mentor:** Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png))\n* **Project Size:** 350 hour (large project)\n\n\n### Hierarchical Collectives for HPX\n* **Abstract:** The standard collective operations in HPX follow a rather naive approach based on point-to-point communication with one host locality. Recently, hierarchical collectives using tree-based communication patterns were developed for the basic one-to-one and one-to-all collective operations. On large scale, these collective show significant performance improvements compared to their naive counterpart. The goal of this project is to add the remaining all-to-all-based collective operations to HPX using a similar tree-based approach.\n* **Difficulty:** Medium\n* **Expected result:** Complementing the hierachcial collectives in HPX with all-to-all, all-reduce, all-gather.  \n* **Knowledge Prerequisite:** C++, Git\n* **Mentor:** Alexander Strack (alexander.strack *[at]* ipvs.uni-stuttgart.com)\n* **Project Size:** 350hour (large project)\n\n\n### Implement parallel `hpx::uninitialized_relocate_*` algorithms for overlapping ranges\n* **Abstract:** HPX [implements](https://github.com/STEllAR-GROUP/hpx/tree/master/libs/core/algorithms/include/hpx/parallel/algorithms) the full set of the [C++ standard algorithms](https://en.cppreference.com/w/cpp/algorithm). This includes algorithms that copy data (e.g. `hpx::copy` copies the elements from a source range to a destination range). Recent proposals (see additional references below) suggest the addition of a new type trait (`std::is_trivially_relocatable`) that defines a new group of types that can benefit from **trivial relocation**. When relocating an object, the **relocation** algorithms will determine if it is valid to reduce the *move-constructor* and *destructor* call to a single `memcpy()`. In that way, relocation improves performance and increases safety. The relocation algorithms are: A) `relocate`, `relocate_at`, to operate on single objects and B) `uninitialized_relocate`, `uninitialized_relocate_backward` to operate on ranges of elements. These were added to HPX in a GSoC 2023 Contribution. However, the parallel versions of `hpx::uninitialized_relocate` and `hpx::uninitialized_relocate_backward` cannot handle overlapping ranges properly, as the forward and backward order of the algorithms is not preserved when running in parallel. The contributor is expected to correct the parallelization of these algorithms for overlapping ranges, as well as benchmark, write tests, and evaluate their solution.\n* **Additional References:** \n    * [P1144 Object relocation in terms of move plus destroy](http://wg21.link/p1144)\n    * [C++Now 2019: \"Trivially Relocatable\"](https://www.youtube.com/watch?v=SGdfPextuAU)\n    * [GSoC 2023: Relocation Semantics in HPX](https://isidorostsa.github.io/gsoc2023/)\n    * [Possible choice for a parallelization method](https://github.com/STEllAR-GROUP/hpx/pull/6364#discussion_r1414485678)\n* **Difficulty:** Medium/Advanced\n* **Expected result:** Parallel implementations of `uninitialized_relocate` and `uninitialized_relocate_backward` that work on overlapping ranges, as well as written tests and benchmarks.\n* **Knowledge Prerequisite:** C++, Git, parallel algorithms\n* **Mentor:** Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png)) and Isidoros Tsaousis-Seiras (tsa.isidoros *[at]* gmail.com)\n* **Project Size:** 175 hour (Medium/Advanced project)\n\n\n### Add HPX to Compiler Explorer (godbolt.org)\n* **Abstract:** Compiler Explorer https://godbolt.org/ is a widely popular web based application which provides easy access to multiple C++ compilers and environments allowing their users to write, test and share anything from small C++ scripts to large CMake-based projects quickly. Given its versatility we thought that it would be a convenient for HPX to have an integration with Compiler Explorer in some way. A preliminary idea is that we will maintain our own fork of Compiler Explorer (which is open source) and experiment with the HPX integration locally before making the integration public through a Pull Request to Compiler Explorer. The result could even be constrained to an environment somewhat similar to Compiler Explorer just for HPX where prospective users would experiment with quick HPX scripts before downloading, building and running the whole library.\n* **Difficulty:** Medium/Hard\n* **Expected result:** Develop a fork of Compiler Explorer (or application with similar basis) where HPX is integrated and available for quick testing and scripting.\n* **Knowledge Prerequisite:** C++, CMake, Compilers, Node.js\n* **Mentor:** Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png)) and Giannis Gonidelis (gonidelis [at] hotmail.com)\n* **Project Size:** 175 (Medium project)\n\n\n### Improve ChplX - Source to Source Transformer for chapel to C++ using HPX\n* **Abstract:** HPX is an excellent runtime system for doing task-based parallelism. Chapel is one of the most easy to use languages for HPC which are readily scalable. [ChplX](https://github.com/ct-clmsn/chplx) is an attempt to make things interoperable. Chapel gets access to existing C++ tooling in HPX and other toolchain integrations that supports C++. We also have traveler visualization and APEX performance counters which are helpful to determine several statistics. This project has a huge interest from Chapel and other communities. \n* **Difficulty:** Medium\n* **Expected result:** \nPropose one of the following or it's sub idea to improve chplx's individual components:\n    1. Library - \n        - Add constructs from Chapel language which are not added yet.\n        - Suggest improvements to the existing constructs which are incorrect or miss important semantics.\n        - Add distributed support. Currently we do not support multiple localities. GPU is not expected for now.\n    2. Compiler - \n        - Fix compiler code generation for certain cases when it might fail (this is vague and needs a lot of work to delve into and figure out wrongs and correct those, totally non-trivial - HARD/LARGE project)\n        - Add more constructs for the compiler end which already exist in the library.\n    3. General Tooling - \n        - Currently there's inconsistency between compilation flags and we need a single command solution i.e. it can build everywhere. Some efforts are on the way https://github.com/SAtacker/chplx/tree/make_integrated_build.\n        - Add benchmark measurements tooling. It needs to compile the chapel code using chapel and c++ compilers and give out various statistics available (peak memory usage, timing characteristics, possibly- cache utilization, etc.). We also need non-trivial benchmarks apart from the few we already have.                               \n* **Knowledge Prerequisite:** C++, Review [codebase1](https://github.com/ct-clmsn/chplx) [codebase2](https://github.com/SAtacker/chplx/tree/make_integrated_build) so you know what's going on. Codebase1 refers to the basic idea, codebase2 has some efforts to make things bit more integrable rather than having to do it the hard way.\n* **Related Talks:** https://youtu.be/JwpQVBcNB7E?si=luZyDNcbD11lVehr https://www.youtube.com/watch?v=aOKqyt00xd8&t=36s\n* **Mentor:** Hartmut Kaiser and Shreyas Atre (@SAtacker) and Chris Taylor (please ping us on STEllAR Group's Discord)\n* **Project Size:** 350 hour (large project)\n\n### \"Green out\" our Continuous Integration tests\n* **Abstract:** There are tests in our Continuous Integration (CI) that are currently failing. These are mainly under our tests.regressions, tests.segmented_algorithms targets, performance tests and certain new compilers tests (clang-13/14, gcc-12). One can see all the tests that are failing if they randomly select an open PR and scroll down to check the list items indicated with a red 'X'. Fixing those tests would include a wide range of bug hunting tasks and creativity from the student side in order to reproduce them locally until they figure out and fix the errors. \n* **Difficulty:** Easy/Medium\n* **Expected result:** All tests in our CI pass (are green).\n* **Knowledge Prerequisite:** C++, CMake, slurm\n* **Mentor:** Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png)) and Giannis Gonidelis (gonidelis *[at]* hotmail.com)\n* **Project Size:** 175 hour (Easy/Medium project)\n\n### Port HPX to iOS and Mac (M1 architecture)\n* **Abstract:** HPX has already proven to run efficiently on ARM-based systems. This has been demonstrated with an [application written for Android tablet devices](https://www.youtube.com/watch?v=IwCJpzMi1jc \"VanDouken Demo: Using Supercomputer Tech to Animate Paintings\"). A port to handheld devices running with iOS would be the next logical step! On top of that since the new Apple M1 ARM-based processors have proven to be very efficient the student should consider providing an HPX version for this architecture as well. To run HPX efficiently on there, we need to adapt our build system to be able to cross-compile for iOS and Mac and add a code to interface with the iOS GUI and other system services. A preexisting Mac support infrastructure exists but the student will need to adapt and update it to current releases.\n* **Difficulty:** Easy/Medium\n* **Expected result:** Provide a prototype HPX application running on an iPhone or iPad.\n* **Knowledge Prerequisite:** C++, Objective-C, iOS\n* **Mentor:** Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png)) and Thomas Heller (![thomas%20heller](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/thomas%20heller.png))\n* **Project Size:** 350 hour (large project)\n\n\n### Study the performance of Halide applications running on HPX threads. \n* **Abstract:** [Halide](https://halide-lang.org/) is a programming language designed to facilitate developing high-performance array-based code with regular access to memory on a wide range of modern architectures. Halide also makes it possible to use custom runtimes, such as HPX, in situ of the native runtime. A preliminary [work](https://github.com/STEllAR-GROUP/phylanx_halide/) has shown promising results for the HPX runtime in code generated by Halide. The goal of this project is to investigate the effectiveness of code generated by Halide in libraries that use HPX as a backend. We are notably interested in improving the performance of level 2, and 3 BLAS operations in the [Blaze](https://bitbucket.org/blaze-lib/blaze/src/master/) math library.\n* **Difficulty:** Medium\n* **Expected result:** Comprehensive performance analysis of Halide code in Blaze and other stencil-like applications.\n* **Knowledge Prerequisite:** C++ \n* **Mentor:** Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png)) and Rod Tohid (rtohid [at] cct.lsu.edu)\n* **Project Size:** 175 hour (medium project)\n\n### HPX distributed algorithms \n* **Abstract:** Along with the [standard parallel algorithms](https://en.cppreference.com/w/cpp/algorithm) provided by the C++ standard, HPX extends its infrastructure by providing (some of) the corresponding distributed versions of those algorithms that run on multiple nodes and on top of that they take care of communication. We currently miss distributed versions of some of the algorithms, notably distributed sorting should be implemented. This project is about working on implementing one or more of the missing algorithms.\nThe set of the implemented algorithms can be found [here](https://github.com/STEllAR-GROUP/hpx/tree/master/libs/full/segmented_algorithms/include/hpx/parallel/segmented_algorithms). [Here](https://github.com/STEllAR-GROUP/hpx/issues/1338) you can find the corresponding ticket.\n* **Difficulty:** Medium/hard\n* **Expected result:** Implement segmented (distributed) sorting and/or additional algorithms.\n* **Knowledge Prerequisite:** C++, CMake\n* **Mentor:** Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png)) and Giannis Gonidelis (gonidelis *[at]* hotmail.com)\n* **Project Size:** 350 hour (large project)\n\n\n### (Re-)Implement executor API on top of sender/receiver infrastructure\n* **Abstract:** [P2300](https://wg21.link/p2300) will most likely be accepted for C++26. Our executor API (customization points) currently dispatch to an executor interface defined by wg21.link/p0443R3. All HPX facilities related to scheduling tasks (algorithms, future, dataflow, async, etc.) rely on the executor customization points to perform their operations. Although [major steps](https://github.com/STEllAR-GROUP/hpx/pull/5758) have been taken for the integration of the executors proposal to HPX there is still many facilities that need to be implemented. The project can be correlated with the [Coroutine-like interface project](#coroutine-like-interface) project and the P2300 proposed [awaitables](https://wg21.link/p2300).\n* **Difficulty:** Medium\n* **Expected result:** The result should be functioning executor customization points built upon senders/receivers.\n* **Knowledge Prerequisite:** Parallel algorithms.\n* **Mentor:** Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png)) and Giannis Gonidelis (gonidelis *[at]* hotmail.com)\n* See [issue #5219 on HPX bug tracker](https://github.com/STEllAR-GROUP/hpx/issues/5219) and the corresponding [Pull Request](https://github.com/STEllAR-GROUP/hpx/pull/5758) that's on the works already.\n* **Project Size:** 350 hour (large project)\n\n\n### Explicit Visualization of Accelerators for HPX Trace Visualization\n* **Abstract:** HPX traces are collected with APEX and written in as OTF2 files with extensions. These trace files are typically visualized using a Gantt chart or collection of timelines. Presently, there is no differentiation between tasks executed on an accelerator versus other hardware. This project requires (1) investigation regarding what data can be collected about accelerators through HPX and APEX, and (2) design and implementation of how accelerator data is implemented in [Traveler](https://github.com/hdc-arizona/traveler-integrated). Collection will require C++, while the Traveler alterations will also require Python (backend) and Javascript (frontend).  \n* **Difficulty:** Medium-Hard\n* **Expected result:** Traveler trace visualization includes query support and visual indicators of data regarding accelerators.\n* **Knowledge Prerequisite:** C++, Python, Javascript.\n* **Mentor:** Kate Isaacs (![kate%20isaacs](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/kate%20isaacs.png)) \n* **Project Size:** Could be 175 hour (medium sized) or 350 hour (large sized) depending on proposal\n\n\n### Improved Scalability for HPX OTF2 Trace Visualization\n* **Abstract:** HPX traces are collected with APEX and written in as OTF2 files with extensions. These trace files are typically visualized using a Gantt chart or collection of timelines in [Traveler](https://github.com/hdc-arizona/traveler-integrated). The present implementation reads the entirety of the trace file before generating the visualization using one of the older APIs to do so. However, the OTF2 interface has support for partial reading of the file and a parallel backend. This project would modify the Gantt chart backend (C++/Python) to utilize these features, thus supporting larger files. The project could also modify the front end to use WebGL (Javascript) when the number of data items is large.\n* **Difficulty:** Medium-Hard\n* **Expected result:** Files that require more memory than on a single machine can be run from that machine. The time from program-start to visualization is decreased due to the use of large file features.\n* **Knowledge Prerequisite:** C++, Python, Javascript.\n* **Mentor:** Kate Isaacs (![kate%20isaacs](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/kate%20isaacs.png)) \n* **Project Size:** 175 hour (medium sized)\n\n\n### Multiple File Load in HPX Trace Visualization\n* **Abstract:** HPX traces are collected with APEX and written in as OTF2 files with extensions. These trace files are typically visualized using a Gantt chart or collection of timelines. We want to load multiple of these files at the same time and align the views between the like-charts for comparison in [Traveler](https://github.com/hdc-arizona/traveler-integrated). Traveler alterations will also require Python (backend) and Javascript (frontend).  \n* **Difficulty:** Medium-Hard\n* **Expected result:** Traveler trace visualization can open multiple files and arranges views so performance can be compared across files.\n* **Knowledge Prerequisite:** Python, Javascript.\n* **Mentor:** Kate Isaacs (![kate%20isaacs](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/kate%20isaacs.png)) \n* **Project Size:** Could be 175 hour (medium sized)\n\n## AI Project Ideas \nThese are project ideas that involve AI methodologies in different applications.\n * [Spatio-Temporal Extrapolation with Generative AI: Advancing Storm Surge Forecast Accuracy through Bias Correction in Unmonitored Areas](#spatio-temporal-extrapolation-with-generative-aI-advancing-storm-surge-forecast-accuracy-through-bias-correction-in-unmonitored-areas)\n * [Spatio-Temporal Extrapolation with GNN: Advancing Storm Surge Forecast Accuracy through Bias Correction in Unmonitored Areas\n](#spatio-temporal-extrapolation-with-GNN-advancing-storm-surge-forecast-accuracy-through-bias-correction-in-unmonitored-areas)\n * [Transformer-based Image-to-Graph Conversion](#Transformer-based-Image-to-Graph-Conversion)\n\n### Spatio-Temporal Extrapolation with Generative AI: Advancing Storm Surge Forecast Accuracy through Bias Correction in Unmonitored Areas\n* **Abstract:** In 2022, severe storms and tropical cyclones represented 14 out of the 18 documented weather and/or climate related disasters reported in the U.S., leading to a dreadful cost in human lives, but also to an overall financial cost exceeding 135 billion dollars [1]. The pronounced frequency and severity of such events demonstrates the critical importance of improving storm surge forecast tools in terms of both accuracy and efficiency. In this context, recent work aims to predict the systemic error between physics-based storm surge forecast model and observed water level data were obtained from gauge stations and use it to correct the simulation results on gauge stations. However, ensuring the accuracy of water level simulations across extensive and unevenly monitored locations remains a critical challenge. Given the limitations of traditional interpolation methods and the sparse distribution of gauge stations, we propose the innovative use of Generative Artificial Intelligence (AI) to address the challenge of extrapolating bias correction values to unmonitored areas. Generative AI, through its capacity to learn and mimic the distribution of complex datasets, offers a groundbreaking approach to understanding and predicting environmental variables across spatial and temporal scales. By training on available data from gauge stations, Generative AI models can generate accurate bias correction predictions for regions beyond the gauge stations. The proposed methodology leverages the latest advancements in Generative AI, including techniques like Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), to model the complex interdependencies within the offsets data. By incorporating spatial correlations and environmental covariates, the Generative AI framework aims to produce spatially coherent and temporally consistent bias corrections across the simulation area. A case study implementing this Generative AI approach will be conducted to validate its effectiveness in enhancing model accuracy.\n\n* **Difficulty:** Medium-Hard\n* **Expected result:** Implementation of generative AI AI model for Spatio-Temporal Extrapolation of offsets. \n* **Knowledge Prerequisite:** Python, Machine learning basics  \n* **Mentor:** Noujoud Nader (noujoude.nader *[at]* gmail.com) and Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png))\n* **Project Size:** 350 hour (large project)\n\n\n### Spatio-Temporal Extrapolation with GNN: Advancing Storm Surge Forecast Accuracy through Bias Correction in Unmonitored Areas\n* **Abstract:** In 2022, severe storms and tropical cyclones represented 14 out of the 18 documented weather and/or climate related disasters reported in the U.S., leading to a dreadful cost in human lives, but also to an overall financial cost exceeding 135 billion dollars [1]. The pronounced frequency and severity of such events demonstrates the critical importance of improving storm surge forecast tools in terms of both accuracy and efficiency. In this context, recent work aims to predict the systemic error between physics-based storm surge forecast model and observed water level data were obtained from gauge stations and use it to correct the simulation results on gauge stations. However, ensuring the accuracy of water level simulations across extensive and unevenly monitored locations remains a critical challenge. Given the limitations of traditional interpolation methods and the sparse distribution of gauge stations, we propose the innovative use of Graph Neural Network (GNN) to address the challenge of extrapolating bias correction values to unmonitored areas. GNNs are inherently good at capturing spatial relationships and dependencies between nodes in a graph. This can be particularly useful for modeling the influence of nearby gauge stations on unmonitored areas. In addition, GNNs can integrate various types of information, including physical properties and geographical context, which can be critical for accurate extrapolation in environmental sciences. They can easily integrate heterogeneous data, making them suitable for our complex environmental systems where offset data is affected by the presence of natural barriers and geographical features, like a lake between two gauge stations.\n\n* **Difficulty:** Medium-Hard\n* **Expected result:** Implementation of GNN AI model for Spatio-Temporal Extrapolation of offsets. \n* **Knowledge Prerequisite:** Python, Machine learning basics  \n* **Mentor:** Noujoud Nader (noujoude.nader *[at]* gmail.com) and Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png))\n* **Project Size:** 350 hour (large project)\n\n\n### Transformer-based Image-to-Graph Conversion\n* **Abstract:** The process of reconstructing graph representations from medical images, known as Image-to-Graph conversion, is a common task, particularly evident in biomedical imaging for extracting vessel graphs. Here, we propose a novel Machine Learning (ML)-based Image-to-Graph pipeline that emphasizes edge features, which are critical for applications such as blood flow simulation. This pipeline incorporates advanced ML algorithms, including the use of the **Transformer** model, to serve dual purposes: firstly, to objectively extract vascular features from medical images without relying on subjective judgment or requiring extensive user skill; and secondly, to facilitate rigorous model validation. For our model training and validation, we will utilize 3D image datasets of healthy and diseased subjects, including those of the brain and lungs.\n\n* **Difficulty:** Medium-Hard\n* **Expected result:** Implementation of transformer model for image to graph conversion. \n* **Knowledge Prerequisite:** Python, Machine learning basics, tranformers  \n* **Mentor:** Noujoud Nader (noujoude.nader *[at]* gmail.com) and Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png))\n* **Project Size:** 350 hour (large project)\n\n## Past Year Projects\nThese are projects that were worked on in previous years of Google Summer of Code, but still have not been fully resolved. Others in this list might have been partially implemented. If you are interested in any of the following project ideas, please reach out to learn more.\n* [Coroutine-like Interface](#coroutine-like-interface)\n* [Async I/O using Coroutines and S/R](#async-io-using-coroutines-and-sr) \n* [Add Vectorization to the `par_unseq` Implementations of the Parallel Algorithms](#add-vectorization-to-par_unseq-implementations-of-parallel-algorithms)\n * [Conflict (range-based) Locks](#conflict-range-based-locks)\n * [Standardize and Visualize HPX Benchmarks](#standardize-and-visualize-hpx-benchmarks)\n * [Rustize HPX!](#rustize-hpx)\n * [Pythonize HPX!](#pythonize-hpx)\n * [Create Generic Histogram Performance Counter](#create-generic-histogram-performance-counter)\n * [Fix libCDS broken dependency](#fix-libcds-broken-dependency)\n\n### Coroutine-like Interface\n* **Abstract:** HPX is an excellent runtime system for doing task-based parallelism. In its current form, however, the results of tasks can only be expressed in terms of returning from a function. However, there are scenarios where this is not sufficient. One example would be lazy ranges of integers (for example, Fibonacci, 0 to n, etc.). For those, a generator/yield construct would be perfect (more on [coroutines](https://en.cppreference.com/w/cpp/language/coroutines))! Additionally, an option would be to rely on top of the <b>senders/receivers</b> [proposed](http://wg21.link/p2300) facilities, a completely new interface for execution in standard C++ that may (or not) revolutionize the way we implement concurrency.\n* **Difficulty:** Medium\n* **Expected result:** Implement yield and demonstrate on at least one example\n* **Knowledge Prerequisite:** C++\n* **Mentor:** Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png)) and Thomas Heller (![thomas%20heller](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/thomas%20heller.png))\n* **Project Size:** 350 hour (large project)\n\n### Async I/O using Coroutines and S/R\n* **Abstract:** Coroutines along with S/R make a really good use case for async I/O [Ref 1](https://db.in.tum.de/~fent/papers/coroutines.pdf?lang=en). Using the recently added HPX S/R facilities to develop an interface for a relatively faster I/O example would be the goal of this project. Additionally for Linux based platforms with [`io_uring`](https://unixism.net/loti/what_is_io_uring.html) support can have even more performance benefits.\n* **Additional References:** \n    * https://github.com/L-v-M/async \n    * https://pabloariasal.github.io/2022/11/12/couring-1/\n* **Difficulty:** Easy/Medium\n* **Expected result:** Develop a non-trivial use case using the above described tools and HPX.\n* **Knowledge Prerequisite:** C++, CMake\n* **Mentor:** Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png)) and Giannis Gonidelis (gonidelis *[at]* hotmail.com) and [Shreyas Atre](https://github.com/SAtacker) (Discord: Shreyas)\n* **Project Size:** 175 hour (Easy/Medium project)\n\n### Add Vectorization to `par_unseq` Implementations of Parallel Algorithms\n* **Abstract:** Our parallel algorithms currently don't support the [`par_unseq` execution policy](http://stellar-group.github.io/hpx/docs/html/hpx.html#hpx.parallel.execution.par_unseq).\n  This project is centered around the idea to implement this execution policy for at least some of the existing algorithms (such as `for_each` and similar).\n* **Difficulty:** Medium/Hard\n* **Expected result:** The result should be functioning parallel algorithms when used with the\n  `par_unseq` execution policy. The loop body should end up being vectorized.\n* **Knowledge Prerequisite:** Vectorization, parallel algorithms.\n* **Mentor:**  Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png)), Srinivas Yadav (vasu.srinivasvasu.14 *[at]* gmail.com), Nikunj Gupta (nikunj *[at]* illinois.edu), Giannis Gonidelis (gonidelis *[at]* hotmail.com)\n* See [issue #2271 on HPX bug tracker](https://github.com/STEllAR-GROUP/hpx/issues/2271)\n* **Project Size:** 350 hour (large project)\n\n### Conflict (Range-Based) Locks\n* **Abstract:** Some multi-threaded algorithms may require resources that must be held using a lock, but the locking mechanism may be range-based rather than absolute. Consider a large array of `N` items where a task requires some small subset of the items to be locked while a second task requires a second range. If these tasks are placed into a DAG so that `task2` can only run once `task1` has been completed, it will be inefficient when the range of items used by task2 does not overlap the range from `task1`. When many tasks operate on the range, with randomly overlapping or non-overlapping regions, DAG-based task scheduling leads to a highly inefficient strategy. We need a range based lock that can be templated over `<items>`, and that can then be locked/unlocked on ranges (of those items) and interact with our `future<>` based scheduling so that items will become _ready_ when the range they need has no locks outstanding, and so that when a task releases a lock, any other tasks that overlap the range are in turn signaled as possibly ready. (For an example of how this is used in conventional HPC programming, look up Byte Range locks in MPI for Parallel IO to a single file). A successful implementation can be extended to multi-dimensional locking *2D/3D etc., ideally templated over dimensions and types).\n* **Difficulty:** Medium/Hard\n* **Expected result:** A test application that creates arrays of items and randomly assigns tasks to operate on regions of those items with locking and schedules the tasks to operate in a non-conflicting way.\n* **Knowledge Prerequisite:** Thread-safe programming. Futures.\n* **Mentor:** John Biddiscombe (![john%20biddiscombe](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/john%20biddiscombe.png))\n* **Project Size:** 350 hour (large project)\n\n### Standardize and Visualize HPX Benchmarks\n* **Abstract:** HPX, as a high-performance computing framework, includes various benchmarks to measure the performance of its algorithms and runtime system. However, these benchmarks lack a standardized format and a comprehensive visualization tool that can help in analyzing performance trends over time and across different computing environments. This project aims to standardize the benchmark formats within HPX using third party benchmarking tools (recommendations below) and develop a visualization tool that can display benchmark results in an intuitive manner. The tool will used in conjunction with CI/CD to track and display performance regressions or improvements, and provide insights into the scalability and efficiency of new components.\n* **Additional References:** \n    * Recommended Benchmarking Frameworks: [Google Benchmark](https://github.com/google/benchmark), [Nanobench](https://nanobench.ankerl.com/)\n    * [Nanobench in HPX](https://github.com/STEllAR-GROUP/hpx/pull/6357)\n    * [Google Benchmark in HPX](https://github.com/SAtacker/hpx-template)\n* **Difficulty:** Medium/Advanced\n* **Expected result:** 1) A unified format for HPX benchmarking using chosen benchmarking framework. 2) Automating the installation of the chosen benchmarking framework in the HPX build system. 3) A visualization tool (suggestion: a python script) to display the results.\n* **Knowledge Prerequisite:** C++, Git, Python or plotting framework of your choice\n* **Mentor:** Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png)) and Isidoros Tsaousis-Seiras (tsa.isidoros *[at]* gmail.com).\n* **Project Size:** 350 hour (Advanced project)\n\n### Rustize HPX!\n* **Abstract:** Rust is an increasingly widely adopted language used because of it's performance and apparent safety. Providing performant HPX functionality written in C++ with Rust APIs would facilitate both safety and ease of learning HPX. The student shall design and implement Rust bindings for HPX, exposing all or parts of the HPX functionality with a Rust API. \n* **Difficulty:** Medium\n* **Expected result:** Demonstrate functioning bindings by implementing small example scripts for different simple use cases\n* **Knowledge Prerequisite:** C++, Rust\n* **Mentor:** Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png))\n* **Project Size:** 350 hour (large project)\n\n### Pythonize HPX!\n* **Abstract:** Python is a widely adopted language due to its simplicity. Providing performant HPX functionality written in C++ with Pythonic APIs would facilitate both usage and ease of learning HPX. The student shall design and implement Python bindings for HPX, exposing all or parts of the HPX functionality with a 'Pythonic' API. This should be possible as Python has a much more dynamic type system than C++. Using [Boost.Python](http://www.boost.org/doc/libs/1_55_0/libs/python/doc/) and/or [Pybind11](https://pybind11.readthedocs.io/en/stable/) seem to be good choices for this.\n* **Difficulty:** Medium\n* **Expected result:** Demonstrate functioning bindings by implementing small example scripts for different simple use cases\n* **Knowledge Prerequisite:** C++, Python\n* **Mentor:** Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png))\n* **Project Size:** 350 hour (large project)\n\n### Create Generic Histogram Performance Counter\n* **Abstract:** HPX supports [performance counters](http://stellar-group.github.io/hpx/docs/html/hpx.html#hpx.manual.performance_counters) that return a set of values for each invocation.\n  We have used this to implement performance counters collecting histograms for various characteristics related to parcel coalescing (such as the histogram of the time intervals between parcels). The idea of\n  this project is to create a general-purpose performance counter which collects the value of any\n  other given performance at given time intervals and calculates a histogram for those values.\n  This project could be combined with [Add more arithmetic performance counters](#add-more-arithmetic-performance-counters).\n* **Difficulty:** Medium\n* **Expected result:** Implement a functioning performance counter which returns the histogram for any\n  other given performance counter as collected at given time intervals.\n* **Knowledge Prerequisite:** Minimal knowledge of statistical analysis is required.\n* **Mentor:** Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png)) and Mikael Simberg (![mikael%20simberg](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/mikael%20simberg.png))\n* See [issue #2237 on HPX bug tracker](https://github.com/STEllAR-GROUP/hpx/issues/2327)\n* **Project Size:** 350 hour (large project)\n\n### Fix libCDS broken dependency\n* **Abstract:** [libCDS](https://github.com/khizmax/libcds) is a Concurrent Data Structures library which provides containers that alleviate the user from taking care of synchronization. HPX provides an [integration](https://github.com/STEllAR-GROUP/hpx/blob/99a4b007f49b60809203cac9555a960cde440ef8/CMakeLists.txt#L940-L964) with libCDS which is currently broken. We are looking for a prospective developer that will bring that libCDS up to date with the current version of HPX and provide testing and benchmarking with the contemporary results.\n* **Difficulty:** Easy\n* **Expected result:** libCDS current version full integration with the latest HPX.\n* **Knowledge Prerequisite:** CMake, Data Parallelism, C++.\n* **Mentor:** Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png)) and Giannis Gonidelis (gonidelis *[at]* hotmail.com)\n* **Project Size:** 350 hour (large project)\n\n\n## HPX User Projects\nThese are projects that improve code that uses HPX. In general, the primary goal with these projects is to improve user uptake of HPX by demonstrating its use in other projects, and only minor fixes/changes/extensions should be necessary for the main HPX library itself.\n\n### Implement your favorite Computational Algorithm in HPX \n* **Abstract:** This is an open project for prospective students who don't want to get their hands dirty into core HPX development. The student shall utilize HPX to implement a short independent project that will utilize HPX for performance boost. The program can implement any given problem that requires heavy computational effort from the literature. [Efficient matrix multiplication](https://en.wikipedia.org/wiki/Matrix_multiplication_algorithm#Parallel_and_distributed_algorithms), sorting, [stencil variations](https://en.wikipedia.org/wiki/Stencil_(numerical_analysis)#See_also) or any AI, Physics related problem would be a good candidate.\nAn extensive [list of use-case examples](https://github.com/STEllAR-GROUP/hpx/tree/master/examples) is already available in our source code. The goal of this project is for the student to get acquainted with HPX development and contribute to our vast range of applications.\n* **Difficulty:** Easy\n* **Expected result:** Implement a standalone program that utilizes HPX for performance. \n* **Knowledge Prerequisite:** C++ \n* **Mentor:**  Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png))\n and Giannis Gonidelis (gonidelis *[at]* hotmail.com)\n* **Project Size:** 175 hour (medium sized)\n\n### Conduct a thorough Performance Analysis on HPX Parallel Algorithms (and optimize)\n* **Abstract:** HPX [implements](https://github.com/STEllAR-GROUP/hpx/tree/master/libs/core/algorithms/include/hpx/parallel/algorithms) all the C++ standard [algorithms](https://en.cppreference.com/w/cpp/algorithm) along with their [ranges](https://en.cppreference.com/w/cpp/ranges) counterparts. Conducting extensive performance analysis on the existing implementations and coming up with possible optimizations would improve the efficiency of our parallel algorithms and boost HPX performance in general. The student shall expect to work both on top of HPX by writing custom benchmarks for [weak and strong scaling](https://en.wikipedia.org/wiki/Scalability#Weak_versus_strong_scaling), evaluate the results and perform source optimizations under the hood (core development).\n* **Difficulty:** Medium\n* **Expected result:** Boost the performance of at least one C++ standard algorithm in HPX. \n* **Knowledge Prerequisite:** C++\n* **Mentor:** Giannis Gonidelis (gonidelis *[at]* hotmail.com) and Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png))\n* **Project Size:** 350 hour (large project)\n \n## Legacy Project Ideas \nThese are project ideas from previous Summer of Code years that we are still interested in working on, but it might be harder to find a mentor willing to supervise a student. Therefore, we would expect only very self-motivated and capable students to select a project from the legacy category. We cannot guarantee that we will select a project from this list unless we are quite satisfied that the student can complete the work.\n * [Implement Your Favorite Parcelport Backend](#implement-your-favorite-parcelport-backend)\n * [Implement A Faster Associative Container for GIDs](#implement-a-faster-associative-container-for-gids)\n * [Create A Parcelport Based on WebSockets](#create-a-parcelport-based-on-websockets)\n * [All to All Communications](#all-to-all-communications)\n * [Distributed Component Placement](#distributed-component-placement)\n * [Port Graph500 to HPX](#port-graph500-to-hpx)\n * [Port Mantevo MiniApps to HPX](#port-mantevo-miniapps-to-hpx)\n * [Distributed solver and load balancing for Peridynamics using asynchronous parallelism](#distributed-solver-and-load-balancing-for-peridynamics-using-asynchronous-parallelism)\n * [Bug Hunter](#bug-hunter)\n * [Project Template](#project-template)\n\nWe are looking to fund work on a number of different kinds of proposals (for more details about concrete project ideas, see below):\n* Extensions to existing library features,\n* New distributed data structures and algorithms\n* Multiple competing proposals for the same project\n\n### Implement Your Favorite Parcelport Backend\n* **Abstract:** The HPX runtime system uses a module called Parcelport to deliver packages over the network. An efficient implementation of this layer is indispensable and we are searching for new backend implementations based on [CCI](https://github.com/CCI/cci), [ucx](https://github.com/openucx/ucx \"Unified Communication X\"), [libfabric](https://github.com/ofiwg/libfabric \"Open Fabric Interfaces\"), or [GASNet](https://gasnet.lbl.gov). These mentioned abstractions over various network transport layers offer the ability to do fast, one-sided RDMA transfers. The purpose of\nthis project is to explore one of these and implement a parcelport using it.\n* **Difficulty:** Medium-Hard\n* **Expected result:** A proof of concept for a chosen backend implementation with performance results\n* **Knowledge Prerequisite:** C++, Basic understanding of Network transports\n* **Mentor:** Thomas Heller (![thomas%20heller](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/thomas%20heller.png))\n* **Project Size:** 350 hour (large project)\n\n### Implement a Faster Associative Container for GIDs\n* **Abstract:** The HPX runtime system uses Active Global Address Space (AGAS) to address global objects. Objects in HPX are identified by a 128-bit unique global identifier, abbreviated as a GID. The performance of HPX relies on fast lookups of GIDs in associative containers. We have experimented with binary search trees (`std::map`) and hash maps (`std::unordered_map`). However, we believe that we can implement a search data structure based on n-ary trees, tries, or radix trees that exploit the structure of GIDs such that it allows us to have faster lookup and insertion.\n* **Difficulty:** Medium-Hard\n* **Expected result:** Various container approaches to choose from together with realistic benchmarks to show the performance properties\n* **Knowledge Prerequisite:** C++, Algorithms\n* **Mentor:** Thomas Heller (![thomas%20heller](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/thomas%20heller.png))\n* **Project Size:** 350 hour (large project)\n\n### Create A Parcelport Based on WebSockets\n* **Abstract:** Create a new parcelport that is based on WebSockets. The [WebSockets++](http://www.zaphoyd.com/websocketpp \"C++ WebSocket Client/Server Library\") library seems to be a perfect starting point to avoid having to dig into the WebSocket protocol too deeply.\n* **Difficulty:** Medium-Hard\n* **Expected result:** A proof of concept parcelport based on WebSockets with benchmark results\n* **Knowledge Prerequisite:** C++, knowing WebSockets is a plus\n* **Mentor:** Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png)) and Thomas Heller (![thomas%20heller](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/thomas%20heller.png))\n* **Project Size:** 350 hour (large project)\n\n### All to All Communications\n* **Abstract:** Design and implement efficient all-to-all communication LCOs. While MPI provides mechanisms for [broadcasting](https://www.open-mpi.org/doc/v1.8/man3/MPI_Bcast.3.php), [scattering](http://www.open-mpi.org/doc/v1.5/man3/MPI_Scatter.3.php) and [gathering](https://www.open-mpi.org/doc/v1.8/man3/MPI_Gather.3.php) with all MPI processes inside a communicator, HPX currently misses this feature. It should be possible to exploit the Active Global Address Space to mimic global all-to-all communications without actually communicating with every participating locality. Different strategies should be implemented and tested. A first and very basic [implementation of broadcast](https://github.com/STEllAR-GROUP/hpx/blob/master/hpx/lcos/broadcast.hpp) already exists which tries to tackle the above-described problem. However, more strategies for granularity control and locality exploitation need to be investigated and implemented. We also have the first version of a [gather utility](https://github.com/STEllAR-GROUP/hpx/blob/master/hpx/lcos/gather.hpp) implemented.\n* **Difficulty:** Medium-Hard\n* **Expected result:** Implement benchmarks and provide performance results for the implemented algorithms\n* **Knowledge Prerequisite:** C++\n* **Mentor:** Thomas Heller (![thomas%20heller](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/thomas%20heller.png)) and Andreas Schaefer (![andreas%20schaefer](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/andreas%20schaefer.png))\n* **Project Size:** 175 hour (medium sized)\n\n### Distributed Component Placement\n* **Abstract:** Implement an EDSL to specify the placement policies for components. This could be done similar to [Chapels Domain Maps] (http://chapel.cray.com/tutorials/SC12/SC12-6-DomainMaps.pdf). In Addition, allocators can be built on top of those domain maps to use with C++ standard library containers. This is one of the key features to allow users to efficiently write parallel algorithms without having them worried too much about the initial placement of their distributed objects in the Global Address space\n* **Difficulty:** Medium-Hard\n* **Expected result:** Provide at least one policy that automatically creates components in the global address space\n* **Knowledge Prerequisite:** C++\n* **Mentor:** Thomas Heller (![thomas%20heller](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/thomas%20heller.png)) and Hartmut Kaiser (![hartmut%20kaiser](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/hartmut%20kaiser.png))\n* **Project Size:** 350 hour (large project)\n\n### Port Graph500 to HPX\n* **Abstract:** Implement Graph500 using the HPX Runtime System. Graph500 is the benchmark used by the HPC industry to model important factors of many modern parallel analytical workloads. The Graph500 list is a performance list of systems using the benchmark and was designed to augment the Top 500 list. The current Graph500 benchmarks are implemented using OpenMP and MPI. HPX is well suited for the fine-grain and irregular workloads of graph applications. Porting Graph500 to HPX would require replacing the inherent barrier synchronization with asynchronous communications of HPX, producing a new benchmark for the HPC community as well as an addition to the HPX benchmark suite. See http://www.graph500.org/ for information on the present Graph500 implementations.\n* **Difficulty:** Medium\n* **Expected result:** New implementation of the Graph500 benchmark.\n* **Knowledge Prerequisite:** C++\n* **Mentor:** Patricia Grubel (![patricia%20grubel](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/patricia%20grubel.png)), and Thomas Heller (![thomas%20heller](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/thomas%20heller.png))\n* **Project Size:** 350 hour (large project)\n\n### Port Mantevo MiniApps to HPX\n* **Abstract:** Implement a version of one or more mini-apps from the Mantevo project (http://mantevo.org/ \"Mantevo Project Home Page\") using HPX Runtime System. We are interested in mini-applications ported to HPX that have irregular workloads. Some of these are under development, and we will have access to them in addition to those listed on the site. On the site, MiniFE and phdMESH would be good addition to include in HPX benchmark suites. Porting the mini-apps would require porting the apps from C to C++ and replacing the inherent barrier synchronization with HPX's asynchronous communication. This project would be a great addition to the HPX benchmark suite and the HPC community.\n* **Difficulty:** Medium\n* **Expected result:** New implementation of a Mantevo mini-app or apps.\n* **Knowledge Prerequisite:** C, C++\n* **Mentor:** Patricia Grubel (![patricia%20grubel](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/patricia%20grubel.png)) and Thomas Heller (![thomas%20heller](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/thomas%20heller.png))\n* **Project Size:** 175 hour (medium sized)\n\n### Distributed solver and load balancing for Peridynamics using asynchronous parallelism\n* **Abstract:**\nPeridynamics is a reformulation of classical continuum mechanics (e.g., linear elastodynamics). The internal force at any point in the solid results from the interaction of that point with neighboring points within some distance ϵ. Typically, ϵ is much larger than the mesh size. As a result, the computation is more intensive and introduces more substantial data dependencies when partitioning the domain for parallel implementation. This project aims to develop and implement a distributed solver for Peridynamics in an existing codebase [1]. This project will benefit from the last year's GSoC student's effort on a similar goal but for a simplified nonlocal model [2]. In [2], several challenges associated with the parallelization of nonlocal models are highlighted, and algorithms are developed to address the challenges. In this project, we will apply techniques in [2] to the Peridynamics problem; first, we will implement the distributed solver; second, we will optimize the code so that compute node does the information exchange and calculation on the free degree of freedoms (DoFs) simultaneously to minimize the wait time. Finally, if possible, we will add the load balancing algorithm [2]. Here for the given compute node, free DoFs are those DoFs that do not depend on the data owned by other compute nodes. After GSoC, we intend to write a workshop paper based on this project's efforts and possibly present it at a computer science conference.\n* **Difficulty:** Medium-Hard\n* **Expected result:** Extend the existing shared memory code to a distributd code\n* **Knowledge Prerequisite:** C++\n* **Mentor:** Patrick Diehl (![patrick%20diehl](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/patrick%20diehl.png)) and Prashant K. Jha (![prashantk%jha](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/Prashant.png))\n* **Project Size:** 350 hour (large project)\n\n[1] [https://github.com/nonlocalmodels/NLMech](https://github.com/nonlocalmodels/NLMech)\n\n[2] [https://arxiv.org/abs/2102.03819](https://arxiv.org/abs/2102.03819)\n\n### Port the GAP Benchmark Suite to HPX\n\n* **Abstract:**\n\nGAP [1] provides a benchmark suite for the following graph algorithms:\n\n* **Breadth-First Search (BFS)** - direction optimizing\n* **Single-Source Shortest Paths (SSSP)** - delta stepping\n* **PageRank (PR)** - iterative method in pull direction, Gauss-Seidel & Jacobi\n* **Connected Components (CC)** - Afforest & Shiloach-Vishkin\n* **Betweenness Centrality (BC)** - Brandes\n* **Triangle Counting (TC)** - order invariant with possible degree relabelling\n\nThis project requires modifying the existing benchmark suite to use HPX's data parallelism and asynchrony capabilities. This project serves as a stepping stone to a distributed implementation. After GSoC, we intend to write a workshop paper based on this project's efforts and possibly present it at a computer science conference.\n\n* **Difficulty:** Easy-Medium\n* **Expected result:** Provide an HPX implementation of the existing shared memory code\n* **Knowledge Prerequisite:** C++\n* **Mentor:** Chris Taylor\n\n[1] [http://gap.cs.berkeley.edu/benchmark.html](http://gap.cs.berkeley.edu/benchmark.html)\n\n[2] [https://github.com/sbeamer/gapbs](https://github.com/sbeamer/gapbs)\n\n### HPX backend for OpenMPI\n\n* **Abstract:**\n\nThis project requires modifying the existing OpenMPI implementation to include HPX support. This project will improve distributed HPX application performance. After GSoC, we intend to write a workshop paper based on this project's efforts and possibly present it at a computer science conference.\n\n* **Difficulty:** Medium\n* **Expected result:** HPX integration with OpenMPI\n* **Knowledge Prerequisite:** C/C++\n* **Mentor:** Chris Taylor\n\n### Bug Hunter\n* **Abstract:** In addition to our extensive ideas list, several active tickets are listed in our [issue tracker](https://github.com/STEllAR-GROUP/hpx/issues) which are worth tackling as a separate project. Feel free to talk to us if you find something interesting. A prospective student should pick at least one ticket with medium to hard difficulty and discuss how to resolve it.\n* **Difficulty:** Medium-Hard\n* **Expected result:** The selected issues need to be fixed\n* **Knowledge Prerequisite:** C++\n* **Mentor:** Thomas Heller (![thomas%20heller](https://raw.githubusercontent.com/wiki/STEllAR-GROUP/hpx/pics/thomas%20heller.png))\n* **Project Size:** 175 hour (medium sized)\n\n* * *\n\n### Project: Template\n* **Abstract:**\n* **Difficulty:**\n* **Expected result:**\n* **Knowledge Prerequisite:** \n* **Mentor:**"
  },
  {
    "name": "OpenELIS Global",
    "slug": "openelis-global",
    "tagline": "Empowering  labs to Ensure Quality Health Care",
    "description": "OpenELIS Global  (Open Enterprise laboratory Information System) is an open-source, standards-based, and secure lab information system for labs of any size and need.\n\nIt is an enterprise-level laboratory information system built on open-source web-based technologies that has been tailored for low- and middle-income country public health laboratories.\n\nThe software serves as both an effective laboratory software solution and a business process framework. It supports the effective functioning of public health laboratories for best laboratory practice and accreditation.",
    "ideas_url": "https://uwdigi.atlassian.net/wiki/spaces/OG/pages/931594241/GSoC+2026",
    "website_url": "https://openelis-global.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "postgresql",
      "javascript",
      "java",
      "react",
      "spring"
    ],
    "topic_tags": [
      "Health Care",
      "Laboratory Information System"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/openelis-global",
    "ideas_content": "# GSoC 2026\n\n[ OpenELIS Global](https://openelis-global.org/) is hoping to be a mentoring organization for\n\n[Google Summer of Code](https://summerofcode.withgoogle.com/)2026 for the Third Time. We're extremely excited about the projects and mentorship opportunities available this year. Coding for\n\n**OpenELIS Global**is a great way to practice your coding skills and, at the same time help making a positive impact on the world through empowering labs with the best tools and support to deliver quality health care to clients.\n\nIf you are new to **OpenELIS Global**, we recommend starting with our [Installation](https://uwdigi.atlassian.net/wiki/spaces/OG/pages/239632402) and [Developer](https://uwdigi.atlassian.net/wiki/spaces/OG/pages/240844805) Instructions\n\n## GSoC 2026 Program Administrators\n\nMutesasira Moses\n\nCasey Iiams-Hauser\n\nHerbert Yiga\n\nReagan Makoba\n\n\n## Selected Projects for GSoC 2026\n\nProject Name | Project Size | Project Description | Expected Out Come | Required Skills | Selected Contributor | Mentors |\n|---|---|---|---|---|---|---|\nCreating a generic robust reporting framework\n| 350 hours | OpenELIS already has support for pre-designed reports. This project aims to create a Robust reporting framework for users to be able to create ad-hoc Patient reports from the UI | Ability to create ad-hoc Patient reports from the UI | React , Typescript, Java , Spring , REST |\n| Mutesasira Moses |\nImprove Integration Tests coverage\n| 350 hours | The current Integration Test This project aims at extending and creating more Integration Tests to achieve a Test Coverage of at least 60% for the Backend Service and Controller Layer | 60% Test coverage | Java , Spring , J-Unit |\n| Herbert Yiga\n|\nCreate a Comprehensive FHIR facade Layer For OpenELIS Global | 350 Hours | OpenELIS currrently implements FHIR through interacting with a parallel HAPI FHIR JPA server. However this creates a challenge of prfectly syncying a separate server with the OpenELIS database. | A working FHIR facade for OpenELIS that supports FHIR transaction for FHIR Resources currenly implemented in OpenELIS | Java , Spring , FHIR , REST |\n| Reagan Makoba |\nModernizing the OpenELIS React Frontend with TypeScript and Performance Optimization | 350 Hours | The current React frontend is mainly JavaScript and struggles with performance as data grows. This project will improve performance, maintainability, and reliability by migrating to TypeScript and applying modern React performance best practices. | The work will include incremental TypeScript adoption, improved state and server-state management, component refactoring, and performance optimizations such as memoization, query caching, and bundle size reduction. | JavaScript , REST , TypeScript |\n| Samwel Male @Male Samuel |\nSecurity Audit and Hardening of the OpenELIS Laboratory Information System | 350 Hours | This project aims to conduct a comprehensive security audit of OpenELIS to identify vulnerabilities, risks, and potential attack surfaces across its architecture and dependencies. The work will include threat modeling, vulnerability scanning, and risk prioritization, followed by recommendations and targeted fixes where feasible. The project will establish a strong security baseline for OpenELIS, improving trust, supporting compliance with healthcare data protection standards, and ensuring long-term maintainability for the open-source community. |\n**Comprehensive Security Audit Report**detailing threat models, identified vulnerabilities, risk severity, and recommended mitigations**Automated Security Testing Assets**, including static analysis, dependency vulnerability scanning, and CI/CD-integrated security checks**Targeted Security Fixes**addressing high-risk vulnerabilities through patches or pull requests**Security Documentation**outlining secure deployment guidelines and coding best practices for OpenELIS contributors**Improved Security Awareness**within the OpenELIS community through actionable findings and recommendations\n| Java ,CI/CD ,OWASP Top 10\n|\n| Caesy Liams Hauser |\n\n## Program Timeline\n\nDate | Status | Activity |\n|---|---|---|\nDec 3, 2025 | DONE | GSoC 2025 Announced |\nJan 19, 2026 | DONE | Mentoring organizations can begin submitting applications to Google |\nFeb 3, 2026 | DONE | Mentoring organization application deadline |\nFeb 19, 2026 | PENDING | List of accepted mentoring organizations announced |\nFeb 19, 2026 - Mar 15, 2026 | PENDING | Potential GSoC contributors discuss application ideas with mentoring organizations |\nMar 16, 2025 | PENDING | GSoC contributor application period begins |\nMar 31, 2026 | PENDING | GSoC contributor application deadline |\nApr 21, 2026 | PENDING | GSoC contributor proposal rankings due from Org Admins |\nApr 21, 2026 | PENDING | Slot Allocation Deadline |\nApr 30, 2026 | PENDING | Projects Announced to Orgs |\nMay 8, 2025 | PENDING | Accepted GSoC contributor projects announced |\nMay 1, 2026-May 24, 2026 | PENDING | Community Bonding Period. Students get to know mentors, read documentation, prepare for work on their projects |\nMay 25, 2026 | PENDING |\n|\nJul 6, 2026 | PENDING | Mentors and GSoC contributors can begin submitting midterm evaluations |\nJul 10, 2026 | PENDING | Midterm evaluation deadline (standard coding period) |\nJul 6, 2026 -Aug 16, 2026 | PENDING | Work Period. GSoC contributors work on their project with guidance from Mentors |\nAug 17, 2026 -Aug 24, 2026 | PENDING | Final week. GSoC contributors submit their final work product and their final mentor evaluation (Standard coding period) |\nAug 24, 2026 -Aug 31, 2026 | PENDING | Mentors submit final GSoC contributor evaluations (standard coding period) for medium size project. |\nAug 24, 2026 -Nov 2, 2026 | PENDING | GSoC contributors with extended timelines continue coding |\nNov 2, 2026 | PENDING | Final date for all GSoC contributors to submit their final work product and final evaluation |\nNov 9, 2026 | PENDING | Final date for mentors to submit evaluations for GSoC contributor projects with extended deadlines |\n\nsee full [Timeline](https://developers.google.com/open-source/gsoc/timeline)\n\n## Guidelines\n\n### Student's guidelines\n\n### Mentor's guidelines\n\nStudents MUST follow our [Student Guidelines](https://uwdigi.atlassian.net/wiki/spaces/OG/pages/245694473) for their proposals to be selected"
  },
  {
    "name": "Accord Project",
    "slug": "accord-project",
    "tagline": "Open source software for smart legal contracts",
    "description": "Accord Project champions the importance of contract text alongside computer-code when automating contracts. This is often referred to as Computable Contracts or Smart Legal Contracts.\n\nThe Accord Project is a non-profit, collaborative, initiative developing an ecosystem and open source tools for computational contracts. The community includes participants from law firms, technology companies, universities, government and private individuals.\n\nToday, the community maintains a technology neutral foundation for smart legal contracts, based on the union of legal text with a machine readable data model, and machine executable logic. This definition of a smart legal contract is recognised across the industry, including by statutory and standards bodies. \n\nAccord Project is a top-level Linux Foundation project.",
    "ideas_url": "https://github.com/accordproject/techdocs/wiki/Google-Summer-of-Code-2026-Ideas-List",
    "website_url": "https://accordproject.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "json",
      "react",
      "artificial intelligence"
    ],
    "topic_tags": [
      "natural language processing",
      "data modeling",
      "legal technology",
      "contract management",
      "document assembly"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/accord-project",
    "ideas_content": "## 1. Agentic Workflow for Drafting Templates\n\nCurrently people can draft and play around with Accord Project Templates either by using their code editors with the Accord Project Extension or using Template-Playground. A person drafting template needs to have the following, legal/domain knowledge, along with the Accord Project Stack knowledge. In this project we aim to use an agentic workflow orchestrator like crew ai, define specialist agents and generate Accord Project Templates just by taking in the template requirements from the user via a CLI or a UI interface.\n\n#### Expected outcomes:\n* Define Agent Personas and Tasks such that they can be used with any agentic workflow orchestrator.\n* Integrate tool calling for Accord Project tools like concerto, template-engine to validate the templates (model, text and logic) generated by workflow.\n* Option to choose AI models\n* CLI interface, similar to gemini-cli or claude code, where user can add their template requirements in natural text.\n\n#### Skills required/preferred: \nBackend development: TypeScript, MCP, Python\n\n#### Mentors: \nSanket Shevkar, Niall Roche\n\n#### Size:\n90hrs / 8 weeks\n\n#### Category\nRisky/Exploratory\n\n#### Difficulty:\nMedium\n\n## 2. Concerto Graphical Editor\n\nBuilding data models (or schemas) in Concerto is limited today to writing code in a text editor, or using an API. This project aims to create a graphical web editor for Concerto files. This is expected to make it easier to explain the meaning of a data model without teaching syntax. The editor can take inspiration from a traditional UML-like editor or a Blockly-like editor or something else. For reference, see [this project](https://github.com/accordproject/web-components/tree/main/packages/ui-concerto) which creates web forms from a Concerto schema.\n\nConsider how this editor would be used to describe the data in agreements document or clauses and their templates as well as other non-legal entities. Scope your solution to include basic type composition, and enumerations, but also consider how to represent more advanced modeling capabilities such as inheritance, abstract types, relationships, arrays and maps.\n\n#### Expected Outcomes:\nA tool that allow users to:\n* Open and edit a Concerto model on a web page\n* Integration into Template Playground\n\n#### Skills required/preferred: \nWeb development, TypeScript, d3, React Flow, Blockly, or similar graphical frameworks\n\n#### Possible Mentors: \nMatt Roberts, Priyanshu Singh\n\n#### Expected size of project:\n175hrs / 12 weeks\n\n\n#### Category\nCore development\n\n#### Expected difficulty: \nMedium\n\n## 3. Template Logic Support for Playground\n\nExtend Template Playground to support Templates with TypeScript logic. Currently, Template Playground supports merging the agreement data modelled using Concerto with TemplateMark templates to generate AgreementMark output document. In the project, the expectation is to build support to trigger contract logic implemented in Typescript. This [repo](https://github.com/accordproject/demo-template) consists of an example of an Accord Project template with logic.\n\n#### Expected Outcomes:\nA tool that allow users to:\n* Open and edit templates that contain Template Logic in Template Playground\n* Test execution of templates within Playground, submitting requests and seeing responses, state updates and emitted events\n\n#### Skills required/preferred: \nWeb development, TypeScript\n\n#### Possible Mentors: \nDan Selman, Sanket Shevkar\n\n#### Expected size of project:\n175hrs / 12 weeks\n\n#### Category\nCore development\n\n#### Expected difficulty: \nMedium\n\n## 4. APAP and MCP Server\n\nExtend and harden the APAP and MCP servers, exposing template operations to MCP clients like ChatGPT, Claude etc. Refer to the experimental MCP support to the APAP server that's being already [implemented](https://github.com/accordproject/apap/tree/main/server#model-context-protocol-mcp-support-experimental).\n\n#### Expected Outcomes:\nImprove the testing, quality and functionality of APAP/MCP servers:\n* System tests\n* Documentation and tutorials for using APAP/MCP with the major MCP clients\n* Functional extensions and developer experience improvements\n\n#### Skills required/preferred: \nBackend development: TypeScript, Postgres, MCP\n\n#### Possible Mentors: \nNiall Roche, Dan Selman\n\n#### Expected size of project:\n175hrs / 12 weeks\n\n#### Category\nCore development\n\n#### Expected difficulty: \nMedium\n\n## 5. Create a new Concerto runtime for multi platform deployment\n\nCurrent Concerto runtime is based in JavaScript. It can run in browser, and also outside the browser via NodeJS. However, integrating this runtime or components of the runtime in other languages, like C# is extremely hard. Usually requires [shimming a JS runtime](https://github.com/accordproject/concerto-dotnet/blob/dbb445959a8300a09b43de283b2e10a216b9fd1c/AccordProject.Concerto.Validate/Validator.cs#L18).\n\nThe aim of this project is to port the JavaScript runtime to a language that can be used directly or can produce artefacts suitable for integration to other languages. Rust, with its wide range of compilation targets, as well as ability to use C ABI is a perfect candidate for such task. On top of all that, having a formally provable memory safety as part of the language will add extra security on the runtime.\n\nThis is a good project if you want to try your hand in secure-first code with interoperability in mind. \n\n#### Expected outcomes:\n* Port runtime validation logic to Rust. We have a proof of concept structural validation already ([concerto-validate-rs](https://github.com/accordproject/concerto-validate-rs)), and another PoC for Rust model manager ([concerto-rust](https://github.com/accordproject/concerto-rust))\n* Update and extend the previous year’s GSoC project, [concerto-conformance](https://github.com/accordproject/concerto-conformance/tree/main) repository to validate the port. We have the [Cucumber support files](https://github.com/accordproject/concerto-conformance/tree/main/semantic/features/support/rust) for Rust in place.\n* Integrate validation runtime to existing JS runtime using WASM.\n\n#### Stretch goals:\n* Create a complete runtime in Rust.\n* Publish relevant packages to Cargo.\n\n#### Skills required/preferred: \nBackend development: Rust, Typescript\n\n#### Mentors:\nErtugrul Karademir\n\n#### Size:\n175hrs / 12 weeks\n\n#### Category\nCore development\n\n#### Difficulty:\nHard\n\n## 6. Testing for Code Generation Targets\n\nWe have tools that allow users to generate code from their Concerto models, supporting [several languages](https://concerto.accordproject.org/docs/category/code-generation). We would like to introduce a way of testing the correctness of the code generation that compiles code for each language we are generating.\n\n#### Expected Outcomes:\n- Set of Docker images for each code generation target\n- Run code gen tests within the correct image using GitHub actions, for example, generate Java code that imports the codegen artifacts, and then compile and run it using `javac` to ensure the generated code is correct\n\n#### Skills required/preferred: \n- Systems engineering, CI/CD\n- Docker, Docker compose\n- GitHub actions\n\n#### Possible Mentors: \nErtugrul Karademir\n\n#### Expected size of project:\n90hrs / 8 weeks\n\n#### Category\nInfrastructure/Automation\n\n#### Expected difficulty: \nMedium\n\n## 7. LLM Based Template Logic Executor\n\nImplement a generic / general purpose template logic executor using an LLM for reasoning. The input to the executor are requests/transaction that represent real-world contract events (modelled Concerto types, with instances as JSON data) and the output from the executor are state changes, response JSON objects and event JSON objects. The generic executor would take the contract text, the current state of the contract and the incoming request and evaluate the logic of the contract using an LLM to produce output objects and new state.\n\n#### Expected Outcomes:\n- A generic executor implemented in TypeScript/JS which delegates to a reasoning LLM and can be associated with an Accord Project template that does not have an explicit TypeScript logic file. It should be integrated into the trigger and init functionality in the [TemplateArchiveProcessor](https://github.com/accordproject/template-engine/blob/6723fd624d8bd85a365cf5483c29fbdabd374953/src/TemplateArchiveProcessor.ts#L93). \n- Configuration parameters to specify how to call the LLM and the API keys to use\n\n#### Skills required/preferred: \n- TypeScript\n- LLM APIs\n\n#### Possible Mentors: \nDan Selman\n\n#### Expected size of project:\n90hrs / 8 weeks\n\n#### Category\nCore development\n\n#### Expected difficulty: \nMedium"
  },
  {
    "name": "Open Transit Software Foundation",
    "slug": "open-transit-software-foundation",
    "tagline": "Help make public transit better",
    "description": "We are the home for the OneBusAway project. OneBusAway is a suite of open source transit information tools based on real-time vehicle data.\n\nOneBusAway is a suite of open source transit information tools that enable transit agencies to provide real-time vehicle locations, alerts, and arrival information to riders, with iOS and Android apps, a web platform, and robust APIs, as well as back office support. OneBusAway lets transit agencies be in control, without needing to build everything themselves and without cutting corners.",
    "ideas_url": "https://opentransitsoftwarefoundation.org/2026/01/google-summer-of-code-2026-project-ideas/",
    "website_url": "https://opentransitsoftwarefoundation.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "android",
      "java",
      "golang",
      "docker",
      "ios"
    ],
    "topic_tags": [
      "apps",
      "Transit",
      "travel",
      "bus"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/open-transit-software-foundation",
    "ideas_content": "# Google Summer of Code 2026 Project Ideas\n\n**Caution:** Please do not consider this list to be definitive: we have lots of ideas for projects we want to see pursued as part of GSoC 2026, but will certainly not receive as many slots as we want. The order of the list is also not indicative of priority.\n\n## iOS App/Apple Platforms\n\n### Modernize the iOS App UI\n\n*Difficulty: Advanced // Size: 350 hours*\n\nThe OneBusAway iOS app has served hundreds of thousands of transit riders well, but its interface is showing its age. We’ve begun initial investigations into modernizing the app’s UI by eliminating the tab bar and adopting a design language closer to Apple Maps—with a focus on a sheet-based interface that feels native to modern iOS.\n\nYou will be responsible for pushing this project through to completion. This includes:\n\n- Working with our design team to finalize the new UI direction\n- Refactoring the app’s navigation architecture to remove the tab bar in favor of a Maps-style sheet-based interface\n- Implementing the new UI in SwiftUI while maintaining compatibility with existing features\n- Ensuring the new design maintains or improves accessibility for VoiceOver users\n- Writing comprehensive UI tests for the new navigation patterns\n\n**Expected outcomes:**\n\n- A fully modernized iOS app UI that matches contemporary Apple design patterns\n- Improved user experience with intuitive sheet-based navigation\n- Complete feature parity with the existing app\n\n## Golang/Backend Projects\n\n### Maglev: Next Generation REST API Server\n\n*Difficulty: Advanced // Size: 350 hours // Slots: 2*\n\n[Maglev](https://github.com/onebusaway/maglev) is our next generation REST API server, written in Go. It’s designed to be a modern, high-performance replacement for portions of the existing Java-based OBA API server. The project is moving along well, but needs sustained work to become production-ready for transit agencies.\n\nWe’re looking for two developers to help us get Maglev across the finish line. You’ll work closely with our core team to:\n\n- Implement missing API endpoints to achieve parity with the existing OBA API server\n- Build comprehensive test coverage for all endpoints\n- Optimize performance for high-traffic deployments\n- Write documentation for transit agency deployment\n- Implement caching strategies and database optimizations\n\n**Expected outcomes:**\n\n- A production-ready REST API server that can serve as a drop-in replacement for transit agency deployments\n- Comprehensive documentation and deployment guides\n- Performance benchmarks demonstrating improvements over the legacy server\n\n### Vehicle Tracker: Realtime Vehicle Positioning for Developing Countries\n\n*Difficulty: Advanced // Size: 350 hours*\n\nThe OneBusAway server relies upon specialized software and hardware to generate the vehicle position feeds that power its realtime data. This works well for transit agencies in developed countries with existing AVL (Automatic Vehicle Location) systems, but creates a significant barrier for transit systems in developing countries that are building out fixed route transit.\n\nTo unlock the potential of OneBusAway for these regions, we need to create a new, lightweight solution for tracking vehicle locations in realtime. This project involves building both a server component and a companion Android app.\n\nYou will be responsible for:\n\n- Building a server application (in Go) that receives vehicle location data and generates GTFS-RT Vehicle Positions protobuf feeds\n- Creating a companion Android app that drivers can use to reliably report their vehicle’s location\n- Implementing secure authentication between the Android app and server\n- Designing the system to work reliably in areas with intermittent network connectivity\n- Building administrative tools for transit operators to manage vehicles and drivers\n\n**Expected outcomes:**\n\n- A production-ready server that generates GTFS-RT Vehicle Positions feeds\n- A reliable Android app for vehicle location tracking\n- Documentation for transit agencies to deploy and operate the system\n- Support for offline operation and data sync when connectivity is restored\n\n## Your Idea Here!\n\nWe don’t have a monopoly on great ideas. Let us know what you think would be a great addition to the OBA platform!"
  },
  {
    "name": "Free and Open Source Silicon Foundation",
    "slug": "free-and-open-source-silicon-foundation",
    "tagline": "Working together for Free and Open Source Silicon",
    "description": "The FOSSi (Free and Open Source Silicon) Foundation is a not-for-profit organization with the support the growing community of open source silicon hardware. We do this with a variety of activities and through Google Summer of Code we bring together enthusiastic mentees and outstanding projects. Under our umbrella are open source silicon hardware projects, operating systems and compilers for such projects, tools for electronic design automation and the related ecosystem.",
    "ideas_url": "https://fossi-foundation.org/gsoc/gsoc26-ideas",
    "website_url": "https://www.fossi-foundation.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "verilog",
      "vhdl",
      "risc-v",
      "compiler"
    ],
    "topic_tags": [
      "hardware",
      "debug",
      "simulation",
      "electronic design tools"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/free-and-open-source-silicon-foundation",
    "ideas_content": "FOSSi Foundation is applying as an umbrella organization for Google Summer of Code 2026. That means that we give FOSSi community projects the chance to participate in the program. Below you can find a list of ideas that community mentors had, but mentees are encouraged to propose their own ideas. These projects are mostly open-ended and can be tailored to your level of experience, assuming that you have the appropriate set of required skills for the particular project idea.\n\nWhether you’re an aspiring mentee or mentor, feel free to contact us,\neither (for mentees) by directly contacting mentors or (for mentors)\nthrough the private GSoC-specific mailing list [gsoc@fossi-foundation.org](mailto:gsoc@fossi-foundation.org).\n\nLooking forward to meet you all!\n\n[ZynqParrot RISC-V Tracer](https://fossi-foundation.org#zynqparrot-risc-v-tracer)\n\nZynqParrot ([https://github.com/black-parrot-hdk/zynq-parrot](https://github.com/black-parrot-hdk/zynq-parrot)) is a framework for doing self-contained, FPGA-based \"hostless\" ASIC accelerator development. It is designed to be extremely general and has been used to prototype IP from individual ASIC/FPGA cores to full multicore processors. In addition, ZynqParrot has been used to bringup N=1 ASIC silicon in the lab.\n\nRISC-V provides a trace format specification ([https://github.com/riscv-non-isa/riscv-trace-spec](https://github.com/riscv-non-isa/riscv-trace-spec)) which can be used for diagnostic performance and debugging. This project will design and integrate a RISC-V Trace implementation into the ZynqParrot environment, requiring SystemVerilog implementation + testing, Block Diagram (Vivado IPI) design and well as writing C++ driver to work in both Co-Simulation and Co-Emulation.\n\nStrong proposals will:\n\n- Have a general understanding of the ZynqParrot infrastructure and\n- Be able to articulate changes needed as well as\n- Produce before / after block diagrams for the planned integration and\n- Be available to work full-time on this project.\n\n*Skill level:* intermediate\n\n*Project length:* medium (175 hours)\n\n*Mentors:* [Dan Ruelas-Petrisko](mailto:dan@fossi-foundation.org)\n\n*Language/Tools:* SystemVerilog, C++, some knowledge of computer architecture. RISC-V knowledge preferred but not required. FPGA tools such as Vivado strongly encouraged but not required.\n\n[BlackParrot UVM Testbenches](https://fossi-foundation.org#blackparrot-uvm-testbenches)\n\nBlackParrot ([https://github.com/black-parrot/black-parrot](https://github.com/black-parrot/black-parrot)) is an open-source Linux-capable RISC-V multicore with a long history of begin used to stress-test open-source EDA tooling. Verilator ([https://github.com/verilator/verilator](https://github.com/verilator/verilator)) has newly added UVM support. We're very interested in seeing what can be done with the current implementation, and compiling a wishlist of new UVM features to support in Verilator.\n\nStrong proposals will:\n\n- Have a general understanding of the current BlackParrot testing infrastructure and\n- Identify a few candidate modules to develop UVM testbenches for and\n- Produce block diagrams to describe verification strategy and\n- Be available to work full-time on this project.\n\n*Skill level:* beginner\n\n*Project length:* medium (175 hours)\n\n*Mentors:* [Dan Ruelas-Petrisko](mailto:dan@fossi-foundation.org)\n\n*Languages/Tools:* SystemVerilog, Verilator, prior UVM knowledge helpful but not required.\n\n[Surfer memory and wide array support](https://fossi-foundation.org#surfer-memory-and-wide-array-support)\n\nSurfer ([https://surfer-project.org](https://surfer-project.org)) is an open source waveform viewer designed to be snappy and extensible. Waveform viewers work well for visualizing individual signals, but for large arrays or memories users are often more interested in changes to individual elements rather than the whole array.\n\nFor this, a separate UI element where memory content can be visualized as a table would be much more useful. Beyond just visualizing the content, also having the ability to highlights elements that have changed between timestamps or around the cursor would be extra useful.\n\n*Skill level:* intermediate\n\n*Project Length:* medium (175 hours)\n\n*Mentors:* [Frans Skarman](mailto:frans.skarman@liu.se), [Oscar Gustafsson](mailto:oscar.gustafsson@liu.se)\n\n*Languages/Tools:* Rust. Familiarity with hardware design is helpful to have some context of what the tool is used for is helpful, but the project itself is pure software. Some familiarity with egui is also helpful though certainly not required.\n\n[cocotb v2 Code Migration Helper](https://fossi-foundation.org#cocotb-v2-code-migration-helper)\n\nThe upcoming cocotb v2.x release will have quite some breaking changes (see [https://docs.cocotb.org/en/latest/release_notes.html](https://docs.cocotb.org/en/latest/release_notes.html)), so users and extension developers will have to actively migrate existing code.\n\nA code migration helper tool would be helpful, even if it is not perfect.\n\nSome links:\n\n*Skill level:* Intermediate/Advanced\n\n*Duration:* medium (175 hours)\n\n*Language/Tools:* Python, cocotb\n\n*Mentor:* [Kaleb Barrett](mailto:dev.ktbarrett@gmail.com)\n\n[Generate Counter Examples for Bounded Model Checks in CIRCT](https://fossi-foundation.org#generate-counter-examples-for-bounded-model-checks-in-circt)\n\nThe [CIRCT](https://github.com/llvm/circt) project has its own bounded model checking tool, circt-bmc. It takes a hardware design described in CIRCT's MLIR dialects and translates it into a program that uses the Z3 SMT solver to formally prove assertions. If it finds a way how assertions can be violated, it simply terminates with an error message. This is not very useful for a user that is trying to debug a hardware design that they have written. Instead, we would like circt-bmc to produce a counter-example, essentially a signal trace that shows and example of how the assertions can be violated. The Z3 SMT solver actually provides a counter-example as part of its checking, circt-bmc just does not use that yet.\n\nWe would love you to extend circt-bmc with a counter-example feature that produces a signal trace for violated assertions, ideally a VCD waveform as a starting point. This will require you to modify the lowering pass that translates a hardware design to Z3 solver calls: in addition to the asserts that need to be checked, you will also want to translate any named ports, wires, registers into the corresponding Z3 solver expressions. The bounded model check can then take a snapshot of all these expressions in every time step. When Z3 finds a counter-example, you can go through every time step, evaluate all the solver expression for all user-visible names, and write them to a waveform.\n\nThis may also be an excellent opportunity to introduce a waveform writing library for CIRCT. Eventually, we'd want different tools in CIRCT to be able to write various waveform formats such as VCD, FST, etc. It would be great if there is a common interface for waveform writers, and if CIRCT could then provide various implementations for different waveform formats. Tools like Arcilator, circt-bmc, and circt-lec would then use this library to produce signal traces.\n\nCIRCT is based on MLIR and LLVM, and are implemented in C++. So you'll definitely want to have some experience writing C++ code, since LLVM-based projects often follow a fairly peculiar and performance-conscious style of C++. You may also benefit from knowing a little bit about SAT and SMT solvers, and how bounded model checks can be implemented incrementally using these solvers.\n\n*Skill Level:* Medium\n\n*Duration:* 175 hours or 350 hours\n\n*Language/Tools:* C++, CIRCT, MLIR, LLVM\n\n*Mentor:* [Fabian Schuiki](mailto:fabian@schuiki.ch), [Martin Erhart](mailto:maerhart@outlook.com), and others in the CIRCT community\n\n[OpenRISC Linux Feature Development](https://fossi-foundation.org#openrisc-linux-feature-development)\n\nThe OpenRISC Linux kernel support is under constant development but there are certain Linux facilities that are not yet used or available on the OpenRISC platform.\n\nThis project will have the student developing, testing and sending patches up to the Linux kernel. This includes:\n\n- Use the cacheinfo API for reporting CPU details in OpenRISC Linux.\n- Add\n[tracing facilities](https://docs.kernel.org/trace/index.html)to OpenRISC Linux including: jump_label, ftrace, kprobes, eBPF etc.\n\n*Skill level:* Advanced\n\n*Project Length:* large\n\n*Language/Tools:* Linux, C, Assembly, OpenRISC architecture\n\n*Mentor:* [Stafford Horne](mailto:shorne@gmail.com)\n\n[Generic MinimumLinuxBoot for RTL Simulations](https://fossi-foundation.org#generic-minimumlinuxboot-for-rtl-simulations)\n\nThis project consists of booting Linux in Qemu, save the memory state, then continue the simulation in an RTL Simulation of OpenPiton. The first part of the project consists of understanding what states need to be saved, probably a combination of the TLB and MMU states as an starting point could be enough. Then, this state needs to be saved in a file format that the checkpoint mechanism of Verilator understand or create a synthetic benchmark that makes the proper MMU configuration. The second part of the project is adding the necessary support in OpenPiton Simulation infrastructure to continue the simulation and being able to launch some applications.\n\nOpenPiton uses different languages like Verilog, Python, Perl, and C. Verilator C++. Additionally, some background in hardware design is useful.\n\n*Skill Level:* Medium/Advanced\n\n*Duration:* 350 hours\n\n*Language/Tools:* Verilog, C++, SystemVerilog\n\n*Mentors:* [Guillem López Paradís](mailto:guillem.lopez@bsc.es) and [Jonathan Balkind](mailto:jbalkind@ucsb.edu)\n\n[Using AI to Improve Open-Source IP](https://fossi-foundation.org#using-ai-to-improve-open-source-ip)\n\nWhat if we could instantly improve all existing open-source Verilog by reducing its size, improving its maintainability, making it more configurable, identifying bugs, and creating visualization for it? Transaction-Level Verilog (TL-Verilog) models are smaller, cleaner, and less bug-prone than their Verilog counterparts. Last year, we made great strides with agentic flows to automate the conversion of Verilog to TL-Verilog as well as to visualize simulations. Agents make incremental refactoring steps and test/debug each step using formal equivalence verification with SymbiYosys and EQY.\n\nYou will use and enhance this flow to refactor open-source Verilog projects, as we've done with [SERV](https://github.com/stevehoover/serv/tree/main/tlv). In the process, you'll contribute to the automation, and your work will become training data to improve future LLMs for this task.\n\n*Skill level:* Intermediate\n\n*Duration:* 350 hours\n\n*Language/Tools:* Verilog, Python, TL-Verilog\n\n*Repos:* [https://github.com/stevehoover/conversion-to-TLV](https://github.com/stevehoover/conversion-to-TLV), [https://github.com/stevehoover/LLM_TLV/tree/main/desktop_agent_verilog_conversion](https://github.com/stevehoover/LLM_TLV/tree/main/desktop_agent_verilog_conversion)\n\n*Mentor:* [Steve Hoover](mailto:steve.hoover@redwoodeda.com)\n\n[LiteX SMP SoC for OpenRISC](https://fossi-foundation.org#litex-smp-soc-for-openrisc)\n\nThe [LiteX](https://github.com/enjoy-digital/litex) project makes creating\nFPGA-based SoCs easy. LiteX supports creating SoCs containing OpenRISC CPU cores.\nUp until now however, there have been no LiteX SoCs that support running\nOpenRISC multicore/SMP Linux. The [linux-on-litex-vexrisc](https://github.com/litex-hub/linux-on-litex-vexriscv)\nproject provides a good example of how to develop and document getting Linux\nup and running on a LiteX SoC; including multicore.\n\nUsing `linux-on-litex-vexrisc`\n\nas an example, this project will have the student\ncreating a project to help people get up and running with OpenRISC. The final\ngoal shall be to have a documented multicore OpenRISC LiteX SoC running Linux\nSMP.\n\n*Skill level:* Advanced\n\n*Project Length:* large\n\n*Language/Tools:* Verilog, LiteX, Linux, Python, OpenRISC architecture\n\n*Mentor:* [Stafford Horne](mailto:shorne@gmail.com)\n\n[Improve CIRCT's Verilog Frontend](https://fossi-foundation.org#improve-circts-verilog-frontend)\n\nThe [CIRCT](https://github.com/llvm/circt) project uses the [Slang](https://github.com/MikePopoloski/slang) frontend to parse the SystemVerilog hardware description language. The [sv-tests](https://chipsalliance.github.io/sv-tests-results/) project runs many SystemVerilog frontends on a benchmark suite of input files to test their quality. We would love you to use the sv-tests results as a starting point to find key missing features that you can add to `circt-verilog`\n\nand fix failing tests. Tests often fail for similar reasons, and fixing small things can cause large numbers of tests to start passing.\n\nSystemVerilog is a complicated language and CIRCT builds a deep stack of intermediate representations using MLIR to process it. The Slang frontend produces an Abstract Syntax Tree which the ImportVerilog pass converts into the Moore dialect, the first IR level in circt-verilog. Various optimizations are already performed at this level. Then the MooreToCore conversion pass lowers the Moore dialect to the HW, Comb, Seq, and LLHD dialects for further processing. Finally, several optimization passes implemented on the LLHD dialect analyze the hardware design and detect common structures. If you want to sink your teeth into compiler and IR design, this is the perfect project for you!\n\nSlang and CIRCT are based on MLIR and LLVM, and are implemented in C++. So you'll definitely want to have some experience writing C++ code, since LLVM-based projects often follow a fairly peculiar and performance-conscious style of C++.\n\n*Skill Level:* Advanced\n\n*Duration:* 175 hours or 350 hours\n\n*Language/Tools:* C++, CIRCT, MLIR, LLVM\n\n*Mentor:* [Fabian Schuiki](mailto:fabian@schuiki.ch), [Martin Erhart](mailto:maerhart@outlook.com), and others in the CIRCT community\n\n[Open Educational Content Development](https://fossi-foundation.org#open-educational-content-development)\n\nA Microelectronics Petagogy Community of Practice (MPCoP) has been established by educators and employers (primarily in the northeastern United States) to develop open digital electronics curricula leveraging Makerchip.com and open-source electronic design automation (EDA) software. The MPCoP aims to overcome the following hurdles that impede digital electronics education:\n\n- access to proprietary tools: licensing, platform compatibility, substantial disk space requirements\n- FPGA lab access or physical hardware distribution and costs\n- the complexity of tools and languages and the abstract nature of concepts\n- ensuring original student work\n\nTo address these issues, MCPoC universities (UConn, Northeastern, Tufts, UWisc, UNT) recognize the importance of:\n\n[Makerchip](https://makerchip.com)as a free, online circuit design environment[TL-Verilog](https://tl-x.org)as an easier/modern hardware description language[Visual Debug](https://redwoodeda.com/viz)as a means of illustrating complex concepts[Virtual FPGA Lab](https://github.com/os-fpga/Virtual-FPGA-Lab)(a former FOSSi GSoC project) for FPGA experience outside the lab- open-source EDA software for easy access and understanding.\n\nMPCoP employers recognize the value of a workforce educated in these technologies.\n\nThis project is an opportunity to contribute to the advancement and democratization of ECE education while learning from modern tools and ECE curricula yourself as you work to improve educational content. With AI assistance, you will:\n\n- convert existing Verilog and VHDL assignments and projects to use Makerchip and TL-Verilog\n- bundle course content and open shared modules\n- incorporate visualizations to enhance the educational experience\n- test assignments and provide reference solutions\n\n*Skill level:* Any (task will vary accordingly)\n\n*Duration:* 175 or 350 hours\n\n*Language/Tools:* TL-Verilog, Verilog, VHDL, Makerchip, various open-source EDA tools\n\n*Mentors:* [Steve Hoover](mailto:steve.hoover@redwoodeda.com) and other members of the MPCoP\n\n[Architectural Improvements to OpenPiton+Ariane for RISC-V Profile Compliance](https://fossi-foundation.org#architectural-improvements-to-openpitonariane-for-risc-v-profile-compliance)\n\n[OpenPiton+Ariane](https://openpiton-blog.princeton.edu/2018/11/announcing-openpiton-with-ariane/) is a permissively-licensed RISC-V manycore processor, built as a collaboration between the [PULP Platform](https://www.pulp-platform.org/) from ETH Zürich and the [OpenPiton Platform](http://www.openpiton.org/) from Princeton University. We would like to co-optimise OpenPiton and Ariane/CVA6 in their combined platform, to improve performance of the processor both in FPGA emulation systems and for eventual silicon chips. We are particularly interested in moving the platform toward RISC-V RVA23 profile compliance and so developing any new extension support needed for this purpose would be a great GSoC opportunity!\n\n*Skill level:* Intermediate\n\n*Duration:* 175 or 350 hours\n\n*Language/Tools:* Verilog, SystemVerilog, RISC-V\n\n*Mentor:* [Jonathan Balkind](mailto:jbalkind@ucsb.edu), [Nils Wistoff](mailto:nwistoff@iis.ee.ethz.ch)\n\n[Cohort++](https://fossi-foundation.org#cohort)\n\n[Cohort](https://jbalkind.github.io/docs/asplosc23main-p494-p-b2f0eacb1a-63706-final.pdf) is a framework designed to integrate hardware accelerators into software systems while maximizing efficiency seamlessly. It introduces Software-Oriented Acceleration (SOA), a paradigm that simplifies and optimizes interactions between software and hardware accelerators. By leveraging existing software abstractions—such as shared-memory queues—Cohort enables a streamlined, high-performance communication channel between software components and accelerators.\n\nThis project consists of improving the performance of OpenPiton memory hierarchy to better suit Cohort. For example, there is prior work on supporting wider NoCs, and cachelines in OpenPiton; we are changing the Cohort engine's interaction with the coherence protocol; multiple MMU outstanding requests for higher performance.\n\nWe have other ideas to work more on Cohort software support and we are also open to new proposals. Some examples:\n\n- Support for other data structures instead of only queues\n- Connect the openMP and/or openMPI runtime library to use Cohort queues\n- Add the support for\n[PRGA](https://dl.acm.org/doi/pdf/10.1145/3431920.3439294)to be used with Cohort\n\n*Skill Level:* Medium/Advanced\n\n*Duration:* 350 hours\n\n*Language/Tools:* C++, SystemVerilog\n\n*Mentors:* [Guillem López Paradís](mailto:guillem.lopez@bsc.es), [Davy Million](mailto:davy.million@cea.fr), [Jonathan Balkind](mailto:jbalkind@ucsb.edu)\n\n[OpenRISC Benchmarking and Performance improvements](https://fossi-foundation.org#openrisc-benchmarking-and-performance-improvements)\n\nThe [OpenRISC](https://openrisc.io) CPU architecture has multiple CPU implementations\nincluding the mor1kx and marocchino. Recent testing has shown that memory access\non the marocchino is slightly slower compared to the mor1kx.\n\nThis project will have the student:\n\n- Continue from where the 2024 GSoC student left off.\n- Use tools like the\n[Embench](https://www.embench.org/news.html)modern benchmark suite to measure OpenRISC processor and compiler toolchain performance. - Document the OpenRISC performance at\n[Embench IoT results](https://github.com/embench/embench-iot-results)to be able to compare OpenRISC vs other popular CPUs. - Track down and improve OpenRISC CPU performance by finding and fixing deficiencies in the verilog designed cores.\n\n*Skill level:* Advanced\n\n*Project Length:* large\n\n*Language/Tools:* Verilog, Shell scripting, C, Assembly, Python\n\n*Mentor:* [Stafford Horne](mailto:shorne@gmail.com)\n\n[Adding TL-Verilog Support to Surfer](https://fossi-foundation.org#adding-tl-verilog-support-to-surfer)\n\n*Details:* Surfer is a modern open-source waveform viewer that evolved alongside the Spade HDL. It has gained broader popularity beyond the Spade ecosystem, and adding support for other emerging HDL capabilities will benefit the community.\n\nTL-Verilog models have higher-level knowledge that can be reflected in a waveform viewer to enhance the debugging experience. Most notably, TL-Verilog signals can be \"invalid\". Invalidity is, in some respects, similar to dont-care state. One distinction is that validity is compatible with two-state simulators, like Verilator.\n\nThis project will focus on two main features to enhance TL-Verilog waveforms in Surfer:\n\n- Displaying TL-Verilog-style signal and hierarchy names in TL-Verilog standard colors.\n- Reflecting validity on signal values.\n\nThese two features can currently be seen in the Makerchip IDE's waveform viewer.\n\n*Skill level:* Medium/advanced\n\n*Language/Tools:* Rust\n\n*Duration:* 350 hrs\n\n*Repo:* [https://gitlab.com/surfer-project/surfer](https://gitlab.com/surfer-project/surfer)\n\n*Mentors:* [Frans Skarman](mailto:frans.skarman@protonmail.com) (creator of Surfer and Spade), [Oscar Gustafsson](mailto:oscar.gustafsson@liu.se), [Steve Hoover](mailto:steve.hoover@redwoodeda.com) (creator of TL-Verilog & Makerchip)"
  },
  {
    "name": "ScummVM",
    "slug": "scummvm",
    "tagline": "Adventure and RPG preservation project",
    "description": "ScummVM is a game preservation project with a quickly growing code base since more than 20 years. Originally focused on 2D Point&Click adventure games, its scope widened in 2016 to RPG thanks to successful GSoC students and to 3D games in 2020 after the merge with its sister project, ResidualVM. The purpose is only to replace the game executable, not to enhance or replace the game assets.",
    "ideas_url": "https://www.scummvm.org/gsoc-2026-ideas",
    "website_url": "https://www.scummvm.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "opengl",
      "c++",
      "assembly",
      "sdl"
    ],
    "topic_tags": [
      "games",
      "game engines",
      "software preservation",
      "software archeology"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/scummvm",
    "ideas_content": "# Making sure you're not a bot!\n\nLoading...\n\nYou are seeing this because the administrator of this website has set up Anubis to protect the server against the scourge of AI companies aggressively scraping websites. This can and does cause downtime for the websites, which makes their resources inaccessible for everyone.\n\nAnubis is a compromise. Anubis uses a Proof-of-Work scheme in the vein of Hashcash, a proposed proof-of-work scheme for reducing email spam. The idea is that at individual scales the additional load is ignorable, but at mass scraper levels it adds up and makes scraping much more expensive.\n\nUltimately, this is a placeholder solution so that more time can be spent on fingerprinting and identifying headless browsers (EG: via how they do font rendering) so that the challenge proof of work page doesn't need to be presented to users that are much more likely to be legitimate.\n\nPlease note that Anubis requires the use of modern JavaScript features that plugins like JShelter will disable. Please disable JShelter or other such plugins for this domain."
  },
  {
    "name": "Swift",
    "slug": "swift",
    "tagline": "Fast, safe, and expressive programming language",
    "description": "Swift is a general-purpose programming language built using a modern approach to safety, performance, and software design patterns.\n\nThe goal of the Swift project is to create the best available language for uses ranging from systems programming, to mobile and desktop apps, scaling up to cloud services. Most importantly, Swift is designed to make writing and maintaining correct programs easier for the developer.",
    "ideas_url": "https://www.swift.org/gsoc2026/",
    "website_url": "https://swift.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c++",
      "cmake",
      "swift"
    ],
    "topic_tags": [
      "compilers",
      "cross-platform",
      "Packages",
      "Server development",
      "Standard Libraries"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/swift",
    "ideas_content": "# Project Ideas for GSoC 2026\n\nThis page contains a non-exhaustive list of potential project ideas that we are keen to develop during [Google Summer of Code 2026](https://summerofcode.withgoogle.com/). If you would like to apply to GSoC as a contributor, please follow these steps to get started:\n\n- Read through this page and the Google Summer of Code guides,\n- Identify, or come up with your own project ideas you find interesting.\n- Check out the\n[Development forum](https://forums.swift.org/c/development/gsoc/98)to connect with potential mentors.- Feel free to mention the project mentors on the forums, when starting a thread about your interest in participating in a specific project they are offering to mentor.\n\n\nWhen posting on the forums about GSoC this year, please use the [ gsoc-2026 tag](https://forums.swift.org/tag/gsoc-2026), so it is easy to identify.\n\n## Tips for contacting mentors [\n](https://www.swift.org#tips-for-contacting-mentors)\n\nThe Swift forums are powered by discourse, a discussion forums platform with spam avoidance mechanisms built-in. If this is your first time joining the forums, you *may* not be able to send mentors a direct message, as this requires a minimum amount of prior participation before the “send private message” feature is automatically enabled.\n\nTo start things off, we recommend starting a new thread or joining an existing discussion about the project you are interested in on the dedicated [GSoC forums category](https://forums.swift.org/c/development/gsoc/98). You should also *tag* your thread with the `gsoc-2026`\n\ntag. It is best if you start a thread after having explored the topic a little bit already, and come up with specific questions about parts of the project you are not sure about. For example, you may have tried to build the project, but not sure where a functionality would be implemented; or you may not be sure about the scope of the project.\n\nPlease use the forums to tag and communicate with the project’s mentor to figure out the details of the project, such that when it comes to writing the official proposal plan, and submitting it on the Summer of Code website, you have a firm understanding of the project and can write a good, detailed proposal (see next section about hints on that).\n\nIf you would like to reach out to a mentor privately rather than making a public forum post, and the forums are not allowing you to send private messages yet, please reach out to Konrad Malawski at `ktoso AT apple.com`\n\ndirectly via email with the `[gsoc2026]`\n\ntag in the email subject and describe the project you would like to work on. We will route you to the appropriate mentor. In general, public communications on the forums are preferred though, as this is closer to the normal open-source way of getting things done in the Swift project.\n\n## Writing a proposal [\n](https://www.swift.org#writing-a-proposal)\n\nGetting familiar with the codebase you are interested in working on during GSoC helps to write a good proposal because it helps you get a better understanding of how everything works and how you might best approach the project you are interested in. How you want to do that is really up to you and your style of learning. You could just clone the repository, read through the source code and follow the execution path of a test case by setting a breakpoint and stepping through the different instructions, read the available documentation or try to fix a simple bug in the codebase. The latter is how many open-source contributors got started, but it’s really up to you. If you do want to go and fix a simple bug, our repositories contain a label “good first issue” that marks issues that should be easy to fix and doable by newcomers to the project.\n\nWhen it comes to writing the proposal, the [Google Summer of Code Guide](https://google.github.io/gsocguides/student/writing-a-proposal) contains general, good advice.\n\nThe best proposals include a detailed timeline, specific milestones and goals as well as an outline the technical challenges you foresee. It is best if you engage with your potential project mentor on the forums before contriburing, and have them clarify the goals and steps that they think are necessary for the project to be successful. Your proposal should have a clear goal, which can be successfully achieved as part of the weeks you’ll be working it. Provide details about your approach, significant milestones you wish to achieve, and clarify with your potential mentor if they agree those seem reasonable. The time before proposal submissions is there for you to reach out and polish your proposal, so make sure you use it well! Good luck!\n\n## Potential Projects [\n](https://www.swift.org#potential-projects)\n\nWe are currently collecting project ideas on the forums in the dedicated [GSoC category](https://forums.swift.org/c/development/gsoc/98).\n\nPotential mentors, please feel free to propose project ideas to this page directly, by [opening a pull request](https://github.com/swiftlang/swift-org-website/edit/main/gsoc2026/index.md) to the Swift website.\n\nYou can browse previous year’s project ideas here: [2025](https://www.swift.org/gsoc2025/), [2024](https://www.swift.org/gsoc2024/), [2023](https://www.swift.org/gsoc2023/), [2022](https://www.swift.org/gsoc2022/), [2021](https://www.swift.org/gsoc2021/), [2020](https://www.swift.org/gsoc2020/), [2019](https://www.swift.org/gsoc2019/).\n\n### Re-implement property wrappers with macros [\n](https://www.swift.org#re-implement-property-wrappers-with-macros)\n\n**Project size**: 350 hours\n**Estimated difficulty**: Intermediate\n**Recommended skills**\n\n- Proficiency in Swift and C++\n\n**Description**\n\n[Property wrappers](https://github.com/swiftlang/swift-evolution/blob/main/proposals/0258-property-wrappers.md) feature is currently implemented purely within the compiler but with the addition of [Swift Macros](https://github.com/swiftlang/swift-evolution/blob/main/proposals/0389-attached-macros.md) and [init accessors](https://github.com/swiftlang/swift-evolution/blob/main/proposals/0400-init-accessors.md) it’s now possible to remove all ad-hoc code from the compiler and implement property wrappers by using existing features.\n\nThis work would remove a lot of property wrapper-specific code throughout the compiler - parsing, semantic analysis, SIL generation etc. which brings great benefits by facilitating code reuse, cleaning up the codebase and potentially fixing implementation corner cases. Macros and init accessors in their current state might not be sufficient to cover all of the property wrapper use scenarios, so the project is most likely going to require improving and expanding the aforementioned features as well.\n\n**Expected outcomes/benefits/deliverables**\n\nThe outcome of this project is the complete removal of all property wrappers-specific code from the compiler. This benefits the Swift project in multiple areas - stability, testability and code health.\n\n**Potential mentors**\n\n### Qualified name lookup for swift-syntax [\n](https://www.swift.org#qualified-name-lookup-for-swift-syntax)\n\n**Project size**: 350 hours\n\n**Estimated difficulty**: Intermediate\n\n**Recommended skills**\n\n- Basic proficiency in Swift.\n\n**Description**\n\nQualified name lookup is the process by which a compiler resolves a reference `A.f`\n\ninto a lookup for entities named `f`\n\nwithin `A`\n\n. In Swift, this can mean looking into the type `A`\n\nand all of its extensions, superclass, protocols, and so on to find visible members. The project involves building a new library to be integrated into the [swift-syntax package](https://github.com/swiftlang/swift-syntax) that implements Swift’s qualified name lookup semantics, making it easy to build source tools that resolve names. The library will likely include a symbol table implementation that provides efficient lookup of a given name within a given type. It should also integrate with last year’s [unqualified name lookup library project](https://forums.swift.org/t/gsoc-2024-swiftlexicallookup-a-new-lexical-name-lookup-library/75889), to provide complete support for name lookup on Swift code processed with swift-syntax.\n\n**Expected outcomes/benefits/deliverables**\n\n- Swift library providing APIs for qualified name lookup in swift-syntax\n- Documentation and tutorial for the library\n- Integration of the Swift library with the\n`SwiftLexicalLookup`\n\nlibrary that implements unqualified name lookup\n\n**Potential mentors**\n\n### Task and TaskGroup tracking for Swift Concurrency [\n](https://www.swift.org#task-and-taskgroup-tracking-for-swift-concurrency)\n\n**Project size**: 160 hours\n\n**Estimated difficulty**: Advanced\n\n**Recommended skills**\n\n- Proficiency in C/C++ and Swift\n- Understanding of atomics and memory ordering\n\n**Description**\n\nThe Concurrency runtime presently does not provide a way to keep track of which `Task`\n\ns and `TaskGroup`\n\ns are executing. This information is especially useful for debugging programs that use Swift Concurrency; without it, it’s possible to end up in situations where no progress is being made but you cannot see which tasks are outstanding since none of them are actually executing on a thread (so they don’t show up in backtraces).\n\nAn easy solution might be to have a global linked list of `Task`\n\ns and `TaskGroup`\n\ns, but that would cause unnecessary synchronization (or, for atomics, contention) between threads, which is highly undesirable.\n\nThe goal of this project is to investigate data structures we might use to track `Task`\n\ns and `TaskGroup`\n\ns and to measure their overhead to make sure that it is acceptable. A stretch goal might be to implement the necessary support to provide a list of extant `Task`\n\ns and `TaskGroup`\n\ns in Swift’s on-crash backtraces, and to provide some Python macros for LLDB that can list `Task`\n\ns and `TaskGroup`\n\ns.\n\n**Expected outcome/benefits/deliverables**\n\n- An implementation of\n`Task`\n\n/`TaskGroup`\n\ntracking for the Concurrency runtime - A document detailing the design of the data structures used in the implementation and characterising their overheads, possibly by comparison to the naïve global list approach\n- (Stretch) Support for dumping the list of\n`Task`\n\ns and`TaskGroup`\n\ns in the on-crash backtracer - (Stretch) A Python module for LLDB to allow inspection of Concurrency runtime state\n\n**Potential mentors**\n\n### WebAssembly Reference Types (`externref`\n\n) Support in Swift Compiler [externref) Support in Swift Compiler section\" href=\"#webassembly-reference-types-externrefsupport-in-swift-compiler\">\n]\n\n**Project size**: 200-300 hours\n\n**Estimated difficulty**: Advanced\n\n**Recommended skills**\n\n- Proficiency in C/C++, Swift, and WebAssembly;\n- Basic understanding of SIL and LLVM IR.\n\n**Description**\n\nCore WebAssembly supports primitive scalar and vector types, such as `i32`\n\n/`i64`\n\n/`f32`\n\n/`f64`\n\n, and `v128`\n\n. For bridging high-level types that have reference semantics, WebAssembly host environment usually maintains an ad-hoc table that maps indices in this table to references stored in it.\n\nFor example, to bridge a garbage-collected JavaScript value to WebAssembly, a naive implementation can allocate a JavaScript array that holds a reference to this value, while an index in this array is passed to Swift compiled to Wasm that it can operate on. While these ad-hoc tables are the primary means to interoperate with JavaScript from Swift, they’re not optimal from binary size and performance perspective.\n\n[Recent WebAssembly standard text defines a new built-in externref type](https://www.w3.org/TR/2025/CRD-wasm-core-2-20250616/#reference-types①) that can be stored in built-in WebAssembly tables and passed around on WebAssembly stack. It can’t be stored in Wasm linear memory, which only supports basic numeric types, integer indices in the built-in table are used for that instead. To support this, LLVM represents\n\n`externref`\n\nas a pointer in a reserved address space, while Clang at a higher level represents this as a built-in `__externref_t`\n\ntype lowered to LLVM pointer type in the reserved address space.We’re looking for a prototype of an experimental feature in the Swift compiler that allows easier interoperability with C and C++ code that uses `__externref_t`\n\nvalues. As a stretch goal, Swift standard library should facilitate easier interop with host environments for [WebAssembly embedding](https://www.w3.org/TR/2025/CRD-wasm-core-2-20250616/#a1-embedding).\n\n**Expected outcome/benefits/deliverables**\n\n`WasmExternref`\n\nexperimental feature that enables`WasmExternref`\n\ntype in the Swift standard library;- Lowering of operations on this type to\n[correct LLVM IR address space](https://discourse.llvm.org/t/rfc-webassembly-reference-types-in-clang/66939); - Type checker semantics that corresponds to\n[existing](https://github.com/swiftlang/swift-for-wasm-examples/blob/main/DOMRefTypes/Sources/externref/bridge.c);`__externref_t`\n\ntype in Clang - (Stretch) Availability of Wasm\n`externref`\n\ntable builtins in the Swift standard library for future use corresponding to`__builtin_wasm_table_*`\n\navailable in Clang - (Stretch)\n`WasmExternrefIndex`\n\nfor wrapping`externref`\n\ntable indices in types available in common Swift values address space.\n\n**Potential mentors**\n\n### WebAssembly Swift SDK with Support for Multi-threading [\n](https://www.swift.org#webassembly-swift-sdk-with-support-for-multi-threading)\n\n**Project size**: 100-160 hours\n\n**Estimated difficulty**: Intermediate\n\n**Recommended skills**\n\n- Proficiency in Swift and WebAssembly;\n- Basic understanding of Python and Swift compiler build system.\n\n**Description**\n\nMulti-threading support in WebAssembly requires building code against `wasm32-unknown-wasip1-threads`\n\ntriple, which is already supported in WASI-libc dependency of the Swift standard library.\n\nSwift toolchain `build-script`\n\ninfrastructure written in Python needs minor updates that will build and package artifacts built for this triple in existing Swift SDK bundle that’s distributed on swift.org.\n\nAs a stretch goal, we’d like this project to include a review of the existing test suite to ensure that the newly supported triple is well tested and supported by the core Swift libraries.\n\n**Expected outcome/benefits/deliverables**\n\n- New Swift SDK with\n`wasm32-unknown-wasip1-threads`\n\ntriple added to the existing Wasm Swift SDK bundle; - Running Swift stdlib tests compiled for the new triple;\n- (Stretch) CI setup for core Swift libraries building with the new Swift SDK.\n\n**Potential mentors**\n\n### DocC Language Features in SourceKit-LSP [\n](https://www.swift.org#docc-language-features-in-sourcekit-lsp)\n\n**Project size**: 200 hours\n\n**Estimated difficulty**: Intermediate\n\n**Recommended skills**\n\n- Basic proficiency in Swift.\n- Basic proficiency in TypeScript.\n\n**Description**\n\nSourceKit-LSP has recently added DocC Live Preview support that can be used in editors such as VS Code. It allows users to view a real time side-by-side preview of their documentation directly in their editor.\n\nLive preview could be further improved by providing language features such as go to definition as well as diagnostics for invalid/missing symbol names within DocC markdown and tutorial files. It would also be useful to have the links within the preview window take the user to the relevant symbol or documentation file within the code base.\n\n**Expected outcomes/benefits/deliverables**\n\n- Syntax highlighting for DocC markdown and tutorial files\n- Go to definition for symbols that appear in DocC documentation\n- Diagnostics that report missing/invalid symbol names in DocC documentation\n- Clicking on links within live preview should take the user to the symbol\n\n**Potential mentors**\n\n### SwiftPM System Executables for Enhanced Plugin User Experience [\n](https://www.swift.org#swiftpm-system-executables-for-enhanced-plugin-user-experience)\n\n**Project size**: 200 hours\n\n**Estimated difficulty**: Intermediate\n\n**Recommended skills**\n\n- Basic proficiency in Swift\n- Basic proficiency in SwiftPM packages\n\n**Description**\n\nSwiftPM is somewhat unique as a package manager because it supports marking dependencies on packages from foreign package managers, such as apt, yum, and homebrew. Today this is mainly used for libraries to be linked into SwiftPM products.\n\nSwiftPM plugins can depend on executable tools, built from source, to help generate code and resources. If a tool cannot be built from source using SwiftPM then the plugin can invoke it using an absolute path. But, how will it know if the tool is present at that path? Also, how will the user be guided to install the package if it is missing?\n\nThe idea is to implement a system executable target, similar to system library targets where package names can be specified based on different package managers. Plugins can then depend on system executable targets so that warnings are emitted if the tool cannot be found on the path, along with the recommended remedy (e.g. “apt-get install foo”) for any build errors. Since package manager may place tools in different locations based on the platform, there would be a SwiftPM plugin API for a plugin to specify the tool name and then it can discover the full path location. Add in some popular language-specific package manager support to gain access to many more tools (e.g. npm, and pip).\n\n**Expected outcomes/benefits/deliverables**\n\n- Complete SwiftPM proposal and working pull request\n\n**Potential mentors**\n\n### Sysroot Support in Swift’s build-script [\n](https://www.swift.org#sysroot-support-in-swifts-build-script)\n\n**Project size**: 160 hours\n\n**Estimated difficulty**: Intermediate\n\n**Recommended skills**\n\n- Basic understanding of CMake, Python\n- Experience with the Swift compiler build system is a plus\n\n**Description**\n\nExtend Swift‘s `build-script`\n\nwith an experimental flag which\nprovides the path to the sysroot of the target triple. This enables\n[cross-compiling](https://github.com/swiftlang/swift-evolution/blob/main/proposals/0387-cross-compilation-destinations.md)\nto other sysroots, meaning the host triple is different to the target triple.\n[Wasm](https://github.com/swiftlang/swift/blob/main/utils/swift_build_support/swift_build_support/products/wasmswiftsdk.py)\nalready uses a [sysroot](https://github.com/swiftlang/swift/blob/main/utils/swift_build_support/swift_build_support/products/wasmswiftsdk.py).\nThe approach is to generalize the mechanism by splitting out the Swift core library builds into separate build products to be used for cross-compiling.\n\n**Expected outcomes/benefits/deliverables**\n\n- New build products for cross-compiling Swift core libraries (reuse from Wasm).\n- The new experimental flag from\n`build-script`\n\nis propagated to the new build products. - Cross-compilation succeeds and tests run successfully on target system.\n- Benefit is to be able to cross-compile to various Linux distros from one host system. It enables generation of Swift SDKs for cross-compilation.\n\n**Potential mentors**\n\n### Example project name [\n](https://www.swift.org#example-project-name)\n\n**Project size**: N hours\n\n**Estimated difficulty**: ???\n\n**Recommended skills**\n\n- Basic proficiency in Swift.\n- …\n\n**Description**\n\nDescription of the project goes here.\n\n**Expected outcomes/benefits/deliverables**\n\n- Expected deliverables of the project go here\n\n**Potential mentors**\n\n- Mentor name and link to their github"
  },
  {
    "name": "CRIU",
    "slug": "criu",
    "tagline": "Chekpoint/Restore for Linux tasks and containers",
    "description": "CRIU (stands for Checkpoint/Restore In Userspace), is a Linux software. It can freeze a running container (or an individual application) and checkpoint its state to disk. The data saved can be used to restore the application and run it exactly as it was during the time of the freeze. Using this functionality, application or container live migration, snapshots, remote debugging, and many other things are now possible. \nCRIU is packaged for all leading Linux distributions and it is integrated wit lots of popular projects such as Docker, Podman, LXC/LXD, OpenVZ,  runc,  open-mpi and others",
    "ideas_url": "https://criu.org/Google_Summer_of_Code_Ideas",
    "website_url": "https://criu.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "python",
      "linux",
      "go"
    ],
    "topic_tags": [
      "cloud",
      "containers",
      "Checkpoint/Restore"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/criu",
    "ideas_content": "# Google Summer of Code Ideas\n\n[Jump to navigation](https://criu.org#mw-head)\n\n[Jump to search](https://criu.org#searchInput)\n\nGoogle Summer of Code (GSoC) is a global program that offers post-secondary students an opportunity to be paid for contributing to an open source project over a three month period.\n\nThis page contains project ideas for upcoming Google Summer of Code.\n\n## Contact[[edit](https://criu.org/index.php?title=Google_Summer_of_Code_Ideas&action=edit§ion=1)]\n\nFirst, make sure to go through the [GSoC Students Recommendations](https://criu.org/GSoC_Students_Recommendations). Once you build CRIU locally and C/R a simple process successfully, please contact the respective mentor for the idea you are interested in. For general questions feel free to send an email to the [mailing list](mailto:criu@lists.linux.dev) or write in [gitter](https://gitter.im/save-restore/criu).\n\n## Project ideas[[edit](https://criu.org/index.php?title=Google_Summer_of_Code_Ideas&action=edit§ion=2)]\n\n### Kubernetes Operator for Automated Checkpointing[[edit](https://criu.org/index.php?title=Google_Summer_of_Code_Ideas&action=edit§ion=3)]\n\n**Summary:** Extend the Checkpoint/Restore Operator with support for automated policy-based checkpointing.\n\nThe [Checkpoint/Restore Operator](https://github.com/checkpoint-restore/checkpoint-restore-operator) for Kubernetes currently supports only policies and parameters that limit the number of checkpoints. This project aims to extend the current support with automated policy-based checkpointing, allowing users to define triggers for checkpoint creation, such as time-based schedules, resource thresholds (CPU, memory, I/O usage), Kubernetes events (node drain, pod eviction, preemption), and application-level signals or annotations.\n\n**Links:**\n\n[https://github.com/checkpoint-restore/checkpoint-restore-operator](https://github.com/checkpoint-restore/checkpoint-restore-operator)[https://kubernetes.io/docs/reference/node/kubelet-checkpoint-api](https://kubernetes.io/docs/reference/node/kubelet-checkpoint-api)\n\n**Details:**\n\n- Skill level: intermediate\n- Language: Go\n- Expected size: 350 hours\n- Mentors: Viktória Spišaková <spisakova@ics.muni.cz>, Radostin Stoyanov <rstoyanov@fedoraproject.org>, Adrian Reber <areber@redhat.com>\n\n### Forensic Checkpointing Framework for Kubernetes[[edit](https://criu.org/index.php?title=Google_Summer_of_Code_Ideas&action=edit§ion=4)]\n\nKubernetes provides a highly dynamic and ephemeral environment where workloads can start and disappear very quickly and are continuously being rescheduled across different nodes in the cluster. One of the key challenges with forensic investigations in Kubernetes is capturing and preserving the evidence during security incidents. This project aims to address this problem by developing a framework for efficiently capturing and preserving the state of all running applications in a container at a specific point in time, along with the associated container configurations and metadata. These artifacts would allow investigators to accurately reconstruct the events, create a timeline, and analyze security incidents without impacting the running cluster. This is an important step towards enabling forensic readiness for Kubernetes, where cluster administrators proactively ensure the environments are prepared to collect and preserve evidence before a security incident occurs.\n\n**Links:**\n\n[https://github.com/checkpoint-restore/checkpointctl](https://github.com/checkpoint-restore/checkpointctl)[Investigating Security Incidents with Forensic Snapshots in Kubernetes](https://fosdem.org/2026/events/attachments/F9RANH-forensic-snapshots-in-kubernetes/slides/266249/fosdem_2_4dh73ni.pdf)[Cloud Native Security Whitepaper](https://www.cncf.io/reports/cloud-native-security-whitepaper/)[Kubernetes Hardening Guide](https://media.defense.gov/2022/Aug/29/2003066362/-1/-1/0/CTR_KUBERNETES_HARDENING_GUIDANCE_1.2_20220829.PDF)\n\n**Details:**\n\n- Skill level: intermediate\n- Language: Go\n- Expected size: 350 hours\n- Mentors: Lorena Goldoni <lory.goldoni@gmail.com>, Radostin Stoyanov <rstoyanov@fedoraproject.org>, Adrian Reber <areber@redhat.com>\n\n### Enabling Checkpoint/Restore of Rootless Containers[[edit](https://criu.org/index.php?title=Google_Summer_of_Code_Ideas&action=edit§ion=5)]\n\n[Rootless containers](https://rootlesscontaine.rs/) are containers that can be created, run, and managed by unprivileged users. Container engines such as Podman natively support running containers in a rootless mode to improve security and usability. While checkpoint/restore functionality is already available for rootful containers and unprivileged checkpointing is possible with the `CAP_CHECKPOINT_RESTORE`\n\ncapability, container engines do not yet support native checkpointing of containers running in rootless mode. This project aims to explore and address the remaining challenges required to enable unprivileged checkpoint/restore for rootless containers.\n\n**Links:**\n\n[https://github.com/checkpoint-restore/criu/pull/1930](https://github.com/checkpoint-restore/criu/pull/1930)[https://github.com/torvalds/linux/commit/124ea650d3072b005457faed69909221c2905a1f](https://github.com/torvalds/linux/commit/124ea650d3072b005457faed69909221c2905a1f)[https://src.fedoraproject.org/rpms/criu/pull-request/10#request_diff](https://src.fedoraproject.org/rpms/criu/pull-request/10#request_diff)\n\n**Details:**\n\n- Skill level: intermediate\n- Language: C, Go\n- Expected size: 350 hours\n- Mentors: Radostin Stoyanov <rstoyanov@fedoraproject.org>, Adrian Reber <areber@redhat.com>\n\n### Files on detached mounts[[edit](https://criu.org/index.php?title=Google_Summer_of_Code_Ideas&action=edit§ion=6)]\n\n**Summary:** Initial support of open files on \"detached\" mounts\n\nWhen criu dumps a process with an open fd on a file, it gets the mount identifier (mnt_id) via /proc/<pid>/fdinfo/<fd>, so that criu knows from which exact mount the file was initially opened. This way criu can restore this fd by opening the same exact file from topologically the same mount in restored mount tree.\n\nRestoring fd from the right mount can be important in different cases, for instance if the process would later want to resolve paths relative to the fd, and obviously resolving from the same file on different mount can lead to different resolved paths, or if the process wants to check path to the file via /proc/<pid>/fd/<fd>.\n\nBut we have a problem finding on which mount we need to reopen the file at restore if we only know mnt_id but can't find this mnt_id in /proc/<pid>/mountinfo.\n\nMountinfo file shows the mount tree topology of current mntns: parent - child relations, sharing group information, mountpoint and fs root information. And if we don't see mnt_id in it we don't know anything about this mount.\n\nThis can happen in two cases\n\n- 1) external mount or file - if file was opened from e.g. host it's mount would not be visible in container mountinfo\n- 2) mount was lazily unmounted\n\nIn case of 1) we have criu options to help criu handle external dependencies.\n\nIn case of 2) or no options provided criu can't resolve mnt_id in mountinfo and criu fails.\n\n**Solution:**\nWe can handle 2) with: resolving major/minor via fstat, using name_to_handle_at and open_by_handle_at to open same file on any other available mount from same superblock (same major/minor) in container. Now we have fd2 of the same file as fd, but on existing mount we can dump it as usual instead, and mark it as \"detached\" in image, now criu on restore knows where to find this file, but instead of just opening fd2 from actually restored mount, we create a temporary bindmount which is lazy unmounted just after open making the file appear as a file on detached mount.\n\nKnown problems with this approach:\n\n- Stat on btrfs gives wrong major/minor\n- file handles does not work everywhere\n- file handles can return fd2 on deleted file or on other hardlink, this needs special handling.\n\nAdditionally (optional part): We can export real major/minor in fdinfo (kernel). We can think of new kernel interface to get mount's major/minor and root (shift from fsroot) for detached mounts, if we have it we don't need file handle hack to find file on other mount (see fsinfo or getvalues kernel patches in LKML, can we add this info there?).\n\n**Details:**\n\n- Skill level: intermediate\n- Language: C\n- Expected size: 350 hours\n- Mentor: Pavel Tikhomirov <ptikhomirov@virtuozzo.com>\n- Suggested by: Pavel Tikhomirov <ptikhomirov@virtuozzo.com>\n\n### Checkpointing of POSIX message queues[[edit](https://criu.org/index.php?title=Google_Summer_of_Code_Ideas&action=edit§ion=7)]\n\n**Summary:** Add support for checkpoint/restore of POSIX message queues\n\nPOSIX message queues are a widely used inter-process communication mechanism. Message queues are implemented as files on a virtual filesystem (mqueue), where a file descriptor (message queue descriptor) is used to perform operations such as sending or receiving messages. To support checkpoint/restore of POSIX message queues, we need a kernel interface (similar to [MSG_PEEK](https://github.com/checkpoint-restore/criu/commit/8ce9e947051e43430eb2ff06b96dddeba467b4fd)) that would enable the retrieval of messages from a queue without removing them. This project aims to implement such an interface that allows retrieving all messages and their priorities from a POSIX message queue.\n\n**Links:**\n\n[https://github.com/checkpoint-restore/criu/issues/2285](https://github.com/checkpoint-restore/criu/issues/2285)[https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/ipc/mqueue.c](https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/ipc/mqueue.c)[https://www.man7.org/tlpi/download/TLPI-52-POSIX_Message_Queues.pdf](https://www.man7.org/tlpi/download/TLPI-52-POSIX_Message_Queues.pdf)\n\n**Details:**\n\n- Skill level: intermediate\n- Language: C\n- Expected size: 350 hours\n- Mentors: Radostin Stoyanov <rstoyanov@fedoraproject.org>, Pavel Tikhomirov <ptikhomirov@virtuozzo.com>\n- Suggested by: Pavel Tikhomirov <ptikhomirov@virtuozzo.com>\n\n### Add support for SCM_CREDENTIALS / SCM_PIDFD and friends[[edit](https://criu.org/index.php?title=Google_Summer_of_Code_Ideas&action=edit§ion=8)]\n\n**Summary:** Support for SCM_CREDENTIALS / SCM_PIDFD\n\nSCM_CREDENTIALS and SCM_PIDFD are types of SCM (Socket-level Control Messages). They play a crucial role in systemd and many other user space applications. This project is about adding support for these SCMs to be properly saved and restored back with CRIU. There is an existing code in OpenVZ CRIU fork, see [1] and [2]. Goal would be first of all to properly port this code, cover with extensive tests and ensure that SCM_PIDFD / SO_PEERPIDFD are handled correctly. Also we expect to cover things like SO_PASSRIGHTS and SO_PASSPIDFD.\n\nThere is some extra source of complexity here pidfds can be \"stale\" (see PIDFD_STALE in Linux kernel) and we need to ensure that we properly cover those cases.\n\n**Links:**\n\n- [1] openvz-criu\n[https://bitbucket.org/openvz/criu.ovz/history-node/918653a0a343194385592d7b50b5bd7a8fbe1cc1/criu/sk-unix.c?at=hci-dev](https://bitbucket.org/openvz/criu.ovz/history-node/918653a0a343194385592d7b50b5bd7a8fbe1cc1/criu/sk-unix.c?at=hci-dev) - [2] openvz-criu\n[https://bitbucket.org/openvz/criu.ovz/history-node/918653a0a343194385592d7b50b5bd7a8fbe1cc1/criu/sk-queue.c?at=hci-dev](https://bitbucket.org/openvz/criu.ovz/history-node/918653a0a343194385592d7b50b5bd7a8fbe1cc1/criu/sk-queue.c?at=hci-dev) - [3] Linux kernel\n[https://github.com/torvalds/linux/commit/5e2ff6704a275be009be8979af17c52361b79b89](https://github.com/torvalds/linux/commit/5e2ff6704a275be009be8979af17c52361b79b89) - [4] Linux kernel\n[https://github.com/torvalds/linux/commit/c679d17d3f2d895b34e660673141ad250889831f](https://github.com/torvalds/linux/commit/c679d17d3f2d895b34e660673141ad250889831f)\n\n**Details:**\n\n- Skill level: intermediate / advanced\n- Language: C\n- Expected size: 350 hours\n- Suggested by: Alexander Mikhalitsyn <alexander@mihalicyn.com>\n- Mentors: Andrei Vagin <avagin@gmail.com>, Alexander Mikhalitsyn <alexander@mihalicyn.com>\n\n## Suspended project ideas[[edit](https://criu.org/index.php?title=Google_Summer_of_Code_Ideas&action=edit§ion=9)]\n\nListed here are tasks that seem suitable for GSoC, but currently do not have anybody to mentor it.\n\n### Optimize logging engine[[edit](https://criu.org/index.php?title=Google_Summer_of_Code_Ideas&action=edit§ion=10)]\n\n**Summary:** CRIU puts a lots of logs when doing its job. Logging is done with simple fprintf function. They are typically useless, but *if* some operation fails -- the logs are the only way to find what was the reason for failure.\n\nAt the same time the printf family of functions is known to take some time to work -- they need to scan the format string for %-s and then convert the arguments into strings. If comparing criu dump with and without logs the time difference is notable (15%-20%), so speeding the logs up will help improve criu performance.\n\nOne of the solutions to the problem might be binary logging. The problem with binary logs is the amount of efforts to convert existing logs to binary form. Preferably, the switch to binary logging either keeps existing log() calls intact, either has some automatics to convert them.\n\nThe option to keep log() calls intact might be in pre-compilation pass of the sources. In this pass each `log(fmt, ...)`\n\ncall gets translated into a call to a binary log function that saves `fmt`\n\nidentifier copies all the args *as is* into the log file. The binary log decode utility, required in this case, should then find the fmt string by its ID in the log file and print the resulting message.\n\n**Links:**\n\n**Details:**\n\n- Skill level: intermediate\n- Language: C, though decoder/preprocessor can be in any language\n- Expected size: 350 hours\n- Suggested by: Andrei Vagin\n- Mentors: Alexander Mikhalitsyn <alexander@mihalicyn.com>\n\n### IOUring support[[edit](https://criu.org/index.php?title=Google_Summer_of_Code_Ideas&action=edit§ion=11)]\n\nThe io_uring Asynchronous I/O (AIO) framework is a new Linux I/O interface, first introduced in upstream Linux kernel version 5.1 (March 2019). It provides a low-latency and feature-rich interface for applications that require AIO functionality.\n\n**Links:**\n\n[https://blogs.oracle.com/linux/an-introduction-to-the-io_uring-asynchronous-io-framework](https://blogs.oracle.com/linux/an-introduction-to-the-io_uring-asynchronous-io-framework)[https://github.com/axboe/liburing](https://github.com/axboe/liburing)\n\n**Details:**\n\n- Skill level: expert (+linux kernel)\n- Expected size: 350 hours\n\n### Add support for SPFS[[edit](https://criu.org/index.php?title=Google_Summer_of_Code_Ideas&action=edit§ion=12)]\n\n**Summary:** The SPFS is a special filesystem that allows checkpoint and restore of such things as NFS and FUSE\n\nNFS support is already implemented in Virtuozzo CRIU, but it's very beneficial to port it to mainline CRIU. The importaint part of it is the need to implement the integration of Stub-Proxy File System (SPFS) with LXC/yet_another_containers_environment.\n\n**Links**\n\n[https://github.com/checkpoint-restore/criu/issues/60](https://github.com/checkpoint-restore/criu/issues/60)[https://github.com/checkpoint-restore/criu/issues/53](https://github.com/checkpoint-restore/criu/issues/53)[https://github.com/skinsbursky/spfs](https://github.com/skinsbursky/spfs)[https://patchwork.criu.org/series/137/](https://patchwork.criu.org/series/137/)\n\n**Details:**\n\n- Skill level: expert\n- Language: C\n- Mentor: Alexander Mikhalitsyn <alexander@mihalicyn.com>\n- Suggested by: Alexander Mikhalitsyn <alexander@mihalicyn.com>\n\n\n\n### Anonymise image files[[edit](https://criu.org/index.php?title=Google_Summer_of_Code_Ideas&action=edit§ion=13)]\n\n**Summary:** Teach [CRIT](https://criu.org/CRIT) to remove sensitive information from images\n\nWhen reporting a BUG it may be not acceptable for the reporter to send us raw images, as they may contain sensitive data. Need to teach CRIT to \"anonymise\" images for publication.\n\nList of data to shred:\n\n- Memory contents. For the sake of investigation, all the memory contents can be just removed. Only the sizes of pages*.img files are enough.\n- Paths to files. Here we should keep the paths relations to each other. The simplest way seem to be replacing file names with \"random\" (or sequential) strings, BUT (!) keeping an eye on making this mapping be 1:1. Note, that file paths may also sit in sk-unix.img.\n- Registers.\n- Process names. (But relations should be kept).\n- Contents of streams, i.e. pipe/fifo data, sk-queue, tcp-stream, tty data.\n- Ghost files.\n- Tarballs with tmpfs-s.\n- IP addresses in sk-inet-s, ip tool dumps and net*.img.\n\n**Links:**\n\n[Anonymize image files](https://criu.org/Anonymize_image_files)[https://github.com/checkpoint-restore/criu/issues/360](https://github.com/checkpoint-restore/criu/issues/360)[CRIT](https://criu.org/CRIT),[Images](https://criu.org/Images)- External links to mailing lists or web sites\n\n**Details:**\n\n- Skill level: beginner\n- Language: Python\n\n### Add support for checkpoint/restore of CORK-ed UDP socket[[edit](https://criu.org/index.php?title=Google_Summer_of_Code_Ideas&action=edit§ion=14)]\n\n**Summary:** Support C/R of corked UDP socket\n\nThere's UDP_CORK option for sockets. As man page says:\n\nIf this option is enabled, then all data output on this socket is accumulated into a single datagram that is transmitted when the option is disabled. This option should not be used in code intended to be portable.\n\nCurrently criu refuses to dump this case, so it's effectively a bug. Supporting\nthis will need extending the kernel API to allow criu read back the write queue\nof the socket (see [how it's done](https://criu.org/TCP_connection) for TCP sockets, for example). Then\nthe queue is written into the image and is restored into the socket (with the CORK\nbit set too).\n\n**Notes:**\n\nWe already had a couple (3) of tries for this problem:\n\n- UDP_REPAIR approach didn't succeed:\n[https://lore.kernel.org/netdev/721a2e32-c930-ad6b-5055-631b502ed11b@gmail.com/](https://lore.kernel.org/netdev/721a2e32-c930-ad6b-5055-631b502ed11b@gmail.com/),[https://lore.kernel.org/netdev/?q=udp_repair](https://lore.kernel.org/netdev/?q=udp_repair) - eBPF (CRIB) approach, socket queue iterator was not merged:\n[https://lore.kernel.org/netdev/AM6PR03MB5848EDA002E3D7EACA7C6BDA99A52@AM6PR03MB5848.eurprd03.prod.outlook.com/](https://lore.kernel.org/netdev/AM6PR03MB5848EDA002E3D7EACA7C6BDA99A52@AM6PR03MB5848.eurprd03.prod.outlook.com/), and we have general objections to CRIB approach[https://lore.kernel.org/bpf/CAHk-=wjLWFa3i6+Tab67gnNumTYipj_HuheXr2RCq4zn0tCTzA@mail.gmail.com/](https://lore.kernel.org/bpf/CAHk-=wjLWFa3i6+Tab67gnNumTYipj_HuheXr2RCq4zn0tCTzA@mail.gmail.com/)\n\nWe still have one idea we didn't try, as UDP allows packets to be lost on the way on restore we can somehow mark the socket to drop all data before UNCORK. This way we don't really need to restore contents of UDP CORK-ed sockets send queue.\n\n**Links:**\n\n[https://github.com/checkpoint-restore/criu/issues/409](https://github.com/checkpoint-restore/criu/issues/409)[https://github.com/criupatchwork/criu/commit/a532312](https://github.com/criupatchwork/criu/commit/a532312)[Sockets](https://criu.org/Sockets),[TCP connection](https://criu.org/TCP_connection)- [\n[UDP cork explained](https://groups.google.com/forum/#!topic/comp.os.linux.networking/Uz8PYiTCZSg)]\n\n**Details:**\n\n- Skill level: intermediate (+linux kernel)\n- Language: C\n- Expected size: 350 hours\n- Mentors: Alexander Mikhalitsyn <alexander@mihalicyn.com>, Pavel Tikhomirov <ptikhomirov@virtuozzo.com>, Andrei Vagin <avagin@gmail.com>"
  },
  {
    "name": "FreeCAD",
    "slug": "freecad",
    "tagline": "Cross-platform 3D parametric modeler",
    "description": "FreeCAD is a general-purpose parametric 3D computer-aided design (CAD) modeler and a building information modeling (BIM) software application with finite element method (FEM) support. It is intended for mechanical engineering product design but also expands to a wider range of uses around engineering, such as architecture or electrical engineering. FreeCAD is free and open-source, under the LGPL-2.0-or-later license, and available for Linux, macOS, and Windows operating systems. Users can extend the functionality of the software using the Python programming language.",
    "ideas_url": "https://wiki.freecad.org/Google_Summer_of_Code_2026",
    "website_url": "https://freecad.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "c++",
      "qt",
      "OpenCASCADE",
      "OpenInventor"
    ],
    "topic_tags": [
      "engineering",
      "graphics",
      "cad",
      "3d",
      "architecture",
      "BIM",
      "CAM"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/freecad",
    "ideas_content": "Making sure you're not a bot!\nLoading...\nPlease wait a moment while we ensure the security of your connection.\nSadly, you must enable JavaScript to get past this challenge. This is required because AI companies have changed the social contract around how website hosting works. A no-JS solution is a work-in-progress."
  },
  {
    "name": "St. Jude Children's Research Hospital",
    "slug": "st-jude-childrens-research-hospital-ai",
    "tagline": "Find cures. Saving children.",
    "description": "St. Jude Children's Research Hospital is a non-profit research hospital dedicated to advancing cures and means of prevention for children with catastrophic diseases. With respect to Google Summer of Code, we're interested in building modern, open-source infrastructure upon which large-scale scientific analyses can be done (typically focused on bioinformatics or genomics specifically).",
    "ideas_url": "https://gist.github.com/claymcleod/ee8e62831a4975cba2032d888bb52080",
    "website_url": "https://stjude.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "rust",
      "simd",
      "WDL"
    ],
    "topic_tags": [
      "programming languages",
      "genomics",
      "developer tools",
      "cloud"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/st-jude-childrens-research-hospital-ai",
    "ideas_content": "# St. Jude Children's Research Hospital - Google Summer of Code 2026\n\nWelcome to St. Jude's Google Summer of Code 2026 homepage! With any questions, feel free to reach out to us via email at clay.mcleod@stjude.org and stephanie.sandor@stjude.org. Please include `[GSoC]` in the subject line.\n\nIf you do apply, please be sure to use our [Application template](#application-template)!\n\n## Table of Contents\n\n- [Background](#background)\n- [Projects](#projects)\n  - [Python bindings for Sprocket's WDL tooling](#python-bindings-for-sprockets-wdl-tooling)\n  - [Plugin system for custom execution backends in Sprocket](#plugin-system-for-custom-execution-backends-in-sprocket)\n  - [Type-safe genomic interval library for `omics`](#type-safe-genomic-interval-library-for-omics)\n  - [SIMD-accelerated sequence alignment for `omics`](#simd-accelerated-sequence-alignment-for-omics)\n- [We're open to other, relevant ideas](#were-open-to-other-relevant-ideas)\n- [Application template](#application-template)\n\n## Background\n\nOur projects are centered around changing how genomics analysis is done at scale. In an effort to advance cures for pediatric catastrophic diseases as quickly as possible, St. Jude has been sharing critical research data with the biomedical community for about 8 years now (see the [St. Jude Cloud paper](https://pubmed.ncbi.nlm.nih.gov/33408242/) for more details). This endeavor has led to a great deal of experience in understanding the challenges of sharing this data with the broader academic community. To address those issues, we recently started our own workflow execution engine written in Rust called **Sprocket** aimed at enabling genomic analyses at petabyte-scale. Though we're focused on genomics, we think that Sprocket can be used for nearly all scientific domains.\n\nSprocket is built on top of the open Workflow Description Language ([github.com/openwdl](https://github.com/openwdl)), of which we have multiple people on the governance committee, and alongside the execution engine we're building, there are also many language design problems we're tackling such as building our own lexer, parser, abstract syntax tree, concrete syntax tree, linter, validation tools, language server protocol, VSCode plugin, formatter, and documentation generator. We're also building foundational Rust libraries for genomics through our [`omics`](https://github.com/stjude-rust-labs/omics) project, which provides primitives for coordinates, molecules, and variations.\n\nLast year, our GSoC contributor [Vaibhav Raj](https://github.com/dead8309) made substantial contributions to the Sprocket ecosystem, including 60+ commits implementing the core LSP features (auto-completions, semantic highlighting, go-to-definition, find-references, hover, and rename support), new linting rules, and critical bug fixes.\n\nYou can find out more by navigating to the links below:\n\n- **https://github.com/stjude-rust-labs/sprocket**. The user-facing command line tool that brings all of the functionality together. Check out [sprocket.bio](https://sprocket.bio) for documentation.\n- **https://github.com/stjude-rust-labs/sprocket/tree/main/crates**. The core `wdl-*` crates for the project, located in the Sprocket repository. These crates contain functionality covering the lexing, parsing, abstract syntax tree, concrete syntax tree, linting, validation, language server protocol, formatting, and documentation generation.\n- **https://github.com/stjude-rust-labs/crankshaft**. A headless workflow execution engine. The `crankshaft` crate(s) contain the language-agnostic plumbing code for submitting jobs to backend execution platforms (local, Docker, Cloud, HPC, etc).\n- **https://github.com/stjude-rust-labs/omics**. Foundational Rust libraries for genomics, including primitives for coordinates, molecules, and variations.\n- **https://github.com/openwdl/wdl**. Some projects may require interacting with or making suggestions to the Workflow Description Language. The linked repository here includes the entire specification that you can browse to get a sense of how it works.\n- **https://github.com/stjude-rust-labs**. The organization as a whole. We encourage you to check out the other projects we're working on here—particularly as it relates to other projects you might want to propose.\n\n## Projects\n\n### Python bindings for Sprocket's WDL tooling\n\n**Length:** 175 hours | **Difficulty:** Medium\n\n#### Description\n\nPython is the dominant language in bioinformatics, yet Sprocket's powerful WDL tooling (lexer, parser, linter, validator) is only accessible from Rust. This project creates Python bindings using PyO3 (or comparable), enabling Python developers to programmatically parse, lint, and validate WDL documents. This opens the door to a vibrant ecosystem of Python-based WDL tooling—IDE plugins, CI integrations, and analysis scripts—without reimplementing the core logic we've built up in Sprocket.\n\n#### Outcomes\n\n- A `sprocket-py` package exposing lexing, parsing, and linting APIs *(Project, Python developers)*\n- Published to PyPI for easy installation *(Project, end users)*\n- *(Stretch Goal)* Workflow execution APIs exposed to Python *(Project, stretch goal)*\n- Experience with Rust FFI, PyO3 (or similar), and cross-language API design *(Contributor)*\n\n#### Relevant Skills\n\nFluency in both Rust and Python. Experience with PyO3 or similar FFI tooling preferred but not required.\n\n#### Potential Mentors\n\n[Ari Frantz](https://github.com/a-frantz) w/ support from [Clay McLeod](https://github.com/claymcleod).\n\n#### Proposal Advice\n\nFirst, explore PyO3's (or similar) documentation and build a minimal Rust-to-Python binding. Then examine the `wdl` crate structure to understand which types would be most valuable to expose. Consider: What would a Python user expect from `import sprocket`? Include your findings in your application. Justify why you chose your approach to this problem. What other ancillary deliverables will be needed for community adoption?\n\n---\n\n### Plugin system for custom execution backends in Sprocket\n\n**Length:** 350 hours | **Difficulty:** Hard\n\n#### Description\n\nSprocket currently supports several execution backends (Docker, TES, LSF+Apptainer, Slurm+Apptainer), but organizations often have unique infrastructure requirements—currently unsupported HPC schedulers, cloud platforms, or specialized compute environments. This project researches and implements a plugin architecture that allows users to develop their own execution backends without modifying Sprocket's core. The contributor will study existing solutions (including Nextflow's plugin system), evaluate approaches for plugins in a compiled Rust world (WASM, dynamic libraries, RPC), and design an extensible backend interface.\n\n#### Outcomes\n\n- A plugin interface for execution backends with clear documentation *(Project, plugin authors)*\n- At least one example plugin demonstrating the architecture *(Project, reference implementation)*\n- Plugin loading and configuration mechanism integrated into Sprocket *(Project, end users)*\n- Deep understanding of systems programming, plugin architectures, and Rust *(Contributor)*\n\n#### Relevant Skills\n\nStrong Rust skills required. Experience with systems programming, dynamic loading, or plugin architectures preferred. Willingness to conduct substantial research and propose novel solutions is essential.\n\n#### Potential Mentors\n\n[Clay McLeod](https://github.com/claymcleod)\n\n#### Proposal Advice\n\nStart by examining how Nextflow handles plugins ([Nextflow Plugins documentation](https://www.nextflow.io/docs/latest/plugins/plugins.html)) and what extension points it offers. Then review Crankshaft's existing backend implementations to understand the current architecture. We've been considering several approaches: WebAssembly modules, subprocess-based plugins with JSON-RPC or similar transport, and dynamic shared libraries. Each has distinct tradeoffs around performance, portability, sandboxing, and language flexibility. **Your application should include a clear recommendation for which approach you believe is best and why**. We want to see your reasoning process and technical judgment, not just a summary of options.\n\n---\n\n### Type-safe genomic interval library for `omics`\n\n**Length:** 350 hours | **Difficulty:** Hard\n\n#### Description\n\nGenomic interval operations are fundamental to bioinformatics pipelines, yet a persistent source of bugs is coordinate system mismatches—mixing interbase intervals (BED) with in-base intervals (VCF, GFF). This project builds a genomic interval library within the `omics` ecosystem that makes these bugs structurally impossible by leveraging Rust's type system. Intervals are parameterized by coordinate system at compile time, ensuring operations between incompatible systems won't compile. The library will support core overlap queries, full set algebra (union, intersection, difference, complement, merge), and streaming/iterator-based processing for large datasets.\n\n#### Outcomes\n\n- Type-safe interval types integrated with `omics::coordinate` *(Project, bioinformatics developers)*\n- Efficient overlap queries using proven algorithms ([implicit interval trees](https://pubmed.ncbi.nlm.nih.gov/32966548/), [augmented interval lists](https://pubmed.ncbi.nlm.nih.gov/31150060/)) *(Project, pipeline authors)*\n- Complete set algebra operations matching bedtools functionality *(Project, end users)*\n- Streaming/lazy operations for memory-efficient processing of large datasets *(Project, large-scale analysis)*\n- Deep understanding of genomic data structures and Rust type system *(Contributor)*\n\n#### Relevant Skills\n\nStrong Rust skills required. Familiarity with genomic coordinate systems and interval data structures preferred. Interest in leveraging type systems for correctness.\n\n#### Potential Mentors\n\n[Clay McLeod](https://github.com/claymcleod)\n\n#### Proposal Advice\n\nStart by reading the [omics-coordinate documentation](https://docs.rs/omics-coordinate) to understand the distinction between *interbase* (pointing to spaces between nucleotides) and *in-base* (pointing directly to nucleotides) coordinate systems—and why mixing them causes bugs. Review existing libraries like [rust-lapper](https://github.com/sstadick/rust-lapper), [coitrees](https://github.com/dcjones/coitrees), and [bedrs](https://lib.rs/crates/bedrs) to understand current approaches. Your proposal should explain how you'd leverage Rust's type system to prevent coordinate system mismatches at compile time.\n\n---\n\n### SIMD-accelerated sequence alignment for `omics`\n\n**Length:** 350 hours | **Difficulty:** Hard\n\n#### Description\n\nSequence alignment is fundamental to bioinformatics—comparing DNA, RNA, or protein sequences to find similarities, identify mutations, or infer evolutionary relationships. Modern CPUs offer SIMD (Single Instruction Multiple Data) instructions that can dramatically accelerate the dynamic programming algorithms at the heart of alignment. This project builds a SIMD-accelerated alignment module for the `omics` ecosystem, including developing foundational primitives (protein sequence types, amino acid representations), alignment infrastructure (scoring matrices, gap penalty models, CIGAR result types), and high-performance implementations of global and local alignments.\n\n#### Outcomes\n\n- Protein sequence primitives: amino acid types, protein polymers extending `omics::molecule` *(Project, library foundation)*\n- Alignment infrastructure: scoring matrices, gap penalties, result types *(Project, core types)*\n- SIMD-accelerated Smith-Waterman (local) and Needleman-Wunsch (global) implementations *(Project, core algorithms)*\n- Integration with existing `omics::molecule` DNA/RNA types *(Project, ecosystem cohesion)*\n- Benchmarks demonstrating performance against existing tools *(Project, community)*\n\n#### Relevant Skills\n\nStrong Rust skills required. Familiarity with SIMD intrinsics (AVX2, NEON) or willingness to learn. Understanding of dynamic programming and sequence alignment algorithms preferred.\n\n#### Potential Mentors\n\n[Clay McLeod](https://github.com/claymcleod)\n\n#### Proposal Advice\n\nStart by understanding Smith-Waterman and Needleman-Wunsch algorithms, then explore how SIMD parallelism accelerates them. Review [Block Aligner](https://github.com/Daniel-Liu-c0deb0t/block-aligner) ([paper](https://pubmed.ncbi.nlm.nih.gov/37535681/)) as a reference for SIMD techniques. Examine `omics::molecule` to understand the current sequence representations—note that protein types, scoring infrastructure, and alignment result types will need to be built as part of this project. Your proposal should outline the primitives you'd create, your approach to SIMD acceleration, and how the API would feel to end users.\n\n---\n\n## We're open to other, relevant ideas\n\nWe're also open to other ideas! Feel free to check out the [St. Jude Rust Labs organization](https://github.com/stjude-rust-labs) to see what we're working on. In particular, ideas using the [`omics`](https://github.com/stjude-rust-labs/omics) library and the [`chainfile`](https://github.com/stjude-rust-labs/chainfile) library would be really cool to see. Last, if you do plan to submit your own idea, please discuss them with us briefly during the discussion period before submitting an application—we don't want you to do a lot of work for an idea that's unlikely to be selected!\n\n## Application template\n\nPlease use this application template when submitting your proposal.\n\n**Note:** We do **not** require prior contributions to Sprocket or any St. Jude Rust Labs repository before applying.\n\n1. **Project Title.** Give a single sentence title to your project. You can use the existing project titles above or tweak them based on your own interests/ideas.\n\n2. **Abstract (~4-6 sentences).** Describe the big picture of what you plan to accomplish during this project. You can feel free to reuse ideas or language that we used above—just make sure you give a sense of what you want to accomplish underneath those broad headings.\n\n3. **Project Description.** An unbounded project description. Feel free to talk through the details of how you prepared for submitting this application (did you follow any of our advice for each idea? How did that shape the way you think about the idea, etc) and any more detailed plans for how you plan to go about the project.\n\n4. **Major Contributions.** A list of goals that you hope to accomplish by the end of the program. Use a bulleted list here, and be sure to include both (a) what the outcome is going to be and (b) the target audience of that outcome.\n\n5. **Timeline.** Break down the work to achieve these major contributions into a timeboxed plan as it aligns to the GSoC timeline. We've provided a template here to get started.\n\n| Period | GSoC Phase | What I'll aim to accomplish |\n|--------|------------|----------------------------|\n| May 1 - May 24 | Community Bonding Period | GSoC contributors get to know mentors, read documentation, get up to speed to begin working on their projects |\n| May 25 - May 31 | Coding (Week 1) | |\n| June 1 - June 7 | Coding (Week 2) | |\n| June 8 - June 14 | Coding (Week 3) | |\n| June 15 - June 21 | Coding (Week 4) | |\n| June 22 - June 28 | Coding (Week 5) | |\n| June 29 - July 5 | Coding (Week 6) | |\n| July 6 - July 12 | Coding (Week 7) | *Midterm evaluation is July 6-10* |\n| July 13 - July 19 | Coding (Week 8) | |\n| July 20 - July 26 | Coding (Week 9) | |\n| July 27 - August 2 | Coding (Week 10) | *Your plan should start to include thinking about documenting the final product around this point.* |\n| August 3 - August 9 | Coding (Week 11) | |\n| August 10 - August 16 | Coding (Week 12) | |\n| August 17 - August 24 | Coding (Final week) | *Final submissions due August 17-24* |\n\n6. **Time Period/Working Hours.** Let us know how much time you plan to spend on the project. Be sure to indicate both (a) how many hours you think the project will take (we're not looking for a complicated hourly breakdown—just if it's 175 hours or 350 hours as defined by the GSoC guidelines) and (b) roughly how many hours per week you plan to spend on the project.\n\n7. **Name and GitHub Username.** Please share with us your name and the GitHub username with which you are going to do the work.\n\n8. **Resume.** Please include a recent copy of a resume/CV.\n\n9. **Code Review.** Please provide us with a link to a code sample that you feel particularly proud of and that demonstrates your abilities. This can be a PR that you made to an existing codebase or a brand new project that you created and worked on. The key is that we want the code to be completely yours (or, at least, it needs to be clear which parts you specifically did, like in the case of a PR you created)."
  },
  {
    "name": "Drupal Association",
    "slug": "drupal-association",
    "tagline": "Build Bold Digital Experiences on Best Open Source",
    "description": "Drupal is a powerful Content Management System (CMS) and framework built on PHP, used globally by governments, universities, and businesses to build complex websites and applications, offering unmatched flexibility, security, and scalability through its modular architecture (modules and themes) and community-driven development.",
    "ideas_url": "https://www.drupal.org/project/issues/gsoc?text=2026&status=All&priorities=All&categories=All&version=All&component=All",
    "website_url": "https://drupal.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "mysql",
      "javascript",
      "html",
      "php",
      "symfony"
    ],
    "topic_tags": [
      "web",
      "cloud",
      "DXP",
      "Massive community",
      "Inclusive"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/drupal-association",
    "ideas_content": null
  },
  {
    "name": "checkstyle",
    "slug": "checkstyle",
    "tagline": "Helps to adheres of Java coding standard",
    "description": "Checkstyle is a development tool to help programmers write Java code that is easy to read and adheres to a coding standard. Our utility automates the process of checking Java code to spare humans of this boring (but important) task. This makes it ideal for projects that want to enforce a coding standard. Each and every check also forces our users who are not familiar with these standards to read them and makes them think about why these standards exist.",
    "ideas_url": "https://github.com/checkstyle/checkstyle/wiki/Checkstyle-GSoC-2026-Project-Ideas",
    "website_url": "https://checkstyle.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "java",
      "antlr",
      "artificial-intelligence"
    ],
    "topic_tags": [
      "static code analysis‎",
      "code review tool",
      "coding standards",
      "coding conventions",
      "artificial-intelligence"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/checkstyle",
    "ideas_content": "* [Java 25 Language Feature Support](#project-name-java-25-language-features-support)\n* [Improve Google Style coverage on false negatives](#project-name-improve-google-style-coverage-on-false-negatives)\n* [Enhancement For Website](#project-name-automated-website-generation)\n* [Implementation of auto-fix Recipes](#project-name-implementation-of-auto-fix-recipes)\n\n\n* [AI-Powered XPath Generator for Checkstyle Suppressions](#project-name-ai-powered-xpath-generator-for-checkstyle-suppressions)\n* [Markdown Javadoc Support](#project-name-markdown-javadoc-support)\n* [Optimization of distance between methods in single Java class](#project-name-optimization-of-distance-between-methods-in-single-java-class)\n* [Reconcile formatters of Eclipse , NetBeans and IntelijIdea IDEs by Checkstyle config](#project-name-reconcile-formatters-of-eclipse--netbeans-and-intellij-idea-ides-by-checkstyle-config)\n* [Coverage of Documentation Comments Style Guide and performance improvement](#project-name-coverage-of-documentation-comments-style-guide-and-performance-improvement)\n* [Open JDK Code convention coverage](#project-name-open-jdk-code-convention-coverage)\n* [Spellcheck of Identifiers by English dictionary](#project-name-spellcheck-of-identifiers-by-english-dictionary)\n* [Patch Suppression improvement](#project-name-patch-suppression-improvement)\n* [Extend Checker Framework Integration](#project-name-extend-checker-framework-integration)\n* [Eliminate Maven Plugin Usage](#project-name-eliminate-maven-plugin-usage)\n\n\n***\n\n### Project Name: Implementation of auto-fix Recipes\n\n**Skills required**: intermediate Java \n\n**Project type**: new feature implementation.\n\n**Project goal**: implement new modules, test it on real projects\n\n**Project size**: large (350 hours)\n\n**Complexity Rating**: hard\n\n**Mentors**: Ruslan Diachenko, Timur Tibeyev\n\n**Description**:\nCheckstyle is known as tool that raises numerous minor issues. There are so many of these and they are so minor that it is hard to find time and engineer to fix them. Most of the issues are so easy to fix but navigation to certain part of the code and making the fix takes time. Engineers could spend this time doing something more valuable. Implementation of an auto-fix functionality could significantly simplify introduction of checkstyle to project as it will do most tedious work automatically.\n\nLast year we made decision to use OpenRewrite to implement auto-fix features. Base foundation is done and now [project](https://github.com/checkstyle/checkstyle-openrewrite-recipes) is ready to scale with implementations for each specific Checkstyle's Check. \n\n**Deliverables**:\n- Implementation of 17 auto fix recipes ( we noticed that it takes about 4 days to make single auto fix module) for Checks that are marked as TBD at [page](https://github.com/checkstyle/checkstyle-openrewrite-recipes?tab=readme-ov-file#openrewrite-recipe-coverage-for-checkstyle-checks).\n\n**QnA**: https://discord.com/channels/845645228467159061/1214569225247793282 ([invite](https://discord.gg/F6MkcwvZT8))\n\n\n***\n\n### Project Name: Java 25 Language Features Support\n\n**Skills required**: Java, basic understanding of testing principles, basic understanding of static analysis\n\n**Project goal**: Support static analysis of Java 25 language features\n\n**Project size**: large (350 hours)\n\n**Complexity Rating**: hard\n\n**Mentors**: Roman Ivanov, Andrei Paikin\n\n**Description**:\n\nDevelopers are enthusiastic about leveraging Java's latest language features, which offer more powerful, declarative,\nand expressive code; these features\ninclude [Flexible constructor bodies (JEP 513)](https://openjdk.org/jeps/513), [JEP 512: Compact Source Files and Instance Main Methods](https://openjdk.org/jeps/512). However, Checkstyle currently lacks robust support for these\nfeatures. This project aims to bridge this gap by updating existing checks and potentially introducing new ones to\nensure thorough coverage of Java 25 syntax and conventions proposed by the JEPs associated with these language\nadvancements. The objective is to deliver comprehensive support for the new language features through revising check\nmodules, exhaustive testing, and detailed documentation updates. This effort not only aligns Checkstyle with\ncutting-edge best practices in the Java community but also contributes to the project's ongoing evolution.\nUsers sharing big interest in [module-info.java support](https://github.com/checkstyle/checkstyle/issues/8240) that was introduced long time ago in Java but Checkstyle never had chance to add support of it.\n\n\n**Deliverables**:\n\n- Analysis of new language features and possible Java parser update to support new features \n- Analysis of possible static analysis coverage (new Checks) for new language features\n- Updates in existing Checks to ensure no false positives and negatives for new language features\n- Update build process to support compilation and all Continuous Integration jobs on jdk25\n- Cleanup our parsing [issues](https://github.com/checkstyle/checkstyle/issues?q=is%3Aissue%20state%3Aopen%20label%3Aantlr).\n\n**QnA**: https://discord.com/channels/845645228467159061/1469487812226056354 ([invite](https://discord.gg/ZsJhmBGy8e))\n\n\n***\n\n\n### Project Name: Enhancement For Website\n\n**Skills required**: Java, basic understanding of testing principles, technical writing, continuous integration\n\n**Project goal**: organize documentation and automate its maintenance\n\n**Project size**: medium (175 hours)\n\n**Complexity Rating**: intermediate\n\n**Mentors**: Roman Ivanov, Baratali Izmailov, Mauryan Kansara\n\n**Description**:\n\nDuring GSoC 2025 we automated a lot and now web content is taken from java sources (javadoc of classes, tests). \nThis year project is designed to tackle the persistent challenge of\nmaintaining accurate and current documentation in our dynamic development environment. Acknowledging the limitations of\nmanual documentation processes, this initiative introduces automation to streamline content creation, with a focus on\nensuring consistent formats and robust verification checks. In the previous year we improved experience of contributors\nwho write new Checks/Modules. This year's goal is to provide Checkstyle users with reliable,\nstandardized, and fully updated documentation with Examples on how to use and benefit each settings of Check/Module.\nBy elevating documentation practices, this project aligns with\nindustry best practices, fostering clarity for both users and contributors within the Checkstyle project.\nWe see a rise of Checkstyle usage in the education process, so having all documentation to be up-to-date and all examples \n\n**Deliverables**:\n\n- Add missed examples for all Check/Modules, [issue](https://github.com/checkstyle/checkstyle/issues/17449).\n- Make consistent all examples of Check/Modules, [issue](https://github.com/checkstyle/checkstyle/issues/18435).\n- HTML Enhancements for our website to ease navigation and user experience by [search toolbar](https://github.com/checkstyle/checkstyle/discussions/16214)\n- Fix users' complaints about our web-site, [issues](https://github.com/checkstyle/checkstyle/issues?q=is%3Aissue%20state%3Aopen%20label%3Awebsite).  \n\n**QnA**: https://discord.com/channels/845645228467159061/1214574452021530686 ([invite](https://discord.gg/F6MkcwvZT8))\n\n\n***\n\n## Project Name: Improve Google Style coverage on false negatives\n\n**Skills required**: Java, basic understanding of testing principles, basic understanding of static analysis\n\n**Project goal**: improve quality of google style guide implementation\n\n**Project size**: large (350 hours)\n\n**Complexity Rating**: hard\n\n**Mentors**: Roman Ivanov, Mauryan Kansara\n\n**Description:**\n\nDuring GSoC'25, we successfully updated our implementation of google style guide to the latest version of Apr 25, 2025.\n[google_checks.xml](https://github.com/checkstyle/checkstyle/blob/master/src/main/resources/google_checks.xml) is the configuration file where our google java style guide is implemented.\nThough we have covered almost all rules of the google style guide, users have reported bunch of issues pointing out flaws in our implementation, these issues are labeled as [google style](https://github.com/checkstyle/checkstyle/labels/google%20style) issues, we need to solve them, majority of such issues are \"false-negatives\" (supposed to be violation, but not happening).\nOn top of this, Google Style Guide is [updated in September 2025](https://github.com/google/styleguide/commits/gh-pages/javaguide.html), we need to update our [coverage page](https://checkstyle.org/google_style.html#Coverage_table) to match latest requirements.\n\n**Deliverables:**\n\n- Resolve all issues labeled as [google style](https://github.com/checkstyle/checkstyle/labels/google%20style)\n- Reduce \"Blue Tick\" rules by analyzing the rule and our coverage for that rule and provide solutions for them.\n- Investigate the issues related to Modules/Checks in issue tracker of Checkstyle repository which are used in [google_checks.xml](https://github.com/checkstyle/checkstyle/blob/master/src/main/resources/google_checks.xml),\nif the Module/Check configuration found in the issue is same as present in [google_checks.xml](https://github.com/checkstyle/checkstyle/blob/master/src/main/resources/google_checks.xml) then that issue is qualified for the project,\nit should be reported to us and marked by [google style](https://github.com/checkstyle/checkstyle/labels/google%20style) label.\n\n**QnA**: https://discord.com/channels/845645228467159061/1338510140277522442 ([invite](https://discord.gg/EqbuAmZA3q))\n\n\n\n***\n\n### Project Name: AI-Powered XPath Generator for Checkstyle Suppressions\n\n**Skills required**:\n- Java (advanced)\n- Knowledge of XPath\n- Experience with machine learning frameworks\n- Basic understanding of Abstract Syntax Trees (AST)\n- Familiarity with Docker\n\n**Project goal**:\nDevelop a local LLM-based solution that generates optimal XPath queries to suppress specific Checkstyle violations based on user prompts, violation details, and code context.\n\n**Project size**: large (350 hours)\n\n**Complexity Rating**: hard\n\n**Mentors**: Ruslan Diachenko, Roman Ivanov, Andrei Paikin, Timur Tibeyev\n\n**Description**:\nCreating XPath expressions to suppress Checkstyle violations is a complex task requiring deep understanding of both XPath syntax and AST structure. This leads to either overly broad suppressions hiding important issues or overly specific rules needing frequent updates. This project aims to create an AI-powered system to convert Checkstyle violations and user instructions into precise XPath expressions for violation suppression. The core focus is on developing a containerized LLM-based solution that can understand both the violation context and user intent to generate accurate XPath queries.\n\nA preliminary [proof of concept (PoC)](https://github.com/rdiachenko/checkstyle-xpath-llm-poc) demonstrates the basic feasibility of using LLMs for XPath generation. While this PoC serves as an experimental starting point, the GSoC project will require a complete redesign and implementation to create a production-ready solution.\n\n**Deliverables**:\n- Containerized LLM-based solution for XPath generation\n- Command-line interface for basic interaction\n- Basic documentation for setup and usage\n- Fix for all issues with \"xpath\" label in the Checkstyle repository\n\n\n**QnA**: https://discord.com/channels/845645228467159061/1338507765207007242 ([invite](https://discord.gg/FWBzr9kZZE))\n\n\n\n***\n\n### Project Name: Markdown Javadoc Support\n\n**Skills required:** Java, basic understanding of testing principles, basic understanding of static analysis\n\n**Project type:** new feature implementation.\n\n**Project goal:** Integrate support for Markdown Javadoc comments in Checkstyle.\n\n**Project size:** large (350 hours)\n\n**Complexity Rating:** hard\n\n**Mentors**: Roman Ivanov\n\n**Description:**\n\n With the introduction of [JEP 467](https://openjdk.org/jeps/467), Java supports Markdown-style documentation comments. \n This feature modernise Java's documentation capabilities but is not currently supported in Checkstyle.\n The current Javadoc parsing in Checkstyle is tightly coupled to the traditional `/** ... */` syntax and HTML-based formatting,\n presenting challenges in extending support for Markdown's structure. \n This project aims to enhance Checkstyle by introducing new grammar and update exisiting checks to support Markdown Javadoc comments.\n \n**Deliverables**\n\n- New implementation of grammar for Markdown Javadoc Comments\n- New tokens to identify and validate elements specific to Markdown Javadoc syntax.\n- New Checkstyle Checks for new format of javadoc, ideas on what should be validated should be taken from existing Checks.\n- Creation of new checks (if necessary): Create new checks to enforce Markdown-specific best practices.\n\n**QnA**: https://discord.com/channels/845645228467159061/1338509670255562772 ([invite](https://discord.gg/8Pwv8RPKqs))\n\n\n\n***\n\n### Project Name: Optimization of distance between methods in single Java class\n\n**Skills required**: basic Java , good analytical abilities, good background in mathematics.\n\n**Project type**: new feature implementation.\n\n**Project goal**: to make quality practices automated and publicly available.\n\n**Project size**: large (350 hours)\n\n**Complexity Rating**: hard\n\n**Mentors**: Roman Ivanov, Baratali Izmailov, Ruslan Diachenko\n\n**Description**:\n\nThis task is ambitious attempt to improve code read-ability by minimizing user jump/scrolls in source file to look at details of method implementation when user looks at method first usage.\n\nIt is required to analyse a lot of code and find a model to minimize distance between methods first usage and method declaration in the same file and respect users preferences to keep grouped overloaded and overridden methods together. Some other preferences may appear during investigation of open-source projects.\n\nFirst step is already done by our team, we created a web service that already calculate distances between methods and make [DSM](https://en.wikipedia.org/wiki/Design_structure_matrix) matrix to ease analysis - [methods-distance](https://github.com/sevntu-checkstyle/methods-distance). We already practice it in our project.\n\nAs a second step it is required to use a matrix of distances between methods and optimize it by some empiric algorithm to allow user define expected model of class by arguments. This will allow to use this algorithm as a Check to enforce code structure automatically during build time.\n\n**Prove of necessity**: we have a number of PRs where contributors put new methods at any possible place in a class but better place is close to first usage. [Example #1](https://github.com/checkstyle/checkstyle/pull/2845#issuecomment-176775813), [Example #2](https://github.com/checkstyle/checkstyle/pull/1518#issuecomment-137070056), [Example #3](https://github.com/checkstyle/checkstyle/pull/1228#issuecomment-113699926), ....\n\n**Deliverables**:\n- new Checkstyle's Check with optimization algorithm to share the algorithm with whole java community.\n- analytical report that proves reason why default values for Check parameters are selected  \n- article with all details of analysis and algorithm details;\n\n**QnA**: https://discord.com/channels/845645228467159061/1214569693336182864 ([invite](https://discord.gg/F6MkcwvZT8))\n\n***\n\n\n### Project Name: Reconcile formatters of Eclipse , NetBeans and IntelliJ IDEA IDEs by Checkstyle config.\n\n**Skills required**: basic Java.\n\n**Project type**: new feature implementation, analysis of existing IDE features.\n\n**Project goal**: to make well-known quality practices publicly available.\n\n**Project size**: large (350 hours)\n\n**Complexity Rating**: hard\n\n**Mentors**: Roman Ivanov, Andrei Paikin, Mauryan Kansara\n\n**Description**:\n\nUsage of different IDEs in the same team is already a serious problem, as different IDEs format code base on their own rules and configurations. Unwanted formatting changes happen to code which complicate code-review process. Problem become more acute when project use static analysis tool like Checkstyle that has a wide range of code formatting Checks.\n \nIt is required to make it possible to use the same Checkstyle config to work in IDEs without conflicts with IDEs internal formatters.\nThis will help team members be independent on IDE choice but at the same time keep the same format and code style throughout the team.\n\nMain focus of this project is the analysis of formatting abilities of IDEs (indentation, imports order, declaration order, separator/operator wrap, .....) . Update existing Checkstyle Rules to be able to work in the similar and non-conflicting way.\n\n**Deliverables**:\n- create configuration for IDEs for Checkstyle project to let Checkstyle team use it and auto-format code to conform with checkstyle_check.xml file that is used by Continuous Integration.\n- create Checkstyle config that follows default Eclipse formatting + inspection rules\n- create Checkstyle config that follows default IntelliJ IDEA formatting + inspection rules\n- create Checkstyle config that follows default NetBeans formatting + inspection rules\n- Deep refactoring of Indentation Check to fix its numerous problems. \n\n\n**Prove of necessity**: [mail-list post #1](https://groups.google.com/forum/#!searchin/sevntu-checkstyle/formatter/sevntu-checkstyle/tl7ZKsk-Lss/UK0IAvb-j7oJ), [mail-list post #2](http://checkstyle.2069334.n4.nabble.com/CheckStyle-to-Eclipse-formatter-td2070054.html), [mail-list post #3](https://groups.google.com/forum/#!searchin/checkstyle/Idea/checkstyle/7zJ4drblSd8/fu1kyJHMGpAJ) , [discussion #1](https://github.com/google/styleguide/issues/27#issuecomment-104002872) \n\n**QnA**: https://discord.com/channels/845645228467159061/1214571037451100180 ([invite](https://discord.gg/F6MkcwvZT8))\n\n***\n\n\n### Project Name: Open JDK Code convention coverage\n\n**Skills required**: basic Java.\n\n**Project type**: new feature implementation.\n\n**Project goal**: to make well-known quality practices publicly available.\n\n**Project size**: large (350 hours)\n\n**Complexity Rating**: hard\n\n**Mentors**: Roman Ivanov, Baratali Izmailov, Daniel Mühlbachler, Mauryan Kansara\n\n**Description**:\n\n[OpenJdk Code Convention](https://www.oracle.com/java/technologies/javase/codeconventions-contents.html) was one of the first guidelines on how to write Java code. OpenJdk Code Convention is marked as outdated (because of date of last update made in it) but best practices described there do not have an expiration date. [New OpenJDK Java Style Guidelines](http://cr.openjdk.java.net/~alundblad/styleguide/) is close to the final version and most likely will be successor of OpenJdk Code Convention. But there is a number of projects in Apache that still follow OpenJdk rules, so both configurations are in need by community.\n\nOpenJdk Code Convention is already partly covered by Checkstyle, known as Sun Code Convention. A lot of validation Rules were added and changed in Checkstyle from the time when Sun's configuration was created ([2004 year](https://github.com/checkstyle/checkstyle/commits/18f6ebbcad23e88e3ae30fc79be464b8b7772a0d/sun_checks.xml)). \n\nDuring the project it is required to review both documents in detail and prove publicly that Checkstyle covers all guideline rules. Missed functionality needs to be created, blocking bugs need to be fixed. Page [OpenJdk Java Style Checkstyle Coverage](http://checkstyle.sourceforge.net/sun_style.html) needs to be updated. New page \"New OpenJDK's Java Style Checkstyle Coverage\" need to be created. Both pages need to be formatted in the same way as it is done for [Google's Java Style Checkstyle Coverage](http://checkstyle.sourceforge.net/reports/google-style/guava/).\n\n\n**Prove of necessity**: [javadoc issues on github](https://github.com/checkstyle/checkstyle/issues?labels=javadoc&page=1&state=open);  [request from users for Openjdk coverage support](https://github.com/checkstyle/checkstyle/issues/6490).\nBig projects (Apache Spark) use this style guide , search for \"Code style guide\" in https://spark.apache.org/contributing.html\n\n**Deliverables**:\n- embedded config file with all modules that are required for coverage\n- html page that explains how each paragraph in style guide is covered by Checkstyle \n\n**QnA**: https://discord.com/channels/845645228467159061/1214571550783840307 ([invite](https://discord.gg/F6MkcwvZT8))\n\n***\n\n### Project Name: Coverage of Documentation Comments Style Guide and performance improvement\n\n**Skills required**: basic Java.\n\n**Project type**: new feature implementation.\n\n**Project goal**: to make well-known quality practices publicly available.\n\n**Project size**: large (350 hours)\n\n**Complexity Rating**: hard\n\n**Mentors**: Roman Ivanov, Baratali Izmailov, Mauryan Kansara\n\n**Description**:\n\nProject will mainly be focusing on automation of [Documentation Comments (javadoc) guidelines](http://www.oracle.com/technetwork/articles/java/index-137868.html) by Checkstyle Checks. Reliable comments parsing  was a major improvement in Checkstyle during GSoC 2014, archived results need to be reused to reliably implement automation of Javadoc best practices.\n\nSeparate configuration file with newly created Checks need to be created. Best practices in documentation make sense not for all projects. Javadoc validation matters only for library projects that need to expose online documentation in web publicly.\n\nPerformance improvement of existing javadoc parser are expected, see details at https://github.com/checkstyle/checkstyle/issues/11193 .\n\n**Deliverables**:\nThe result of this project will be a configuration file with the maximum possible coverage of Comment style guide. Report should look like [Google's Java Style Checkstyle Coverage](http://checkstyle.sourceforge.net/google_style.html).\nPerformance improvements of javadoc parsing.\nIf there will be time left we can focus on coverage of guidelines from https://blog.joda.org/2012/11/javadoc-coding-standards.html\n\n**Prove of necessity**: [javadoc issues on github](https://github.com/checkstyle/checkstyle/issues?labels=javadoc&page=1&state=open).\n\n**QnA**: https://discord.com/channels/845645228467159061/1214571282776064130 ([invite](https://discord.gg/F6MkcwvZT8))\n\n***\n\n### Project Name: Spellcheck of Identifiers by English dictionary \n\n**Skills required**: intermediate Java.\n\n**Project type**: new feature implementation.\n\n**Project goal**: implement spell checking for java code for all identifiers .\n\n**Project size**: large (350 hours)\n\n**Complexity Rating**: hard\n\n**Mentors**: Roman Ivanov, Andrei Paikin\n\n**Description**:\n\nThe correct spelling of words in code is very important, since a typo in the name of method that is part of API could result in serious problem.\nMistakes in names also make reading of code frustrating and misleading, especially when a typo in one letter makes developer to read javadoc or even implementation of the method.\nTwo most popular IDEs (Eclipse and IntelliJ IDEA) already have spell-check ability. It will be beneficial for Checkstyle to have the same functionality that could be used in any Continuous Integration system by Command Line Interface or as part of build tool (maven, ant, gradle, ....) with wide range of options to customize to users needs.\nFeatures of existing spell-checkers need to be analyzed -  \n[IntelliJ IDEA Spellchecking](https://www.jetbrains.com/help/idea/using-code-editor.html#spellchecking) , \n[Eclipse Spelling](http://help.eclipse.org/mars/index.jsp?topic=%2Forg.eclipse.platform.doc.user%2Freference%2Fref-36.htm). \nThere are numbers of open-source projects that do spell-check. It is ok to reuse them if license is compatible. Examples: https://code.google.com/archive/p/bspell/ , http://www.softcorporation.com/products/spellcheck/, ...\nhttps://github.com/giraciopide/shellcheck-maven-plugin, https://github.com/codespell-project/codespell\n\n**Deliverables**:\n- regular Checkstyle module that does validation\n- such module should be applied to all sources of our Code\n- disablement of shell based implemnetation of spellcheck in our project for java sources.\n- documentation on how to use module\n\n**QnA**: https://discord.com/channels/845645228467159061/1214572273038786631 ([invite](https://discord.gg/F6MkcwvZT8))\n\n\n***\n\n### Project Name: Eliminate Maven Plugin Usage\n\n**Skills required**: Java, Groovy, Maven\n\n**Project goal**: remove all usages of maven-checkstyle-plugin in our tools\n\n**Project size**: medium (175 hours)\n\n**Complexity Rating**: intermediate\n\n**Mentors**: Roman Ivanov, Daniel Mühlbachler,\n\n**Description**:\n\nCheckstyle serves as a widely used library across various tools, with a notable dependency on\nthe [maven-checkstyle-plugin](https://maven.apache.org/plugins/maven-checkstyle-plugin/) for continuous integration and\nregression testing. However, this reliance on an external tool has restricted our ability to introduce breaking changes\nto the Checkstyle project, given the potential disruptions it causes in testing. Consequently, we've had to implement\nworkarounds to maintain the connection and dependence on the maven-checkstyle-plugin. To foster autonomy and minimize\ndependencies, Checkstyle is undertaking efforts to break away from this plugin and shift towards relying solely on tools\nunder our maintenance. The list of connected issues below outlines specific areas that require modification to\nfacilitate this transition.\n\n**Deliverables**:\n\n - Remove all usages of maven-checkstyle-plugin in our tools\n - Update documentation to reflect changes\n - Update build, CI, and regression testing to use internal tools exclusively\n\n**Connected Issues**:\n - [Launch/Diff Groovy should remove use of maven-checkstyle-plugin](https://github.com/checkstyle/contribution/issues/273)\n - [Convert sevntu-checkstyle-check to ant run](https://github.com/checkstyle/checkstyle/issues/5385)\n - [Convert regressions that use maven-checkstyle-plugin to CLI based](https://github.com/checkstyle/checkstyle/issues/11602)\n\n**Example of Plugin Issue**: [Upgrade XML logger to XML 1.1](https://github.com/checkstyle/checkstyle/issues/5168)\n\n**QnA**: https://discord.com/channels/845645228467159061/1214574180591214592 ([invite](https://discord.gg/F6MkcwvZT8))\n\n\n***\n\n### Project Name: Patch Suppression improvement\n\n**Skills required**: basic Java \n\n**Project type**: extension of existing feature implementation.\n\n**Project goal**: implement new strategies for existing filter/suppression module or improve existing \n\n**Project size**: large (350 hours)\n\n**Complexity Rating**: hard\n\n**Mentors**: Roman Ivanov, Ruslan Diachenko\n\n**Description**:\nIntroducing Checkstyle to a project can be a challenging and NOT an easy job, especially when a project has massive amount of code, very active in development, and there are no resources to start a new process of code cleanup. It may require an extensive effort, especially when there is legacy code from previous contributors that becomes a monotonous job, that everyone tries to avoid. It is easy to say how code should look like, but may be hard to actually enforce rules in existing codebase.\n\nFor example [Guava is not following google style](https://github.com/google/guava/issues/1891), and it is easy to say how code should look like but hard to assign somebody to fix ALL problems from previous contributors. It is very boring activity that all will try to avoid. [Good practice from openjdk](http://cr.openjdk.java.net/~alundblad/styleguide/index-v6.html#toc-when-to-reformat-code) actually discourage code changes without good reason. \n\nBetter approach is to let existing code be as is and validate only new code. Checkstyle already has a wide array of filter functionality that could suppress certain violations if user classify a violation as “won’t fix”. Just getting started with setting up the initial suppressions still requires a huge effort to review all the violations, or organize a team on special cleanup process.\n\nThis project was originally done at [GSOC 2020](https://github.com/checkstyle/checkstyle/wiki/Checkstyle-GSoC-2020-Project-Ideas#project-name-patch-suppression), but during usage of this [project](https://github.com/checkstyle/patch-filters) we found problems that \ncheckstyle violations are still going beyond changed code that creates avalanche of change so it complicate usage of it in real project. \n\nWe need to invest focus on parsing of patch files to get more precise location of changes and be able skip violation if fix for it goes outside of changed lines. For example: user changing line wrapping of long signature of method and we should not demand decreasing of amount of parameters or fixing names, as this will trigger changes in other part of code.\n\nAs proof of success for this project, it is required to get some open source project onboard to use checkstyle and this new feature. It would be good to try collaborate one more time with Guava project or we can ask our friends in Eclipse-CS or Spring or Hbase project.\n\n**Deliverables**:\n- new Filter in Chekstyle that is applied to our code base.\n- documentation on how to use new filter.\n- apply filer to eclpse-cs project to work on each update (address feedback from usage). \n\n**QnA**: https://discord.com/channels/845645228467159061/1214572538043043890 ([invite](https://discord.gg/F6MkcwvZT8))\n\n***\n\n### Project Name: Extend Checker Framework Integration\n\n**Skills required**: Java, basic understanding of testing principles, basic understanding of Java type system\n\n**Project goal**: Further usage of Checker Framework and increase internal knowledge base\n\n**Project size**: large (350 hours)\n\n**Complexity Rating**: hard\n\n**Mentors**: Roman Ivanov\n\n**Description**:\n\nThe goal of this project is to advance the integration of the [Checker Framework](https://checkerframework.org/) into our existing codebase, enhancing\ncode quality, correctness, and maintainability. In addition to refining the setup already present in our build, the\nproject will focus on incorporating the Checker Framework's type system into key components of our code and creating\ncomprehensive documentation and best practices to guide developers in utilizing the framework effectively.\nWe identified https://github.com/checkstyle/checkstyle/issues/18482 as additional challenge to address only concerns\nthat practical.\n\n**Deliverables**:\n\n- Integrate Checker type system with codebase\n- Refine existing build\n- Develop internal documentation about our usage of Checker\n- Provides examples, guidelines and best practices for developers to follow\n\n**QnA**: https://discord.com/channels/845645228467159061/1214572824736571472 ([invite](https://discord.gg/F6MkcwvZT8))"
  },
  {
    "name": "cBioPortal for Cancer Genomics",
    "slug": "cbioportal-for-cancer-genomics",
    "tagline": "Aid discovery in complex cancer genomics data",
    "description": "The cBioPortal for Cancer Genomics is a resource designed to provide broad community access to cancer genomic data. It provides a unique user­-friendly and \"biology­-centric computational user interface\", with the goal of making genomic data more easily accessible to translational scientists, biologists, and clinicians. The interface was explicitly built and continues to evolve with careful usability studies involving multiple biological and clinical users, and an active and engaged user base.\n\nThe public instance of cBioPortal (https://cbioportal.org/) is one of the most popular online resources for cancer genomics data and attracts more than 3,000 unique visitors (cancer researchers and clinicians) per day. The three papers documenting the cBioPortal: Cerami et al. Cancer Discov. 2012; Gao et al. Sci. Signal. 2013; and de Bruijn et al. Cancer Res. 2023; have been cited more than 16,000, 17,000, and 800 times, respectively. There are more than 100 actively used cBioPortal instances in hospitals, universities, pharmaceutical companies, and other institutes around the globe.\n\nWe are a group of software engineers, bioinformaticians, and cancer biologists building software solutions for precision medicine for cancer patients. Our overall goal is to build infrastructure to support clinical decisions for personalized cancer treatment by utilizing “big data” of cancer genomics and patient clinical profiles. Our multi-institutional team currently has more than 30 active members, primarily from Memorial Sloan Kettering Cancer Center,  the Dana-Farber Cancer Institute, Princess Margaret Cancer Centre, Children's Hospital of Philadelphia, and The Hyve, a bioinformatics company from the Netherlands.",
    "ideas_url": "https://github.com/cBioPortal/GSoC/issues?q=is%3Aissue%20state%3Aopen%20label%3AGSoC-2026",
    "website_url": "https://www.cbioportal.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "mysql",
      "javascript",
      "java",
      "react",
      "typescript"
    ],
    "topic_tags": [
      "genomics",
      "cancer",
      "bioinformatics",
      "big data",
      "precision medicine"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/cbioportal-for-cancer-genomics",
    "ideas_content": "# Issues\n\n## Search results\n\n- Status: Open.#140 In cBioPortal/GSoC;\n- Status: Open.#138 In cBioPortal/GSoC;\n- Status: Open.#137 In cBioPortal/GSoC;\n- Status: Open.#134 In cBioPortal/GSoC;\n- Status: Open.#132 In cBioPortal/GSoC;\n- Status: Open.#131 In cBioPortal/GSoC;\n- Status: Open.#126 In cBioPortal/GSoC;"
  },
  {
    "name": "National Resource for Network Biology (NRNB)",
    "slug": "national-resource-for-network-biology-nrnb",
    "tagline": "Developing open source tools for network biology",
    "description": "The National Resource for Network Biology (NRNB, https://nrnb.org) organizes the development of free, open-source software technologies to enable network-based visualization, analysis, and biomedical discovery. Biomedical research is increasingly dependent on knowledge expressed in terms of networks, including gene, protein and drug interactions, cell-cell and viral-host communication, and vast social networks. Our technologies enable researchers to assemble and analyze these networks and to use them to better understand biological systems and, in particular, how they fail in disease. \nThe NRNB mentoring organization includes projects such as Cytoscape (https://cytoscape.org/), WikiPathways (https://wikipathways.org/), SBML (https://sbml.org/), SBGN (https://sbgn.github.io/) and others. This is a great opportunity to work at the intersection of biology and computing! For example, Cytoscape is downloaded over 24,000 times per month by researchers. We take mentoring seriously and are proud of our 96% success rate (https://nrnb.org/alumni.html#gsoc-tab) with former students and projects. But don’t take our word for it, read testimonials from prior NRNB students (https://nrnb.org/testimonials.html#student-tab) and mentors (https://nrnb.org/testimonials.html#mentor-tab). \nFind out more about the software projects being developed in coordination with NRNB at our website (https://nrnb.org). Also refer to our GSoC page (https://nrnb.org/gsoc.html) for additional resources and application tips.",
    "ideas_url": "https://github.com/nrnb/GoogleSummerOfCode/issues",
    "website_url": "https://nrnb.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "html",
      "css",
      "LLM"
    ],
    "topic_tags": [
      "machine learning",
      "web application",
      "data science",
      "scientific computing",
      "network biology"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/national-resource-for-network-biology-nrnb",
    "ideas_content": "We read every piece of feedback, and take your input very seriously.\n\nTo see all available qualifiers, see our documentation."
  },
  {
    "name": "API Dash",
    "slug": "api-dash",
    "tagline": "Next-gen Open Source API DevTool powered by AI",
    "description": "API Dash is a beautiful open-source cross-platform (macOS, Windows, Linux, Android & iOS) API Client built using Flutter & powered by AI which can help you easily create & customize your HTTP, GraphQL, SSE & AI API requests, visually inspect responses and generate API integration code.",
    "ideas_url": "https://github.com/foss42/apidash/discussions/1054",
    "website_url": "https://apidash.dev",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "react",
      "flutter",
      "typescript",
      "ai"
    ],
    "topic_tags": [
      "testing",
      "api",
      "developer tools",
      "ai",
      "Agents"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/api-dash",
    "ideas_content": "# GSoC 2026: List of Ideas #1054\n\n[animator](https://github.com/animator)started this conversation in\n\n[Ideas & Features](https://github.com/foss42/apidash/discussions/categories/ideas-features)\n\n-\n\n## GSoC 2026 [\n|\n\n| Link | |\n|---|---|\n| Learn about GSoC |\n|\n\n[Link](https://github.com/foss42/apidash/discussions/1048)[Link](https://luma.com/embed/calendar/cal-ZTW02O2EsWRs6V4/events)[Link](https://discord.com/invite/bBeSdtJ6Ue)#### Resources you must go-through to better understand the project\n\n| Link | |\n|---|---|\n| API Dash Contribution Guidelines |\n|\n\n[Video](https://www.youtube.com/live/rIlwCTKNz-A?si=iMxTxzkpY_ySo4Ow&t=339)[Read](https://github.com/foss42/apidash/blob/main/doc/dev_guide/README.md)[Read](https://github.com/foss42/apidash/tree/main/doc/user_guide)[Video](https://www.youtube.com/watch?v=8K2gV1P6ZHI)This season some of our core objectives are:\n\n- To help test MCP tools/endpoints that have become the defacto interface or APIs for AI communication.\n- To push the boundaries of Multimodal AI API evaluations.\n- To improve the agentic AI features of API Dash to improve API development, testing, visualization, integration & observability.\n- To develop community requested core features.\n\n### AI Usage Policy\n\nYou must read and agree to the [AI Usage Policy](https://github.com/foss42/apidash/discussions/1055). As it is a discussion thread, contributors can feel free to discuss and ask their doubts in the same.\n\n### Mentors for GSoC 2026\n\n[Ashita Prasad](https://github.com/ashitaprasad)(Org Admin)[Ankit Mahato](https://github.com/animator)(Org Admin, GSoC 2013)[Ragul Raj M](https://github.com/DenserMeerkat)([GSoC 2024](https://github.com/foss42/apidash/blob/main/doc/gsoc/2024/ragul_raj_m.md))[Manas Hejmadi](https://github.com/synapsecode)([GSoC 2025](https://github.com/foss42/apidash/blob/main/doc/gsoc/2025/manas_hejmadi.md))\n\n### Tech Stack for Projects\n\nThis year, we're offering projects across multiple tech stacks (React/Node/TypeScript, Flutter/Dart, Python), enabling contributors to participate without having to switch from the technologies they're already comfortable with.\n\n### Final words\n\nThe list of ideas provided below are not restrictive. In case you have any other innovative idea in mind which can help fellow developers in tackling the various problems of the API Lifecycle, please feel free to [open a new issue for discussion](https://github.com/foss42/apidash/issues/new/choose) and comment it below.\n\nIf a project is successfully selected you will be allocated a primary mentor and supported by the entire team. If you are interested in learning more about a particular idea please communicate in the corresponding \"related issue\" thread or feel free to drop by our [Discord server](https://discord.com/invite/bBeSdtJ6Ue) and we can have a chat.\n\n*In case you are working on an AI project which requires GPU, we will provide access to cloud GPUs.*\n\n**Once you shortlist an idea, the next steps are outlined in Application Guide**\n\n## List of Ideas\n\n### 1. MCP Testing\n\nThe [Model Context Protocol (MCP)](https://modelcontextprotocol.io) acts as the API layer of the AI world, defining a standard way for AI agents to discover, understand, and interact with tools, data, and software systems—much like REST or GraphQL do for traditional applications.\n\nIn this project, your task is to strengthen the MCP Developer ecosystem by designing and building the capability to create & test MCP servers and clients.\n\n**Skills**: AI, Python, React, Node, TypeScript\n\n**Difficulty**: Medium-High\n\n**Length**: 175 hours\n\n### 2. Multimodal AI and Agent API Eval Framework\n\nDevelop an end-to-end AI and Agent API eval framework which should (list is suggestive, not exhaustive):\n\n- Provide an intuitive interface to run AI benchmarks on tools (like lm-harness, lighteval).\n- Provide a UI interface for configuring AI API requests, where users can input test/custom datasets, configure request parameters, send queries to various AI API services and view the eval results.\n- Support evaluation of voice, image, text AI Models and AI Agents (via API interface) across various task benchmarks.\n\n**Skills**: AI, Agents, Evaluations, Python, React, Node, TypeScript\n\n**Difficulty**: Medium-High\n\n**Length**: 350 hours\n\n### 3. Git Support, UI Workflow Builder & Collection Dashboard\n\nThe objective of this project is to design and implement the following features in API Dash:\n\n**Git Integration**- To support version control for API requests, environments, and workflows using familiar Git-based workflows. It will also help users share collections via git and collaborate on them.**Visual Workflow Builder**- Use Agentic AI to enable users to create node based API workflows directly from a prompt. The UI should also allow users to manually compose, export, connect, and manage multi-step API workflows (chained requests) through an intuitive UI, without relying solely on AI.**Collection Dashboard**- Build a dashboard to provide a unified view of requests, collections, workflows, test coverage, execution history, and health metrics. Also, add the ability to send automated reports via Webhooks.\n\n**Skills**: Git, UI/UX Design, AI, Agents, Node Flows, Dart, Flutter\n\n**Difficulty**: Medium-Hard\n\n**Length**: 175 hours\n\n### 4. Agentic API Testing\n\nAgentic AI transforms API and API-workflow testing from script-driven validation into an intelligent, autonomous quality layer. AI agents can understand the API specifications, contracts, workflows, and then automatically design comprehensive test strategies covering functional correctness, edge cases, error handling, security, and performance. These agents can execute multi-step API workflows end-to-end, maintain context across calls, manage dynamic data and state, and adapt test paths based on intermediate responses. If APIs change, agents can self-heal tests by updating schemas, parameters, and assertions without manual intervention.\n\nYour task is to design, build, and refine the agentic AI library in API Dash and build AI agents that can understand API specs and workflows, generate and execute end-to-end tests, validate outcomes, and continuously improve test coverage and resilience as APIs evolve.\n\n**Skills**: AI, Agent, API Testing, Dart, Flutter\n\n**Difficulty**: Medium-Hard\n\n**Length**: 175 hours\n\n### 5. Open Responses & Generative UI\n\n[Open Responses](https://www.openresponses.org) is an open-source specification and ecosystem for building interoperable, multi-provider LLM interfaces inspired by the OpenAI Responses API. It defines a common, vendor-neutral way to describe AI requests and structured response outputs, enabling portability and consistency across AI platforms. Complementing this, Google's [A2UI](https://github.com/google/A2UI) introduces clear guidelines for building Generative UIs, with first-class support available through Flutter's [GenUI SDK](https://github.com/flutter/genui).\n\nYour task is to understand these specifications and build rich API response UI visualization in API Dash to enable end users to integrate the same in their Flutter Apps and Web Apps.\n\n**Skills**: UX, AI, Parsing, JSON, Spec, Dart, Flutter, React, TypeScript\n\n**Difficulty**: Easy-Medium\n\n**Length**: 90 hours\n\n### 6. CLI & MCP Support\n\nThis project focuses on creating a CLI tool to run API Dash via terminal. Contributors will design and implement command-line interfaces that expose core capabilities of API Dash that help in API testing. Also, your task is to expose API Dash as a MCP Server so that it can be run via any Agent interface (like VS Code, AI Apps, etc.) that supports MCP.\n\n**Skills**: CLI, MCP, Dart, Flutter\n\n**Difficulty**: Easy-Medium\n\n**Length**: 90 hours\n\n### 7. WebSocket, MQTT & gRPC\n\nTesting WebSocket and MQTT (Message Queuing Telemetry Transport) protocols is crucial for ensuring the reliability, scalability, and security of real-time communication systems. Whereas, gRPC (Remote Procedure Call) facilitates efficient communication between distributed systems using Protocol Buffers (protobuf) as its interface definition language (IDL) and offers features such as bi-directional streaming, authentication, and built-in support for load balancing and health checking. Each of these API protocols/styles serves different purposes and is utilized in various applications ranging from finance to web applications to IoT (Internet of Things) devices. The objective of this project is to design the architecture of the core library, understand the specs & implement the support for testing, visualization & integration code generation of these APIs in API Dash.\n\n**Skills**: Understanding Specs/Protocols, UX Design, Dart, Flutter\n\n**Difficulty**: Medium-High\n\n**Length**: 175 hours\n\n### 8. API Explorer\n\nThis project is designed to enhance the API user experience by providing a curated library of popular and publicly available APIs. This feature allows users to discover, browse, search, and directly import API endpoints into their API Dash workspace for seamless testing and exploration. Developers can access pre-configured API request templates, complete with authentication details, sample payloads, and expected responses. This eliminates the need to manually set up API requests, reducing onboarding time and improving efficiency. APIs spanning various domains—such as AI, finance, weather, and social media—are organized into categories, making it easy for users to find relevant services.\n\nYou are required to develop the entire process backend in the form of an automation pipeline which parses OpenAPI/HTML files, auto-tag it to relevant category, enrich the data, create templates. You can also add features such as user ratings, reviews, and community contributions (via GitHub) to ensure accurate and up-to-date resources.\n\n**Skills**: UX Design, OpenAPI, Automation, Python, React, Nodejs, TypeScript\n\n**Difficulty**: Easy\n\n**Length**: 90 hours\n\nRelated Issue(s) - [#619](https://github.com/foss42/apidash/issues/619)\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n## Replies: 3 comments 3 replies\n\n-\n\n|\nGreat, Very Excited to contribute. |\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n-\n\n|\nHi everyone! 👋 I've been looking through the GSoC 2026 ideas and I'm really interested in Idea To help me draft a solid technical architecture for my proposal, I just wanted to clarify how this specific framework will fit into the broader API Dash ecosystem. I'm completely comfortable handling the integration with the Dart client if that's the long-term goal. I just want to make sure I align my 350-hour timeline with the right architectural vision! |\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n-\n\n|\nHey everyone I’m very excited to contribute this year, especially to API Explorer and Idea The CLI & MCP Support project really interests me because it focuses on: Building a CLI tool to run API Dash from the terminal Exposing API Dash as an MCP Server, so it can be used with agent-based tools like VS Code and other AI apps I have worked on projects with a similar idea, for example: I also wanted to ask: I’m excited to learn more, contribute consistently, and start working on a PoC with the right guidance. Thanks! |\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)"
  },
  {
    "name": "United Nations Office of Information Communication Technology",
    "slug": "united-nations-office-of-information-communication-technology",
    "tagline": "Sustainable future through innovative technology.",
    "description": "The Open Source Team at the United Nations, based within the UN Office of Information and Communications Technology (UNOICT), supports the development and adoption of open source technologies across the UN system and in collaboration with external partners. The team works to advance digital public goods that address global challenges such as climate resilience, sustainable food systems, and inclusive digital participation.\nThrough initiatives including “Reboot the Earth” and other open source collaborations, our team enables early-stage ideas to mature into scalable, production-ready solutions. Our work emphasizes open collaboration, responsible use of emerging technologies such as AI, focusing on deployment in real-world, resource-constrained environments. The Open Source Team also provides technical guidance, mentorship, and governance support to ensure projects not only align with UN values but also prioritize long-term sustainability.\nDisclaimer: All Summer of Code work is conducted independently. Contributors are not considered United Nations employees or official representatives.",
    "ideas_url": "https://opensource.unicc.org/un/unoict/mentorship-programme/google-summer-of-code/-/blob/main/README.md",
    "website_url": "https://unite.un.org/en",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "css"
    ],
    "topic_tags": [
      "Technology",
      "innovation"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/united-nations-office-of-information-communication-technology",
    "ideas_content": "Skip to content\nGitLab\nExplore\nSign in\nRegister\ngoogle-summer-of-code\nREADME.md\nFind file\nBlame\nHistory\nPermalink\nUpdate README.md\n· a27fda96\nMithusa KAJENDRAN\nauthored\nFeb 16, 2026\na27fda96\nLoading"
  },
  {
    "name": "R project for statistical computing",
    "slug": "r-project-for-statistical-computing",
    "tagline": "R software for statistical computing & graphics",
    "description": "R provides a wide variety of statistical and graphical techniques, and is highly extensible. R is often the tool of choice for research in statistical methodology.\n\nR is an integrated suite of software facilities for data manipulation, calculation and graphical display. It includes\n\n* an effective data handling and storage facility,\n* a suite of operators for calculations on arrays, in particular matrices,\n* a large, coherent, integrated collection of intermediate tools for data analysis,\n* graphical facilities for data analysis and display either on-screen or on hardcopy, and\n* a well-developed, simple and effective programming language which includes conditionals, loops, user-defined recursive functions and input and output facilities.\n\nThe term “environment” is intended to characterize it as a fully planned and coherent system, rather than an incremental accretion of very specific and inflexible tools, as is frequently the case with other data analysis software.\n\nR, like S, is designed around a true computer language, and it allows users to add additional functionality by defining new functions. Much of the system is itself written in the R dialect of S, which makes it easy for users to follow the algorithmic choices made. For computationally-intensive tasks, C, C++ and Fortran code can be linked and called at run time. Advanced users can write C code to manipulate R objects directly.\n\nMany users think of R as a statistics system. We prefer to think of it of an environment within which statistical techniques are implemented. R can be extended (easily) via packages. There are about eight packages supplied with the R distribution and many more are available through the CRAN family of Internet sites covering a very wide range of modern statistics.\n\nR has its own LaTeX-like documentation format, which is used to supply comprehensive documentation, both on-line in a number of formats and in hardcopy.",
    "ideas_url": "https://github.com/rstats-gsoc/gsoc2026/wiki/table-of-proposed-coding-projects",
    "website_url": "https://www.r-project.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "javascript",
      "c++",
      "r-project",
      "fortran"
    ],
    "topic_tags": [
      "visualization",
      "machine learning",
      "data science",
      "graphics",
      "statistics"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/r-project-for-statistical-computing",
    "ideas_content": "-\n[Notifications](https://github.com/login?return_to=%2Frstats-gsoc%2Fgsoc2026)You must be signed in to change notification settings -\n[Fork 0](https://github.com/login?return_to=%2Frstats-gsoc%2Fgsoc2026)\n\n# table of proposed coding projects\n\n[7 revisions](https://github.com/rstats-gsoc/gsoc2026/wiki/table-of-proposed-coding-projects/_history)\n\nMentors, please edit this wiki page, and add your ideas to the table below.\n\nContributors, please look for a project that interests you in the table below. Before emailing project mentors, please do at least one project Test and post a link to your solution on the proposal’s wiki page.\n\n| Proposal | Hours | Status/Results | Mentors | Non-R languages? |\n|---|---|---|---|---|\n|\n\n[Animated interactive ggplots](https://github.com/rstats-gsoc/gsoc2026/wiki/Animated-interactive-ggplots)[Time-dependent constraints in gfpop](https://github.com/rstats-gsoc/gsoc2026/wiki/time-dependent-constraints-in-gfpop)[data.table](https://github.com/rstats-gsoc/gsoc2026/wiki/data.table)[glmmTMB via RTMB](https://github.com/rstats-gsoc/gsoc2026/wiki/glmmTMB-via-RTMB)[torchvision and ecosystem](https://github.com/rstats-gsoc/gsoc2026/wiki/torchvision-and-ecosystem)[mlr3 hugging face](https://github.com/mlr3hf)Project ideas have a ‘Status’ column which describes the current status of mentor and contributor interest. Project ideas where no contributor has yet contacted mentors should be listed as ‘need contributor’. Project ideas where one or more potential contributors are communicating with mentors should have a status of ‘potential contributors’. You can still communicate your interest to mentors to apply to projects with status “potential contributor” – that implies that there is another contributor who has already shown some capability for that project (see below for more details on how we evaluate applications). Projects that need to identify another mentor (e.g. to find a mentor with a specific skill, or from a different institution) should be marked with a status of ‘need mentor’ and the idea page should provide details in the ‘Mentors’ section.\n\nAll contributor applications will be discussed by the R mentor community, and proposals will be ranked considering factors such as quality, difficulty, and impact for the R community. Slots are a finite resource granted to R by Google, and only the best proposals will get chosen. In prior years, R has received 4-5 times more applications than slots, so application quality is key.\n\nContributors, if you have an idea for an R package coding project that is\nnot listed above, please\n[try to find mentors\nby posting a description of your project idea on the r-gsoc google\ngroup](https://groups.google.com/forum/#!forum/gsoc-r). If you find mentors, feel free to add your project idea to\nthis wiki. You should NOT submit any project applications to Google\nwithout finding TWO mentors for your project proposal."
  },
  {
    "name": "INCF",
    "slug": "incf",
    "tagline": "An open & FAIR neuroscience standards organization",
    "description": "The International Neuroinformatics Coordinating Facility (INCF; www.incf.org) is an international organization launched in 2005, following a proposal from the Global Science Forum of the OECD. \n\nINCF was established to facilitate and promote the sharing of data and computing resources in the international neuroscience community.  A larger objective of INCF is to help develop scalable, portable, and extensible applications that can be used by neuroscience laboratories worldwide. \n\nThe mission of INCF is to make neuroscience FAIR (Findable, Accessible, Interoperable and Reusable) by sharing and integrating neuroscience data and knowledge worldwide. We foster scientific community collaboration to develop standards for data sharing, analysis  modeling and simulation in order to catalyze insights into brain function in health and disease.\n\nINCF activities are open to all who can contribute to neuroinformatics at the international level. We have a global community of neuroscience researchers working on new and improved tools for all of neuroscience – enabling other researchers to make more and faster discoveries, and improving our understanding of the brain.",
    "ideas_url": "https://docs.google.com/document/d/1XkelmTUV8zMtg99GsZhbYvPoyUG5uzEIWji7IXj0M4k/edit?tab=t.0",
    "website_url": "https://www.incf.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "java",
      "c++",
      "gpu"
    ],
    "topic_tags": [
      "machine learning",
      "data visualization",
      "neuroscience",
      "brain modelling",
      "neuroimage processing"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/incf",
    "ideas_content": "Die Datei kann in Ihrem Browser nicht geöffnet werden, weil JavaScript nicht aktiviert ist. Aktivieren Sie JavaScript und laden Sie die Seite noch einmal.\nINCF GSOC 2026 Ideas List\nTab\nExtern\nFreigeben\nAnmelden\nDatei\nBearbeiten\nAnsicht\nTools\nHilfe\nBedienungshilfen\nFehlerbehebung"
  },
  {
    "name": "Kornia",
    "slug": "kornia",
    "tagline": "Advancing Computer Vision & Spatial AI, Openly",
    "description": "Kornia AI is a non-profit organization advancing Spatial Artificial Intelligence through open collaboration. Founded in 2018 and  registered as a non-profit in 2023, Kornia AI is supported by a global contributor community. The organization began with Kornia, a widely adopted Python library for Differentiable Computer Vision (>2M downloads/month, 400+ Google Scholar citations).\n In recent years, the core maintainers have shifted focus to kornia-rs, a native Rust stack for high‑performance 3D computer vision and spatial AI. Our direction emphasizes robotics and edge deployment: safe, memory‑efficient, low‑latency pipelines that run on constrained devices (e.g., embedded/Jetson‑class hardware). kornia-rs is gaining traction in the open-source community and is used by leading companies such as Farm-ng, Rerun.io, and Copper Robotics, who have featured the project on their platforms.",
    "ideas_url": "https://github.com/kornia/kornia-rs/wiki/%5B2026%5D-Google-Sumer-of-Code-Application",
    "website_url": "https://docs.rs/kornia",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "cuda",
      "rust",
      "deep learning",
      "data science",
      "Spatial AI"
    ],
    "topic_tags": [
      "machine learning",
      "artificial intelligence",
      "robotics",
      "computer vision",
      "3D Geometry"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/kornia",
    "ideas_content": "![Google Summer of Code](https://raw.githubusercontent.com/kornia/data/main/gsoc_2026_banner.png)\n\n⚠️ ⚠️ [[ **READ APPLICATION PROTOCOL**]](https://github.com/kornia/kornia-rs/wiki/Google-Sumer-of-Code-Application) ⚠️ ⚠️\n\n# Kornia-rs GSoC 2026 Project Ideas\n\n**Timeline (official):**\n- Org application deadline: **Feb 3, 2026 (18:00 UTC)**\n- Accepted orgs announced: **Feb 19, 2026 (18:00 UTC)**\n- Contributor application window: **Mar 16–Mar 31, 2026 (18:00 UTC)**\n\n**How this ideas list helps our application:**\n- Clear, scoped projects with measurable outcomes\n- Defined prerequisites and evaluation criteria\n- Community impact across core kornia-rs crates\n\n## AI Tooling Policy (GSoC 2026)\n\nWe follow Google’s 2026 guidance on AI tooling for both contributors and mentoring orgs. **Using AI is allowed only when it is transparent, limited, and fully understood by the contributor.** Raw AI output is not accepted.\n\n**Allowed uses (with disclosure):**\n- Research and learning (reading papers, summarizing docs)\n- Boilerplate/refactoring, test scaffolding, or debugging support\n\n**Not allowed:**\n- Submitting AI‑generated proposals as-is\n- Committing code you cannot fully explain\n- Copying AI output without review and verification\n\n**Contributor responsibility:** You remain 100% responsible for correctness, licensing, and explaining every line you submit. If you used AI, say where and how in your proposal and PRs.\n\n---\n\n## Projects Index\n\n1. [GPU acceleration for kornia-tensor and kornia-imgproc](#1-gpu-acceleration-for-kornia-tensor-and-kornia-imgproc)\n2. [Expand kornia-vlm with ONNX/TensorRT backends](#2-expand-kornia-vlm-with-onnxtensorrt-backends)\n3. [kornia-SLAM: baseline Visual-Inertial Odometry (VIO)](#3-kornia-slam-baseline-visual-inertial-odometry-vio)\n4. [Bubbaloop simulation integration and improvements (MuJoCo)](#4-bubbaloop-simulation-integration-and-improvements-mujoco)\n5. [Bubbaloop real-robot integration](#5-bubbaloop-real-robot-integration)\n\n**Projects are ordered by soft priority.**\n\n---\n\n## 1. GPU acceleration for kornia-tensor and kornia-imgproc\n\n**Description**\nImplement GPU kernels for core tensor ops and image processing transforms in Rust. Focus on frequently used operations (resize, warp_affine/warp_perspective, color transforms, distance transform) and ensure API parity with existing CPU implementations. Use CubeCL (multi-platform GPU compute in Rust) and/or native CUDA interop as appropriate.\n\n**Expected Outcomes**\n- Minimal GPU backend for kornia-tensor ops used by kornia-imgproc\n- GPU implementations for a handful of high-impact transforms\n- Benchmarks vs CPU and basic docs/examples\n\n**Resources**\n- CubeCL (Rust GPU compute): https://github.com/tracel-ai/cubecl\n- Rust std on GPU (Vectorware blog): https://www.vectorware.com/blog/rust-std-on-gpu/\n- CUDA Toolkit docs: https://docs.nvidia.com/cuda/\n- kornia-rs repository: https://github.com/kornia/kornia-rs\n\n**Possible Mentors**: Edgar Riba, Jian Shi, Christie Purackal\n\n**Difficulty**: Hard\n\n**Duration**: 350 hours\n\n---\n\n## 2. Expand kornia-vlm with ONNX/TensorRT backends\n\n**Description**\nBring more vision-language models from kornia (PyTorch) into kornia-rs and deliver optimized inference via ONNX Runtime with TensorRT where available. Focus on model portability and clear runtime selection (CPU/CUDA/TensorRT), with an emphasis on embedded targets (e.g., Jetson).\n\n**Expected Outcomes**\n- 1–2 VLM models integrated into kornia-vlm\n- ONNX Runtime backend + optional TensorRT path\n- Benchmarks and a small demo\n\n**Resources**\n- ONNX Runtime TensorRT Execution Provider: https://onnxruntime.ai/docs/execution-providers/TensorRT-ExecutionProvider.html\n- ONNX-TensorRT backend: https://github.com/onnx/onnx-tensorrt\n- Kornia (PyTorch) project: https://github.com/kornia/kornia\n- kornia-rs repository: https://github.com/kornia/kornia-rs\n\n**Possible Mentors**: Edgar Riba,  Miquel Farré\n\n**Difficulty**: Medium–Hard\n\n**Duration**: 350 hours\n\n---\n\n## 3. kornia-SLAM: baseline Visual-Inertial Odometry (VIO)\n\n**Description**\nFormalize and extend our kornia-SLAM crate within kornia-rs and implement a baseline visual-inertial odometry pipeline. Extend the crate to support stereo VIO, add GPU support, optimize existing kernels, and extend functionality toward LiDAR SLAM techniques. Emphasis on a modular API that can later host learning-based modules.\n\n**Expected Outcomes**\n- kornia-slam crate integrated into workspace\n- Baseline VIO pipeline + dataset evaluation\n- Benchmarks for CPU/GPU performance and accuracy\n- Documentation + example CLI\n\n**Resources**\n- SLAM Handbook: https://github.com/SLAM-Handbook-contributors/slam-handbook-public-release\n- ORB SLAM3 repository: https://github.com/UZ-SLAMLab/ORB_SLAM3\n\n**Possible Mentors**: Christie Purackal, Dmytro Mishkin, Edgar Riba\n\n**Difficulty**: Hard\n\n**Duration**: 350 hours\n\n---\n\n## 4. Bubbaloop simulation integration and improvements (MuJoCo)\n\n**Description**\nImprove the Bubbaloop simulation stack by integrating or enhancing a MuJoCo-based workflow. Focus on stable simulation bindings, reproducible training/evaluation loops, and better tooling for dataset generation and benchmarking.\n\n**Expected Outcomes**\n- MuJoCo integration with example tasks\n- Simulation-focused training/evaluation scripts\n- Documentation + demo video\n\n**Resources**\n- Bubbaloop repository: https://github.com/kornia/bubbaloop\n- kornia-rs repository: https://github.com/kornia/kornia-rs\n\n**Possible Mentors**: Edgar Riba, Jian Shi, Christie Purackal\n\n**Difficulty**: Medium–Hard\n\n**Duration**: 350 hours\n\n---\n\n## 5. Bubbaloop real-robot integration\n\n**Description**\nConnect the Bubbaloop learning framework to real robot hardware. Focus on hardware abstraction, safety/recovery procedures, and a minimal real-world demo that mirrors a simulation task.\n\n**Expected Outcomes**\n- Hardware integration layer with a small example robot\n- Real-world demo aligned with a simulation scenario\n- Documentation + setup guide\n\n**Resources**\n- Bubbaloop repository: https://github.com/kornia/bubbaloop\n- kornia-rs repository: https://github.com/kornia/kornia-rs\n\n**Possible Mentors**: Edgar Riba, Jian Shi, Christie Purackal, Miquel Farré\n\n**Difficulty**: Medium–Hard\n\n**Duration**: 350 hours\n\n---\n\n## General Evaluation Criteria\n\n- Code quality: idiomatic Rust, clear APIs, tests, docs\n- Performance: benchmarks and regression tracking where relevant\n- Reproducibility: scripts, datasets, and/or instructions to validate results\n- Impact: usefulness to kornia-rs users and downstream projects\n\n## Prerequisites (Required for Consideration)\n\nTo reduce spam proposals and prioritize contributors who can execute, applicants must complete **all** of the following before submitting a final proposal:\n\n- Join our community chat and introduce yourself\n- Make at least **one small, accepted PR** to kornia-rs (or related crate)\n- Share a draft proposal with a mentor for feedback\n- Be able to explain the code you submitted (short interview or async review)\n\n## Selection Process (How we evaluate)\n\nWe **select contributors, not proposals**. Proposals help shortlist, but we prioritize:\n- Engagement in the community and responsiveness to feedback\n- Demonstrated ability to explain code and design choices\n- Evidence of learning and independent problem‑solving\n\n## Pre-Application Work (Recommended)\n\n- Read the application protocol and join the community channels\n- Pick a project and submit a small PR to kornia-rs\n- Write a short design proposal with milestones and risks"
  },
  {
    "name": "LabLua",
    "slug": "lablua",
    "tagline": "Programming Language Research with emphasis on Lua",
    "description": "LabLua is a research lab at the Catholic University of Rio de Janeiro (PUC-Rio), affiliated with its Computer Science Department. It is dedicated to research on programming languages, with emphasis on the Lua language and reactive programming. It was founded on May 2004 by Prof. Roberto Ierusalimschy, the chief architect of the Lua language.\n\n\nLabLua consists of people from a wide range of backgrounds, including PhD candidates, professors and alumni who are the developers and maintainers of projects that are used by the Lua community at large.\n\n\nWhat is Lua?\n\n\nLua is a powerful, efficient, lightweight, embeddable scripting language. It supports procedural programming, object-oriented programming, functional programming, data-driven programming, and data description.\n\n\nLua has been used in many industrial applications (e.g., Adobe's Photoshop Lightroom), with an emphasis on embedded systems (e.g., the Ginga middleware for digital TV in Brazil) and games (e.g., World of Warcraft and Angry Birds). Several versions of Lua have been released and used in real applications since its creation in 1993.\n\nWhat is Lunatik?\n\nLunatik is an extension framework for Linux that combines the approaches of Extensible Operating Systems and Scripting Languages. This approach, named Kernel Scripting, advocates that OS kernels can be dynamically extended by using a high-level scripting language. Lunatik is a programming and execution environment that offers two main features: it allows developers to make subsystems scriptable and allows users to run Lua scripts in the kernel.\n\nWhat is Pallene?\n\nPallene is a statically-typed programming language, intended to serve as a more performant companion to Lua. It is designed to seamlessly interoperate with Lua, with first-class support for Lua data types. Pallene is able to be faster than Lua (sometimes as fast as LuaJIT) by taking advantage of the type annotations in Pallene in order to guide the compiler into outputting efficient executable code.",
    "ideas_url": "https://github.com/labluapucrio/gsoc",
    "website_url": "http://www.lua.inf.puc-rio.br",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "lua",
      "luarocks",
      "kernel",
      "lunatik",
      "pallene"
    ],
    "topic_tags": [
      "compilers",
      "scripting languages",
      "kernel scripting",
      "statically-typed languages"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/lablua",
    "ideas_content": "In this page we introduce some of the projects that are are working with us this year under the LabLua umbrella and list some potential ideas for GSoC 2026 projects.\n\nIf you are a contributor candidate, feel free to get in touch with us via our [Matrix](https://matrix.to/#/#lablua:matrix.org), [mailing list](mailto:labluagsoc@googlegroups.com) or by sending an email to one of our mentors. You can apply using one of the ideas in the list or you can bring your own idea. Either way, don't leave it to the last minute =).\n\nPlease use our [application template](https://github.com/labluapucrio/gsoc/blob/main/apply.md) to prepare your proposal and take a look at our [successful projects](http://www.lua.inf.puc-rio.br/gsoc/blog2025.html) from last year.\n\n| ❗ Important note on AI usage |\n|---|\n| GSoC is about learning and growing your personal skills. Using AI to code for you will not help you reach that goal. If you are eager to learn, then don't use AI to write your code. AI is improving quickly and provides great opportunities for research and learning, but you should write your own code. As mentors we're here to mentor you, not your bot. |\n\n[Evaluating Structured Reactive Patterns in Atmos](https://github.com#evaluating-structured-reactive-patterns-in-atmos)[Add Video Support to pico-sdl and pico-lua](https://github.com#add-video-support-to-pico-sdl-and-pico-lua)[Prepared Statements for LuaSQL](https://github.com#add-support-for-prepared-statements-for-luasql)\n\nLua integration means to integrate Lua into an existing program written in C/C++ to make it scriptable and/or to provide the functionality of software written in C/C++, typically libraries, to Lua programs.\n\n[Bring the libcurl Lua Binding Up to Date and Make it More Lua Friendly](https://github.com#bring-the-libcurl-lua-binding-up-to-date-and-make-it-More-lua-friendly)[Extend the Server Side Only Lua Websocket Module with a Websocket Client](https://github.com#extend-the-server-side-only-lua-websocket-module-with-a-websocket-client)[Update the LuaPGSQL Module to PostgreSQL 18](https://github.com#update-the-luapgsql-module-to-postgresql-18)[A Comprehensive Lua Module for Linux](https://github.com#a-comprehensive-lua-module-for-linux)[Integrate Lua into OpenRTX, the Free and Open Source Firmware for Digital Ham Radios](https://github.com#integrate-lua-into-openrtx-the-free-and-open-source-firmware-for-digital-ham-radios)\n\nLunatik is a project that brings Lua to the Linux kernel to make it possible to script the Linux kernel in Lua.\n\n[Conntrack and NAT support for Lunatik](https://github.com#conntrack-and-nat-support-for-lunatik)[Port The Lua Test Suite to Lunatik](https://github.com#port-the-lua-test-suite-to-lunatik)[Lunatik Binding for Linux Traffic Control (TC) and eBPF Maps](https://github.com#lunatik-binding-for-linux-traffic-control-tc-and-ebpf-maps)[Lunatik Binding for Netlink](https://github.com#lunatik-binding-for-netlink)[Lunatik Binding for OpenWrt UBUS](https://github.com#lunatik-binding-for-openwrt-ubus)[Lunatik Binding for sched-ext](https://github.com#lunatik-binding-for-sched-ext)\n\n[Atmos](https://github.com/atmos-lang/atmos/) is an experimental\nprogramming language that compiles to Lua 5.4 and reconciles structured\nconcurrency and event-driven programming.\n\n[pico-lua](https://github.com/fsantanna/pico-sdl/tree/main/lua/) is a a Lua\nbinding to [pico-sdl](https://github.com/fsantanna/pico-sdl/)), a graphics\nlibrary for 2D games and applications based on SDL.\n\nIn this project, we will combine Atmos with pico-lua (\"pico-atmos\") to\ndevelop graphical applications using structured reactive primitives, such as\n`await`\n\n/`emit`\n\n, `par`\n\n/`par_or`\n\n/`par_and`\n\n, and `spawn`\n\n/`task`\n\n.\n\nA [previous case study](https://fsantanna.github.io/pingus/) rewrote\nthe game logic of [Pingus](https://pingus.github.io/) using structured reactive\nprogramming.\nThat study identified **5 control-flow patterns** commonly found in\ngame development:\n\n**Finite State Machines**--- entities whose behavior maps event occurrences to transitions between states (e.g., double-click detection, character animations).**Continuation Passing**--- long-lasting activities that carry an action to execute next upon completion (e.g., interactive dialogs, menu transitions).**Dispatching Hierarchies**--- container entities that automatically forward stimuli to managed children (e.g., redraw and update callbacks).**Lifespan Hierarchies**--- container entities whose termination automatically destroys managed children (e.g., UI containers, particle systems).**Signaling Mechanisms**--- entities that communicate explicitly when no hierarchy relationship exists between them (e.g., key shortcuts, screen pausing).\n\nThis project proposes to **port an existing graphical application to\npico-atmos**, systematically applying and evaluating these patterns.\n\nThe contributor will select a game (written in any language) that contemplate\nthese five patterns above.\nGood candidates include well-known open-source games with menus, animations,\nentity hierarchies, and inter-entity communication --- for example, games built\nwith [LÖVE](https://love2d.org/) or other Lua frameworks.\n\nThe project has two interleaved tracks:\n\n**Implementation**--- Incrementally port the game to pico-atmos, replacing callbacks, state variables, and dispatching code with Atmos constructs (`await`\n\n/`emit`\n\n,`par`\n\n/`par_or`\n\n,`spawn`\n\n,`task`\n\n, pattern matching, etc.).**Evaluation**--- For each rewritten module, classify the applied patterns, compare lines of code, and document qualitative observations (readability, expressiveness, limitations encountered).\n\n- A port of the chosen application running on pico-atmos.\n- A document evaluating the control-flow patterns and the whole process.\n- Source code published in a public repository with clear commit history showing the incremental porting process.\n\n- Programming experience in Lua and at least one other language (C, C++, or Python).\n- Familiarity with 2D game development concepts (game loop, sprites, collision detection, state machines).\n- Willingness to learn Atmos (the\n[manual](https://github.com/atmos-lang/atmos/blob/main/doc/manual-out.md)and existing games[Birds](https://github.com/atmos-lang/pico-birds/)and[Rocks](https://github.com/atmos-lang/pico-rocks/)serve as learning material). - Reading the Pingus case study:\n[web version](https://fsantanna.github.io/pingus/)and[SBGames 2018 paper](http://www.ceu-lang.org/chico/ceu_sbgames18_pre.pdf).\n\n- Hard\n\n- Medium (175 hours) or Large (350 hours), depending on the complexity of the chosen game.\n\n[pico-sdl](https://github.com/fsantanna/pico-sdl/) is a simple educational 2D graphics library for C.\n\n[pico-lua](https://github.com/fsantanna/pico-sdl/tree/main/lua/) is the Lua binding for `pico-sdl`\n\n, enabling rapid\nprototyping and scripting of interactive applications.\n\nThis project aims to extend `pico-sdl`\n\nand `pico-lua`\n\nto support synchronized\naudio/video playback.\nThe project should support, at least, raw formats, such as YUV video and PCM\naudio.\n\nMore specifically, this project proposes a `pico.video`\n\nand `pico.audio`\n\nsub-modules to manipulate media files and play them following SDL2's streaming\ntexture and audio queue APIs.\n\nAudio/video synchronization should follow time-based frame scheduling, in which the expected frame number is calculated from a delta elapsed time to properly construct a timeline.\n\n- C implementation of audio/video sub-modules for\n`pico-sdl`\n\n- Lua bindings for the audio/video module for\n`pico-lua`\n\n- Synchronized A/V playback demo application\n- Documentation and API reference\n- Optional: FFmpeg integration for MP4/compressed formats\n\n- Lua and C programming languages\n- Experience with the Lua C API\n- SDL multimedia API (nice to have)\n- Experience with video formats and codecs (nice to have)\n\n- Intermediate\n\n- Small (90 hours) or Medium (175 hours)\n\n['LuaSQL'](https://github.com/lunarmodules/luasql) is a generic interface from Lua to a DBMS. It aims at portability over performance, but it allows extensions to suit the particularities of each DBMS.\n\nThe inclusion of support for prepared statements in LuaSQL has been discussed thoroughly some time ago, but since each DBMS offers very different APIs there is no standard that could be defined to assure portability between them. Anyway the demand persists.\n\nThis project proposes the addition of a minimal API that would allow each driver to offer prepared statements according to its DBMS restrictions and mechanisms.\n\n- Propose a new API that would be flexibly enough to cover the main features of each database respecting each different mechanisms of defining prepared statements\n- Implement the new API into one or more drivers\n- Test and document everything\n\n- C programming languages\n- Experience with any database C API (highly desirable)\n- Experience with Lua C API (highly desirable)\n- Experience with Lua (good to have)\n\n- Challenging\n\n- Large (350 hours)\n\n['libcurl'](https://curl.se/libcurl/) is the de-facto standard network transfer\nlibrary to handle all kind of network requests.\n\nA Lua binding for libcurl exists ['LuaCURL'](https://github.com/arcapos/luacurl)\nbut it has not seen much development activity recently.\n\nThe goal of this project is to bring the libcurl Lua binding up to the current state of libcurl and provide all (or at least most) of libcurls functionality to Lua. At the same time LuaCURL should be made more Lua friendly (instead of just providing libcurls functions to Lua.) E.g. LuaCURL currently uses integer constants taken from libcurl for LuaCURL options, but Lua has the paradigm of using strings for options. So this should be reworked to use strings.\n\n- The\n['libcurl'](https://curl.se/libcurl/)website ['The Lua Integration Guide'](https://lua.msys.ch)by Marc Balmer\n\n- A LuaCURL module that is in par with libcurl\n- Make LuaCURL more \"Lua-ish\", e.g. no more integer constants\n- Ensure that LuaCURL remains agnostic of the libcurl version it is compiled against (i.e. check the libcurl version at runtime to only provide to Lua what is available in the underlying libcurl)\n- Test and document everything\n\n- Be proficient in the C programming language\n- Experience with the Lua C API\n- Experience with cURL and networking in general\n- Experience with Lua\n\n- Medium to advanced\n\n- Medium (175 hours) or Large (350 hours)\n\nWebsockets are a common way for clients, e.g. a webbrowser, to communicate with server applications over a persistent connection, the Websocket.\n\nWith ['luawebsocket'](https://github.com/arcapos/luawebsocket) a server side\nonly implementation of Websockets exists for Lua, i.e. it allows to write\nWebsocket Servers in Lua.\n\nThe goal of this project is to add client functionality to the luawebsocket module so that Lua programs can be first class Websocket clients.\n\n[The Websocket Standard](https://websockets.spec.whatwg.org)['The Lua Integration Guide'](https://lua.msys.ch)by Marc Balmer\n\n- Add a client side Websocket implementation to luawebsocket\n- Test and document everything\n\n- Be proficient in the C programming language\n- Experience with the Lua C API\n- Experience with Websockets and networking in general\n- Experience with Lua\n\n- Medium to advanced\n\n- Medium (175 hours) or Large (350 hours)\n\nPostgreSQL is the most advanced open source database system and it is in very wide use.\n\nWith ['luapgsql'](https://github.com/arcapos/luapgsql) a Lua client interface\nexists that is based on PostgreSQLs libpq C client library. It aims at being\nfeature complete and support all functionality of PostgreSQL itself, that\nincludes advanced features like asnychronous notifications etc. It has, however,\nnot been updated since ca. PostgreSQL version 16.\n\nThe goal of this project is to bring the Lua PostgreSQL client module up to date with the current PostgreSQL 18 version while at the same make a critical review of the module and ensure its readyness to be used in a Lua environment and to add Lua idioms where needed. On suche existing \"Luaism\" is e.g. that a PostgreSQL result set can be directly converted to a Lua table.\n\nA second goal is to write an extensive set of example programs in Lua to serve as a base and guide for developers that want to include PostgreSQL in their Lua programs.\n\n['libpq - the C client interface'](https://www.postgresql.org/docs/current/libpq.html)['The Lua Integration Guide'](https://lua.msys.ch)by Marc Balmer\n\n- Review and extend where needed the Lua PostgreSQL client module\n- Add a comprehensive set of example programs\n- Test and document everything\n\n- Be proficient in the C programming language\n- Experience with the Lua C API\n- Experience with PostgreSQL in general and libpq in special\n- Experience with Lua\n\n- Medium to advanced\n\n- Medium (175 hours) or Large (350 hours)\n\nLinux offers a rich programming interface for C programmers and we aim with this project to make this interface available to Lua.\n\nWith ['lualinux'](https://github.com/arcapos/lualinux) a Lua module to use\nthe Linux programming interface exists, but it is far from complete. It\nalready has a modular approach, so that Lua programs don't have to load a\n\"monster\" binding, but just so much as is needed. Part of the project is\nto review this modularization.\n\nThe module tries to mimick a bit what is done in C: You include, e.g. syslog.h when you want to use the syslog() function in your C program. Likewise in Lua you would require 'syslog' to use the syslog functionality.\n\nThe goal of this project is to make as much as possible of the Linux programming interface available to Lua programs and try use Lua paradigms where possible. For example, while in C header files #defines for constants are used, in Lua we prefer strings for options. In the end the module should provide the Linux programming interface in a Lua friendly style.\n\nA second goal is to write an extensive set of example programs in Lua to serve as a base and guide for developers that want to use the Linux programming interface in their Lua programs.\n\n['The Linux Programming Interface'](https://man7.org/tlpi/)by Michael Kerrisk['The Lua Integration Guide'](https://lua.msys.ch)by Marc Balmer\n\n- Complete as much as possible the Linux module for Lua\n- Add a comprehensive set of example programs\n- Test and document everything\n\n- Be proficient in the C programming language\n- Experience with the Lua C API\n- Experience with the Linux programming interface\n- Experience with Lua\n\n- Advanced\n\n- Medium (175 hours) or Large (350 hours)\n\nMost firmware for digital ham radios is proprietary and uses patented commercial voice codecs based on the AMBE+2 chips made by HSI.\n\nOpenRTX, on the other hand, provides a completely free, non patent-encumbered alternative that uses the M17 protocol for voice and data communication. M17 uses the free and opensource Code 2 voice codec.\n\nMaking OpenRTX scriptable pursues several goals: First it is another showcase of integrating Lua into an operating system kernel, something that has previously been done for the Linux and NetBSD kernel, with the difference that OpenRTX, which uses the Miosix kernel, runs in a restricted embedded environment. Secondly, having a radio that can be scripted allows for new applications that have never been done before with a radio. It opens a door to unprecedented experimentation.\n\n['The OpenRTX Project'](https://openrtx.org/#/)['The M17 Project'](https://m17project.org/)['The Miosix OS Kernel'](https://miosix.org/)['The Lua Integration Guide'](https://lua.msys.ch)by Marc Balmer\n\n- Make OpenRTX scriptable\n- Add a comprehensive set of example scripts\n- Test and document everything\n\n- Be proficient in the C programming language\n- Experience with the Lua C API\n- Experience with Lua\n- Experience with embedded system\n- Have an amateur radio license and callsign\n\n- Advanced\n\n- Large (350 hours)\n\n[Marc Balmer](mailto:mhbalmer@gmail.com)HB9SSB\n\nThis project aims to create **Lunatik bindings for the Linux Traffic Control (TC) subsystem and eBPF maps** to enable efficient and programmable network traffic control. These bindings will allow **Lua scripts** to manipulate TC and interact with **eBPF maps**, providing a flexible interface for traffic shaping, filtering, and monitoring.\n\nThis work is **heavily inspired by** the [luaxdp](https://github.com/luainkernel/lunatik?tab=readme-ov-file#xdp) binding, which integrates Lua with **XDP (eXpress Data Path)** using eBPF. Given that **TC and XDP both utilize eBPF**, this new binding (*luatc*) will **reuse and adapt parts of the luaxdp codebase**, ensuring consistency and maintainability.\n\n[Linux Traffic Control (TC)](https://man7.org/linux/man-pages/man8/tc.8.html) is a subsystem of the Linux kernel that allows administrators to **manage network packet transmission**, enabling features like **traffic shaping, queuing, scheduling, and policing**. It is widely used for **bandwidth control, Quality of Service (QoS), and network performance optimization**.\n\nConfiguring TC using traditional tools can be **complex and static**, making it difficult to implement **custom traffic processing logic**. **Lunatik**, a Lua-based kernel scripting interface, can simplify this process by allowing users to write **Lua scripts** that dynamically interact with **TC queuing disciplines (qdiscs), classes, and filters**.\n\nAdditionally, this project will introduce **support for eBPF maps** within Lunatik. [eBPF maps](https://docs.kernel.org/bpf/maps.html) are a key component of eBPF, providing **efficient storage and retrieval of structured data between user space and kernel space**. This functionality will **not be restricted to the TC binding ( luatc)**, but will be implemented\n\n**as a general feature in Lunatik**, enabling\n\n**other kernel extensions**to leverage eBPF maps.\n\n- A fully functional\n**Lunatik binding for the TC subsystem**, allowing Lua scripts to configure and manipulate network traffic. **Support for eBPF maps in Lunatik**, enabling efficient**data sharing between Lua scripts and eBPF programs**.**Integration with the existing luaxdp codebase**, reusing and adapting components where possible.**Clear documentation and examples**, demonstrating how to use*luatc*for**network traffic control**and**eBPF maps for data storage**.\n\n- Lua and C programming languages\n- Linux Networking\n- Experience with Linux Kernel (highly desirable)\n- Experience with Traffic Control (TC) subsystem (good to have)\n- Experience with eBPF maps (good to have)\n\n- Challenging\n\n- Large (350 hours)\n\n[Lunatik](https://github.com/luainkernel/lunatik/) is a framework for scripting the Linux kernel with Lua. For example, Lunatik can be used for scripting the Linux networking subsystem (as presented at Netdev [0x14](https://netdevconf.info/0x14/session.html?talk-linux-network-scripting-with-lua) and [0x17](https://netdevconf.info/0x17/sessions/talk/scripting-the-linux-routing-table-with-lua.html)) among other [examples](https://github.com/luainkernel/lunatik#examples).\n\nThe purpose of this project is to port the [Lua Test Suite](https://www.lua.org/tests/) to Lunatik. That is, to adapt scripts from the Lua Test Suite and develop a Linux loadable kernel module containing its C portion. This project might leverage the [GSoC 2015 project](http://www.lua.inf.puc-rio.br/gsoc/blog2015.html#kerneltest) developed by [Guilherme Salazar](https://github.com/labluapucrio/gsoc/blob/main/cdn-cgi/l/email-protection#2a4d59506a4b49470445584d), which ported the Lua Test Suite to the [NetBSD kernel](https://man.netbsd.org/lua.4).\n\nThe main difference between the kernel Lua and regular user-level Lua is that kernel Lua doesn't have support for standard libraries that depend on operating system (e.g., io and os) and for floating-point numbers.\n\n- Adapted test scripts for Lunatik\n- Lunatik library for testing the Lua C API\n- Test Report at least for x86_64 and ARM64\n\n- Lua and C programming languages\n- Experience with the Lua C API (nice to have)\n- Experience with Linux kernel (nice to have)\n\n- Beginner\n\n- Small (90 hours) or Medium (175 hours)\n\nConnection tracking (conntrack) is a fundamental component of the Linux kernel's networking stack. It is part of the Netfilter framework and is responsible for monitoring active network connections passing through the system. Conntrack maintains a state table, allowing the kernel to track packets as part of a flow and apply connection-oriented filtering, NAT (Network Address Translation), and stateful firewalling.\n\nNAT is used to modify IP addresses and ports in packet headers to facilitate address translation, load balancing, and security enforcement. The Linux kernel provides APIs to manipulate NAT and connection tracking through the Netfilter framework.\n\nThe purpose of this project is to port conntrack and NAT data structures and kernel APIs to lunatik. These are present under:\n\n`net/netfilter/conntrack.h`\n\n`net/netfilter/nf_conntrack_common.h`\n\n`net/netfilter/conntrack_tuple.h`\n\n`net/netfilter/nf_conntrack_core.h`\n\n`net/netfilter/nf_nat.h`\n\n\nThis projects builds upon the GSoC 2024 Project ['Lunatik binding for Netfilter'](https://summerofcode.withgoogle.com/archive/2024/projects/BIJAPZjf). For complete reference on the relevant kernel headers and data structures, refer to the following [gist](https://gist.github.com/sheharyaar/cbbd43037fa43fd391e52964347a2bc9).\n\n- Allow fetching the conntrack entries and connection information\n- Ability to conntrack add entries from lua programs that need to perform NAT. Example use case - L7 load balancing using netfilter in lua\n- Ability to perform NAT for atleast inet protocols\n\n- Lua and C programming languages\n- Linux Networking\n- Experience with Linux Kernel (highly desirable)\n- Experience with Netfilter subsystem (good to have)\n\n- Challenging\n\n- Medium (175 hours) or Large (350 hours)\n\nThis project aims to implement a Netlink binding for Lunatik, allowing Lua scripts running in kernel space to interact with Netlink-based kernel subsystems and user space applications.\n\nThe binding should support Generic Netlink, enabling bidirectional communication with user space, and expose kernel APIs that are only available via Netlink, such as the cfg80211 subsystem. It should also allow the extraction of data from Netfilter hooks through Netlink.\n\nAs part of the project, luafib should be reimplemented entirely in Lua, using the new Netlink binding.\n\n- Netlink communication between kernel-space Lua and user space\n- Lua interfaces for Netlink-only kernel subsystems (e.g., cfg80211)\n- Support for extracting data from Netfilter via Netlink\n- A pure Lua reimplementation of luafib\n- Documentation and usage examples\n\n- Lua and C programming languages\n- Linux Networking\n- Basic understanding of Netlink and Sockets\n- Experience with Linux Kernel (highly desirable)\n\n- Intermediate\n\n- Medium (175 hours) or Large (350 hours)\n\nThis project aims to implement a UBUS binding for Lunatik, allowing Lua scripts running in kernel space to interact directly with the OpenWrt configuration and management bus.\n\nUBUS is OpenWrt’s IPC mechanism, widely used for system configuration, status reporting, and service control. It is built on top of libubus and libubox, and uses UNIX Domain Sockets for communication between clients and services.\n\nWith the recent addition of UNIX Domain Socket support in Lunatik, this project proposes creating a native Lunatik API for UBUS, enabling both read and write access to the bus directly from kernel-space Lua scripts. This would allow Lunatik-based logic to query system state, react to configuration changes, and interact with OpenWrt services in a structured and consistent way.\n\n- A Lua API exposing core UBUS functionality\n- Support for reading from and writing to the UBUS bus\n- Integration based on UNIX Domain Sockets\n- Example scripts demonstrating interaction with OpenWrt configuration and services\n- Documentation of the API\n\n- Lua and C programming languages\n- Familiarity with OpenWrt architecture\n- Basic understanding of UBUS, libubus, and libubox\n\n- Beginner\n\n- Medium (175 hours) or Large (350 hours)\n\nRecently, sched-ext was added to the Linux kernel, introducing a framework that allows scheduler extensions implemented using eBPF. This mechanism enables custom scheduling policies to be developed and dynamically attached to the kernel scheduler, without modifying core scheduler code.\n\nsched-ext has already been used to implement experimental and unconventional schedulers, including a example of a scheduler based on astrology, highlighting both the flexibility of the framework and its suitability for rapid experimentation.\n\nThis project aims to create a Lunatik integration API for sched-ext, following a design similar to luaxdp, enabling Lua callbacks to be invoked from sched-ext hooks in order to implement process scheduling policies. The project also includes exporting the required scheduler-related kernel APIs to Lua, allowing policies to be expressed clearly and concisely.\n\nThe expected outcome is a new binding, luasched, along with example scheduling policies implemented in Lua, and a comparative evaluation against eBPF implementations in terms of performance and code clarity.\n\n- A new Lunatik binding for sched-ext (luasched)\n- A Lua API exposing sched-ext hooks and required scheduler primitives\n- Support for implementing process scheduling policies using Lua callbacks\n- Example scheduling policies implemented in Lua\n- Benchmark comparisons between Lua-based sched-ext policies and eBPF equivalents\n- Code clarity and maintainability comparisons between Lua and eBPF approaches\n- Documentation and usage examples\n\n- Lua and C programming languages\n- Linux kernel internals\n- Basic understanding of Linux scheduling\n- Familiarity with eBPF and sched-ext is a plus\n\n- Intermediate\n\n- Small (90 hours) or Medium (175 hours)"
  },
  {
    "name": "Project Mesa",
    "slug": "project-mesa",
    "tagline": "Mesa: Agent-based modeling in Python 3+",
    "description": "Mesa is an Apache2 licensed agent-based modeling (or ABM) framework in Python.\n\nIt allows users to quickly create agent-based models using built-in core components (such as spatial grids and agent schedulers) or customized implementations; visualize them using a browser-based interface; and analyze their results using Python’s data analysis tools. \n\nIts goal is to provide an ecosystem to support generative science approaches, improve understanding of complex systems and aid practical decision-making.",
    "ideas_url": "https://github.com/mesa/mesa/wiki/GSoC-2026-Project-Ideas",
    "website_url": "https://mesa.readthedocs.io/latest/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "gis",
      "object oriented programming",
      "LLMs",
      "network topology"
    ],
    "topic_tags": [
      "simulation",
      "Agent Based Models",
      "Generative Science"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/project-mesa",
    "ideas_content": "Tentative Projects & Mentors\n\n* [Behavioral framework](#behavioral-framework) Size: Medium/Large Mentors: @EwoutH/@quaquel\n* [Mesa-Geo Update](#modernizing-mesageo-propertylayer-refactor-aggregationapi-and-visualizationoverhaul) Size: Medium/Large Mentors: @wang-boyu/@jackiekazil\n* [Mesa-LLM iteration to push to production](#Mesa-LLMs-iteration-to-push-to-production) Size: Medium Mentors: @colinfrisch/@jackiekazil\n* [Meta Agents](#meta-agents) Size: Medium Mentors: @tpike3/@EwoutH\n* [Mesa Examples Revival](#reviving-mesa-examples) Size: Small/Medium Mentors: @jackiekazil/@EwoutH\n\nMore info:\n- [Mesa's Google Summer of Code 2026 guide](https://github.com/mesa/mesa/wiki/Google-Summer-of-Code-2026)\n- [GSoC 2026 ideas discussion](https://github.com/mesa/mesa/discussions/2927)\n\n# Extended descriptions\n## Behavioral framework\n### Summary\nThis project evaluates how well Mesa currently supports building agent models based on established behavioral theories. The suggested approach is hands-on: implement example models, document what works and what doesn't, and identify improvements that would help the most users. When similar models exist in other ABM platforms, compare and learn from them.\n\n### Motivation\nMany agent-based models need agents with realistic behavioral patterns - animals balancing hunger and fear, people making economic decisions, or entities learning from experience. Theories like Belief-Desire-Intention (BDI), needs-based architectures, and reinforcement learning provide proven frameworks for this. But we don't have a clear picture of how well Mesa supports these patterns today. This project finds out through actual implementation rather than guesswork.\n\n### Historical context\nMesa started with simple discrete time steps but has grown more capable. The DiscreteEventScheduler and DEVSimulator enable flexible timing and event-driven modeling. Recent discussions have explored continuous states ([#2529](https://github.com/projectmesa/mesa/discussions/2529)), tasks with duration and interruption ([#2526](https://github.com/projectmesa/mesa/discussions/2526)),  and a unified behavioral framework ([#2538](https://github.com/projectmesa/mesa/discussions/2538)). Experimental work on observables and signals ([PR #2547](https://github.com/projectmesa/mesa/pull/2547)) adds more building blocks. This project aims to move these discussions forward with practical experience.\n\n### Overall goal\nProduce a clear picture of what Mesa does well and where it falls short for behavioral modeling. Capture this in example models, tutorials, and documentation that help current users and guide future development. Optionally, propose and implement focused improvements that benefit multiple behavioral modeling approaches.\n\n### Potential approaches\nPick two or three behavioral theories to explore. For each, build an example model in Mesa and document the experience: What was easy? What needed workarounds? What was genuinely hard? Good candidates include predator-prey with needs-based behavior, market agents using BDI reasoning, or learning agents using reinforcement approaches.\n\nWhere comparable models exist in NetLogo, GAMA, Agents.jl, or other platforms, study how they solve the same problems. What can Mesa learn from their approaches?\n\nBased on what you find, you might propose targeted improvements: documentation, utility functions, or new components. Any additions should be justified by your implementation experience and useful across multiple behavioral theories, not just one narrow case.\n\n### Possible outcomes\n* Example models as PRs to mesa-examples\n* Tutorials showing how to implement behavioral theories in Mesa\n* Documentation of what works, what's awkward, and what's missing\n* Comparisons with other ABM platforms\n* Optionally, PRs introducing broadly useful building blocks for behavioral modeling\n\n### Useful skills\nContributors should have solid Python programming experience and familiarity with object-oriented design patterns. Prior experience with agent-based modeling concepts is valuable, whether through Mesa or other platforms. Interest in behavioral theories from psychology, economics, or artificial intelligence will help in selecting and implementing meaningful examples. Experience with technical writing will support the documentation aspects of the project. Familiarity with other ABM platforms (NetLogo, GAMA, Agents.jl) is helpful for comparison work but not required.\n\n### Getting Started\nRead the linked discussions ([#2529](https://github.com/projectmesa/mesa/discussions/2529), [#2526](https://github.com/projectmesa/mesa/discussions/2526), [#2538](https://github.com/projectmesa/mesa/discussions/2538)) to understand current thinking. Explore Mesa's DEVS module and signals work. Try extending Wolf-Sheep with basic needs-based decisions to get hands-on experience. Look at mesa-examples to understand contribution patterns. Think about which behavioral theories interest you and what models would test Mesa effectively. Join the Mesa community on GitHub or chat to refine your ideas.\n\n### Suggested size\n- Medium (focused on evaluation & documentation)\n- Large (evaluation, documentation and feature implementation)\n### Mentors (committed)\n- Ewout ter Hoeven (@EwoutH) & Jan Kwakkel (@quaquel)\n\n## Modernizing Mesa‑Geo: PropertyLayer Refactor, Aggregation API and Visualization Overhaul\n\n### Summary\n\nMesa‑Geo is Mesa's geospatial extension, providing CRS‑aware agents, raster and vector layers and geometry queries. Its current design predates Mesa's modern discrete‑space architecture and stores raster values as per‑cell Python attributes. This project will refactor Mesa‑Geo to follow Mesa's new `PropertyLayer` abstraction for raster data, expose a fluent API for aggregation and random sampling, clarify cell coordinate semantics, and upgrade the visualisation pipeline to Mesa ≥ 3.3. The goal is a faster, more intuitive framework that aligns with Mesa's evolving space model and prepares Mesa‑Geo for future integration.\n\n### Motivation\n\nMesa‑Geo carries technical debt from its early implementation. Raster data are stored as individual Python attributes rather than vectorised arrays, neighbourhood aggregation is ad‑hoc, and the package duplicates grid logic that Mesa's core has since generalised. Issues [#201](https://github.com/mesa/mesa-geo/issues/201), [#91](https://github.com/mesa/mesa-geo/issues/91) and [#81](https://github.com/mesa/mesa-geo/issues/81) highlight the need for a `PropertyLayer`‑based `RasterLayer` with file I/O helpers and random point sampling; issue [#295](https://github.com/mesa/mesa-geo/issues/295) shows that GeoSpace's visualisation should be updated for Mesa 3.3; and PR [#299](https://github.com/mesa/mesa-geo/pull/299) underscores confusion around coordinate property names. Addressing these themes will align Mesa‑Geo with Mesa’s modern space model, simplify user code and improve performance.\n\n### Historical Context\n\nMesa‑Geo was first released in 2018 and later expanded in 2022 to provide GIS support for Mesa. It introduced `GeoSpace` for raster/vector layers and `GeoAgent` with CRS‑aware geometries, at a time when Mesa lacked a unified discrete‑space API. Since then Mesa has developed a new space model featuring first‑class `Cell` objects, `CellCollection` views and vectorised `PropertyLayer`s. Mesa‑Geo has not yet adopted these concepts, which leads to duplicated grid code and difficulty keeping up with changes such as the Solara‑based visualisation system in Mesa 3.x. Past issues and PRs mentioned above illustrate interest in aligning Mesa‑Geo with these newer abstractions.\n\n### Overall Goal\n\nDeliver a Mesa‑Geo release that is intuitive and aligned with Mesa's modern space architecture. The project will:\n\n- Replace per‑cell Python attributes with `PropertyLayer` arrays for raster storage, keeping CRS and affine metadata intact.\n- Provide convenient APIs for loading and saving raster bands, and for sampling random coordinates within cells.\n- Introduce a fluent aggregation API for per‑cell operations, filtering, mapping and neighbourhood statistics on raster data.\n- Clarify coordinate semantics by introducing explicit properties such as `cell.xy`, `cell.grid_pos` and `cell.rowcol`, and emitting deprecation warnings for legacy names.\n- Migrate GeoSpace and raster rendering to Mesa's `SpaceRenderer`/Solara backend to ensure compatibility with Mesa 3.3 and later.\n- Explore, as time permits, how Mesa‑Geo can plug into Mesa's upcoming multi‑space design and position/index translation hooks.\n\n### Expected Outcomes\n\n#### Core Improvements\n\n- **Property‑Layer RasterLayer:** Refactor `RasterLayer` to store each band as a `PropertyLayer`, with methods to add/remove bands and convert existing raster cells into property descriptors.\n\n- **Raster I/O & Sampling:** Provide `RasterLayer.from_file` and `RasterLayer.to_file` using rasterio or rioxarray (optional dependency) and implement `get_random_coord(cell)` for random sampling within a cell's geometry.\n\n- **Aggregation API:** Extend Mesa's `CellCollection` patterns to raster layers, with functions such as `do(fn)` for per‑cell operations, `select(predicate)`, `map(fn)` and `aggregate(func, by=None)` to compute statistics over groups or neighbourhoods.\n\n- **Coordinate Semantics:** Add Cell properties such as `cell.xy`, `cell.grid_pos` and `cell.rowcol`, emit deprecation warnings for `cell.pos` and `cell.indices`, and document the migration path.\n\n- **Visualisation Overhaul:** Update Mesa-Geo visualization to work reliably with Mesa's SolaraViz environment and current rendering expectations. Applicants are encouraged to propose a good GeoSpace visualization architecture and API. The proposal should ideally specify (1) the public API exposed to users, (2) how it plugs into `SolaraViz`, and (3) how raster + vector layers and agents are rendered.\n\n   Note: The solution does not have to mirror Mesa's `SpaceRenderer` API; it only needs to integrate cleanly with SolaraViz's rendering system.\n\n#### Enhancements & Stretch Goals\n\n- **Alternative Grids:** Investigate irregular or hexagonal grid support, and test integration of H3 or axial coordinate systems with property layers and the aggregation API.\n\n- **Integration Proof of Concept:** Prototype a `GeoSpace` redesign that follow https://github.com/mesa/mesa/discussions/2585#discussioncomment-11732488.\n\n#### Documentation\n\n- Update Mesa‑Geo documentation to describe the new raster API, aggregation methods and coordinate properties.\n\n- Provide tutorials showing how to load raster bands from files, visualise them with `SpaceRenderer`, and implement a simple cellular automaton using the aggregation API.\n\n#### Testing & Quality Assurance\n\n- Create unit tests for the refactored `RasterLayer`, including property‑layer creation, coordinate conversions, file I/O and deprecation warnings.\n- Add tests for aggregation and random sampling functions to ensure correctness and reproducibility.\n- Integrate visualisation tests into Mesa‑Geo's CI to verify compatibility with Mesa ≥ 3.3 and maintain performance benchmarks.\n\n### **Skills Required**\n\n**Required:**\n\n- Strong Python programming and experience with object‑oriented design.\n- Knowledge of GIS concepts such as CRS, affine transforms and raster vs vector data.\n- Experience with Mesa and/or Mesa‑Geo, including the new discrete space and PropertyLayer APIs.\n- Comfort with NumPy for vectorised operations.\n\n**Preferred:**\n\n- Experience using rasterio, rioxarray or xarray for raster I/O and CRS handling.\n- Familiarity with Shapely and GeoPandas for geometric operations.\n- Exposure to Solara or Altair for interactive web visualisation.\n\n### Project Size\n\nMedium/Large\n\n### Mentors\n\n- **Primary:** Boyu (@wang-boyu)\n- **Backups:** Jackie (@jackiekazil)\n\n### **Getting Started**\n\n1. Review issues [#201](https://github.com/mesa/mesa-geo/issues/201), [#91](https://github.com/mesa/mesa-geo/issues/91) and [#81](https://github.com/mesa/mesa-geo/issues/81) and PR [#299](https://github.com/mesa/mesa-geo/pull/299) to understand the motivations.\n2. Study Mesa's discrete space and `PropertyLayer` implementations (`mesa.discrete_space`, `CellCollection`, `AgentSet`) to inform the aggregation API design.\n3. Experiment with `SpaceRenderer` using Mesa's tutorials to understand how property layers are rendered.\n4. Refactor a small raster model (e.g. a land‑use cellular automaton) to use `PropertyLayer` manually; note challenges and open questions.\n\n## Mesa LLMs iteration to push to production \n\n### Summary\nMesa-LLM integrates Large Language Models (LLMs) into the Mesa framework, allowing for agents with complex cognitive architectures and communication capabilities. This project aims to stabilize the library as well as enhance its features, documentation, and *ease of use* to make it a reliable tool for researchers and developers.\n\n### Motivation\nGenerative Agents represent a paradigm shift in ABM. However, implementing them currently requires significant  coding to handle API connections, prompt history, and parsing text outputs into simulation actions. Mesa-LLM needs to bridge the gap between LLM text generation and the deterministic logic required to obtain reliable results in an ABM simulation.\n\n### Historical Context\nMesa-LLM was created as a 2025 GSoC project to address the growing demand for \"smart\" agents within Mesa. Initial ideas were initiated in [Discussion #2773](https://github.com/mesa/mesa/discussions/2773) and [Discussion #2775](https://github.com/mesa/mesa/discussions/2775) after GSoC selection process. The project has since seen contributions from various developers, but it remains in an experimental state with open issues and areas for improvement.\n\n\n### Overall Goal\nCreate a stable, well-tested, and fully-featured version of Mesa-LLM that seamlessly integrates with Mesa (including preparing to the breaking changes from the future update to mesa 4.0.0) while maintaining its versatility. This includes expanding documentation, improving test coverage, and simplifying processes that can still be hard for the user to understand (with reasoning, memory and other simple functionalities).\n\n**Core Features:**\n\n1. Address outstanding issues in the mesa-llm repo\n2. Improve LLM tool modularization and extensibility\n3. Create a stable release cadence aligned with Mesa's releases\n4. Improve continuous integration and testing infrastructure\n5. Optimize ollama and local inference support\n\n**Documentation:**\n\n1. Expand tutorials with advanced usage examples\n2. Create migration guides from Mesa to Mesa-llm\n3. Add performance/cost optimization guidelines\n4. Document integration patterns with other Mesa extensions\n5. Build examples (if possible sourced from existing scientific papers) showcasing complex agent architectures using mesa-llm and comparison with non-LLM agents\n\nTesting & Quality Assurance: Improve current comprehensive test suite covering all features and add new tests and edge cases\n\n### Skills Required\n**Required:**\n* Strong Python programming skills.\n* Deep understanding of LLM APIs (OpenAI, Anthropic, Gemini, etc.) and local model usage (Ollama, huggingface).\n* Experience with Prompt Engineering and Context Window management.\n* Understanding of Asynchronous programming (asyncio).\n\n**Preferred:**\n* Familiarity with Mesa core architecture.\n\n**Level:** Medium/Hard\n**Size:** 175 / 350 hours\n\n### Mentors\n* **Primary:** Jackie (@jackiekazil)\n* **Backup:** Colin (@colinfrisch)\n\n### Getting Started\n1. Get familiar with the Mesa framework: [Mesa Documentation](https://mesa.readthedocs.io/)\n2. Explore the Mesa-LLM repository: [mesa-llm GitHub](https://github.com/mesa/mesa-llm)\n3. Analyze current issues regarding API latency and memory handling.\n4. Implement one or more basic models using the current version to identify friction points in the API.\n\n## Meta Agents \n### Summary\nComplex systems often have multiple levels of components. An organization is not one entity, but is made of departments, sub-departments,\nand people. A person is not a single entity, but it is made of microbiomes, organs, and cells. A city is not a single entity, but it is made of districts, neighborhoods, buildings, and people. A forest comprises an ecosystem of trees, plants, animals, and micro-organisms. This reality is the motivation for meta-agents. It allows users to represent these multiple levels, where each level can have agents with `constituting_agents`. \n\n### Motivation \nEnhancing meta-agents into a optimally working module that allows users to create complex adaptive networks can fundamentally aid complexity research. It can allow for more elegant models where agents are in a active and dormant networks and who's behavior is changing based on stimulus allowing for greater opportunity for emergent behavior. In addition, as best Mesa can tell meta-agents is a unique functionality to Mesa, we also want to capitalize on this uniqueness and further build this capability.\n\n### Historical Context \nCurrently, `meta-agents` is a rapidly thrown together prototype. It needs to be enhanced to optimally integrate with Mesa and it needs to allow for greater functionality and optimization.  \n\n### Overall Goals\nDevelop meta-agents to: \n- robust, sustainable, and modular base architecture \n- Determine optimizations meta agent employment and for registry management\n\n### **Getting Started**\n- See the examples [Alliance Formation](https://mesa.readthedocs.io/latest/examples/advanced/alliance_formation.html) and [Warehouse](https://github.com/mesa/mesa-examples/tree/main/examples/warehouse)\n- Be familiar with the [base code ](https://github.com/mesa/mesa/tree/main/mesa/experimental/meta_agents)\n- Build you own meta-agent model\n\n\n### Project Size\n\n* Medium\n\n### Mentors\n\n- **Primary:** Tom (@tpike3)\n- **Backups:** Ewout (@EwoutH)\n\n## Reviving Mesa-examples\n### Summary\nAfter moving core examples to the main Mesa repository ([#2358](https://github.com/projectmesa/mesa/pull/2358)), the [mesa-examples](https://github.com/projectmesa/mesa-examples) repository needs a clear purpose and sustainable maintenance strategy. This project defines what mesa-examples should be, makes it attractive to contribute to and use, and sets up systems to keep examples working over time.\n\n### Motivation\nMesa-examples contains dozens of user-contributed models showcasing different Mesa features and ABM techniques. But without the core examples driving regular maintenance, the repository risks bit rot: examples breaking silently as Mesa evolves, outdated patterns persisting, and contributors uncertain whether their PRs will be reviewed. Meanwhile, users struggle to find examples relevant to their needs or trust that what they find actually works. A healthy examples ecosystem benefits everyone: users get working code to learn from, contributors get their work showcased, and Mesa gets real-world validation of its features.\n\n### Historical Context\nExamples were originally part of the main Mesa repository, then split into mesa-examples to reduce maintenance burden and encourage community contributions. In late 2024, core \"seminal\" examples (Boltzmann Wealth, Wolf-Sheep, Schelling, etc.) were moved back to Mesa ([#2349](https://github.com/projectmesa/mesa/pull/2349), [#2358](https://github.com/projectmesa/mesa/pull/2358)) where they receive full CI testing and guaranteed compatibility. This left mesa-examples as a \"show and tell gallery\" of community models, but without clear guidelines, testing infrastructure, or maintenance commitments. The tracking issue [#2364](https://github.com/projectmesa/mesa/issues/2364) documents the integration work done for core examples; similar attention is now needed for the community repository.\n\n### Overall Goal\nTransform mesa-examples into a thriving community gallery where contributors want to share their models, users can easily find and run working examples, and maintenance stays manageable. This means defining clear standards, building infrastructure to catch breakage early, improving discoverability, and lowering barriers to contribution.\n\n### Potential Approaches\nSeveral questions need answers, and a good proposal might focus on one or more:\n\n* **Keeping examples working:** How do we ensure examples don't silently break? Options include pinned dependencies (requirements.txt or environment.yml per example), version compatibility markers, automated weekly CI against Mesa releases, or compatibility matrices showing which examples work with which Mesa versions.\n* **Making contribution attractive:** What would make someone want to contribute an example? Clear templates, fast PR reviews, recognition (featured examples, contributor credits), lower standards than core Mesa (working > perfect), or themed contribution drives could help.\n* **Improving discoverability:** How do users find relevant examples? Better categorization (by feature, complexity, domain), search/filter on a documentation site, integration with Mesa docs, or a gallery page with screenshots and descriptions could address this.\n* **Sustainable maintenance:** What level of maintenance is realistic? Options range from \"best effort, use environment files\" to \"community maintainers for categories\" to \"automated PRs for simple fixes.\" The answer shapes everything else.\n\nConsider studying how other projects handle community examples: NetLogo's Models Library, Julia's model zoo repositories, or scikit-learn's examples gallery all offer lessons.\n\n### Possible Outcomes\nDepending on the approach, outcomes might include:\n\n- Clear contribution guidelines and templates for mesa-examples\n- CI/CD infrastructure that tests examples against Mesa releases\n- Per-example environment files or version compatibility markers\n- Improved README and documentation with better categorization\n- A gallery or catalog page making examples browsable\n- Automated tools (bots, scripts) to help maintain examples\n- Migration of examples to updated patterns or Mesa versions\n- Analysis of what's working in other ABM example ecosystems\n\nThe specific deliverables should match the problems you choose to tackle.\n\n### Useful skills\nPython packaging and dependency management. Familiarity with CI/CD systems (GitHub Actions). Experience with Mesa or willingness to learn quickly. Technical writing for documentation and guidelines.\n\n### Getting Started\nBrowse [mesa-examples](https://github.com/projectmesa/mesa-examples) and try running several examples: note what works, what breaks, and what's confusing. Read the original discussion in [#2330](https://github.com/projectmesa/mesa/discussions/2330) and the core examples integration ([#2349](https://github.com/projectmesa/mesa/pull/2349), [#2358](https://github.com/projectmesa/mesa/pull/2358)) to understand the history. Look at open PRs and issues in mesa-examples to see what contributors want and where things are stuck. Compare with example galleries in other projects. Then pick an angle that interests you and sketch a concrete plan.\n\n### Suggested size\n- Small (focused on specific aspect)\n- Medium (more broad/integral approach)\n\n_Large might also be possible in consultation mentors_\n### Mentors (committed)\n- Jackie Kazil (@jackiekazil) & Ewout ter Hoeven (@EwoutH)\n\nArchive: \nDiscussions: [Discussion #2927](https://github.com/mesa/mesa/discussions/2927) | [Matrix chat](https://matrix.to/#/#GSoC:matrix.org)"
  },
  {
    "name": "OpenAstronomy",
    "slug": "openastronomy",
    "tagline": "Look at the Universe with the power of Open Source",
    "description": "OpenAstronomy is a collaboration between open source astronomy, astrophysics & heliophysics projects that are used by researchers and software engineers around the world to study our universe either by analysing the data obtained from amazing instruments like the [James Webb Space telescope](https://jwst.nasa.gov/), the [Square Kilometer Array](https://www.skatelescope.org/) or the [Solar Dynamic Observatory](http://sdo.gsfc.nasa.gov/), developing very sophisticated numerical models (eg., [FLASH](http://flash.uchicago.edu/)) or designing interplanetary trajectories for human-made spacecraft. The analysis of such data helps multiple types of research, from being able to forecast solar storms to detecting planets in other stars, to understanding how galaxies are formed to explain the expansion and the origin of the universe.\n\nOpenAstronomy currently consists of [18 projects](https://openastronomy.org/members/) that develop tools, the range of which is wide. \nFor example: \n- [Astropy](https://www.astropy.org/) is a general Python library for astronomy, providing common tools such as celestial coordinates, image processing, tabular data, reading and writing, units and support for astronomy-specific file formats; \n- [SunPy](https://sunpy.org/) provides utilities for obtaining and representing solar physics data, with access to the largest online solar physics data archives and solar specific analysis tools and visualisation code;\n- [Julia Astro](https://juliaastro.org/dev/index.html) is a set of packages for general astronomy and astrophysics analysis using Julia;\n- And more!\n\nAs a single organisation, we strive to strengthen collaborations between each sub-organisation, and at the same time increase the awareness among our users on the capabilities of our \"sister\" projects. With the goal being unification of standards and libraries to enable true multidisciplinary research.",
    "ideas_url": "https://openastronomy.org/gsoc/gsoc2026/#/projects",
    "website_url": "https://openastronomy.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "python",
      "c++",
      "julia"
    ],
    "topic_tags": [
      "image processing",
      "astronomy",
      "data analysis",
      "solar physics",
      "high energy astrophysics"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/openastronomy",
    "ideas_content": "Google Summer of Code\nMembers\nNews and Events\nContributor Blogs\nPyAstro Conference\nEvents Calendar\nProjects\nMentors\nFAQ"
  },
  {
    "name": "MLLAM",
    "slug": "mllam",
    "tagline": "Research software for AI weather forecasting",
    "description": "MLLAM is a collaborative community dedicated to advancing machine learning applications in weather forecasting, specifically for Limited Area Modeling (LAM). The organization hosts several open-source key repositories, including neural-lam, which focuses on neural weather prediction using graph-based models. Members are from various research institutions and national weather services committed to improve weather forecasting at regional, high-resolution scale.",
    "ideas_url": "https://github.com/mllam/neural-lam/wiki/GSoC-ideas",
    "website_url": "https://github.com/mllam",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "numpy",
      "pytorch",
      "xarray",
      "Zarr"
    ],
    "topic_tags": [
      "machine learning",
      "ai",
      "deep learning",
      "earth science",
      "Weather Forecasting"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/mllam",
    "ideas_content": "# neural-lam\n\n<img src=\"\nhttps://raw.githubusercontent.com/joeloskarsson/neural-lam-dev/refs/heads/extra-figures/figures/overview.png\" width=\"800\">\n\n## About neural-lam and the MLLAM community\n\nMLLAM is a collaborative community dedicated to advancing machine learning applications in weather forecasting, specifically for Limited Area Modeling (LAM). The organization hosts several open-source key repositories, including neural-lam, which focuses on neural weather prediction using graph-based models. Members are from various research institutions and national weather services committed to improve weather forecasting at regional, high-resolution scale.\n\n### Policy on the use of AI tooling\nWe generally allow the use of AI tools to write, edit and review source code, but each contributor is fully responsible for their code. This means that everyone must understand all the code they contribute, and be able to argue why the design choices made are suitable (no \"vibe-coding\").\n\n# Getting started\nIf you plan to become a GSoC contributor, we encourage you to\n* contact us early to show your interest in a project idea (join e.g. the `GSoC` slack channel at https://kutt.it/mllam)\n* look through the current list of issues and identify one that you want to solve to get familiar with the project. You likely want to choose one that is marked as good-first-issue\n* comment on the issue and request to be assigned to the issue so that we can make sure only one person is working on each issue. If we do not see any progress within 7 days (e.g. by opening a PR and actively engage in the conversation) we might re-assign the issue again.\n* open a pull request and discuss your contributions with the maintainers\n\n\n# Writing the Proposal\n**Deadline to upload proposal at https://summerofcode.withgoogle.com/ is [March 31 18:00 UTC](https://developers.google.com/open-source/gsoc/timeline#march_31_-_1800_utc)!**\n\n- Select a project idea (see below) and write a detailed proposal (in advance!). You can use [this template](https://github.com/python-gsoc/python-gsoc.github.io/blob/master/ApplicationTemplate.md) as inspiration, as well as the [GSoC guide](https://google.github.io/gsocguides/student/writing-a-proposal).\n- Plan your prepwork for the community bonding period (eg. a Proof-Of-Concept)\n- Define milestones for each evaluation phase (i.e. Prototype, Pilot / Final Demo)\n- Plan you weekly work & deliverables (tasking out: high-level goals for each milestone)\n- Describe the acceptance criteria (\"Minimum Viable Product\" of each phase)\n- Share an early draft and discuss your approach in the group with mentors. We are here to help! Do not forget to submit your application to the [Google system](https://summerofcode.withgoogle.com/) when ready, some days before the deadline (the server can be overloaded at last minute).\n\n# Project ideas\n\nHere is a list of projects we think are interesting and can be managed within the time-frame of the Google Summer of Code:\n\n## 1. Flexible graph construction\n\nNeural-LAM supports already a variety of graphs like multi-scale and hierarchical graphs in rectangular and triangular arrangements. The training data might however be on a different grid, which can lead to non-optimal alignments of the neural network architectural grid and the data grid. The challenge is to explore and implement a methodology that can create well-balanced neural network grids based on different data structures, from irregularly structured atmospheric model output to sparse ship-observations.\n\n- **Skills**: Shell, Python, familiarity with [PyTorch](https://pytorch.org/) is highly beneficial.\n- **Difficulty**: Medium\n- **Project length**: 350 hour\n- **Potential mentors**: Hauke Schulz ([@observingClouds](https://github.com/observingClouds)), Leif Denby ([@leifdenby](https://github.com/leifdenby)), Joel Oskarson ([@joeloskarsson](https://github.com/joeloskarsson))\n\nRelated issues are: [#164](https://github.com/mllam/neural-lam/issues/164), [weather-model-graphs](https://github.com/mllam/weather-model-graphs/issues)\n\n## 2. Automatic generation of documentation from source code files\n\nOne of the challenges for users of the neural-lam codebase is that much of the documentation of different functions and constructs can only be found within the code. The project would strongly benefit from having a separate documentation system set up, where both much of the information currently in the readme could be found, but also a structured presentation of the API. Since much of the codebase contains well-written Python docstrings, it should be possible to use automatic tools to generate documentation pages from these. Such a documentation system should also be integrated in the CI/CD workflow, to be updated when new changes are merged.\n\n- **Skills**: Shell, Python\n- **Difficulty**: Medium\n- **Project length**: 175 hour\n- **Potential mentors**: Hauke Schulz ([@observingClouds](https://github.com/observingClouds)), Leif Denby ([@leifdenby](https://github.com/leifdenby)), Joel Oskarson ([@joeloskarsson](https://github.com/joeloskarsson))\n\nRelated issues are: https://github.com/mllam/neural-lam/issues/61 https://github.com/mllam/neural-lam/issues/69\n\n## 3. Generalizing to probabilistic forecasting models\n\nThe scientific field of neural weather prediction is increasingly moving towards probabilistic model formulations. In these approaches, generative machine learning is used to produce ensemble forecasts representing different possible outcomes. Here the neural-lam codebase has earlier been leveraged in research projects to build such probabilistic models (see e.g. https://arxiv.org/abs/2406.04759 and https://arxiv.org/abs/2502.07532). However, these new ideas and models rarely find their way back to the main repository due to the big discrepancy with how the codebase is currently structured. To allow for such probabilistic models, parts of the neural-lam model code would need to be generalized for models that can sample different possible forecasts, rather than just giving a single prediction. This includes changing how forecasts are being produced, visualized and evaluated.\n\n- **Skills**: Python, PyTorch\n- **Difficulty**: Large\n- **Project length**: 350 hour\n- **Potential mentors**: Joel Oskarson ([@joeloskarsson](https://github.com/joeloskarsson)), Hauke Schulz ([@observingClouds](https://github.com/observingClouds)), Leif Denby ([@leifdenby](https://github.com/leifdenby))\n\nRelated issues are: https://github.com/mllam/neural-lam/issues/49 https://github.com/mllam/neural-lam/issues/62\n\n## 4. Global weather forecasting\n\nNeural-lam was mainly designed with regional, limited-area, forecasting in mind, integrating boundary conditions around the region. However, global weather forecasting is really just a special case of this, where the region is the whole earth and there are no boundary conditions. Still, some changes are needed in the codebase in order to make this work frictionless. The major challenge with enabling global forecasting is the need to construct a global graph for the Graph Neural Network models to work on. There are multiple options for this, including writing code for such graph-generation ourselves or building in a connection to suitable third-party libraries.\n\n- **Skills**: Python, PyTorch, PyTorch Geometric and [xarray](xarray.pydata.org) are highly beneficial\n- **Difficulty**: Medium\n- **Project length**: 175 hour\n- **Potential mentors**: Joel Oskarson ([@joeloskarsson](https://github.com/joeloskarsson)), Hauke Schulz ([@observingClouds](https://github.com/observingClouds)), Leif Denby ([@leifdenby](https://github.com/leifdenby))\n\nRelated issues are: https://github.com/mllam/neural-lam/issues/63"
  },
  {
    "name": "Measurement Lab",
    "slug": "measurement-lab",
    "tagline": "Providing Internet performance data since 2009.",
    "description": "Founded in 2009, Measurement Lab (M-Lab) is an open platform for studying Internet performance and neutrality over time. We provide public, transparent data to empower researchers, policymakers, and open Internet advocates to make informed decisions about Internet infrastructure and policies.",
    "ideas_url": "https://github.com/m-lab/gsoc",
    "website_url": "https://www.measurementlab.net/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "html",
      "sql",
      "css"
    ],
    "topic_tags": [
      "data analysis",
      "speed test",
      "Internet measurements",
      "Internet quality"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/measurement-lab",
    "ideas_content": "Welcome to M-Lab's Google Summer of Code page! We're excited to have you here and look forward to working with talented contributors from around the world.\n\nMeasurement Lab (M-Lab) [https://www.measurementlab.net/](https://www.measurementlab.net/) is an open source project with contributors from civil society organizations, educational institutions, and private sector companies dedicated to:\n\n- Providing an open, verifiable measurement platform for global network performance\n- Hosting the largest open Internet performance dataset on the planet\n- Creating visualizations and tools to help people make sense of Internet performance\n\n**Mentorship**: Work closely with experienced developers and active community members**Real Impact**: M-Lab's tools are used by a large community of researchers, policymakers, and open Internet advocates. Your contributions can become a core part of M-Lab's tools.**Skill Development**: Gain hands-on experience with Python, JavaScript and other Web technologies, large datasets (SQL, BigQuery)**Open Source**: All work is open source and publicly available\n\nBefore applying, we strongly encourage you to:\n\n- Explore our\n[main repository](https://github.com/orgs/m-lab/repositories)and the repositories of the proposed projects (see below) - Visit our\n[website](https://www.measurementlab.net/)and read about our[activities](https://www.measurementlab.net/about/),[news](https://www.measurementlab.net/blog/), and documentation of our[tools](https://www.measurementlab.net/tests/)and[data](https://www.measurementlab.net/data/) - Join our communication channels:\n- Mailing list:\n[link](https://groups.google.com/a/measurementlab.net/g/discuss)\n\n- Mailing list:\n\nWe are looking for applicants who:\n\n- Carefully study our project ideas\n- Develop an initial technical proposal or idea\n- Think critically about scope, feasibility, and implementation\n- Contact us with a structured, well-prepared message\n\nWe strongly discourage:\n\n- ❌ Contacting us just to “introduce yourself” without having done prior research\n- ❌ Submitting AI-generated or low-effort PRs\n- ❌ Submitting drive-by PRs just to “show activity”\n\nQuality of thinking matters far more than quantity of commits.\n\nHow to engage with us:\n\n- You may contact us at\n[support@measurementlab.net](mailto:support@measurementlab.net). Please begin your email subject withfollowed by a concise project title.`[GSoC2026]`\n\n- Kindly\n**do not**post proposal ideas directly to the[mailing list](https://groups.google.com/a/measurementlab.net/g/discuss). - Please note that, due to limited mentor availability, we may not be able to respond to all inquiries—particularly those that do not demonstrate prior research or substantive preparation.\n\nA strong proposal should include:\n\n**Personal Information**: Name, contact details, time zone, GitHub username**Background**: Your relevant experience, skills, and courses**Project Selection**: Which project idea(s) interest you and why**Project Plan**:- Clear objectives and deliverables\n- Weekly timeline with milestones\n- Technical approach and implementation details\n- Testing strategy\n- Documentation plan\n\n**Availability**: Expected hours per week, any planned absences**Why You**: What makes you a good fit for this project**Post-GSoC**: Your plans for continued involvement\n\n- Application period: Feb 19 to Mar 31 (see official\n[timeline](https://developers.google.com/open-source/gsoc/timeline)) - Submit through the\n[official GSoC website](https://summerofcode.withgoogle.com/) - Deadline: 31 March 2026\n- You may submit up to 3 proposals total (across all organizations)\n\n**Be respectful**: Follow our Code of Conduct**Be patient**: Mentors are volunteers and may take time to respond**Be proactive**: Don't wait to be told what to do**Ask smart questions**: Show what you've already tried**Use public channels**: So others can learn and help too\n\nBelow are project ideas for GSoC 2026. These are starting points - we encourage you to propose your own ideas or variations on these themes!\n\n**Difficulty Levels:**\n\n- 🟢 Easy (90 hours) - Good for first-time GSoC participants\n- 🟡 Medium (175 hours) - Requires some project familiarity\n- 🔴 Hard (350 hours) - Complex projects requiring deep expertise\n\n**Difficulty**: 🟡 Medium (175 hours)\n\n**Mentor(s)**: Pavlos Sermpezis, Roberto D'Auria, Simone Basso\n**Skills Required**: Python 3.10+, Docker, Poetry, Git, CI/CD (GitHub Actions), Network measurement\n\n**Difficulty**: 🔴 Hard (350 hours)\n\n**Mentor(s)**: Pavlos Sermpezis, Roberto D'Auria, Simone Basso\n\n**Skills Required**: Python, Data Visualization (Plotly), Streamlit, Pandas\n\n**Skills Preferred**: Geographic data visualization, BigQuery/SQL, UX/UI design, Statistics\n\nThe Internet Quality Barometer (IQB) is M-Lab's comprehensive framework for measuring Internet performance across various use cases (web browsing, video streaming, gaming, etc.). Unlike simple \"speed tests,\" IQB calculates a composite score reflecting the quality of Internet experience holistically. Currently, IQB has a prototype Streamlit application for applying the framework, but it lacks comprehensive dashboards for analyzing and comparing ISP performance across geographic regions.\n\nThis project involves extending the IQB platform by creating interactive, user-friendly dashboards that provide actionable insights into ISP performance. You'll design and implement visualizations that allow users to compare ISPs within countries and cities, identify performance trends, and make informed decisions about Internet service quality. The dashboards should serve multiple user personas: consumers choosing ISPs, researchers studying Internet quality, policymakers monitoring infrastructure, and ISPs benchmarking their performance.\n\nYou'll work with M-Lab's extensive measurement dataset, implement statistical aggregations, create interactive geographic visualizations, and design intuitive comparison tools. This is an opportunity to impact how millions understand and choose their Internet services based on real measurement data.\n\n**ISP Performance Dashboard**: Create a comprehensive dashboard showing ISP performance metrics (IQB score, latency, throughput, packet loss) with time-series trends, percentile distributions, and sample size indicators**Geographic Comparison Tool**: Build interactive map-based visualizations showing ISP performance across countries, regions, and cities with drill-down capabilities and geographic heatmaps**ISP Head-to-Head Comparison**: Implement a side-by-side comparison feature allowing users to compare 2-5 ISPs across multiple metrics with statistical significance testing**Use Case Performance Analysis**: Create specialized views showing how ISPs perform for specific use cases (video streaming, gaming, video conferencing, web browsing) based on IQB's multi-dimensional framework**Data Export and Reporting**: Add functionality to export visualizations, generate PDF reports, and download filtered datasets for further analysis**User Experience Design**: Design an intuitive interface with responsive layouts, clear data presentation, and guided workflows for different user types**Performance Optimization**: Implement efficient data caching, lazy loading, and aggregation strategies to handle large M-Lab datasets without lag**Documentation**: Create user guides, API documentation, and developer documentation for extending the dashboard system\n\n**Difficulty**: 🟡 Medium (175 hours)\n\n**Mentor(s)**: Pavlos Sermpezis, Roberto D'Auria, Simone Basso\n\n**Skills Required**: JavaScript, Angular.js, HTML/CSS, REST APIs\n\nM-Lab's speed test at speed.measurementlab.net is one of the most widely used open-source Internet measurement tools globally. Currently, after running a test, users receive basic metrics (download/upload speeds, latency) but limited context about what these numbers mean or how they compare to others. This project enhances the results page to provide actionable insights and meaningful comparisons.\n\nYou'll extend the speed test interface to calculate and display IQB (Internet Quality Barometer) scores based on test results, explain what the results mean for different use cases (streaming, gaming, video calls), and show how the user's performance compares to their ISP's average and regional benchmarks. This makes the speed test results more meaningful and helps users understand their Internet quality in practical terms.\n\n**Difficulty**: 🔴 Hard (350 hours)\n\n**Mentor(s)**: Pavlos Sermpezis, Roberto D'Auria, Simone Basso\n\n**Skills Required**: JavaScript, HTML/CSS, REST APIs, Authentication (OAuth/Firebase Auth), Database design, Data visualization, Security best practices\n\nThis extended version of Project 3A includes all the features from the medium project (IQB scores, insights, comparisons) plus a comprehensive user authentication system and personalized dashboard for tracking measurement history over time.\n\nUsers will be able to create accounts, run tests while logged in, and access a personal dashboard showing their historical test results, trends over time, comparisons across different locations/networks, and personalized recommendations. This transforms the speed test from a one-time measurement tool into a long-term monitoring solution that helps users track their Internet quality, identify patterns, and make informed decisions about their service.\n\nYou'll implement secure user authentication, design a database schema for storing user measurements, build a personal dashboard with rich visualizations, ensure privacy compliance (GDPR, data retention policies), and maintain the existing functionality for anonymous users who don't want to create accounts.\n\nWe evaluate proposals based on:\n\n**Prior engagement**: Contributions to our project, community participation**Proposal quality**: Clear goals, realistic timeline, technical soundness**Communication**: Clarity, responsiveness, professionalism**Relevant experience**: Skills and background relevant to the project\n\nNo, GSoC allows you to work on only one project. However, you can submit proposals for up to 3 different projects across all organizations.\n\nAbsolutely! We have projects for all skill levels. Start with our \"good first issues\" and don't hesitate to ask questions.\n\nThis depends on the project. See individual project descriptions for required and preferred skills.\n\nWhile not mandatory, prior contributions significantly strengthen your application and help you understand our workflow.\n\nCommunication is key. If you face challenges, reach out to your mentors immediately. We're here to help you succeed.\n\nGSoC is open to new open-source contributors who are 18 years or older. You don't need to be enrolled in a university.\n\n**Good luck with your application!** 🚀"
  },
  {
    "name": "GNU Compiler Collection (GCC)",
    "slug": "gnu-compiler-collection-gcc",
    "tagline": "GNU compilers",
    "description": "The GNU Compiler Collection (GCC) is an optimizing compiler produced by the GNU Project supporting various programming languages, hardware architectures and operating systems. It includes front-ends for C, C++, D, Objective-C, Fortran, Ada, and Go, as well as libraries for these languages (such as libgcc and libstdc++). Modula-2, Rust, Cobol, and Algol 68 front-ends are under development too.  GCC includes a Static Analyzer, and supports OpenMP, OpenACC with code offloading to Nvidia and AMD GPUs.",
    "ideas_url": "https://gcc.gnu.org/wiki/SummerOfCode",
    "website_url": "https://gcc.gnu.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c/c++",
      "gnu make",
      "gnu autotools"
    ],
    "topic_tags": [
      "compilers",
      "developer tools",
      "toolchain",
      "openmp",
      "link time optimization"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/gnu-compiler-collection-gcc",
    "ideas_content": "Making sure you're not a bot!\nLoading...\nPlease wait a moment while we ensure the security of your connection."
  },
  {
    "name": "gprMax",
    "slug": "gprmax",
    "tagline": "Simulating electromagnetic wave propagation",
    "description": "gprMax is open source software that simulates electromagnetic wave propagation. It uses Yee's algorithm to solve Maxwell’s equations in 3D using the Finite-Difference Time-Domain (FDTD) method.\n\nIt is designed for simulating Ground Penetrating Radar (GPR) and is used to model electromagnetic wave propagation in fields such as engineering, geophysics, archaeology, and medicine. There are a wide range of applications from assessing infrastructure such as bridges and roads, locating buried utilities, mapping glaciers, finding anti-personnel landmines, to detecting tumours in the human body, and exploring the sub-surface of Mars and the Moon.\n\ngprMax is command-line-driven software written in Python with performance-critical parts written in Cython. It does not currently feature a graphical user interface (GUI) which allows it to be very flexible and scriptable software that can run in high-performance computing (HPC) environments, i.e. on supercomputers.\n\ngprMax can be run on either CPU or GPU. The CPU solver has been parallelised using OpenMP which enables it to run on multi-core CPUs. The GPU solver has been developed using the NVIDIA CUDA programming model. gprMax also features a Messaging Passing Interface (MPI) task farm, which can operate with CPU nodes or multiple GPUs.",
    "ideas_url": "https://github.com/gprMax/GSoC/blob/main/project-ideas-2026.md",
    "website_url": "https://www.gprmax.com",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "cuda",
      "openmp",
      "mpi",
      "opencl"
    ],
    "topic_tags": [
      "science",
      "engineering",
      "geophysics",
      "electromagnetics",
      "ground penetrating radar"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/gprmax",
    "ideas_content": "# GSoC 2026 - Project Ideas List\n\ngprMax is hoping to participate in the [Google Summer of Code](https://summerofcode.withgoogle.com) 2026 program, following successful GSoCs in 2019, 2021, 2023, 2024, and 2025. \n\nBelow is list of some potential project ideas (in no particular order). These ideas have been discussed with all mentors in our team: \n- Dr Craig Warren\n- Professor Antonis Giannopoulos\n- Dr Iraklis Giannakis\n- Miss Petroula Karacosta\n- Mr Zach Wilson\n\nIf a project is successfully selected you will be allocated a primary mentor and supported by the rest of the team. If you are interested in learning more about a particular project idea please contact us using [info@gprmax.com](mailto:info@gprmax.com) or on our [Zulip channel](https://gprmax.zulipchat.com/join/stpagw5qy775k7p2tcjkkk4q/). \n\n## Statement on Responsible Use of AI in GSoC 2026 for gprMax\n\nWe understand that AI tools like large language models have become helpful resources in many aspects of work and learning, including proposal writing. We want to support you in using these tools responsibly while ensuring your proposal genuinely represents you.\n\n**Ways AI Can Help:**\nAI tools can be wonderful for checking grammar, improving clarity, exploring ideas, learning new concepts, and refining your writing. We encourage you to use these tools as learning partners that help you develop and express your ideas more effectively.\n\n**What We're Looking For:**\n- Proposals that reflect your authentic understanding and enthusiasm for the project\n- Technical approaches that align with your actual skill level and that you're prepared to implement\n- A genuine sense of who you are as a contributor and what you bring to the project\n- Transparency about your capabilities so mentors can provide appropriate guidance and support\n\n**What to Avoid:**\n- Relying on AI to generate content you don't fully understand or can't explain\n- Presenting technical solutions or experience levels that don't match your actual abilities\n- Submitting work that doesn't reflect your own voice and thinking\n\n**Why This Matters:**\nThe proposal process helps us match contributors with projects where they'll thrive and learn. When your proposal authentically represents your skills and interests, we can create better mentorship pairings and set everyone up for a successful, rewarding summer. We're excited to see your genuine ideas and to support your growth throughout GSoC.\n\n\n## Project 1. GPU Acceleration of Plane Wave Source Formulations in gprMax\n\ngprMax is one of the few open-source FDTD solvers that leverages a ragne of GPUs to accelerate the main FDTD update kernels. \nHowever, our relatively new addition of a Plane Wave (TF/SF) excitation source, using the Discrete Plane Wave (DPW) formulation, \nthat was initially developed during a previous GSoC project, remains as an only CPU-based solver implementation using Cython. \n\nThis project aims to port this (TF/SF) plane wave injection source to the GPU solvers of gprMax, \nensuring that the entire simulation pipeline remains on the GPU, minimizing data transfer between CPU and GPU \nand maximizing throughput.\n\n**Objectives & Deliverables:**\nDevelop GPU kernels - prioritising CUDA - to handle the injection of the incident field at the TF/SF interfaces.\nMove the DPW 1D FDTD auxiliary Cython update (used to calculate the incident field) to the GPU.\nOptimise the storage, as needed, of the TF/SF boundary fields to ensure coalesced memory access during the main update loop.\nCreate a small testing suite of simple models to compare the GPU-accelerated plane wave results against the existing Cython implementation to ensure numerical consistency.\n\n**Expected outcome:** Enable the use of TF/SF sources when the user executes gprMax on a GPU \n\n**Skills required:** Python, GPU programming using Python bindings \n\n**Difficulty:** Medium\n\n**Length:** 350 hours\n\n\n## Project 2. Reactive Simulation & Analytics: Integrating marimo with gprMax\n\ngprMax users typically interact with the software via terminal commands or by using\nstatic Jupyter notebooks. Although, Jupyter notebooks are very convenient workflows based on them can \nlead to errors when parameters are changed out of order and feel cumbersome to the user. Equally, terminal \nbased execution does not allow for an integrated simulation experience as it offers very limited data analysis.\n \nThis project aims to build a reactive, web-based dashboarding interface for gprMax using [marimo](https://marimo.io/).\n\nBy integrating marimo, we will provide users with a new concept of a \"computational notebook\" that doubles \nas an interactive GUI for building models, monitoring simulations in real-time, and performing \nsimple data post-processing (A-scan/B-scan analysis) with synchronised plotting. The aim is to build an \ninitial framework that can also be easily extended in future by its users. \n\n\n**Objectives & Deliverables:**\nCreate a marimo-based UI where users can adjust physical parameters (permittivity, geometry, antenna position) via sliders and see the gprMax commands or API calls \nor model preview update instantly.\nDevelop a reactive hook to track gprMax log files or output arrays, updating a progress bar and some selected field-preview within the notebook.\nBuild a library of marimo-native components for gprMax post-processing, including:\nCreate a set of \"Reactive Recipes\" for common modelling and data analysis scenarios (e.g., A-Scan or B-Scan modelling, Antenna parameters calculations, etc.).\n\n\n**Expected outcome:** A reactive notebook interface for better user experience and easier adoption of gprMax for electromagnetic simulations.\n\n**Skills required:** Python and good proficiency in numerical stacks (e.g. NumPy, Pandas, H5py), Experience with reactive programming concepts (preferably using marimo). \nFamiliarity with data visualisation using Python (Plotly, Matplotlib, or Bokeh). Some basic understanding of GPR related gprMax outputs (A-Scans, B-Scans, etc.)\n\n**Difficulty:** Medium\n\n**Length:** 350 hours\n\n\n## Project 3. Building a Comprehensive Test Suite\n\nCurrently, the project lacks comprehensive automated testing, making it difficult to catch bugs and verify that code changes work correctly. This project will create a solid foundation of automated tests to make gprMax more reliable and easier to develop.\n\n**Objectives & Deliverables:**\nWrite unit tests for core gprMax functions\nCreate validation tests that check if physics calculations are correct\nMake sure tests work on different operating systems (Windows, Linux, macOS)\n\n**Expected outcome:** A working test suite with tests covering the most important parts of gprMax, making it safer and easier for developers to improve the code. \n\n**Skills required:** Python, basic familiarity with testing (pytest is a bonus) \n\n**Difficulty:** Medium\n\n**Length:** 350 hours\n\n\n## Project 4. Implementing CI/CD Automation\n\nThis project will modernise gprMax's development workflow by implementing Continuous Integration and Continuous Deployment (CI/CD) using GitHub Actions. You'll automate testing, improve the build process, and make it easier for new contributors to participate in the project.\n\n**Objectives & Deliverables:**\nGitHub Actions workflows that automatically test code changes\nPre-commit hooks and automated code quality checks\nRefactored build scripts supporting different backends (CPU-only, MPI, CUDA)\n\n**Expected outcome:** An automated development pipeline that reduces manual work, speeds up code reviews, and makes gprMax more accessible to both contributors and users. \n\n**Skills required:** Python, GitHub workflows \n\n**Difficulty:** Medium\n\n**Length:** 350 hours"
  },
  {
    "name": "Genome Assembly and Annotation",
    "slug": "genome-assembly-and-annotation",
    "tagline": "Unleashing the potential of big data in biology",
    "description": "EMBL-EBI is a global centre for biological data, developing and maintaining open data resources and open-source software that support life science research worldwide. Our services are used daily by researchers across academia, healthcare, and industry, and span genomics, transcriptomics, metagenomics, molecular interactions, chemistry, and functional annotation.\n\nEMBL-EBI develops and maintains a wide range of long-standing, high-impact resources, including Ensembl for genome data, the European Nucleotide Archive (ENA) for sequence data, MGnify for metagenomics analysis, and BioStudies for structured biological datasets. Together, these resources support data submission, analysis, integration, and reuse at global scale.\n\nGiven the rapid growth and increasing complexity of biological data, EMBL-EBI operates a fast-evolving software ecosystem and continuously explores new approaches to data processing, storage, distribution, and visualisation. Our codebases are open source, our data are freely available, and we actively engage with the open-source community to ensure our infrastructure remains robust, scalable, and accessible.\n\nThrough Google Summer of Code, EMBL-EBI offers contributors the opportunity to work on real-world scientific software, gaining experience in open-source development while contributing to tools and resources used by the global life science community.",
    "ideas_url": "https://www.ebi.ac.uk/about/events/events/public-event/2025/2026-google-summer-of-code/",
    "website_url": "https://www.ebi.ac.uk/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "mysql",
      "docker",
      "pytorch",
      "nextflow"
    ],
    "topic_tags": [
      "machine learning",
      "genomics",
      "big data",
      "cloud",
      "hpc"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/genome-assembly-and-annotation",
    "ideas_content": "Public event/Ext Seminar event | Other\n\nEMBL-EBI is a global leader in biological data. We develop and maintain open data resources and open-source software that support life science research worldwide. Our teams work at the intersection of biology, data science, and software engineering, building tools used daily by researchers across academia, healthcare, and industry.\n\nThrough Google Summer of Code (GSoC), EMBL-EBI mentors contributors to work on real-world open-source projects, helping them develop technical skills, domain knowledge, and experience contributing to widely used scientific software. The project ideas listed below reflect the breadth of work across EMBL-EBI and are designed to support contributors at different experience levels.\n\nHow to apply\n\nGoogle Summer of Code contributors apply directly through the GSoC platform, but we strongly encourage you to engage with EMBL-EBI **before** submitting your application.\n\n**Step 1: Explore the project ideas**Review the project ideas listed below and identify one (or more) that match your interests and skills. Each project includes information about expected outcomes, required skills, and difficulty level.\n\n**Step 2: Do some background reading** You are not expected to be an expert in the domain, but spending some time familiarising yourself with the relevant technologies, data resources, or scientific context will help you prepare a stronger application.\n\n**Step 3: Get in touch with us early** Once you have a project in mind, contact our GSoC helpdesk (\n\n- a short CV or link to relevant experience (e.g. GitHub, portfolio)\n- the project you are interested in\n- a brief explanation of why you are interested\n- any specific questions you may have\n\nIf you are interested in proposing your own project idea, include a short description and the technologies you expect to use so we can assess mentor availability.\n\n**Step 4: Draft your application** Prepare your application well ahead of the deadline. A strong proposal clearly explains:\n\n- what you plan to build\n- how you will approach the work\n- a realistic timeline with milestones\n- what you hope to learn during the project\n\nMentors can provide guidance and feedback, but they will not write the application for you.\n\n**Step 5: Incorporate feedback and submit** Use any feedback provided to refine your proposal, then submit your final application via the official GSoC website before the deadline.\n\nFor more detailed advice, please see our [Contributor Guide](https://www.ebi.ac.uk#contributor-guide), which outlines what we look for in successful applications and how contributors engage with EMBL-EBI teams during the programme.\n\n[Expose a subset of ENA REST Services as MCP](https://www.ebi.ac.uk#project-1)[Creating a knowledge graph from a subset of ENA and BioSamples data](https://www.ebi.ac.uk#project-2)[Annotation metrics reporting & analysis modules for the Ensembl Assembly/Annotation tracking app](https://www.ebi.ac.uk#project-3)[Development of a refinement tool to identify selenoproteins in Ensembl genesets](https://www.ebi.ac.uk#project-4)[Expanding a pipeline for small non-coding RNA (sncRNA) identification in Ensembl Genomes](https://www.ebi.ac.uk#project-5)[Expand genome metadata in Ensembl with AI tools](https://www.ebi.ac.uk#project-6)[BUSCO-Missing Investigator (BMI): a reproducible pipeline to explain “missing/fragmented BUSCOs”](https://www.ebi.ac.uk#project-7)[Ask VEPai. Trained chatbot interface for Ensembl VEP web.](https://www.ebi.ac.uk#project-8)[nf-core/vep: Extending and standardising Ensembl VEP workflow for nf-core](https://www.ebi.ac.uk#project-9)[Building a perturbation-aware LLM for multimodal](https://www.ebi.ac.uk#project-10)*in-silico*perturbation modelling[Designing an open access Ensembl GraphQL Workshop](https://www.ebi.ac.uk#project-11)[Standardised evaluation for microbiome dataset classifiers](https://www.ebi.ac.uk#project-12)[Sequence similarity networks for the visualisation and exploration of MGnify Proteins](https://www.ebi.ac.uk#project-13)[A genomic feature database in the browser](https://www.ebi.ac.uk#project-14)[Design and API-aware UI generation using MCP servers and Figma APIs](https://www.ebi.ac.uk#project-15)[Expose BioSamples Submission and Search Capabilities as MCP Tools for AI-Assisted Metadata Interaction](https://www.ebi.ac.uk#project-16)\n\n**Brief Explanation**\n\nThe European Nucleotide Archive (ENA) provides a rich set of REST APIs that allow users to query genomic metadata, sequence records, and submission information. While these APIs are powerful, they are not directly accessible to modern AI agents or LLM-based tools that rely on standardized interaction protocols.\n\nThis project aims to expose a carefully selected subset of ENA REST services through the **Model Context Protocol (MCP)**, enabling AI agents to interact with ENA programmatically in a safe, structured, and reproducible way. MCP acts as a bridge between large language models and external tools by defining explicit schemas, inputs, and outputs, preventing hallucinations and ensuring reliable access to authoritative data sources.\n\nThe student will design and implement an MCP server that wraps ENA REST endpoints (e.g. study metadata lookup, run/sample queries, accession search) and exposes them as well-defined MCP tools. The project focuses on correctness, usability, and extensibility rather than deep bioinformatics analysis.\n\nThis project is intentionally scoped to be beginner-friendly, with limited bioinformatics background required, and emphasizes software engineering, API design, and AI-tool integration.\n\n**Expected results**\n\n- A production-ready MCP server exposing a broad subset of ENA REST APIs\n- Demonstrations of:\n- LLM or agent-based querying of ENA via MCP\n- Deterministic, traceable responses backed by ENA data\n- A scalable foundation that can be extended to other EMBL-EBI data resources\n\n- Comprehensive documentation, including:\n- Architecture and design decisions\n- MCP tool specifications, Examples of AI agent workflows using ENA MCP tools\n\n- Support for advanced capabilities such as:\n- Composing multiple ENA queries into a single logical operation\n- Normalizing heterogeneous ENA responses into consistent formats\n- Caching and rate-limit-aware request handling\n\n- Well-designed MCP tool schemas with:\n- Strong input validation, explicit output contracts, clear error semantics\n\n\nRequired knowledge\n\n- Strong Python programming skills\n- REST APIs, HTTP, and JSON\n- Software architecture and modular design\n- Schema definition and validation\n\nDesirable knowledge\n\n- Familiarity with MCP or LLM tool/function calling\n- API performance optimization and caching strategies\n- Experience with containerization (Docker) or CI/CD pipelines\n\nDifficulty\n\nMedium\n\nLength\n\nMedium – 175h\n\nMentors\n\n**Brief explanation**\n\nEuropean Nucleotide Archive (ENA), one of the three major nucleotide databases in the world, is hosting over 70 PB of genomics data. LLMs are well-developed to parse unstructured data but less so with the structured data.\n\nThis project is to create a prototype of a knowledge graph (KG) to make the database directly accessible to AI tools. A graph engine will be integrated with the existing structured data store to avoid duplicating data into a graph database. An AI-friendly Graph Query Language (GQL) will be used to interact with the KG backed by the relational data model via the graph engine dynamically. High profile LLM models are to be evaluated to generate GQL statements. The final output will be one or more AI agents to support Graph RAG to interact with a subset of the structured genomics data in ENA with the following characteristics:\n\n- A working prototype capable of querying a small subset of ENA data (e.g. pathogen, AMR or data deposition analytics).\n- A clear path to scale up the prototype to expand to all structured data in ENA.\n- AI agent(s) with absolutely no hallucination.\n\n**Expected results**\n\n- Students would learn how AI components are used to construct agent workflows.\n- Students would gain firsthand experience how to create working prototypes beyond “hello-world” toys.\n- Students would be able to create standalone AI agents capable of interacting with ENA data but with minimum dependency.\n- Students would be able to apply the knowledge learned in the summer school to create Graph RAGs on any structured data.\n\n**Required knowledge**\n\n- AI-friendly GQL (e.g. Gremlin)\n- Graph engine (e.g. PuppyGraph)\n- Python and libraries for AI-agent construction (e.g. LangChain)\n- Methodology for benchmarking Graph RAG and GQL\n\n**Desirable knowledge**\n\n- ENA schema and tagging mechanism\n- Kubernetes and its scaling\n- Scalable local deployment of LLM models (e.g. Ollama)\n\n**Difficulty**: High\n\n**Length**: 350h\n\n**Mentors**: [David Yuan](mailto: davidyuan@ebi.ac.uk)\n\n**Brief explanation**\n\nEnsembl maintains an internal web application to track genome assembly status (e.g. candidates for annotation), Ensembl annotation status, and associated quality/completeness metrics. While the app stores important annotation completeness scores and other quantitative measures, it currently lacks richer reporting and comparative views that help users quickly interpret genome annotation quality across many species.\n\nThis project focuses on designing and implementing Python-based analysis modules for genome annotation metrics and comparative analysis, with a strong emphasis on clean workflows, test coverage, and maintainability. These modules will generate per-genome reports and perform comparative analyses across taxonomic groupings, enabling annotators and production teams to identify unusual annotations, trends, and priorities in a reproducible and testable way.\n\nThere is an opportunity to integrate the resulting modules into the existing tracking web application, but web/UI integration is not essential to the core project. The primary goal is to produce robust, well-tested backend analysis components that can later be surfaced via the app or reused in other contexts (e.g. batch reporting, pipelines).\n\n**Expected results**\n\nDeliverable 1: Per-genome annotation metrics report module\n\n- Develop a Python module that generates a structured metrics report for a single genome, based on the existing data model.\n- The report should include (as available in the stored data model), for example:\n- annotation completeness scores (and/or component sub-scores)\n- number of protein-coding genes/transcripts\n- exon counts and distribution summaries (e.g. exons per transcript)\n- gene/transcript length distributions or summary stats\n- any other tracked QC/production metrics already stored\n\n- Include clear tables and a small set of “at-a-glance” visuals (e.g. sparklines, histograms, boxplots, score badges).\n- Unit tests for individual metric calculations\n- Integration tests for full per-genome report generation\n- Clear separation between data access, computation, and presentation layers\n\nDeliverable 2: Taxonomy grouping + comparative analysis module\n\n- Add functionality to group genomes by taxonomic classification at multiple ranks (e.g. species/genus/family/order/class/phylum).\n- Provide controls to select:\n- taxonomic rank\n- comparison set (e.g., “all annotated in Ensembl release X”)\n- metrics to include in analysis\n\n- Implement multivariate analysis (MVA) to identify trends and outliers within each group, e.g.:\n- PCA (or similar dimensionality reduction)\n- clustering (optional, depending on scope and usefulness)\n- outlier detection heuristics (distance-based, robust z-scores, etc.)\n\n- Produce “nice visuals” suitable for production/QC workflows, such as:\n- PCA scatter with interactive point details (genome name, key metrics)\n- heatmaps/correlation views\n- rank-based comparison plots (e.g. boxplots per clade)\n- outlier summary list linking back to the genome report page\n\n\n**Final project output**\n\n- A set of well-documented, reusable Python modules for:\n- per-genome annotation metric reporting\n- taxonomy-based comparative analysis\n\n- Comprehensive test suite covering core logic and analysis workflows\n- Clear documentation describing:\n- module data flow\n- how metrics are computed\n- how to extend the system with new metrics or analyses\n\n- Optional (stretch goal): example integration points or lightweight endpoints demonstrating how the modules could be plugged into the existing tracking web application\n\n**Required knowledge**\n\n- Python for data handling and statistical analysis.\n- Basic understanding of genome annotations and common metrics (genes/transcripts/exons, completeness/QC measures).\n\n**Desirable knowledge**\n\n- Experience with multivariate analysis (PCA, clustering) and practical outlier detection.\n- Familiarity with taxonomy sources/identifiers and rank-based grouping (NCBI taxonomy, etc.).\n- Experience producing clear scientific dashboards/visualisations.\n- Experience working with existing codebases and adding features in a maintainable way (tests, docs, code style).\n- Experience designing clean APIs and modular analysis code\n- Experience working in existing codebases with an emphasis on testing, documentation, and code quality\n- Familiarity with web application backends or data visualisation, for optional integration work (FastAPI)\n- Familiarity with web application frontends for optional integration work (React/\n[Node.js](http://node.js)) - Interest in product design and design tools (ex. Figma)\n\n**Difficulty**: Beginner\n\n**Length**: 175h\n\n**Mentors**: [Anna Lazar](mailto:lazar@ebi.ac.uk), [Simarpreet Kaur Bhurji](mailto:sbhurji@ebi.ac.uk), [Leanne Haggerty](mailto:leanne@ebi.ac.uk)\n\n**Brief explanation**\n\nSelenocysteine-containing proteins (selenoproteins) play crucial biological roles, but their annotation remains challenging due to the unique incorporation of selenocysteine (Sec, U) at UGA codons. Currently, Ensembl uses Exonerate to align known selenoproteins to genomes and manually verifies models based on sequence identity and coverage. However, the existing approach is inefficient and outdated, requiring a more scalable and automated solution.\n\nThis project will develop a Nextflow pipeline to efficiently annotate selenoproteins that can be applied to Ensembl gene sets by:\n\n- Optimising the search for selenoprotein homologs\n- Aligning known selenoproteins against the genome using more efficient tools like MMseqs2, DIAMOND, or TBLASTN.\n- Filtering candidate regions based on sequence similarity, focusing on high-identity and high-coverage matches.\n\n- Improving selenocysteine validation\n- Detecting UGA codons in aligned models and verifying the presence of SECIS elements (selenocysteine insertion sequences) in downstream regions.\n- Ensuring selenocysteine positions match the reference protein sequences.\n\n- Automated filtering and quality control\n- Retaining only models with expected coverage and sequence identity to known selenoproteins.\n- Benchmarking against accurate but computationally intensive dedicated selenoprotein annotation tools\n- Benchmarking against accurate but computationally intensive dedicated selenoprotein annotation tools\n- Removing false positives by integrating BUSCO-like completeness scoring with clade specific selenoprotein sets.\n- Generating quality assessment reports.\n\n- Deployability and scalability\n- Implementing the pipeline in Nextflow to improve reproducibility and scalability across multiple genomes.\n- Providing Docker/Singularity containers for easy deployment in HPC and cloud environments.\n\n\nThe final pipeline will be integrated within Ensembl’s genome annotation pipeline to be integrated within Ensembl’s genome annotation pipeline to streamline selenoprotein identificationidentification, thus thus improving accuracy, efficiency, and automation.\n\n**Expected results**\n\n- A Nextflow-based selenoprotein annotation pipeline that aligns known selenoproteins and predicts valid selenocysteine-containing models.\n- Automated verification of UGA codons and SECIS elements.\n- Integration-ready outputs for Ensembl gene sets.\n- Containerised workflow for deployment on multiple computing environments.\n\n**Required knowledge**\n\n- Nextflow or similar workflow automation tools.\n- Sequence alignment tools (DIAMOND, MMseqs2, TBLASTN, Exonerate).\n- Genome annotation formats (FASTA, GFF3).\n- Basic knowledge of selenoprotein biology and SECIS elements.\n\n**Desirable knowledge**\n\n- Experience with gene annotation pipelines (e.g., AUGUSTUS, BRAKER, HELIXER, HELIXER).\n- RNA structure analysis tools for SECIS detection (e.g., SECISearch, Infernal).\n- BUSCO or other completeness assessment tools.\n- Containerisation technologies (Docker, Singularity).\n\n**Difficulty**: Medium\n\n**Length**: 175h\n\n**Mentors**: [Jack Tierney](mailto:jackt@ebi.ac.uk)\n\n**Brief explanation**\n\nThis project aims to enhance an existing pipeline for identifying small non-coding RNAs (sncRNAs) in Ensembl genomes. Building on the current MirMachine modules, the pipeline will be expanded to incorporate additional analyses using RFAM and miRBase databases.\n\nFurther improvements will include running sequence similarity searches with NCBI-BLAST and generating structural models using the Infernal software suite. The final pipeline will be optimised for flexibility, supporting various input sources, and containerised using Docker/Singularity to ensure reproducibility and shareability.\n\n**Expected results**\n\n- Integration of RFAM and miRBase data for improved sncRNA annotation.\n- Incorporation of NCBI-BLAST for sequence similarity searches.\n- Implementation of Infernal for RNA structural model generation.\n- Optimisation of pipeline scalability and flexibility for different input sources.\n- Containerisation of the pipeline using Docker/Singularity for easy deployment.\n- Documentation and testing to ensure usability and reproducibility.\n\n**Required knowledge**\n\n- NextFlow or other workflow management tools.\n- Python and/or Bash for pipeline scripting.\n- Basic RNA bioinformatics (FASTA, GFF3 formats, RNA databases).\n\n**Desirable knowledge**\n\n- Experience with RFAM, miRBase, and NCBI-BLAST.\n- Familiarity with Infernal for RNA secondary structure modeling.\n- Knowledge of Docker/Singularity for workflow containerisation.\n- Experience in workflow optimisation for large-scale genomic data.\n\n**Difficulty**: Medium\n\n**Length**: 175h\n\n**Mentors**: [Jose Perez-Silva](mailto:ereboperezsilva@ebi.ac.uk), [Vianey Paola Barrera Enriquez](mailto:vianey@ebi.ac.uk)\n\n**Brief explanation**\n\nEnsembl Plants and Ensembl Metazoa import publicly available genome assemblies and their annotations from community contributors. Whilst assemblies are submitted to INSDC sequence archives, it is often the case that these submissions are missing some key information that can usually be found in the paper publication corresponding to that assembly (most frequently due to those metadata fields being not available in the submission process). This metadata is not useful useful for our users, but Ensembl can benefit from it, e.g. polyploid genomes require different processing parameters/tools than diploid genomes when it comes to comparative genomics. Current AI tools are making fetching such metadata from research papers much easier, so we would like to build a standalone module that performs such task with the ultimate goal to incorporate it into our genome loading pipeline.\n\n**Expected results**\n\n- A standalone module (preferrably written in Python, but any current bioinformatics programming language would be acceptable) that can fetch the required genome metadata from current (publicly available) literature\n- The code will include documentation as well as type hints (if the selected programming language allows it) and unit testing\n- Capacity to retrain/expand as new research papers are published\n\n**Required knowledge**\n\n- AI tools for fetching/querying a database of research papers\n- Build of a module to be later included as part of a production pipeline written in Nextflow\n\n**Desirable knowledge**\n\n- Familiarity with the metadata associated with invertebrate and/or plant assemblies\n\n**Difficulty**: Medium\n\n**Length**: 175h\n\n**Mentors**: [Jorge Alvarez](mailto:jalvarez@ebi.ac.uk), [Disha Lodha](mailto:dishalodha@ebi.ac.uk)\n\n**Brief description**\n\nBUSCO is widely used to measure assembly completeness, but after seeing “Missing” (and often “Fragmented”) BUSCOs, users still need to answer: why are these genes missing and what should I do next?\n\nThis project proposes a reproducible, best-practice pipeline/tool that takes BUSCO outputs (and optionally assemblies/annotations/reads) and automatically gathers evidence to generate interpretable, ranked explanations per BUSCO along with a clean, actionable report.\n\n**Expected results**\n\n- Summary table: BUSCO ID → status, top reason code(s), confidence scores\n- Report (HTML/Markdown): overview plots + top actionable recommendations (e.g., “try a closer lineage dataset”, “investigate contig ends”, “annotation rerun suggested”, “coverage drop suggests gap”)\n\n**Required skills**\n\n- Command line + Linux basics\n- Python (or similar) for parsing, feature extraction, and reporting\n- Genomics basics (assemblies, gene models, alignments)\n- Reproducibility practices\n\n**Desirable skills**\n\n- Familiarity with alignment outputs and scoring\n- Workflow engineering (Nextflow)\n- Experience packaging bioinformatics tools and writing robust docs/tests\n\n**Difficulty**: Medium\n\n**Length**: 175 hours\n\n**Mentors**: [Swati Sinha](mailto:swati@ebi.ac.uk), [Jitender Jit Singh Cheema](mailto:jitender@ebi.ac.uk)\n\n**Brief explanation**\n\nEnsembl VEP is a widely used tool (10+ million dockerhub pulls alone) enabling the annotation and prioritisation of genetic variants and is used extensively in academic research and clinical assessments.\n\nThis project would be to prototype an AI chatbot configuration interface for the version of Ensembl VEP run from the new Ensembl website. The current selection of options for running the web version of Ensembl VEP is extensive, and requires users to be experienced or willing to read lots of tooltips and help documentation. A better option would be if they were able to describe their data and what they’re trying to achieve then receive a set of suggested options, with justifications. They could then click to apply these to the configuration before Ensembl runs.\n\nEach Ensembl VEP option would be assessed and labelled and weighted appropriately. We would then identify an appropriate base chat-bot model and assemble a corpus of training data, from a mixture of our responses to users and specific constructed examples. These would be divided into training and test sets for first training the model and then assessing responses.\n\nIf this is completed, an optional extension of the project would be to produce a simple API wrapper for IO.\n\n**Expected results**\n\n- Assemble and label training data\n- Train a prototype model\n- (Optional) API wrapper\n\n**Required knowledge**\n\n- Python (and ML libraries)\n- Data annotation\n- Desirable knowledge\n- HPC interaction\n- Model training experience\n- Prompt engineering\n- Understanding / interest in genetic variant annotation\n\n**Learning outcomes**\n\nGain experience with data annotation and agent model training and testing, supporting a globally utilised genetic variant annotation tool.\n\n**Difficulty**: Medium\n\n**Length**: 175 hours\n\n**Mentors**: [Likhitha Surapaneni](mailto:likhithas@ebi.ac.uk)\n\n**Brief explanation**\n\nThe goal of this project is to design, develop, and document an nf-core pipeline for the Ensembl Variant Effect Predictor (VEP) that follows nf-core best practices, fully modularizes the existing Nextflow VEP workflow from the Ensembl repository, providing required testing and continuous integration. This project will bring the Nextflow VEP workflow inline with [nf-core standards](https://nf-co.re/docs/guidelines/pipelines/overview), providing greater usability for the community.\n\nThe [Ensembl VEP](https://github.com/Ensembl/ensembl-vep) is a widely used variant annotation tool capable of producing rich functional annotations for genomic variants. It has been part of different bioinformatics workflows. A Nextflow workflow already exists that leverages nextflow parallel processing capabilities (e.g., splitting VCFs, parallelizing chromosome analysis, and merging results), but it is not packaged as an nf-core pipeline with the community standards around modularity, container support, automated testing, documentation, and configuration profiles.\n\n**Expected results**\n\n- A repository containing the workflow following nf-core guidelines which needs to include –\n- Required modules and workflows\n- Nextflow configurations profile for different executor environments\n- Easy-to-follow and standard documentation\n\n- Publishing the workflow in nf-core\n\n**Required knowledge**\n\n- Strong Python programming skills\n- Nextflow core concepts\n\n**Desirable knowledge**\n\n- Basic understanding of HPC environments\n- Experience working with Ensembl VEP\n- Familiarity with unit testing and CI/CD\n- Familiarity with Groovy and scripting languages such as bash\n\n**Learning outcomes**\n\nEnhanced understanding of the structure and workflows required for production pipelines. Appreciation of community standards implementation and the generation of reliable, repeatable and reusable workflows.\n\n**Difficulty**: Medium\n\n**Length**: 175 hours\n\n**Mentors**: [Syed Hossain](mailto:snhossain@ebi.ac.uk)\n\n**Brief explanation**\n\nRecent advances in single-cell foundation models and perturbation-driven datasets are bringing the concept of a “virtual cell” closer to reality. However, most current models remain siloed by modality (CRISPR screens, MAVE, scPerturb-seq) and lack a unifying layer that can integrate causal perturbation knowledge across data types.\n\nIn this project, the student will build a prototype perturbation-aware large language model (LLM) by fine-tuning an existing open-source model on curated perturbation datasets from the Perturbation Catalogue. The goal is not to train a foundation model from scratch, but to explore how LLMs can act as a knowledge-integration layer that connects genetic perturbations, variants, and single-cell responses.\n\nThe project directly supports the emerging “lab-in-the-loop” and scPerturb-seq Atlas concepts, where models guide experimental design and hypothesis generation by predicting cellular responses to unseen perturbations. The student will prototype workflows for:\n\n- Encoding perturbation experiments into LLM-friendly representations\n- Integrating multiple modalities (CRISPR screens, MAVE, scPerturb-seq)\n- Evaluating how well an LLM can support reasoning over causal perturbation data\n\nThis will position the Perturbation Catalogue as a core resource for next-generation in silico perturbation modelling and virtual cell development.\n\n**Expected results**\n\nBy the end of the project, the student will deliver:\n\n- A curated multimodal training corpus derived from the Perturbation Catalogue, including:\n- CRISPR screen summaries\n- MAVE variant–effect annotations\n- scPerturb-seq perturbation–response profiles\n\n- A fine-tuned perturbation-aware LLM prototype capable of:\n- Answering structured questions about perturbation effects\n- Reasoning across modalities (e.g. linking variant effects to transcriptional responses)\n- Supporting simple in silico perturbation queries (e.g. “What happens if gene X is knocked out in cell type Y?”)\n\n- Benchmarking and evaluation framework, comparing:\n- LLM-based reasoning vs simple baselines\n- Performance across perturbation regimes (seen vs unseen genes, cell types, variants)\n\n- A reproducible open-source pipeline, including:\n- Data preprocessing scripts\n- Fine-tuning notebooks/workflows\n- Documentation for future contributors\n\n- A short technical report and blog post describing how LLMs can support the “virtual cell” and lab-in-the-loop paradigms in perturbation biology.\n\n**Required knowledge**\n\n- Strong Python programming skills\n- Basic machine-learning concepts (training, validation, overfitting)\n- Familiarity with deep-learning frameworks (PyTorch preferred)\n- Experience working with structured biological data (e.g. CSV/TSV, JSON, HDF5)\n- Background in computational biology or bioinformatics\n- Familiarity with single-cell data (scRNA-seq, perturb-seq concepts)\n- Experience with large language models and fine-tuning (e.g. HuggingFace ecosystem)\n\n**Desirable knowledge**\n\n- Knowledge of causal inference or perturbation biology\n- Basic understanding of cloud or HPC environments\n\n**Difficulty**: High\n\n**Length**: 350h\n\n**Mentors**: [Alexey Sokolov](mailto:alexey@ebi.ac.uk), [Kirill Tsukanov](mailto:ktsukanov@ebi.ac.uk), [Aleksandr Zakirov](mailto:zakirov@ebi.ac.uk)\n\n**Brief explanation**\n\nThe Ensembl GraphQL service can be used to access information about genes, transcripts, assemblies and associated metadata held by Ensembl.This project will be conducted in collaboration with the Ensembl Outreach and Platform team to develop a freely available hands‑on, workshop teaching participants how to query Ensembl data using GraphQL. The workshop will include modules covering an introduction to GraphQL, schema exploration, query building, and techniques for error handling and debugging. As part of the project, the participant will create documentation with example prompts that can be used with AI assistants (e.g. Gemini) to help generate valid GraphQL queries or assist in debugging scripts. The workshop will be designed to be reproducible and easily extendable, enabling integration of future Ensembl GraphQL resources.\n\nThis experience will provide a mentored learning pathway focusing on practical software and data science skills, preparing the contributor for future open-source work.\n\n**Learning objectives**\n\n- Understand the structure and functionality of Ensembl core GraphQL API, including its schema and queries.\n- Workshop design and educational resource development.\n- Gain foundational understanding of key Ensembl data entities such as genes, transcripts, assemblies and species.\n\n**Aims**\n\n- Develop a teaching kit, including presentation slides, Jupyter notebooks with real world examples of exporting genomic data via Ensembl GraphQL.\n- Document all components comprehensively so that another trainer can run the workshop with minimal setup or additional development.\n- Design structured AI prompts that help participants use an AI assistant to construct accurate and efficient GraphQL queries.\n\n**Expected results**\n\n- A robust and interactive Ensembl GraphQL training resource featuring example code, helper functions, and debugging documentation.\n- A transferable design adaptable to other Ensembl GraphQL resources in the future.\n\n**Required knowledge**\n\n- Intermediate programming skills (preferably in Python), including HTTP requests, JSON handling, and basic packaging or testing workflows.\n- Experience in interacting with AI models (e.g. Gemini) including prompt design.\n\n**Desirable skills**\n\n- Core genomics knowledge, such as genes, transcripts, variants, and species identifiers, sufficient to interpret Ensembl data.\n- Basic understanding of GraphQL, including schemas, queries, arguments, nesting, and executing GraphQL endpoints with POST requests\n\n**Difficulty**: Medium\n\n**Length**: 175 hours\n\n**Mentors**: [Aleena Mushtaq](mailto:amushtaq@ebi.ac.uk), [Bilal El Houdaigui](mailto:bilal@ebi.ac.uk)\n\n**Brief explanation**\n\nAccurate metadata is essential for interpreting and comparing microbiome datasets. Despite its importance, it often remains incomplete or inconsistent in life-science public repositories. [Trapiche](https://github.com/Finn-Lab/trapiche) is a metadata classification tool for microbiome datasets that combines microbial composition (taxonomic) profiles with free text from project and sample descriptions. The base models can be repurposed for other classification tasks, but users currently lack a simple, standardised way to evaluate model quality and interpret results.\n\nThis project will develop an evaluation and reporting toolkit for Trapiche that automatically produces standardised metrics and human-readable reports. A key focus will be to monitor and compare the contribution of both input components: the taxonomic profiles and the text features. This will allow users to understand not only how well models perform, but also how each input type influences the predictions.\n\nThe resulting module will shorten development cycles for new microbiome classification tasks and support more reliable, comparable, and reusable life-science datasets.\n\n**Expected results**\n\n- A Python evaluation module that computes standard classification metrics (accuracy, precision, recall, F1-score, confusion matrix).\n- Support for component-aware evaluation, reporting performance for text-only, taxonomy-only, and combined inputs.\n- An automated report generator producing HTML or PDF summaries with metrics and plots.\n- Documentation covering installation, usage, and interpretation of results.\n- A walk-through Jupyter notebook demonstrating the use of the module.\n\n**Required knowledge**\n\n- Proficiency in Bash and Python.\n- Experience with data processing using Pandas and NumPy.\n- Familiarity with machine learning evaluation concepts and Scikit-learn metrics.\n- Experience with data visualisation tools such as Matplotlib or similar.\n\n**Desirable knowledge**\n\n- Familiarity with version control (Git) and collaborative coding workflows\n- Fundamentals of metagenomics and its applications\n- Experience with natural language processing (NLP) methods\n\n**Difficulty**: Medium\n\n**Length**: 175 hours\n\n**Mentors**: [Santiago Fragoso](mailto:fragoso@ebi.ac.uk), [Mahfouz Shehu](mailto:mahfouz@ebi.ac.uk)\n\n**Brief explanation**\n\nIn this project, we aim to develop a prototype method for the generation of [sequence similarity networks](https://pubs.acs.org/doi/full/10.1021/acs.biochem.8b00473) (SSNs) for the MGnify Proteins database to help enable graph-based analyses of its sequence space. Using tools like [MMseqs2](https://github.com/soedinglab/MMseqs2) to compute pairwise sequence similarities, and Python graph libraries like NetworkX, a collection of representative SSNs will be generated for a small subset of the database of ~10 million proteins. The nodes of these networks will then be annotated with relevant MGnify metadata, starting with biome of origin. Finally, we will generate visualisations of these annotated SSNs to be displayed on the MGnify Proteins website using modern graph rendering tools like [Cytoscape](https://cytoscape.org/) and [Cosmograph](https://cosmograph.app/).\n\nThe latest release of the[ MGnify Proteins Database](https://www.ebi.ac.uk/metagenomics/proteins/) contains over 2.4 billion non-redundant protein records including relevant metagenomics metadata. The visualisation of sets of protein sequences using SSNs is a common approach for extracting novel insights about protein-protein relationships, including functional, structural, and evolutionary hypotheses. Facilitating the generation of SSNs for the MGnify Proteins database would therefore be a significant contribution to open metagenomics science.\n\n**Expected results**\n\n- Develop a prototype workflow for generating SSNs for a given set of protein sequences using MMSeqs2\n- Apply the latter workflow to a workable subset of the MGnify Proteins representative clusters to generate SSN representations\n- Annotate generated SSNs with biome of origin\n- Generate visualisations for all biome-annotated SSNs\n\n**Required knowledge**\n\n- Proficiency in Bash and Python\n- Comfortable with using a Unix shell\n- Basic git skills for version-control of work\n\n**Desirable knowledge**\n\n- Familiar with graph theory and network analysis concepts\n- Experience with Python graph libraries like NetworkX\n- Experience with workflow design and implementation\n\n**Difficulty**: Beginner\n\n**Length**: 350 hours\n\n**Mentors**: [Christian Atallah](mailto:chrisata@ebi.ac.uk)\n\n**Brief explanation**\n\nInteractive data science web applications often need to support efficient search over large structured datasets, while keeping latency low and avoiding heavy server-side infrastructure. At large scale, this can be done in several ways, for example: 1) precompute an index file to accompany the dataset; 2) load records into a server-side indexed database behind a REST API; or 3) index and query data in the browser (e.g. using IndexedDB).\n\nIn bioinformatics, annotating (meta)genomes involves tagging regions of genomic sequences with feature details (like the location of a gene and its function). Computational pipelines produce these annotations and output standardised formats like GFF (General Feature Format) – effectively a TSV file for genomics. There are various ways to interrogate and visualise these annotations, including genome browsers like [JBrowse](https://jbrowse.org/jb2/). A frequent use case is to search the annotations by a query such as a function category label, and then browse to the matching locations in the sequences. Like any database, this becomes challenging for large datasets – in particular the metagenomes we analyse in [MGnify](https://www.ebi.ac.uk/metagenomics) become very large.\n\nThe objective of this project is to try a mixed approach: convert GFF (and other) files into a SQLite database using [gffutils](https://daler.github.io/gffutils/database-import.html), creating extra database indexes at the same time. We would like to distribute this feature SQLite to the browser, and query it using the [sqlite3 WASM](https://sqlite.org/wasm/doc/trunk/index.md) in-browser capabilities to both display a feature search interface and pass data to JBrowse (perhaps via a new [plugin](https://github.com/GMOD/jbrowse-plugin-template)).\n\n**Expected results**\n\n- A python script that uses gffutils to produce a suitably indexed SQLite database from a large metagenome GFF genomic feature file.\n- Unit tests for the script.\n- A react javascript component that queries the SQLite file client-side, using sqlite3 WASM’s javascript API\n- Ideally: the ability to partially read the SQLite file from a remote server, using HTTP Range requests\n- Demonstrated integration with the JBrowse viewer, e.g. via a plugin\n\n**Required knowledge**\n\n- Python\n- Python testing frameworks e.g. pytest\n- Javascript:\n[React.js](http://react.js) - Relational database concepts (e.g. SQL)\n- Version control\n\n**Desirable knowledge**\n\n- Use of WASM (Web Assembly)\n- Database indexing\n- Bioinformatics file formats\n\n**Difficulty**: Medium\n\n**Length**: 175 hours\n\n**Mentor**: [Vikas Gupta](mailto:vikasg@ebi.ac.uk)\n\n**Brief explanation**\n\nMGnify’s web interfaces are built on a large and evolving API surface, with complex data relationships and established frontend patterns. Translating Figma designs into production-ready UI code currently requires significant manual effort, particularly when wiring components to backend endpoints and maintaining consistency across the application.\n\nMGnify already has a prototype **(Model Context Protocol) server** that exposes tools backed by existing API endpoints. However, coverage is currently partial and focused on selected workflows.\n\nThis project proposes **extending and integrating an existing MCP server prototype** with the **Figma API**, enabling a design- and API-aware pipeline that assists developers in generating frontend components that are:\n\n- Grounded in authoritative Figma design artifacts (Visual Framework Assets)\n- Aware of MGnify’s API surface and response schemas\n- Aligned with existing frontend conventions, dependencies, and coding patterns\n\nThe system will act as **developer-assist infrastructure**, reducing repetitive boilerplate work and accelerating the design-to-implementation cycle while preserving full human control.\n\n**Expected results**\n\nBy the end of the project, the student will deliver:\n\nEnd-to-end proof of concept\n\n- Demonstrate generating a new or updated MGnify UI page (e.g. a detail or results page) from:\n- A Figma design\n- MCP-exposed API context\n\n- An integrated MCP server using a Client Side LLM Chat interface e.g Claude Desktop\n\n**Learning outcomes**\n\nThrough this project, the student will gain experience in designing and implementing production-grade developer tooling that integrates design systems, APIs, and modern web frameworks. Specifically, the student will learn to:\n\n- Work with large, real-world APIs\n- Understand and extend an existing MCP server exposing a complex, evolving API surface\n- Reason about API schemas, relationships, pagination, and error handling\n- Design abstractions that remain stable as backend APIs evolve\n- Learn to integrate with external APIs\n- Responsibly build AI assisted developer tools\n\n**Required knowledge**\n\n- JavaScript/TypeScript, Python\n- Experience with modern frontend frameworks (React preferred)\n- REST APIs and JSON schema interpretation\n- Git and collaborative software development workflows\n\n**Desirable knowledge**\n\n- Familiarity with design systems and component libraries\n- Experience with Figma or design-to-code tooling\n- Backend development experience (Node.js or Python)\n- Interest in developer tooling and automation\n- Exposure to scientific or data-heavy web platforms\n\n**Difficulty**: Medium\n\nThe project involves real-world system integration and design decisions, but is well-scoped and suitable for a student with solid web development fundamentals.\n\n**Length**: 175 Hours\n\n**Mentors**: [Mahfouz Shehu](mailto:mahfouz@ebi.ac.uk)\n\n**Brief explanation**\n\nThe BioSamples database at EMBL-EBI provides a central repository for the storage, validation, and retrieval of biological sample metadata across a wide range of life science domains. BioSamples plays a critical role in ensuring that sample descriptions are structured, standards-compliant, and reusable across downstream archives such as ENA, ArrayExpress, and others.\n\nDespite the availability of REST APIs for sample submission, validation, and search, these interfaces are not directly accessible to modern AI agents or large language model (LLM)–based systems, which require explicit schemas, deterministic interactions, and well-defined tool boundaries. As a result, the use of AI for assisting users in preparing high-quality BioSamples submissions or performing structured sample discovery remains limited.\n\nThis project aims to design and implement a **BioSamples MCP server** that exposes a carefully selected subset of BioSamples submission and search functionality through the **Model Context Protocol (MCP)**. The system will enable AI agents to interact with BioSamples in a safe, structured, and reproducible manner, reducing metadata errors while improving usability for submitters and data consumers.\n\nThe project focuses on two complementary capabilities:\n\n**AI-assisted sample submission**from plain-text descriptions, with interactive clarification and validation against BioSamples checklists.**Natural-language-driven sample search**, converting free-text queries into structured BioSamples search requests.\n\nBy leveraging MCP’s explicit tool schemas, input/output contracts, and error semantics, the project prevents hallucinations, enforces metadata correctness, and ensures that all responses are traceable to authoritative BioSamples data sources.\n\nThe project is intentionally scoped to be beginner-friendly, requiring limited domain-specific bioinformatics knowledge, and emphasizes software engineering, API design, schema validation, and AI-tool integration rather than biological interpretation.\n\n**Project objectives**\n\nThe primary objectives of the project are to:\n\n- Expose BioSamples submission and search functionality as MCP-compatible tools\n- Enable AI agents to assist users in creating valid, checklist-compliant BioSamples metadata\n- Provide deterministic, explainable responses grounded in BioSamples APIs\n- Demonstrate interactive clarification workflows for incomplete or invalid metadata\n- Establish a reusable MCP-based foundation that can be extended to other EMBL-EBI data resources\n\n**Scope and functionality**\n\n1. AI-Assisted BioSamples Submission\n\nThe system will allow users to describe a biological sample using **plain natural language**, for example:\n\n“Human liver biopsy collected in London in 2023 from a patient with cirrhosis.”\n\nThe MCP server, in combination with an LLM-based agent, will:\n\n- Extract candidate metadata fields from the text\n- Map extracted information to BioSamples attributes\n- Validate the resulting sample against a selected BioSamples checklist\n- Detect missing mandatory attributes (e.g. organism, material, collection date)\n- Detect missing or incomplete spatiotemporal metadata\n- Prompt the user with explicit clarification questions when required information is missing\n- Produce a fully structured BioSamples sample representation once all requirements are satisfied\n\nThe final output will be a validated, submission-ready BioSamples sample object, with all validation decisions and user interactions explicitly traceable.\n\n2. Natural-Language BioSamples Search\n\nThe project will also support **plain-text search queries**, such as:\n\n“Human blood samples collected in Europe after 2020 related to diabetes.”\n\nThe system will:\n\n- Parse the free-text query into structured search criteria\n- Translate these criteria into BioSamples-compatible search filters\n- Execute the search via BioSamples APIs\n- Normalize and summarize the returned results into a consistent, human-readable format\n- Return accession identifiers and key metadata fields for downstream exploration\n\nThis enables AI agents to act as structured discovery interfaces while preserving the determinism and correctness of the underlying BioSamples queries.\n\n**Expected results**\n\nBy the end of the project, the following deliverables are expected:\n\n- A near production-ready MCP server exposing a subset of BioSamples submission and search APIs\n- Demonstrations of:\n- AI-assisted, checklist-aware BioSamples submissions\n- Interactive clarification workflows for incomplete metadata\n- Natural-language-driven BioSamples search via MCP\n\n- Deterministic, auditable responses fully backed by BioSamples APIs\n- A scalable MCP-based architecture that can be extended to additional checklists or EMBL-EBI resources\n\n**Advanced capabilities (optional / stretch goals)**\n\nDepending on time and interest, the project may additionally explore:\n\n- Composing multiple BioSamples operations into a single logical workflow (e.g. validate → clarify → submit)\n- Normalizing heterogeneous BioSamples responses into a unified internal representation\n- Rate-limit-aware request handling and response caching\n- Clear error categorization (validation errors vs. system errors vs. user input issues)\n- Multi-turn conversational state management for submissions spanning multiple interactions\n\n**Documentation requirements**\n\nThe project will include comprehensive documentation covering:\n\n- System architecture and design decisions\n- MCP tool definitions and schemas\n- Validation and clarification workflows\n- Example AI agent interactions for submission and search\n- Limitations, assumptions, and potential extensions\n\n**Required knowledge**\n\n- Strong Java or Python programming skills\n- REST APIs, HTTP, and JSON\n- Software architecture and modular design\n- Schema definition and validation\n- Basic understanding of metadata modeling\n\n**Desirable knowledge**\n\n- Familiarity with BioSamples or similar metadata repositories\n- Experience with MCP or LLM tool/function calling\n- API performance optimization and caching strategies\n- Experience with containerization (Docker) or CI/CD pipelines\n\n**Difficulty**: Medium\n\n**Length**: 175 hours\n\n**Mentor**: [Dipayan Gupta](mailto:dgupta@ebi.ac.uk)\n\nTo be successful with your application, it is important to demonstrate the following:\n\n**1. An understanding of the major aims of the project**\n\nWe do not expect contributors to have expert domain knowledge at the outset. However, some light background reading on the proposed technologies and underlying science will help you better understand the project context and goals.\n\n**2. An ability to build on the project idea**\n\nWe provide a set of project ideas as starting points. Strong applications go beyond simply restating the description and instead bring new ideas, questions, or alternative approaches that build on the initial outline.\n\n**3. Clear and appropriate communication with mentors**\n\nEngaging with potential mentors ahead of submitting an application is key to success. Mentors are available to answer questions and provide guidance, but they will not write your application for you.\n\nIf you need clarification or additional background, communicate this clearly and in good time. Be concise and specific in your questions. Last-minute requests for substantial feedback are generally a sign of poor planning.\n\n**4. A realistic and well-structured timeline**\n\nAlthough GSoC timelines are flexible and can sometimes be extended, the programme is still relatively short. A good application includes:\n\n- clearly defined milestones\n- deliverables aligned with GSoC evaluation periods\n- a workload that is realistic given your other commitments\n\nWe value sustainable working practices and do not expect contributors to work excessive hours. Availability and constraints should be clearly stated and discussed with mentors.\n\n**5. Genuine enthusiasm and engagement**\n\nDemonstrated interest in the project, the technologies involved, and working with EMBL-EBI teams goes a long way. Enthusiastic and engaged contributors tend to have more productive mentor relationships and more successful projects.\n\nThe steps below provide a general guide to submitting a strong application. While we publish a list of suggested projects, contributor-proposed ideas are also welcome.\n\n**Review the project ideas**Review our GSoC project ideas page to explore available projects and their associated technologies.**Select a project of interest**Read the description carefully and do some light background research if needed.**Get in touch with us**Contact our GSoC helpdesk ([helpdesk@ensembl.org](mailto:helpdesk@ensembl.org)) with the subject line**“GSoC”**. Please include:- a short CV or link to relevant experience\n- a brief explanation of your interest in the project\n- any specific questions you may have\n\n- If you are proposing your own project idea, include a short description and the technologies you expect to use so we can assess mentor availability.\n**Draft your application early**Prepare a first draft well ahead of the deadline and share it with your mentor(s) or via the helpdesk for feedback.**Incorporate feedback and finalise**Use the feedback provided to refine your proposal, then submit the final version once it has been reviewed.\n\nGSoC contributors at EMBL-EBI are treated as members of their project teams. Contributors typically engage through:\n\n- Slack and mailing lists\n- GitHub issues and pull requests\n- regular meetings with mentors\n\nWhere time zones permit, contributors may also attend team or section-wide meetings and may be invited to present their work during the programme.\n\nGood luck with your application. GSoC has consistently been a rewarding experience for both contributors and mentors at EMBL-EBI, and we look forward to supporting contributors in developing skills, gaining domain knowledge, and contributing to open scientific software.\n\n**GSoC Resources**\n\n**EMBL-EBI resources and services**We develop and maintain a wide range of open biological data resources, including:\n\n[Ensembl](https://www.ensembl.org)and the[beta Ensembl website](https://beta.ensembl.org)[European Nucleotide Archive (ENA)](https://www.ebi.ac.uk/ena)[BioStudies](https://www.ebi.ac.uk/biostudies)[MGnify (Metagenomics)](https://www.ebi.ac.uk/metagenomics)\n\n**Code repositories**\n\n- Ensembl:\n[https://github.com/Ensembl](https://github.com/Ensembl) - ENA:\n[https://github.com/enasequence](https://github.com/enasequence) - BioStudies:\n[https://github.com/EBIBioStudies](https://github.com/EBIBioStudies) - MGnify:\n[https://github.com/EBI-Metagenomics](https://github.com/EBI-Metagenomics)\n\nDate: 16 - 31 Mar 2026\n\nLocation: Virtual\n\nVenue: Online"
  },
  {
    "name": "Stichting SU2",
    "slug": "stichting-su2",
    "tagline": "Computational Fluid Dynamics and Optimization",
    "description": "Computational analysis tools have revolutionized the way we design engineering systems as a society, but most established codes are proprietary, unavailable, or prohibitively expensive for many users. The SU2 Foundation will change this, making multiphysics analysis and design optimization software free and publicly available, in a single place, without restriction on who can contribute to its creation and development.\nThe SU2 Foundation is an educational and scientific not-for-profit that will bring together computational scientists and engineers through the SU2 Foundation platform. The SU2 Foundation develops, maintains, and supports a collection of C++ and Python-based software tools for performing Partial Differential Equation (PDE) analysis and solving PDE-constrained optimization problems. Through maintaining and improving the quality of software, documentation, and tutorials, and by growing the community of users and developers, the SU2 Foundation will ensure quality improvement of multiphysics software tools, accessible by everyone, for continued innovation in the engineering sciences.",
    "ideas_url": "https://su2code.github.io/gsoc/Introduction/",
    "website_url": "https://su2foundation.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "c++"
    ],
    "topic_tags": [
      "aerodynamics",
      "Computational Fluid Dynamics",
      "Multi-Disciplinary Optimization",
      "Adjoint Design Optimization",
      "Fluid Dynamics"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/stichting-su2",
    "ideas_content": "# Ideas List for SU2 Google Summer of Code\n\n**Welcome to SU2 - GSOC!**\n\nThis is the updated ideas list for GSOC 2026. If you are interested in participating in [Google Summer of Code](https://summerofcode.withgoogle.com/about) with the SU2 team, then please read the page on [participation](https://su2code.github.io/gsoc/Participation/). The projects listed below have been tuned to fit within the google summer of code program and they have mentors assigned to them. We can also accept personal ideas beyond the ones presented below but you need to convince one of the mentors to support you. We also need you to be proficient in SU2 and have some kind of technical background beyond general computer science (studying physics, mechanical engineering, aerospace engineering,…).\n\n## Project BP: Adding pressure-based solver\n\nProject Description (max. 5 Sentences) The pressure-based solver has been requested for a long time. This solver is an important addition to the CFD solvers, especially for low Mach and incompressible flows. People have worked on it (detailed documentation available), and there is a branch that contains a working version, but this was never finalized and added to the main SU2 branch. Hence, the project’s objective is to evaluate the current status of attempts, and propose a strategy for getting the pressure-based solver in the latest version of SU2. Expected Outcome (deliverables): Finalize pressure-based solver, validate with test cases, tutorial and merge the PR.\n\n- Skills Required: C++, experience with CFD and numerical methods\n- Possible Mentors: Nitish Anand and Edwin van der Weide\n- Expected Project Size: 175 hrs/medium\n- Difficulty rating:\n**medium-hard**(needs experience with Computational Fluid Dynamics)\n\n## Project GPU: Continuation of GPU acceleration in SU2\n\nProject Description (max. 5 Sentences) The SU2 code relies heavily on sparse linear algebra. In this area, there is significant speed-up potential with the adoption of GPU-based processing, as was demonstrated in the GSOC 24 project that applied CUDA to sparse matrix-vector multiplications in SU2. The objective of this project is to move more linear algebra operations to GPU in order to avoid host-device communication bottlenecks within the sparse linear system solver. Expected Outcome (deliverables): Make SU2’s sparse linear solver GPU-native, i.e. minimal host-device communication after the initial setup of the system.\n\n- Skills Required C++\n- Possible Mentors Pedro Gomes (lead), Ole Burghardt\n- Expected Project Size (90 hrs/ small , 175 hrs/medium, 350 hrs/large): 175 hrs (medium)\n- Difficulty rating:\n**medium**\n\n## Project AMR: Quick Adaptive Mesh refinement for 2D testcases\n\nProject Description (max. 5 Sentences) Many users have asked for adaptive mesh refinement capabilities. Several research groups are working on this. The aim of this project is to introduce a quick and easy adaptive mesh refinement that simply reads an existing results file and adaptively refines the meshes based on the value of a field. Expected Outcome (deliverables): SU2_AMR, an added executable that simply splits 2D quad and triangle cells\n\n- Skills Required: C++\n- Possible Mentors: Nijso Beishuizen (lead)\n- Expected Project Size (90 hrs/ small , 175 hrs/medium, 350 hrs/large): 175 hrs (medium)\n- Difficulty rating:\n**medium**\n\n## Project CMPLX: Performance Optimization of Complex Arithmetic in SU2\n\nProject Description (max. 5 Sentences) Complex arithmetic operations currently cause significant performance degradation in SU2 when features requiring complex numbers are enabled. This limitation affects the efficiency of certain solver capabilities and restricts their practical application in industrial-scale problems. Preliminary observations suggest that complex arithmetic is a primary bottleneck, but systematic profiling is needed to confirm and quantify these losses. The project’s objective is to profile the solver to identify performance hotspots, validate that complex arithmetic is the root cause, and develop a custom complex arithmetic library optimised for SU2’s specific use cases. This work will enable more efficient execution of complex-number-dependent features without compromising computational performance. Expected Outcome (deliverables): Performance profiling report, custom complex arithmetic library (if validated as necessary), benchmark comparisons demonstrating speedup, integration into SU2 codebase, and documentation with usage guidelines.\n\n- Skills Required: C++\n- Possible Mentors: Joshua A. Kelly (lead)\n- Expected Project Size (90 hrs/ small , 175 hrs/medium, 350 hrs/large): 175 hrs (medium)\n- Difficulty rating:\n**medium**\n\n## Project PIML: Towards physics-informed machine learning with SU2\n\nProject Description (max. 5 Sentences)\nSU2 uses algorithmic differentiation (AD) for the adjoint solver and has the ability to use multi-layer perceptrons in data-driven equation of state models through the [MLPCpp](https://github.com/EvertBunschoten/MLPCpp.git) submodule. The aim of this project is to combine these two functionalities to enable physics-informed machine learning (PIML) in SU2 by updating the weights and biases of multi-layer perceptrons using AD for sensitivity calculation. PIML would enable data-driven turbulence modeling, solving partial differential equations without a mesh, and open the door to many other interesting research opportunities.\nExpected Outcome (deliverables): Demonstration of training a MLP for a reference data set within SU2 and comparison, MLP training library including at least one commonly used training algorithm (e.g. Adam), and documentation explaining usage.\n\n- Skills Required: C++, experience with machine learning\n- Possible Mentors: Evert Bunschoten (lead)\n- Expected Project Size (90 hrs/ small , 175 hrs/medium, 350 hrs/large): 175 hrs (medium)\n- Difficulty rating:\n**medium-hard**\n\n## Project FWH: Generalizing FWH-Based Aeroacoustic Noise Prediction\n\nThis project aims to generalize a Python tool that implements Farassat’s 1A formulation of the Ffowcs Williams-Hawkings (FWH) equation for far-field noise prediction. While originally developed for tandem cylinder test cases and recently extended to airfoils, the current implementation is limited by case-specific logic. The primary objective is to refactor the codebase into a robust, geometry-agnostic framework capable of handling diverse and complex flow configurations. Test cases should be included in the regression tests. Expected Outcome (deliverables): A stand-alone Python code.\n\n- Skills Required: Python\n- Possible Mentors: Huseyin Ozdemir, (lead) Nijso Beishuizen\n- Expected Project Size (90 hrs/ small, 175 hrs/medium, 350 hrs/large): 175 hrs (medium)\n- Difficulty rating:\n**medium**\n\n-\nPrevious -\n[Next](https://su2code.github.io/gsoc/Participation/)"
  },
  {
    "name": "Kiwix",
    "slug": "kiwix",
    "tagline": "Internet content available offline.",
    "description": "Kiwix provides copies of websites that can be browsed offline. We run scrapers that will crawl a given website and compress it into a single .zim archive (based on the openZIM format). <br/><br/>\n\nThe zim files can then be stored locally and read on the fly by Kiwix in such a way that the user experience is similar to being online. <br/><br/>\n\nWe can fit the entirety of Wikipedia on a regular Android phone, but there are more than 7,000 zim files available in 100+ languages, mostly focused on educational content (e.g. Wikipedia, StackOverflow, Khan Academy, etc.).\n\n<br/><br/>\n\nKiwix runs on all platforms (Linux, Windows, Android, etc.) and has around 10-12 million users worldwide, in pretty much any place you can think of that has limited or no connectivity: prisons, rural schools, refugee camps, even Antarctic bases!\n<br/><br/>\nOur big challenge is to make it as easy as possible to access or share offline content.",
    "ideas_url": "https://kiwix.org/en/google-summer-of-code/",
    "website_url": "https://www.kiwix.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "c++",
      "nodejs",
      "kotlin",
      "vue.js"
    ],
    "topic_tags": [
      "offline",
      "browser",
      "compression"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/kiwix",
    "ideas_content": "-\nFor the full list of issues you can work on, see our GitHub repositoriesÂ\n\n[/openZIM](https://github.com/openzim),[/offspot](https://github.com/offspot)and[/kiwix](https://github.com/kiwix)GSoC has three sets of projects, lasting ~90, ~175 and ~350 hours approximately so that people who can not work full-time (because of exams or whatnot) can still participate.\n\n**We do not prioritize long over short projects**: the job must be done, they’re just an indication for your own comfort.A couple of project ideas are listed below to get you started:Â\n\n## WP1 Combinator Builder\n\nWP1 is the bot and website that provides tables like\n\n[this one](https://en.wikipedia.org/wiki/User:WP_1.0_bot/Tables/OverallArticles)on English Wikipedia. The tables help editors determine which articles they should focus on in their WikiProjects. The website also provides tools for creating a Wikipedia âselectionâ, ie a list of articles, so that they can create a ZIM file and have a subsetted offline version of Wikipedia.There are currently multiple ways to build a selection, from simple article lists to SPARQL queries. We wish to create a âcombinatorâ builder, which allows a user to combine existing or future builders to create a final selection.\n\n**Deliverables:**- Provide a data model for a combinator builder that integrates with the rest of the WP1 site\n- Provide a UI frontend for users to create combinator builders\n- Sufficient backend and frontend tests\n\n**Skills required:**- Good understanding of Python\n- Understanding of Javascript\n- Understanding of Vue.js or willingness to learn\n\n**Project length:**Small (about 90 hours of work)**Repository:**[https://github.com/openzim/wp1](https://github.com/openzim/wp1)## Hermetic Test Suite for MWoffliner\n\nMWofflinerâs test suite currently relies heavily on live HTTP requests to Wikipedia and other MediaWiki sites, resulting in 30 minutes test runs that are flaky, resource-intensive, and unsuitable for CI/CD pipelines. This project aims to rewrite the test infrastructure to be hermeticâusing mocked responses, local test fixtures, and in-memory MediaWiki instances where needed.\n\n**Deliverables:**Contributors will identify all external dependencies, create comprehensive mock data representing various MediaWiki configurations and edge cases, refactor tests to use dependency injection for HTTP clients, and establish patterns for future hermetic testing. The goal is reducing test runtime to under 10 minutes while improving coverage and reliability. By the end, the tests should be as hermetic as possible. A stretch goal is to separate any remaining non-hermetic tests (which need to make HTTP calls for a technical reason) to a separate e2e test target.**Skills required:**Strong testing experience (unit, integration, mocking frameworks), TypeScript/Node.js proficiency, understanding of HTTP mocking techniques (nock, MSW, or similar), experience with CI/CD systems. Familiarity with MediaWiki structure and test architecture design patterns is a plus: use the time before applications are opened to familiarize yourself with the tool.**Project Length:**Medium (150-175 hrs in total)**Repository:**[github.com/openzim/mwoffliner](https://github.com/openzim/mwoffliner)## Refactor MWoffliner Core Architecture\n\nMWoffliner is a tool for scraping MediaWiki content into ZIM files for offline access. This project involves refactoring the codebase to improve maintainability, modularity, and performance. The current architecture has grown organically over time, leading to tight coupling between components, unclear separation of concerns, and difficulty adding new features.\n\n**Deliverables:**Contributors will work to identify architectural pain points, design a cleaner module structure, and incrementally refactor critical paths while maintaining backward compatibility. Key areas include separating scraping logic from ZIM packaging, improving the article processing pipeline, and making the codebase more testable.**Skills required:**Strong TypeScript/Node.js experience, understanding of software architecture patterns, experience with large-scale refactoring, familiarity with MediaWiki APIs (beneficial, but youâll learn anyway). Contributors should be comfortable reading unfamiliar codebases, writing design documents, and working incrementally with extensive test coverage to prevent regressions (hard requirement).**Project length:**Long (350 hours)**Repository**:[github.com/openzim/mwoffliner](https://github.com/openzim/mwoffliner)## Testing and Reliability Engineering for Kiwix-Android\n\nWhile the project already contains unit and instrumentation tests, the current testing infrastructure has several gaps: incomplete test coverage, flaky tests, missing scenario tests for critical flows (downloads, storage, restart behavior), partial or unused coverage tooling, and inconsistent CI reliability\n\nThis project focuses on building a robust, scalable, and maintainable testing ecosystem for the app. The goal is not simply âadding tests,â but establishing production-grade reliability engineering practices\n\n**Deliverables:**By the end of the program we expect fixed flaky/failing tests; significant (and measured) increase in unit test coverage; Multiple stable instrumentation tests; a working coverage pipeline; CI improvements and reliability; a testing documentation and of course throughout the project clean, reviewable PRs**Skills required:**Kotlin, JUnit, Robolectric, Espresso / Compose Testing, MockK or Mockito, GitHub Actions and Jacoco**Project length:**Long (350 hours)**Repository**:[github.com/kiwix/kiwix-android](https://github.com/kiwix/kiwix-android) -\n### Want to join?\n\nThink hard about what you want to do, and go to the\n\n[Google Summer of Code](https://summerofcode.withgoogle.com/)website between 16 to 31 March to register and submit your project idea(s).After reviewing all proposals, projects will be announced on 30 April. (\n\n[full timeline](https://developers.google.com/open-source/gsoc/timeline))### Help & Tips\n\nWe want to be clear upfront that\n\n**we will not select candidates who have never made at least**: we make our choice based on how candidates handle themselves (is the code clear, are there comments, how do they explain their choices when asked,*one*PR to our codebase*etc.*). PRs do not need to be related to the project submitted – we just need to know that you can work in a team. If we don’t know you, we can’t choose you! And if your project has “UI” in it, then it probably is a good idea to submit a mockup of what you plan to implement.(We also wrote a helpful\n\n[guide to Writing your Google Summer of Code](https://kiwix.org/en/writing-your-google-summer-of-code-application/)application)Last but not least: over the years about half the contributors who did GSoC with Kiwix came up with their own project rather than one from our list â be\n\n**bold**!### Do you have questions?\n\nThen come and join us on ourÂ\n\n[Slack channel](https://join.slack.com/t/kiwixoffline/shared_invite/enQtOTUyMTg4NzMxMTM4LTU0MzYyZDliYjdmMDYzYWMzNDA0MDc4MWE5OGM0ODFhYjAxNWIxMjVjZTU4MTkyODJlZWFkMmQ2YTZkYTUzZDY)!"
  },
  {
    "name": "Python Software Foundation",
    "slug": "python-software-foundation",
    "tagline": "A programming language used for science & more",
    "description": "Python is a programming language that lets you work more quickly and integrate your systems more effectively.\n\nThe Python Software Foundation serves as an umbrella organization to a\nvariety of Python-related projects, as well as sponsoring projects related to the\ndevelopment of the Python language.\n\nYou can view a full list of participating sub-orgs here:\nhttps://python-gsoc.org/ideas.html\n\nSub-orgs:\n- Borg Collective - backup tools\n- CVE Binary Tool - scanning for known security vulnerabilities\n- DIPY - 3d/4d+ imaging\n- Fury - scientific visualization tools\n- LPython - ahead of time compiler for python\n- MNE-Python - tools for human neurophysiological data\n- Mission Support System - atmospheric science tools for flight planning\n- PyData/Sparse - n-dimensional sparse arrays for pyData\n- PyElastica - simulation and modeling for slender structures",
    "ideas_url": "https://python-gsoc.org/ideas.html",
    "website_url": "https://python-gsoc.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript"
    ],
    "topic_tags": [
      "security",
      "visualization",
      "compiler",
      "modeling",
      "Backup"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/python-software-foundation",
    "ideas_content": "## Ideas for GSoC 2026\n\n\n## Mentoring orgs for GSoC 2026 have not been announced!\n\nStudents: It's too early to apply but any open source experience will make your application better so feel free to get some practice in while you wait. Here are the [Instructions on getting started](https://python-gsoc.org/index.html#gettingstarted).\n\nMentors: If you're a sub-org who wants to join, please\n[read the information for sub-orgs](https://python-gsoc.org/mentors.html#sub-orgs).\n\n## pocketpy\n\npocketpy is an organization dedicated to creating game development tools. It maintains a portable Python 3.x implementation, which has no dependencies other than the C11 standard library, making it easy to to embed Python scripting into existing C/C++ projects. pocketpy also provides plugins for popular game engines like Godot and raylib.\n\n## Borg Collective\n\nWe are the Borg Collective and maintain multiple Python-based backup tools that are often used in combination: Borg, Borgmatic and Vorta. The core Borg tool is a deduplicating archiver with compression and encryption. Vorta is a desktop backup client that integrates with Linux and macOS desktops. Borgmatic is a wrapper for server systems that also takes care of database backups and pre-backup commands.\n\n## DIPY\n\nDIPY is the paragon 3D/4D+ imaging library in Python. Contains generic methods for spatial normalization, signal processing, machine learning, statistical analysis and visualization of medical images. Additionally, it contains specialized methods for computational anatomy including diffusion, perfusion and structural imaging.\n\n## FURY\n\nFURY offers a rich collection of visualization actors, interactive tools, and animation utilities that make it easy to build dynamic and engaging 2D and 3D scenes. Its growing set of tutorials and examples helps users quickly get started with interactive visualizations, animations, and custom rendering workflows. Features such as real-time interactivity, camera controls, animated transitions, and GPU-accelerated rendering enable efficient exploratory analysis and compelling visual storytelling. By shifting to wgpu while maintaining a strong focus on usability, documentation, and interactivity, FURY v2 aims to deliver a more flexible, modern, and powerful visualization framework for the Python ecosystem.\n\n## MNE-Python\n\nMNE-Python software is an open-source Python package for exploring, visualizing, and analyzing human neurophysiological data such as MEG, EEG, sEEG, ECoG, and more. It includes modules for data input/output, preprocessing, visualization, source estimation, time-frequency analysis, connectivity analysis, machine learning, and statistics.\n\n## Not participating in GSoC2026\n\nSome of our sub-orgs from 2025 won't be participating in GSoC 2026. Please let them enjoy their time off!\n\n## Friends of the PSF\n\nHere's some more interesting organizations that use Python!\n\n-\n[TARDIS](https://tardis-sn.github.io/summer_of_code/ideas/)TARDIS is an open-source Monte Carlo radiative-transfer spectral synthesis code for 1D models of supernova ejecta. It is designed for rapid spectral modelling of supernovae. It is developed and maintained by a multi-disciplinary team iincluding software engineers, computer scientists, statisticians, and astrophysicists."
  },
  {
    "name": "ArduPilot",
    "slug": "ardupilot",
    "tagline": "World's most advanced autonomous vehicle software",
    "description": "ArduPilot is the world's most widely used open source flight code software for unmanned autonomous vehicles including planes, multicopters, helicopters, cars, boats, submarines, blimps, antenna trackers and much more.\n\nWritten primarily in C++, ArduPilot supports over 100 different types of autopilot hardware including the well known Pixhawk autopilot.\n\nOur team motto, \"Versatile, Trusted, Open\" reflects our team's aim to provide high quality autopilot software that reliably supports a huge variety of frames, sensors and use cases.  The software is open but so is the team, always welcoming of new contributors whether they be software developers, wiki documentors, testers or users.",
    "ideas_url": "https://ardupilot.org/dev/docs/gsoc-ideas-list.html",
    "website_url": "https://ardupilot.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "lua",
      "c++",
      "pixhawk"
    ],
    "topic_tags": [
      "robotics",
      "ai",
      "Drone",
      "autonomous vehicle",
      "unmanned vehicle"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/ardupilot",
    "ideas_content": "# List of Suggested Projects for GSoC 2026[Â¶](https://ardupilot.org#list-of-suggested-projects-for-gsoc-2026)\n\nThis is a list of projects suggested by ArduPilot developers for [GSoC 2026](https://summerofcode.withgoogle.com/). These are only suggestions so if you have your own ideas then please discuss them on the [ArduPilot Discord Chat](https://ardupilot.org/discord) or on the [discuss server here](https://discuss.ardupilot.org/c/google-summer-of-code)\n\nFleet Management Webtool\n\nSITL Model Generation from Flight Data\n\nMulti-Drone Mesh Networking (MAVLink-aware)\n\nArduHumanoid (ArduPilot controlling a simple humanoid)\n\nAI-Assisted Log Diagnosis & Root-Cause Detection\n\nReal-Time Companion-Computer Health Monitoring & Failsafe\n\n\nSee lower down on this page for more details on each project\n\n## Timeline[Â¶](https://ardupilot.org#timeline)\n\nThe timeline for [GSoC 2026 is here](https://developers.google.com/open-source/gsoc/timeline)\n\n## How to improve your chances of being accepted[Â¶](https://ardupilot.org#how-to-improve-your-chances-of-being-accepted)\n\nWhen making the difficult decision about which students to accept, we look for:\n\nClear and detailed application explaining how you think the project could be done\n\nRelevant prior experience\n\nExperience contributing to ArduPilot or other open source projects\n\nUnderstanding of Git and/or GitHub\n\n\n### Fleet Management WebTool[Â¶](https://ardupilot.org#fleet-management-webtool)\n\nSkills required: Javascript, Python\n\nMentors: Ryan Friedman, Randy Mackay\n\nExpected Size: 175h\n\nLevel of Difficulty: Medium\n\nExpected Outcome: Webtool to ease the management of a fleet of ArduPilot vehicles\n\n\nThe goal of this project is create a fleet management web tool that helps companies and individuals manage the data collected by multiple ArduPilot vehicles\n\nShould extend the capabilities of the existing\n\n[LogFinder Webtool](https://firmware.ardupilot.org/Tools/WebTools/LogFinder/)Accept onboard logs, tlogs, photos and videos uploaded by the GCS or from the vehicleâs companion computer (possibly running BlueOS or APSync)\n\nAllow users to search and download data based on vehicle ID, recording date, location\n\nSupport both table views and map views of the uploaded data\n\n\nFunding will be provided for hardware and cloud server as required.\n\n### SITL Model Generation from Flight Data[Â¶](https://ardupilot.org#sitl-model-generation-from-flight-data)\n\nSkills required: Python, C++ (ArduPilot/SITL), system identification\n\nMentors: Nathaniel Mailhot\n\nExpected Size: 350h\n\nLevel of Difficulty: Hard\n\nExpected Outcome: A toolchain that auto-builds or tunes SITL airframe models from real flight logs\n\n\nThe goal of this project is to take ArduPilot logs and estimate the key dynamics/sensor parameters needed for SITL, then output an updated model + params that better match the real vehicle.\n\n### Multi-Drone Mesh Networking (MAVLink-aware)[Â¶](https://ardupilot.org#multi-drone-mesh-networking-mavlink-aware)\n\nSkills required: Networking, C/C++, Linux, MAVLink\n\nMentors: Nathaniel Mailhot\n\nExpected Size: 350h\n\nLevel of Difficulty: Hard\n\nExpected Outcome: A practical mesh networking layer for multi-vehicle comms (telemetry + coordination)\n\n\nThe goal of this project is to enable resilient multi-hop links between multiple ArduPilot vehicles, so telemetry and commands can route through the swarm when direct links drop.\n\n### ArduHumanoid (ArduPilot controlling a simple humanoid)[Â¶](https://ardupilot.org#arduhumanoid-ardupilot-controlling-a-simple-humanoid)\n\nSkills required: C++, control, servo systems, simulation (Gazebo/Ignition)\n\nMentors: Nathaniel Mailhot\n\nExpected Size: 175h\n\nLevel of Difficulty: Medium\n\nExpected Outcome: A minimal humanoid âvehicle typeâ running on ArduPilot with SITL support\n\n\nThe goal of this project is to prove ArduPilot can command a small humanoid-style jointed frame (think âservo robotâ), with a basic control interface and a simple simulated model.\n\n### AI-Assisted Log Diagnosis & Root-Cause Detection[Â¶](https://ardupilot.org#ai-assisted-log-diagnosis-root-cause-detection)\n\nSkills required: Python, ML (classification + retrieval), ArduPilot logs/parameters\n\nMentors: Nathaniel Mailhot\n\nExpected Size: 350h\n\nLevel of Difficulty: Hard\n\nExpected Outcome: A model/service that flags likely root causes from logs and suggests fixes with confidence\n\n\nThe goal of this project is to automatically diagnose common failures and misconfigurations by learning from labeled log segments, known issue patterns, and parameter states. It should output a probable root cause, suggested fixes, and a confidence score (with links to the relevant evidence in the log).\n\n### Real-Time Companion-Computer Health Monitoring & Failsafe[Â¶](https://ardupilot.org#real-time-companion-computer-health-monitoring-failsafe)\n\nSkills required: C/C++ or Python, MAVLink, Linux companion computers\n\nMentors: Jaime Machuca\n\nExpected Size: 175h\n\nLevel of Difficulty: Medium\n\nExpected Outcome: A standard MAVLink-based health reporting + failsafe mechanism for companion computers\n\n\nThe goal of this project is to define and implement a consistent âcompanion healthâ report (CPU/GPU load, heartbeat, critical services, watchdog) and connect it to configurable failsafes so ArduPilot can respond predictably when the companion degrades or dies.\n\n### Projects Completed in past years[Â¶](https://ardupilot.org#projects-completed-in-past-years)\n\nIn 2025, students completed the following projects:\n\nIn 2024, students completed the following projects:\n\nIn 2023, students completed the following projects:\n\nIn 2022, students worked on these projects:\n\nIn 2019, students successfully completed these projects:\n\nAirSim Simulator Support for ArduPilot SITL\n\nDevelopment of Autonomous Autorotations for Traditional Helicopters\n\nFurther Development of Rover Sailboat Support\n\nIntegration of ArduPilot and VIO tracking camera for GPS-less localization and navigation\n\nMAVProxy GUI and module development\n\n\nIn 2018, students successfully completed these projects:\n\nRedTail integration with ArduPilot\n\nLive video improvements for APSync\n\n\nIn 2017, 3 students successfully completed these projects:\n\nSmart Return-To-Launch which involves storing the vehicleâs current location and maintaining the shortest possible safe path back home\n\nRework ArduRover architecture to allow more configurations and rover type (\n\n[see details here](https://github.com/khancyr/GSOC-2017))Add âsensor headâ operation of ArduPilot, split between two CPUs\n\n\nYou can find their proposals and works on the\n\n[Google GSoC 2017 archive page]"
  },
  {
    "name": "The Honeynet Project",
    "slug": "the-honeynet-project",
    "tagline": "Honeypots and Threat Intelligence R&D",
    "description": "The Honeynet Project is a leading international 501c3 non-profit security research organization, dedicated to investigating the latest attacks and developing open source security tools to improve Internet security. With Chapters around the world, our volunteers have contributed to fight against malware (such as Conficker), discovering new attacks and creating security tools used by businesses and government agencies all over the world.\n\nThe Honeynet Project uses GSoC as a incubator for new R&D projects, and to recruit active new members.",
    "ideas_url": "https://www.honeynet.org/gsoc/gsoc-2026/google-summer-of-code-2026-project-ideas/",
    "website_url": "https://honeynet.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "django",
      "go",
      "docker"
    ],
    "topic_tags": [
      "honeypots",
      "malware analysis",
      "Threat Intelligence"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/the-honeynet-project",
    "ideas_content": "# Google Summer of Code 2026 Project Ideas\n\n###### 17 Jan 2026\n\n### Getting Started\n\nThis page contains a list of potential project ideas that we are keen to develop during GSoC 2026. If you would like to apply as a GSoC student, please follow these two steps to get started:\n\n- Read through this page and identify the project ideas you find interesting. Play around with our tools!\n- Join us on Discord and talk to your potential mentors on\n[Discord](https://discord.gg/68B8Ru5fSU)You can also find us in[Slack](https://gsoc-slack.honeynet.org/).\n\nIf there are any questions, please don’t hesitate and get in touch! 🙂\n\n### GSoC and The Honeynet Project\n\nDuring the previous years of GSoC, the Honeynet Project’s students have created a wide range of very successful open source security projects, many of which have gone on to become the industry standard open source tools in their respective fields.\n\nWe are also always interested in hearing any ideas for additional relevant computer security and honeynet-related R&D projects (although remember that to qualify for receiving GSoC funding from Google your project deliverables need to fit in to [GSoC’s project timescales](http://developers.google.com/open-source/gsoc/faq)!). If you have a suitable and interesting project, we will always try and find the right resources to mentor it and support you.\n\nPlease note - even if you aren’t an [eligible GSoC participant](http://developers.google.com/open-source/gsoc/faq), we are also always looking for general volunteers who are enthusiastic and interested in getting involved in honeynet R&D.\n\nEach sponsored GSoC 2026 project will have one or more mentors available to provide a guaranteed contact point to students, plus one or more technical advisors to help applicants with the technical direction and delivery of the project (often the original author of a tool or its current maintainer, and usually someone recognized as an international expert in their particular field). Our Google Summer of Code organizational administrators will also be available to all sponsored GSoC students for general advice and logistical support. We’ll also provide hosting for project infrastructure, if required.\n\nFor all questions about the Honeynet Project, the GSoC program or our projects, please contact us on [Discord](https://discord.gg/68B8Ru5fSU) (preferred)** or email us at [[email protected]](https://www.honeynet.org/cdn-cgi/l/email-protection#3e4e4c51545b5d4a7e5651505b47505b4a10514c59). You can also find us in [Slack](https://gsoc-slack.honeynet.org/).\n\n**Application template**\n\nIf you are considering applying to participate with us in GSoC 2026 please find our [application template here](https://honeynet.org/gsoc/gsoc-2026/application/). Use it when you are preparing your application on the official GSoC site and don’t hesitate to ask your mentors for feedback before submitting!\n\n# GSoC 2026 Project Ideas Overview\n\n[#1 - Improving the DICOMHawk medical honeypot](https://www.honeynet.org#improving-the-dicomhawk-medical-honeypot)[#2 - EventHorizon: the tarpit framework](https://www.honeynet.org#eventhorizon-the-tarpit-framework)[#3 - Extending the Artemis scanner](https://www.honeynet.org#extending-the-artemis-scanner)[#4 - Greedybear: Access payload files](https://www.honeynet.org#greedybear-access-payload-files)[#5 - Greedybear: Dashboard Modularization](https://www.honeynet.org#greedybear-dashboard-modularization)[#6 - Greedybear: Injection / Event Collector API](https://www.honeynet.org#greedybear-injection--event-collector-api)[#7 - IntelOwl: Integrating a Self-Deployed LLM Chatbot for Threat Intelligence](https://www.honeynet.org#intelowl-integrating-a-self-deployed-llm-chatbot-for-threat-intelligence)[#8 - IntelOwl: Integration Ecosystem & Connector Optimization](https://www.honeynet.org#intelowl-integration-ecosystem--connector-optimization)[#9 - IntelOwl: Maintenance Optimization & Architectural Refinement](https://www.honeynet.org#intelowl-maintenance-optimization--architectural-refinement)\n\n### #1 - Improving the DICOMHawk medical honeypot\n\n**Mentor:**Manolis Vasilomanolakis\n\n**Project type:**Improving an existing tool\n\n**URL:**\n\n[https://github.com/honeynet/DICOMHawk](https://github.com/honeynet/DICOMHawk)\n\n**Expected Project hours:**175 - 350 based on received proposal\n\n### Project Overview\n\nDICOMHawk is an open-source honeypot designed to emulate a vulnerable DICOM (Digital Imaging and Communications in Medicine) server to attract, log and analyze unauthorized access attempts against medical imaging systems. It provides a realistic DICOM environment with detailed logging and a web interface for monitoring interactions, helping security researchers understand how attackers probe and interact with such services in the wild.\n\n### Goal\n\nThe GSoC project focuses on\n\n- code improvement and debugging to make the software more robust, maintainable, and effective at capturing meaningful threat data.\n- securing the honeypot itself, including hardening its deployment (e.g., through Docker and better configuration practices) so that it’s safer to run in research or production-like environments.\n- general improvements to usability, monitoring, logging capabilities, and integration with threat intelligence.\n\nTogether, these efforts help evolve DICOMHawk into a more realistic, secure, and useful tool for studying attacks against healthcare infrastructure and improving defensive strategies.\n\n### Required Skills\n\n- Basic Linux/Command Line skills\n- Docker\n- Python\n\n### #2 - EventHorizon: the tarpit framework\n\n**Mentor:**Manolis Vasilomanolakis\n\n**Project type:**Improving an existing tool\n\n**URL:**\n\n[https://github.com/honeynet/EventHorizon](https://github.com/honeynet/EventHorizon)\n\n**Expected Project hours:**175 - 350 based on received proposal\n\n### Project Overview\n\nEventHorizon is an open-source multiprotocol IoT tarpit framework designed to emulate commonly abused IoT services such as Telnet, SSH, MQTT, UPnP, and CoAP in order to trap and study automated attackers. The framework focuses on keeping malicious clients engaged at the protocol level, slowing scanning and propagation activity while safely collecting measurement data. It provides a modular, containerized architecture that allows multiple protocol-aware tarpits to be deployed consistently across different environments. This GSoC project is centered on improving the framework’s capabilities, including making the codebase more robust, maintainable, and extensible for future protocol support.\n\n### Goal\n\nKey goals include refactoring and hardening the implementation, improving reliability and logging, and addressing edge cases discovered during real-world deployments. Additional efforts focus on enhancing deployment safety, reducing predictability to attackers, and improving overall framework usability for researchers. Together, these improvements strengthen EventHorizon as a reliable foundation for studying attacker behavior and advancing deception-based defenses for IoT systems..\n\n### Required Skills\n\n- Python programming and familiarity with Linux and Docker.\n\n### #3 - Extending the Artemis scanner\n\n**Mentor:**Krzysztof Zając\n\n**Project type:**Improving an existing tool\n\n**URL:**\n\n[https://github.com/CERT-Polska/Artemis](https://github.com/CERT-Polska/Artemis)\n\n**Expected Project hours:**175 or 350 hours\n\nArtemis is a modular vulnerability scanner that checks multiple aspects of website security and builds easy-to-read messages to send to organizations to get the vulnerabilities fixed. Multiple national-level CSIRTs use it to improve the security of their constituencies - for example, since 2023, CERT PL has used Artemis to find and report more than a million vulnerabilities.\n\nThe goal is to improve the number and quality of detected vulnerabilities. There may be multiple ways of achieving this goal:\n\n- Extend Artemis with modules detecting new types of vulnerabilities (for example, by integrating existing open-source tools),\n- Improve Artemis in other aspects such as performance or ease of use.\n\nThe primary required skills are Python programming and familiarity with Linux and Docker. Familiarity with web security topics is also desired.\n\n### #4 - Greedybear: Access payload files\n\n**Mentor:**Tim Leonhard, Matteo Lodi\n\n**Project type:**Improving an existing tool\n\n**URL:**\n\n[https://github.com/intelowlproject/Greedybear](https://github.com/intelowlproject/Greedybear)\n\n**Expected Project hours:**175 - 350 based on received proposal\n\n### Project Overview\n\nCurrently GreedyBear obtains all its data from T-Pots Elastic stack. Some data that is collected by T-Pot however is not available there. Some honeypots, like Dionaea, collect payloads that are only written to the filesystem, that is to `~/tpotce/data`\n\n. It would be great to make those artifacts available in GreedyBear. This project might not be limited to work on GreedyBear but can also include tinkering with the configuration of T-Pot itself or even introducing changes to T-Pot.\n\nRelated issues:\n[https://github.com/intelowlproject/GreedyBear/issues/558](https://github.com/intelowlproject/GreedyBear/issues/558)\n[https://github.com/telekom-security/tpotce/discussions/1653](https://github.com/telekom-security/tpotce/discussions/1653)\n\n### Goal\n\nHave a clean and reliable way to\n\n- access or extract payload files and other samples from T-Pot\n- present them to the user in a safe manner\n\n### Required Skills\n\n- basic knowledge of Python, Linux and Docker\n- motivation to deeply dive into both projects, GreedyBear and T-Pot, to create a stronger integration\n\n### #5 - Greedybear: Dashboard Modularization\n\n**Mentor:**Tim Leonhard, Matteo Lodi\n\n**Project type:**Improving an existing tool\n\n**URL:**\n\n[https://github.com/intelowlproject/Greedybear](https://github.com/intelowlproject/Greedybear)\n\n**Expected Project hours:**175 - 350 based on received proposal\n\n### Project Overview\n\nThe GreedyBear dashboard currently displays statistics through hard coded chart components and has a fixed layout. It would benefit the project to refactor the dashboard into a flexible, configuration-driven widget system that allows easy addition and removal of dashboard components.\n\n### Goal\n\nHave a configuration-driven dashboard where widgets can be added or removed by editing a single configuration file, or even better, directly in the frontend for admin users.\n\n### Required Skills\n\n- basic knowledge of JavaScript, preferably also of React and chart libraries\n- motivation to design and implement and test substantial changes to an already existing frontend\n\n### #6 - Greedybear: Injection / Event Collector API\n\n**Mentor:**Tim Leonhard, Matteo Lodi\n\n**Project type:**Improving an existing tool\n\n**URL:**\n\n[https://github.com/intelowlproject/Greedybear](https://github.com/intelowlproject/Greedybear)\n\n**Expected Project hours:**175 - 350 based on received proposal\n\n### Project Overview\n\nGreedyBear obtains all its data by pulling it from a T-Pot instance. While this will always be the main data source, it would be great to build an API where external, authenticated applications can inject data into GreedyBear’s database. This API would accept incoming event data in a specified format, process and save it. This would give honeypot developers the option to use GreedyBear as a frontend / data store.\n\n### Goal\n\nHave a documented and tested API endpoint that enables GreedyBear to receive event data from other sources than T-Pot in a safe and reliable manner.\n\n### Required Skills\n\n- basic knowledge of Python\n- motivation to thoroughly design and implement an API endpoint\n\n### #7 - IntelOwl: Integrating a Self-Deployed LLM Chatbot for Threat Intelligence\n\n**Mentor:**Matteo Lodi, backups to be defined\n\n**Project type:**Improving an existing tool\n\n**URL:**\n\n[https://github.com/intelowlproject/IntelOwl](https://github.com/intelowlproject/IntelOwl)\n\n**Expected Project hours:**175 - 350 based on received proposal\n\n### Project Overview\n\nThe goal of this project is to revolutionize how analysts interact with IntelOwl by integrating a cutting-edge, self-deployed LLM-based chatbot. This tool will transform static threat intelligence into a conversational experience, allowing users to query complex data using natural language.\n\nBy leveraging modern AI frameworks, the project aims to make threat investigation more intuitive, efficient, and accessible.\n\n### Key Objectives\n\n-\nConversational Interface Development: Utilize Python, LangChain, and ChainLit (or whatever tool is better to be used) to build a seamless chat interface capable of handling complex natural language queries (e.g., “Which campaigns are associated with this IOC?”).\n\n-\nIntelOwl Module Integration: Deeply interface the chatbot with IntelOwl’s enrichment modules, allowing the AI to trigger deeper investigations and pull real-time data when required.\n\n-\nSelf-Deployed Architecture: Ensure the LLM infrastructure is self-hosted to maintain data privacy and security—a critical requirement for threat intelligence environments.\n\n-\nAdaptive Investigative Workflows: Design the system to adapt to evolving user needs, streamlining the communication between the analyst and the platform’s underlying data.\n\n\n### Contributor Profile & Required Soft Skills\n\nThe LLM and AI landscape is moving at an incredible pace. To succeed in this project, we are looking for a contributor who demonstrates:\n\n-\nProactivity: you propose creative solutions and architectural improvements to overcome technical hurdles.\n\n-\nTechnical Autonomy: You are comfortable diving into dense documentation and managing your development cycles with minimal supervision.\n\n-\nHigh Adaptability: You stay updated with the latest open-source AI frameworks and are ready to pivot or adapt your approach as new, more efficient models or tools emerge.\n\n\n### #8 - IntelOwl: Integration Ecosystem & Connector Optimization\n\n**Mentor:**Matteo Lodi, backups to be defined\n\n**Project type:**Improving an existing tool\n\n**URL:**\n\n[https://github.com/intelowlproject/IntelOwl](https://github.com/intelowlproject/IntelOwl)\n\n**Expected Project hours:**90 - 175 based on received proposal\n\n### Project Overview\n\nA core strength of our platform is its ability to communicate with the broader security ecosystem. We are looking for a contributor to lead the revitalization of our “Connectors”—the vital bridges used to export and share analysis reports with external platforms.\n\nThe focus will be on ensuring seamless interoperability with industry-standard tools, specifically MISP, Yeti, and OpenCTI.\n\n### Key Objectives\n\n-\nComprehensive Connector Audit: Review the existing codebase for our primary connectors to identify, reproduce, and resolve reported bugs and performance bottlenecks.\n\n-\nInfrastructure Setup & Debugging: Deploy and configure local instances of the relevant open-source projects (MISP, Yeti, OpenCTI) to create a robust testing environment for end-to-end debugging.\n\n-\nNative Health Check Integration: Enhance user experience by implementing dedicated “Health Check” features. By utilizing the native APIs of external tools, you will build a diagnostic layer that allows users to instantly verify the status of their integrations.\n\n-\nFuture-Proofing: Refactor existing integration logic to make future updates easier to manage as external API schemas evolve.\n\n\n### Contributor Profile\n\nThe ideal candidate for this project enjoys digging into third-party documentation and has a passion for building reliable, interconnected systems. You will play a crucial role in improving the reliability of the platform for our entire user base.\n\n#### Key expectations include:\n\n-\nTechnical Research: Deep-diving into external API specifications.\n\n-\nEnvironment Orchestration: Willingness to set up and manage the open-source tools required for testing.\n\n-\nProactive Communication: Working closely with mentors to standardize how data is mapped between platforms.\n\n\nGithub issues reference:\n\n[https://github.com/intelowlproject/IntelOwl/issues/2737](https://github.com/intelowlproject/IntelOwl/issues/2737)[https://github.com/intelowlproject/IntelOwl/issues/2480](https://github.com/intelowlproject/IntelOwl/issues/2480)[https://github.com/intelowlproject/IntelOwl/issues/2122](https://github.com/intelowlproject/IntelOwl/issues/2122)[https://github.com/intelowlproject/IntelOwl/issues/2309](https://github.com/intelowlproject/IntelOwl/issues/2309)\n\n### #9 - IntelOwl: Maintenance Optimization & Architectural Refinement\n\n**Mentor:**Matteo Lodi, backups to be defined\n\n**Project type:**Improving an existing tool\n\n**URL:**\n\n[https://github.com/intelowlproject/IntelOwl](https://github.com/intelowlproject/IntelOwl)\n\n**Expected Project hours:**90 - 175 based on received proposal\n\n### Project Overview\n\nThis project focuses on resolving core architectural bottlenecks that hinder development velocity. The primary objectives are to enhance the testing suite performance and streamline the project’s dependency graph. Currently, the project suffers from slow CI/CD cycles and frequent dependency conflicts that complicate the build process.\n\n### Key Objectives\n\n-\nTesting Suite Optimization: Investigate and implement strategies to significantly reduce test execution time.\n\n-\nDependency Management: Conduct a comprehensive audit of frontend and backend dependencies. The goal is to minimize the footprint by removing redundant packages, resolving version conflicts, and updating or replacing outdated libraries.\n\n-\nAnalyzer & Plugin Refactor: Evaluate existing analyzers and plugins. You will be expected to identify obsolete or unecessary components and either refactor them for modern standards or replace them with more efficient alternatives. Also complete removal of an analyzer is an option.\n\n\n### Contributor Expectations\n\nAs this project involves fundamental changes to the project structure, we are looking for a contributor who prioritizes:\n\n-\nAnalytical Research: Proactively identifying which dependencies are “dead weight” or causing bottlenecks.\n\n-\nIterative Development: Implementing changes in manageable increments to avoid breaking core functionality.\n\n-\nHigh Communication: This role requires consistent interaction with mentors to ensure structural changes align with the long-term vision of the project.\n\n\nGithub issues reference:\n\n[https://github.com/intelowlproject/IntelOwl/issues/2958](https://github.com/intelowlproject/IntelOwl/issues/2958)[https://github.com/intelowlproject/IntelOwl/issues/2776](https://github.com/intelowlproject/IntelOwl/issues/2776)[https://github.com/intelowlproject/IntelOwl/issues/2737](https://github.com/intelowlproject/IntelOwl/issues/2737)"
  },
  {
    "name": "QEMU",
    "slug": "qemu",
    "tagline": "Open source machine emulator and virtualizer",
    "description": "The QEMU Project includes the QEMU open source machine emulator and virtualizer and also acts as an umbrella organization for the KVM Linux kernel module and rust-vmm community.\n\nWhen used as a machine emulator, QEMU can run operating systems and programs made for one machine (e.g. an ARM board) on a different machine (e.g. your own PC). By using dynamic translation, it achieves very good performance.\n\nWhen used as a virtualizer, QEMU achieves near native performances by executing the guest code directly on the host CPU. QEMU supports virtualization when executing under the Xen hypervisor or using the KVM kernel module in Linux. When using KVM, QEMU can virtualize x86, ARM, server and embedded PowerPC, and S390 guests.",
    "ideas_url": "https://wiki.qemu.org/Google_Summer_of_Code_2026",
    "website_url": "https://qemu.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "python",
      "linux",
      "rust"
    ],
    "topic_tags": [
      "systems programming",
      "kernel",
      "compiler",
      "emulator",
      "hypervisor"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/qemu",
    "ideas_content": "Making sure you're not a bot!\nLoading...\nPlease wait a moment while we ensure the security of your connection.\nSadly, you must enable JavaScript to get past this challenge. This is required because AI companies have changed the social contract around how website hosting works. A no-JS solution is a work-in-progress."
  },
  {
    "name": "Open Robotics",
    "slug": "open-robotics",
    "tagline": "Open source robotics and a whole lot more!",
    "description": "Open Robotics supports the development, distribution, and adoption of open source software for use in robotics research, education, and product development. Open Robotics is an umbrella organization encompassing five projects: \n- Robot Operating System (ROS), a robot development framework.\n- Gazebo, a robot simulation framework.\n- Open-RMF, a framework for coordinating multiple fleets of robots.\n- ros-controls, an extensive control framework built for ROS.\n- The ROS Infrastructure that is used to build and distribute ROS packages.",
    "ideas_url": "https://github.com/osrf/osrf_wiki/wiki/GSoC-2026",
    "website_url": "https://www.openrobotics.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "ros",
      "gazebo",
      "c++",
      "Bevy"
    ],
    "topic_tags": [
      "robotics",
      "simulation",
      "Hardware Control",
      "fleet management",
      "buildfarms"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/open-robotics",
    "ideas_content": "# Overview\nThis document describes a list of potential ideas created for the [2026 Google Summer of Code](https://summerofcode.withgoogle.com/). However, the ideas are open to everyone with interest on collaborating, and OSRF is open to new ideas. Feel free to use our application template below to indicate your interest in some of the projects. If you would like to suggest new projects please email [gsoc@openrobotics.org](mailto:gsoc@openrobotics.org).\n\nThe following list shows a set of ideas that can extend the functionality of some of the open source projects led by OSRF.\n\nROS (Robot Operating System) provides libraries and tools to help software developers create robot applications. It provides hardware abstraction, device drivers, libraries, visualizers, message-passing, package management, and more.\n\nGazebo is a multi-robot simulator for indoor and outdoor environments. It is capable of simulating a population of robots, sensors and objects in a three-dimensional world. It generates both realistic sensor feedback and interactions between physically plausible objects.\n\nOpen-RMF is a free, open source, modular software system that enables robotic system interoperability. Open-RMF coordinates multiple fleets of indoor and outdoor robots with typical robotic use cases and integrates them with elevators/lifts, doors and other infrastructure.\n\nInfrastructure is the computing infrastructure that supports the above projects, such as by providing continuous integration services and building binary packages.\n\nThe link between all projects is their open source nature and its relationship with robotics. Browse through the list and do not hesitate to contact us if you wish to participate in any of the projects. Share with us your thoughts and ideas on any future improvement or project you may have.\n\n# Template\n\n### Title\nPrerequisites: \n\nNecessary programming skills: \n\nPotential mentors: [Mentor and Info](https://github.com/fujitatomoya)\n\nExpected size: *expected number of hours*\n\nExpected outcome: *one sentence description of outcome*\n\nDetailed description: *paragraph description*\n\n## ROS 2\n\n## Gazebo\n\n### Vendor Agnostic SONAR implementation\nPrerequisites: Linux, Git, familiarity with ROS 2 and Gazebo, basic understanding of sonar and simulation pipelines.\nNecessary programming skills: C++ (Gazebo / ROS 2 integration), Rust (or willingness to learn), CMake, ABI basics (FFI), CUDA GPGPU compute fundamentals.\n\nDifficulty level: Medium to hard\n\nMentors: [Woen-Sug Choi](https://scholar.google.com/citations?user=9rpkxUwAAAAJ&hl=en), [Arjo Chakravarty](https://github.com/arjo129)\n\nExpected size: 175 hours to 350 hours\n\nExpected outcome: A source-buildable, distribution package providing a Gazebo sonar plugin with GPU acceleration that is vendor-agnostic (no CUDA dependency), using wgpu as the compute backend.\n\nDetailed description:\nThis project develops a vendor-agnostic GPU-accelerated SONAR simulation plugin for Gazebo by migrating the current CUDA-centric approach to a wgpu-based compute pipeline. Current existing physics-based underwater sonar plugin rely on CUDA for speed, which limits users to NVIDIA GPUs and complicates deployment in mixed hardware environments (AMD/Intel/Apple Silicon GPUs, and future-proofed stacks). Recent advances in cross-platform GPU APIs and the Rust wgpu ecosystem make it feasible to run high-throughput compute workloads across Vulkan / DirectX / Metal backends via a unified abstraction to utilize GPGPU capabilities. This project uses that foundation to implement sonar image synthesis on the GPU without vendor lock-in, while keeping Gazebo/ROS 2 integration clean and upstream-friendly.\n\n### QA of Reset of core systems\n\nPrerequisites: Linux, Git, familiarity with ROS 2 and Gazebo, basic understanding of sonar and simulation pipelines.\n\nNecessary programming skills: C++ (Gazebo / ROS 2 integration), CMake, ABI basics (FFI), CUDA GPGPU compute fundamentals.\n\nExpected size: 175 hours \n\nDifficulty: Easy\n\nExpected outcome: A comprehensive test suite and audit of all system resets in gazebo\n\nDetailed description: Gazebo ships with a lot of core plugins out of the box. Initially these were implemented with Configure, PreUpdate, Update, and PostUpdate hooks for each time step. However, as reinforcement learning took off, reset was added as a core behavior. Many of these plugins may behave weirdly upon reset as we have not audited their behaviours. The goal is to have a test suite that covers all the core plugins and their reset behaviour so that we can catch oddities and regressions.\n\n\n\n## ROS Control\n\n### Mission Control for ros2_control\n\nThe ros2_control framework focuses on direct management of hardware and their controllers to enable real-time capabilities with ROS.\nAlthough those interfaces are easy to use, they provide only \"manual\" control over the system's state.\nTherefore, very often in more complex systems our users have to implement an external, state-machine like component that serves as an orchestrator for ros2_control.\nThe main purpose of such a component is to serve as conductor of ros2_control by taking care of scenarios and making sure that at the appropriate moment the right controllers and hardware are in expected states.\n\nThis functionality should replace some high-level components currently used, e.g., MoveIt2-\"SimpleControllerManager\".\n\nThe main functionalities for the components and goals of the project are:\n\n* Defining a scenario in form of a multi-robot and multi-tool configuration and its behavior that serves as a benchmark.\n* Extending controller_manager with status publisher, providing all needed data to a mission-control component.\n* Adding status topics to all standard controllers.\n* Defining format of a YAML file where users can configure controller presets.\n* Implementing the mission-control module/script that sets the controller_manager, i.e., the ros2_control framework, in a specific configuration/state.\n## Open-RMF\n\n### UI/UX improvements to the [Crossflow Diagram Editor](https://open-rmf.github.io/crossflow/?diagram=3VhLb%2BM2EP4rhtCjGZMUKYm%2BF2gPPbVAD4uFwcfQVleWvHokGwT57x1K8isbO%2FJigwY9xSKHo%2Fk%2BznwzylP0S2M3sNXRMtq07a5ZLha1frhb5%2B2mM10Dta3KFsr2zlbbRbWDktRbv7B11TS%2BqB4WNfhmsQHtmsVW5%2BXC5Xpd6%2B3d4PXun6Yqo3l0D3WT469lRO%2FYHcWVFra7QrfQRMun53nUtLpucbvZFXmL29UubETfGKXhb%2Fu4A9wtKwe4abq8cFDjwrYr8LmEb%2BFsMCam8x635hHG7fN1tMTFeeRydKwfV%2B3RMgpv7bbXvGvnDt6f%2BvU2DxhaqLd5icEHHy9cB5e4%2Bk8VLA%2Bu%2B8fgOgSHyD69CBaf9g%2BfD3hGV7h3CwWvMfAaAT3%2Bnu2j8z37DXzt8M5zXexDHWKMPg%2FxHF5yPDouDPuXtwNh0Ng637VDPvxd1V9CIs3ajW5nfQDNrNvhI8w4KbutgXqWl7uunRV5085niLfN0QyaYLPFPZff567TRfE4nwWih435TJduhlc42rXVGvBHfYdQen8r%2BKYxB0MGfnp6EdUfx5cwHs%2FM4wxBo4sZ%2BggrmFOngQiZDDZ7E1xAC7xAzJP1Hk4NDR7BcEY3SZYEXu910QWKPqHfeTj5GVm8EFD%2FjhfR0BfBkEPEe5Ow8mY4BG3OosET4SBGgymJaQNlKOG%2BLA%2FlT8ZyJ%2BDytqrJPQvbG91s0EUMID1VRolEaMdErLkCby3LWEohcXGaAZd9OmP5YzXh0ZDew4XkDl0sV6ux7Fa9QqxWQTrGZO0lYx7tqiYfWEK9iJacy3n0iH9lSHAowLbaFHjA66IBTD%2Fdotjhm%2FQWmp22wVVI2y3opqsB3%2FoUPeSuRQQ8SMcG8vUGi0RSTN7vwzpowWloR4G4GF7ynvElUnGnvCOJ9pII4RwxKfOEm0xYTy3IWB%2BjHSXlRaC9bgYe%2B0BfjSrI9O%2FhfaNCVLt30%2BobCUiNSlNnE%2BJTxC4kZySzxmE%2BC6aN4ZiW%2FC0C9jclJxAQpPot%2FD%2FcTW7EHseUUUk5kWAsEVQLkjkniHE80zR1ACY9Yh870wXsYgL20cMZ%2BB%2FvdzeC5TQzaczxorMsRrBCEk2VIqBibTDTBcv8Wxcdy5sy%2FeZEn96RbwSfMdCSakawtikRFijRoCyRVolMSSGd60et8%2BZ%2B4arZlDQ%2FTGe3DQ23XmqsPGWJIrFIUb58IomhJg0algiwzAsfSul8tLgoYPFEATte0xm8k8nlFgzY6RjHDk9iVFsilPVEKZNgYibeSC54qk%2Fu5hKGfWpOxPBzIIR279anbdipNPZOWmIUQ0nheDUm0SmRLpEyppkAGocMqLq6D%2BrVtj3s%2FoZTWeh2ZVcUCF%2FXOHvckMq9%2FbmPra6%2FQP1r2WMaEeu6rh5sUTWIdH4EesTJKZIxGjvwGichNNwTXHUtDojDl0k%2FK5643ls%2Fn9Shy3SW%2BYxox1GEHNeouMgR94JR62LmetU40DOxPV8lbGqNfEjCLPdpJmIgArTC4LkkigOQJAWBZGEyMHNK2MR2fpWwyzPbh6QIG1dKneckSzKOjQ31SUFCCWZYYuMYsCDtKUUT8%2BEqRVMnh%2Fcg7KBcU%2FgajP%2BEr0PbiZbo1ENrN3%2F1%2B6hhRx32kCr85CDMCky1QKHOVEJSXDUGa5X2nz0HHifq9v%2BUR3aRR1T6VHPriEs8apxC4co0%2FrKGqVQqpTw%2FatZ0Dq7yOHWK%2F5AF7IwzPMDG5oUEZF6RjIMjaazxG5gnKfa1swKeNsleJWzq0PEhCUs0%2Fj%2BEUk2okwYrNcuIiWlCqM2YMSaW8lzxJo4MVwmb%2BqH8HoT1c%2FNQe98xNqraNOJonAonHCaNZBpBYEvVMlYkTaj0MmacUfaziZv63fXfEMeuE4cfJM%2FP%2FwI%3D)\n\nPrerequisites: [React](https://react.dev/), [React Flow](https://reactflow.dev/)\n\nNecessary programming skills: TypeScript and a little Rust\n\nPotential mentors: [mxgrey](https://github.com/mxgrey)\n\nExpected size: 175 to 350 hours\n\nDifficulty: Medium\n\nExpected outcome: Improved user experience for the [crossflow](https://github.com/open-rmf/crossflow) diagram editor\n\nDetailed description: [Crossflow](https://github.com/open-rmf/crossflow) is a general-purpose high-performance reactive programming library written in Rust on top of the [Bevy Game Engine](https://bevy.org/). One way to use crossflow is to manually draw a diagram that describes a workflow, and then send that diagram to a crossflow application to be executed. We provide the [crossflow diagram editor](https://open-rmf.github.io/crossflow/) as a basic open source out-of-the-box diagram editor tailored to creating workflows that can be executed by the crossflow library. Participants for this project would add features to the diagram editor to improve its user-friendliness. Some features to consider may include:\n* Real-time validation of the diagram (e.g. make sure all connections are compatible)\n* Make it easier/faster to add new operations to the diagram\n* Real-time tracing of workflow execution, illustrated on the diagram (e.g. highlighting active nodes)\n* Interactive debugging\n  * Pause / resume\n  * Toggle breakpoints\n  * Step in / Step out\n  * Hot start a workflow from a saved state\n* Manage multiple workflow sessions from the same window\n\n### Continuous integration testing of the reservation node.\n\nPrerequisites: Basic understanding of ROS2, colcon and python.\n\nNecessary programming skills: C++, Python\n\nPotential mentors: [arjo129](https://github.com/arjo129)\n\nExpected size: 90 hours\n\nExpected outcome: Provide an integrated test suite for open-rmf's reservation node.\n\nDetailed description: Open-RMF's reservation system makes sure that robots dont end up occupying each others spaces. In its current form it is a very simple greedy queue based allocator. This component, however is incredibly brittle and any change to the protocol or heuristics requires extensive testing. Currently, we have [some hacky scripts](https://github.com/arjo129/stress_test_rmf_chope) which we need to watch for testing edge cases. It would be good to be able to run these in CI or automatically.\n\n### Improved throughput for Traffic Dependency Calculation\n\nNecessary programming skills: Rust\n\nPotential mentors: [arjo129](https://github.com/arjo129)\n\nExpected size: 90 hours\n\nExpected outcome: Implement a faster collision detection mechanism in our traffic dependency code\n\nDetailed Description: Traffic Dependency calculations are critical for executing MAPF plans. The current prototype uses an older algorithm that runs in $O(N^4)$. Recent works are able to reduce this bound using\nKD-Trees. The goal would be to implement one of these faster algorithms within the traffic dependency calculator.\n\n## ROS Infrastructure\n\n# Application template for students\n\n * If you would like to suggest new projects you are free to e-mail your ideas to us at: gsoc@osrfoundation.org. _We recommend you stick to one of the projects listed above unless you have already recruited a mentor._\n * If you have specific questions to discuss about a project, send an email to gsoc@osrfoundation.org. You may also ask your question in the `gsoc-q-and-a` channel [on our Discord server](https://discord.com/servers/open-robotics-1077825543698927656).\n * If you meet the general requirements and are interested in working on one of the OSRF projects during Google Summer of Code, **you can apply by submitting your application through the [Google GSoC web site](https://summerofcode.withgoogle.com) once participant** applications open on March 25th, 2025. \n\n# Completing Your GSoC Application\n\n## Proposal Title\n\nYour proposal title should match one of the projects listed above.\n\n## Proposal Summary\n\nFor your proposal summary introduce yourself and briefly discuss your plan for addressing the project you have selected. \n\n## What to Include in Your Proposal PDF File \n\nYour proposal PDF file should include the bulk of your application. Please include the information outlined in the subsequent four sections below. \n\n### Contact Information\n\n * Your name\n * A phone number\n * An email address where we can reach you for daily communication\n * **Your Github profile or personal website**\n\n\n### Education and Coursework\n\nPlease provide information about your university, degree type, and your expected graduation year. Please list relevant technical courses you have taken.  In particular, we are interested in your background in:\n\n * Robotics\n * Software engineering\n * Computer graphics\n * Physics simulation\n\n### Experience\n\nPlease list any experience you’ve had in software development, including relevant class projects, internships, undergraduate or graduate research, and/or **contributions to open source projects**.\nFor each example, please include a brief description of the overall project along with the specific contributions you made and when you made them.\n\nIn addition to the above information, we are interested in concrete examples of your work, which may include:\n\n * 📢 Open source contributions: **Our mentors are looking for students who have mastered the fundamentals of open source contribution.** If you have contributed to any of our open source projects, or any other open source projects, please include a link to those contributions prominently in your application.  \n * Sample code: please send an example of code you have written that you are proud of; be prepared to answer questions about it. A link to a Github repository works the best!\n * Publications: if you have participated in undergraduate or graduate research, please include a link to a copy of any relevant publications.\n * Specialized skills: if you have experience/skills in particular areas that you believe would be useful to one of our projects, please let us know.\n * Personal website: if you have a website that discusses your research or other projects, please include a link.\n * References: names and contact information for people you have worked with who can recommend you.\n\n### Statement of Intent\n\nIn a paragraph or two, describe your interests and background.  Please tell us which of the project ideas you are interested in and why you’d like to work on it.  If you have a proposal for a project not included on our list, please describe the idea clearly and provide a motivation for the work and a timeline for how you plan to accomplish it.\n\n## ⚠️ A Note on Generative AI ⚠️\n\n**We strongly discourage students from using generative AI tools to generate their application.** Students working with OSRF project mentors over the summer must possess strong communication skills. Our mentors use GSoC applications to evaluate each student's written communication skills. Our mentors may choose to reject students they suspect have used generative AI tools as part of their application. Moreover, as per the [OSRA's interim policy on generative AI tools,](https://discourse.ros.org/t/interim-policy-on-the-use-of-generative-ai-in-osrf-projects/39731) contributors are not permitted to use generative AI tools for code contributions."
  },
  {
    "name": "Learning Unlimited",
    "slug": "learning-unlimited",
    "tagline": "Building excitement for teaching and learning",
    "description": "Learning Unlimited's mission is to create educational opportunities for high school and middle school students, and to provide leadership and teaching opportunities for college students. Learning Unlimited strives to engage students of all ages in an educational setting to share and discover their passions. To accomplish this, Learning Unlimited links local universities with their communities. Our open source work revolves around building and maintaining website infrastructure for these chapters to use.",
    "ideas_url": "https://docs.google.com/document/d/e/2PACX-1vQHE4OyXDdhDPkP2X7OWdSjauW_rQi1Fhr3RwEgTrSjDbrHO3nePDCdJkCheeocMrRTdqbHqnmb9WcG/pub",
    "website_url": "https://www.learningu.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "django",
      "html",
      "css"
    ],
    "topic_tags": [
      "education",
      "web",
      "full stack",
      "Outreach"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/learning-unlimited",
    "ideas_content": "Learning Unlimited GSoC 2026\n\nIdeas List\n\n[Better Onsite Management for Admins 5](https://docs.google.com#h.uhbmsktcnw5)\n\nThe use of generative AI is permitted for most aspects of a pull request submission (e.g., software creation and review, generating documentation and tests).\n\nRequired disclosure: All new pull request submissions must include an AI usage disclosure section that clearly states whether generative AI tools were used. This disclosure must include:\n\n- Tool identification: Specify which AI systems and versions were employed, noting exactly where they were applied (code, documentation, manuscript sections).\n- Scope of assistance: Describe the nature of support provided—examples include code generation, refactoring assistance, and testing scaffolding.\n- Human verification confirmation: Contributors must affirm that human team members thoroughly reviewed, modified, and validated all AI-generated content while making primary architectural and design decisions.\n\nProhibited AI interactions: Conversational use of AI between contributors and reviewers is restricted, except for translation support.\n\nAuthor accountability: Submitting contributors bear complete responsibility for accuracy, originality, licensing compliance, and ethical/legal standards of submitted materials. Incomplete or inaccurate AI disclosures constitute ethical violations with consequences ranging from rejection to institutional notification.\n\nDetailed description: Our website has automated testing via GitHub Actions and Codecov integration, but there is a lot of legacy code that lacks exhaustive testing. Furthermore, due to our small development team, often new features are implemented without the creation of new tests. This project involves systematically identifying untested code paths and creating unit tests to cover them. Some areas have already been identified (see issues listed below), while many other areas will need to be identified using our existing code coverage metrics.\n\nExpected outcomes:\n\n- Increased code coverage metrics\n- Unit tests for all program modules and other website components\n- Documentation of testing patterns for future contributors\n\nRelevant skills/what you might learn:\n\n- Python/Django testing frameworks (unittest, Django TestCase)\n- Test design and code coverage analysis\n- GitHub Actions CI/CD workflows\n- Writing effective test fixtures and mocks\n- Selenium or browser-based testing\n- Reading and understanding a large Django codebase\n\nDifficulty: Easy\n\nExpected size: 175 hours\n\nPossible mentors: Miles Calabresi, Will Gearty\n\nRelevant GitHub issues:\n\n[#3780 - Create more unit tests](https://www.google.com/url?q=https://github.com/learning-unlimited/ESP-Website/issues/3780&sa=D&source=editors&ust=1771588003776390&usg=AOvVaw0zLhyLkd0EIjPWkivk9sot)(parent issue)[#3773 - Add tests for Scheduling Checks Program Module](https://www.google.com/url?q=https://github.com/learning-unlimited/ESP-Website/issues/3773&sa=D&source=editors&ust=1771588003776578&usg=AOvVaw1E_-ru2a8zAbVN0bY03oMy)[#599 - Update dashboard tests for new JSON interface](https://www.google.com/url?q=https://github.com/learning-unlimited/ESP-Website/issues/599&sa=D&source=editors&ust=1771588003776715&usg=AOvVaw3zAU-RhvLuvpxdEcgyn9E9)[#794 - Tests for editclass/makeaclass view](https://www.google.com/url?q=https://github.com/learning-unlimited/ESP-Website/issues/794&sa=D&source=editors&ust=1771588003776842&usg=AOvVaw0WDeewTBLE9SWPgnUazQKh)[#1452 - Ajax autocomplete should have tests](https://www.google.com/url?q=https://github.com/learning-unlimited/ESP-Website/issues/1452&sa=D&source=editors&ust=1771588003776969&usg=AOvVaw3qON7Uh0VLNItyWaubYF35)[#933 - Automated tests for new TwoPhaseStudentReg](https://www.google.com/url?q=https://github.com/learning-unlimited/ESP-Website/issues/933&sa=D&source=editors&ust=1771588003777104&usg=AOvVaw0xloKLYpV0Tix3vO498p9k)[#3457 - Run ajax scheduler JS unit tests with other unit tests](https://www.google.com/url?q=https://github.com/learning-unlimited/ESP-Website/issues/3457&sa=D&source=editors&ust=1771588003777244&usg=AOvVaw1YwS1qeTpgs7ary-eGuUzb)[#3460 - Fix selenium tests](https://www.google.com/url?q=https://github.com/learning-unlimited/ESP-Website/pull/3460&sa=D&source=editors&ust=1771588003777364&usg=AOvVaw17fC1QqbXTYyNPTY5bPVbJ)\n\nDetailed description: Our website uses custom “modules” to control various registration features for users, but the current module management interface is confusing for administrators. Larger chapters often need to enable/disable different modules as they transition between registration phases (e.g., student lottery → class lottery → first-come-first-served). This project involves designing and implementing a new, user-friendly module management interface that allows admins to easily view, enable/disable, and schedule modules with opening/closing times.\n\nExpected outcomes:\n\n- New admin interface for managing program modules (separate views for student and teacher modules)\n- Ability to enable/disable modules with visual feedback\n- Support for module opening/closing times (start/expire dates)\n\nRelevant skills/what you might learn:\n\n- UI/UX design principles\n- Frontend development (HTML/CSS/JavaScript)\n- Django ORM and model design\n- Django views and forms\n\nDifficulty: Medium\n\nExpected size: 175 hours\n\nPossible mentors: Will Gearty\n\nRelevant GitHub issues:\n\nDetailed description: Our website’s theming system, which allows individual chapters to customize the look of their websites, is due for a major overhaul. The site currently uses Bootstrap 2.3.2, which is over a decade old—the current version is 5.3. Bootstrap is used minimally (primarily for buttons and minor elements), and there are existing issues with color contrast. This project involves upgrading Bootstrap to the latest version, expanding its use throughout the website for standardized styling, and implementing Bootswatch themes as default customization options. Bootswatch would provides cohesive color sets, fonts, and other stylings that administrators could select and then tweak appropriately to work for their chapters.\n\nExpected outcomes:\n\n- Upgraded Bootstrap from version 2.3.2 to 5.3\n- Expanded Bootstrap integration across website elements (forms, navigation, cards, modals, etc.)\n- Fixed color contrast issues\n- Integration of Bootswatch theme library as selectable base theme settings\n- Improved documentation for theme customization\n- Improved mobile responsiveness through Bootstrap's modern grid system\n\nRelevant skills/what you might learn:\n\n- Frontend development (HTML/CSS/JavaScript)\n- Bootstrap 5 components, utilities, and grid system\n- LESS/SASS CSS preprocessing\n- Responsive web design and accessibility\n- UI/UX design principles\n\nDifficulty: Hard\n\nExpected size: 350 hours\n\nPossible mentors: Katherine Brumberg, Will Gearty\n\nRelevant GitHub issues:\n\n[#3810 - Theming overhaul](https://www.google.com/url?q=https://github.com/learning-unlimited/ESP-Website/issues/3810&sa=D&source=editors&ust=1771588003780965&usg=AOvVaw2hp9Z2E6EgAi6dONH3WpG0)(parent issue)[#3809 - Upgrade bootstrap](https://www.google.com/url?q=https://github.com/learning-unlimited/ESP-Website/issues/3809&sa=D&source=editors&ust=1771588003781094&usg=AOvVaw2xn2opaMf0Mk3cyQJvZXET)[#3808 - Upgrade theme system to use bootswatch](https://www.google.com/url?q=https://github.com/learning-unlimited/ESP-Website/issues/3808&sa=D&source=editors&ust=1771588003781253&usg=AOvVaw3KbobEQJWS_8cwv-MVQ9ve)\n\nDetailed description: The ESP Website uses various forms for student and teacher registration, but administrators currently face two key pain points. First, when viewing a form, there's no easy way to navigate to where that form can be configured. Second, adding custom fields to forms (like the teacher registration form) currently requires hardcoding form fields in Python, which is inaccessible to chapter administrators without developer support. This project aims to make form customization more intuitive and accessible by adding direct links from forms to their configuration pages and by creating an admin-friendly interface for adding custom form fields without code changes.\n\nExpected outcomes:\n\n- Banners/links on forms directing admins to configuration pages (\"Want to edit this form? Click HERE\")\n- Field-by-field links showing where specific fields can be modified (stretch goal)\n- Frontend interface for creating custom form fields without hardcoding\n- Custom field data accessible in printables and exports\n\nRelevant skills/what you might learn:\n\n- Django forms and form customization\n- Frontend development (HTML/CSS/JavaScript)\n- Database schema design for dynamic fields\n- Django template system\n- UI/UX design for admin interfaces\n\nDifficulty: Medium\n\nExpected size: 175 hours\n\nPossible mentors: William Gearty, Miles Calabresi\n\nRelevant GitHub issues:\n\n[#3690 - Links from Django forms to where they can be configured](https://www.google.com/url?q=https://github.com/learning-unlimited/ESP-Website/issues/3690&sa=D&source=editors&ust=1771588003783044&usg=AOvVaw34AVSXtcVlJdIrnQpagdLL)[#2707 - Make teacher reg custom fields more flexible and accessible](https://www.google.com/url?q=https://github.com/learning-unlimited/ESP-Website/issues/2707&sa=D&source=editors&ust=1771588003783198&usg=AOvVaw2hV6fuK5UfXdzvMsbuyLST)\n\nDetailed description: During Splash and other events, administrators need real-time visibility and control over class registration and attendance. Currently, there's no dedicated mobile-friendly interface for admins to manage onsite operations. This project creates an admin onsite webapp that provides live monitoring of class enrollments and program check-ins (students and teachers), toggles to open/close registration for individual classes, and controls for overenrollment settings. The interface should stay up-to-date and be optimized for use on tablets and phones during the event.\n\nExpected outcomes:\n\n- Admin onsite webapp module with mobile-friendly interface\n- Live/auto-refreshing view of all classes with enrollment progress bars (showing both enrollments and check-ins)\n- Per-class toggle to open/close registration\n- Quick access to overenrollment settings\n- Mini class management page accessible by clicking through to individual classes\n- Settings tab for general onsite configuration\n\nRelevant skills/what you might learn:\n\n- Django views and REST API development\n- JavaScript/AJAX for real-time updates\n- Mobile-responsive UI/UX development\n- WebSocket or polling-based live updates\n- Understanding event logistics and registration systems\n\nDifficulty: Medium\n\nExpected size: 175 hours\n\nPossible mentors: William Gearty, Katherine Brumberg\n\nRelevant GitHub issues:\n\nDetailed description: The ESP Website's communications panel (comm panel) is how administrators send emails to students, teachers, and parents. While functional, it lacks modern email features that users expect from services like MailChimp. This project aims to enhance the comm panel with email templates that admins can select to pre-populate HTML-formatted emails, scheduled sending capabilities to queue emails for a specific date/time, and a teacher-facing comm panel so teachers can easily email students enrolled in their classes. These improvements will streamline communications workflows and bring the system up to par with modern email tools.\n\nExpected outcomes:\n\n- Template selection UI in comm panel with preview thumbnails\n- Ability to create, edit, and manage reusable email templates\n- Scheduled email sending with date/time picker\n- Integration with SendGrid's scheduling API (or cron-based alternative)\n- Teacher comm panel for emailing enrolled students\n- UI to view and manage scheduled/pending emails\n- Documentation for template creation and email scheduling\n\nRelevant skills/what you might learn:\n\n- Django views and forms\n- HTML email design and templating\n- Email delivery systems (SendGrid API)\n- Cron jobs and scheduled task processing\n- Frontend development (JavaScript for date/time pickers, template previews)\n- UX design for communication tools\n- Database design for storing templates and scheduled emails\n\nDifficulty: Hard\n\nExpected size: 350 hours\n\nPossible mentors: Miles Calabresi, William Gearty\n\nRelevant GitHub issues:\n\n[#2885 - Comm panel template UI](https://www.google.com/url?q=https://github.com/learning-unlimited/ESP-Website/issues/2885&sa=D&source=editors&ust=1771588003787140&usg=AOvVaw1HWN9-mRZhYORKA8EbpsUF)[#3833 - Add comm panel for teachers to email students](https://www.google.com/url?q=https://github.com/learning-unlimited/ESP-Website/issues/3833&sa=D&source=editors&ust=1771588003787288&usg=AOvVaw1ev8aWgUnr1gigySASSrRA)[#3951 - Schedule emails to send at a particular time](https://www.google.com/url?q=https://github.com/learning-unlimited/ESP-Website/issues/3951&sa=D&source=editors&ust=1771588003787425&usg=AOvVaw0M8B9jltnCYArw4Cufdsn0)"
  },
  {
    "name": "KolibriOS Project Team",
    "slug": "kolibrios-project-team",
    "tagline": "A tiny and fast operating system in fasm",
    "description": "KolibriOS is a tiny open-source graphical operating system for x86 (and compatible) architecture computers, developed and maintained by the KolibriOS Project Team. It contains a monolithic kernel that runs in 32-bit protected mode and supports full preemptive multitasking.\n\nKolibriOS is a fork of MenuetOS, written almost entirely in FASM (assembly language). However, C, Sphinx C--, C++, Free Pascal, Forth, among other high-level languages and compilers, can also be used in user application development (although FASM is preferred).\n\nThe OS features a rich set of applications that include a word processor, image viewer, graphical editor, textual web browser, and over 30 games. Full FAT12/16/32 and EXT2/3/4 support is implemented, as well as read-only support for NTFS, ISO9660 and XFS. Drivers are written for popular sound, network and graphics cards.\n\nKolibriOS is VERY light on system requirements, using as little as 1MB of disk space and 8MB RAM to run. In terms of processing power, Intel®'s original Pentium® (P5 microarchitecture) or compatible CPU is sufficient to fully enjoy KolibriOS. We strive to become the OS of choice for all older computers, and provide their owners full modern OS experience.",
    "ideas_url": "https://wiki.kolibrios.org/wiki/Ideas_Page",
    "website_url": "https://kolibrios.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "assembly",
      "asm",
      "fasm",
      "pci"
    ],
    "topic_tags": [
      "kernel",
      "operating system",
      "drivers",
      "OS",
      "low-level"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/kolibrios-project-team",
    "ideas_content": "# Ideas Page\n\n[Jump to navigation](https://wiki.kolibrios.org#mw-head)\n\n[Jump to search](https://wiki.kolibrios.org#searchInput)\n\n## Introduction\n\nThis is our ideas page for new developers who want to participate in the Google Summer of Code event by contributing to KolibriOS. It also contains a description of the process and requirements to participate.\n\nA general information about Google Summer of Code can be found here: [Google Summer of Code](https://summerofcode.withgoogle.com/)\n\n## Google Summer of Code'26 Contributor Requirements\n\nProspective contributors are required to register [on our developers forum](https://board.kolibrios.org) and submit a small bugfix / improvement [to our Git](https://wiki.kolibrios.org/wiki/Get_source_code) in order for their application to be considered. Examples of such tasks can be obtained by asking on the developers forum or on our IRC channel (#kolibrios @ irc.libera.chat), [Discord server](https://discord.com/invite/FeB2NvE6bF) or [Telegram chat](https://t.me/kolibri_os). This requirement is only to show us that you are able to work with [our Git](https://wiki.kolibrios.org/wiki/Get_source_code) and interact with our developers if you are selected.\n\n**This task has to be completed before contributor proposal deadline (8 April 18:00 UTC).**\n\nIn addition, contributors need to answer the following questions when applying:\n\n- Full Name (First + Last Name).\n- E-mail address.\n- Nickname you plan to use on our forums, Git repository or IRC chat.\n- Age.\n- Country + city of residence (Russia and Belarus residence are not allowed according to GSoC terms)\n- Human languages you speak (write all languages and knowledge level - basic/intermediate/expert/mother tongue).\n- Name of college or university you are accepted into or enrolled in + link to their website (if applicable).\n- Name of program (or faculty, or department) in that college/university you are accepted into or enrolled in (if applicable).\n- Your current timezone in UTC/GMT terms (for example, Paris is UTC/GMT +1 hours right now).\n- Have you been involved with any open-source project in the past? If yes, which one, and what have you done for that project?\n- Code samples - please provide links to code that you have written. It can be your high school project, contribution to open-source organization, your college/university task or anything like that.\n- The task you are willing to work on from our list of Summer of Code 2026 ideas (or suggest your own idea, if you don't like any of the proposed ideas).\n- What other time commitments, such as school work, another job, planned vacation, etc., will you have between May 8 and November 19?\n\n## Organization\n\nYou can find the organizers at our forum: [https://board.kolibrios.org](https://board.kolibrios.org)\n\nName\n|\nNickname\n|\nRole\n|\n| Ivan Baravy |\n|\n\n[hidnplayr](https://wiki.kolibrios.org/wiki/User:Hidnplayr)[Punk_Joker](https://wiki.kolibrios.org/wiki/User:Punk_Joker)[Leency](https://wiki.kolibrios.org/wiki/User:Leency)## Ideas\n\n| Idea Name | Area | Programming Language | Mentors |\n|---|---|---|---|\n|\n\n[Widget toolkit](https://wiki.kolibrios.org#Widget_toolkit)[Finish Mbed TLS port](https://wiki.kolibrios.org#Finish_Mbed_TLS_port)[Port FLTK](https://wiki.kolibrios.org#Port_FLTK)[FASMG port](https://wiki.kolibrios.org#FASMG_port)[Unicode library](https://wiki.kolibrios.org#Unicode_library)[Virt-IO driver](https://wiki.kolibrios.org#Virt-IO_driver)[Loop device driver](https://wiki.kolibrios.org#Loop_device_driver)[RSS/Atom news reader](https://wiki.kolibrios.org#RSS/Atom_news_reader)[Add HTML forms to WebView](https://wiki.kolibrios.org#Add_HTML_forms_to_WebView)[J2ME Emulator](https://wiki.kolibrios.org#J2ME_Emulator)[Rust library development for KolibriOS](https://wiki.kolibrios.org#Rust_library_development_for_KolibriOS)[WebAssembly runtime development](https://wiki.kolibrios.org#WebAssembly_runtime_development)[MIDI subsystem implementation](https://wiki.kolibrios.org#MIDI_subsystem_implementation)[Git client development](https://wiki.kolibrios.org#Git_client_development)### File system improvement\n\n**General Description**\n\nKolibriOS has already implemented support for many file systems, both write and read, but at the same time support for some systems leaves a lot to be desired and opens up a vast scope for work.\n\n**What it gives us**\n\nSupport for more file systems, particularly write support, will greatly expand the functionality of KolibriOS, especially when working with files on third-party drives.\n\n**Other information**\n\n- Goals:\n- Primary: Add write support for ext4 file system (ext4 reading and ext2 writing are already supported).\n- Additional: Improve write support for NTFS file system.\n\n- Language:\n**Assembler/FASM**. - Difficulty:\n**Intermediate**, you need to be familiar with how file systems work in general, and writing drivers. - Time/Size:\n**175 hours**. - Links:\n\n### Widget toolkit expansion\n\n**General Description**\n\nAt the moment KolibriOS has its own library (box_lib) for implementing various GUI widgets (input fields, checkboxes, scrolls, etc.). However, its functionality is far from complete, and its extension would be very useful for further application development.\n\n**What it gives us**\n\nExtended functionality of the library would help developers in the future to create applications with more complex interface, spending less effort on it, as well as to unify interface components in existing applications.\n\n**Other information**\n\n- Goals:\n- Primary: Extend box_lib (a set of separate widgets) to create a full-featured widget toolkit, design it's architecture and implement focus handling, callbacks and other core ideas.\n- Additional: Integrate created box_lib widgets to the C-framework, extend framework with font handling, layout manager\n\n- Language:\n**Assembler/FASM, C**(Framework). - Difficulty:\n**Intermediate**, you need to be familiar with library development and FASM Assembler. - Time/Size:\n**175 hours**. - Links:\n\n### Finish Mbed TLS port\n\n**General Description**\n\nMbed TLS is an implementation of the TLS and SSL protocols and associated cryptographic algorithms and support code that aims to be \"easy to understand, use, integrate and extend\".\n\n**What it gives us**\n\nThe implementation of MbedTLS support will significantly expand the capabilities of the KolibriOS networking stack and allow it to be used in more networking scenarios, for example, HTTPS support.\n\n**Other information**\n\n- Goals:\n- Primary: Finish MbedTLS port (headers for FASM, get ceritificates working) (\n[TODOs](https://board.kolibrios.org/viewtopic.php?p=76983#p76983)). - Additional: Update HTTP library (written in FASM) to support HTTPS by using mbedtls.obj.\n\n- Primary: Finish MbedTLS port (headers for FASM, get ceritificates working) (\n- Language:\n**C, Assembler/FASM**. - Difficulty:\n**Intermediate**, you need to be familiar with library porting. - Time/Size:\n**175 hours**. - Links:\n\n### FLTK Port\n\n**General Description**\n\nFLTK, or Fast Light Toolkit, is a cross-platform GUI toolkit. It is designed to provide modern GUI functionality without overkill and supports 3D graphics via OpenGL and native GLUT emulation.\n\n**What it gives us**\n\nFLTK provides a wide and convenient enough choice of plugins to implement a complex GUI, and is also cross-platform, and therefore its support in KolibriOS will make it easier to write applications. Also, compared to other UI libraries, FLTK uses a lighter design and is limited to GUI functionality.\n\n**Other information**\n\n- Goals:\n- Primary: Make a working port of FLTK widget library and add it to the automatic build system.\n- Additional: Port Scintilla source code editing component (minimum working version).\n\n- Language:\n**C++, C--, Assembler/FASM** - Difficulty:\n**Intermediate**, you need to be familiar with library porting. - Time/Size:\n**175 hours**. - Links:\n\n### FASMG port\n\n**General Description**\n\nIn 2018 Tomasz Gryshtar (creator of FASM) introduced FASMG, a new assembler engine with more advanced features for simplified writing of complex code. It is quite a powerful and useful tool, and so it would be nice to support its new syntax in KolibriOS.\n\n**What it gives us**\n\nThe kernel, drivers and many programs in KolibriOS are written exactly in FASM Assembler, and porting FASMG would make life easier for developers who work on improving the OS functionality.\n\n**Other information**\n\n- Goals:\n- Primary: Write FASMG application like FASM one. Port standard KolibriOS macros to FASMG syntax.\n- Additional: Implement macros for compatibility with FASM.\n\n- Language:\n**Assembler/FASM/FASMG** - Difficulty:\n**Intermediate**, you need to be familiar with FASM Assembly language. - Time/Size:\n**175 hours**. - Links:\n\n### Unicode library\n\n**General Description**\n\nUnicode is a character encoding standard that includes characters from almost all written languages of the world. The standard is currently prevalent on the Internet and is also frequently used in modern operating systems. The main advantage of Unicode is that it supports a huge number of characters, which allows it to be used for encoding and storing almost any textual information.\n\n**What it gives us**\n\nUnicode is a large and complex standard, nevertheless, modern OS should provide libraries with Unicode related routines like NFC, NFD, sorting, comparing, etc. Support for this standard in KolibriOS would greatly increase its compatibility with various data sources, and make new application scenarios available.\n\n**Other information**\n\n- Goals:\n- Primary: Write a tiny Unicode library with core Unicode algorithms and example application.\n- Additional: Update existing applications to use the new library.\n\n- Language:\n**Assembler/FASM** - Difficulty:\n**Intermediate**, you need to be familiar with writing libraries and FASM Assembler language. - Time/Size:\n**175 hours**. - Links:\n\n### VirtIO driver\n\n**General Description**\n\nVirtIO is a virtualization standard for network and disk device drivers where just the guest's device driver \"knows\" it is running in a virtual environment, and cooperates with the hypervisor. This enables guests to get high performance network and disk operations, and gives most of the performance benefits of paravirtualization.\n\n**What it gives us**\n\nBecause there is no easy way to automatically install KolibriOS on a hard disk, it is often used specifically in a virtualized environment, and therefore improving support and device performance in this situation would be extremely beneficial to it.\n\n**Other information**\n\n- Goals:\n- Primary: Write kernel driver for any VirtIO device, for example - Ethernet card.\n- Additional: Also write drivers for any another VirtIO devices.\n\n- Language:\n**Assembler/FASM** - Difficulty:\n**Intermediate**, you need to be familiar with writing drivers and FASM Assembly language. - Time/Size:\n**175 hours**. - Links:\n\n### Loop device driver\n\n**General Description**\n\nLoop device, vnd (vnode disk), or lofi (loop file interface) is a pseudo-device that makes a computer file accessible as a block device. After mounting a file that holds a file system, the files in that system can be accessed through the usual file system interface of the operating system, without any need for special functionality, such as reading and writing to ISO images, in applications.\n\n**What it gives us**\n\nLoop device drivers allow for mounting a file that holds a file system, making the files within that file system accessible. It also provides a block device on top of a file (or another block device, optionally with remapping). Lastly, if the file contains an encrypted file system, the loop device can be the decrypted version of the original encrypted file and can therefore be mounted as if it were a normal file system.\n\n**Other information**\n\n- Goals:\n- Primary: Write loop device driver and example application to manage loop devices.\n- Additional: Prepare a set of disk images to be used in filesystem unit tests.\n\n- Language:\n**Assembler/FASM**. - Difficulty:\n**Intermediate**, you need to be familiar with writing drivers and FASM Assembly language. - Time/Size:\n**175 hours**. - Links:\n\n### RSS/Atom news reader\n\n**General Description**\n\nRSS and Atom are web feeds that allow users and applications to access updates of websites in a standardized, computer-readable format. For the average user, it can be used primarily as a news/update feed, where the user can subscribe to channels of interest and receive news or other updates from different sources in one place. They are based on XML and can easily be processed using AsmXml library. User application for reading RSS/Atom feeds would be a good addition to usability of KolibriOS, as it will allow users to read news feeds from different sources without need to manually open news websites.\n\n**What it gives us**\n\nRSS/Atom feed can be a great addition to the KolibriOS functionality, as it allows users to conveniently receive updates from different sources, including even on very weak devices, where opening the source of interest in the browser is impossible or problematic.\n\n**Other information**\n\n- Goals:\n- Primary: Write RSS news reader as a standalone KolibriOS application.\n- Additional: Also add Atom standart support to the app.\n\n- Language: Any, but\n**Assembly/FASM**is preferable. - Difficulty:\n**Easy**, you need to be familiar with XML processing and HTTP requests, as well as general app development for KolibriOS. - Time/Size:\n**90 hours**. - Links:\n\n### Add HTML forms support to WebView\n\n**General Description**\n\nDespite supporting many basic HTML features, the WebView browser does not currently support HTML forms (<form>, <input>, etc.). This makes its use extremely limited and prevents it from utilizing the functionality of many popular sites. Therefore, it would be great to implement this functionality in WebView.\n\n**What it gives us**\n\nBecause of the lack of form support, WebView can't even use search engines directly (currently only indirect use of Google in the address bar is possible). This alone would be a great addition to its capabilities and would make its use much more convenient and intuitive. In addition, forms could also be used on sites like online libraries or forums, thus giving KolibriOS users a more complete access to the Internet.\n\n**Other information**\n\n- Goals:\n- Primary: Add support for <form>, <input> tags for types that was prior to HTML5.\n- Additional: Add input types that was introduced in HTML5.\n\n- Language:\n**C--**. - Difficulty:\n**Easy**, you need to be familiar with HTML parsing and web requests. - Time/Size:\n**90 hours**. - Links:\n\n### J2ME Emulator\n\n**General Description**\n\nJ2ME (Java Platform, Micro Edition) is a version of the Java platform for devices with limited resources, such as cell phones, pocket computers, etc. It was especially popular in the 00s, when most mobile phones ran on it. Accordingly, a large number of software for this platform was created at that time, and it would be quite nice to have its support in KolibriOS.\n\n**What it gives us**\n\nThere are already quite a lot of emulators for various retro platforms, which makes it possible to use it, including for retro gaming. Therefore, support for another popular platform will certainly not hurt, especially since in addition to a lot of great games for J2ME also released other programs that can be useful.\n\n**Other information**\n\n- Goals:\n- Primary: Port JVM and java.microedition.* runtime.\n- Additional: Make it run most of popular J2ME games.\n\n- Languages:\n**C**,**Java**. - Difficulty:\n**Hard**, you need to be familiar with emulators porting and Java Runtime Enviroment. - Time/Size:\n**350 hours**. - Links:\n\n### Rust library development for KolibriOS\n\n**General Description**\n\nAt the moment, the Rust library for KolibriOS is in the early stages of development - it doesn't support all system functions, and it doesn't know how to work with system libraries. You can do a great thing, and help in the design and development of this library!\n\n**What it gives us**\n\nRust is a modern programming language that has been actively gaining popularity in recent years, and the number of its users is growing. In addition, it is positioned as fast and compact, which fits perfectly with the KolibriOS ideology. Therefore, it would be very good to have its support as another tool for potential developers.\n\n**Other information**\n\n- Goals:\n- Primary: Implement other system functions support. Make wrappers for DLL's.\n\n- Languages:\n**Rust**,**Assembly/FASM (optional)**. - Difficulty:\n**Intermediate**, you need to be familiar with Rust development. - Time/Size:\n**350 hours**. - Links:\n- Working repository:\n\n### WebAssembly runtime development\n\n**General Description**\n\nWebAssembly is a low-level assembly-like language with a compact binary format that runs with near-native performance and provides languages such as C/C++, C# and Rust with a compilation target so that they can run on the web. A proper runtime will allow running such code in KolibriOS without need of massive rewrite and adaptation.\n\n**What it gives us**\n\nWebAssembly is a unique tool, that combines the performance of low-level languages and web portability, as it allows running tons of programs written in multiple languages in one single runtime. Thus, it will be a great addition for such a system as KolibriOS, where performance and compact size are very important.\n\n**Other information**\n\n- Goals:\n- Primary: Implement minimalistic WASM runtime.\n\n- Languages:\n**Assembly/FASM**. - Difficulty:\n**Intermediate**, you need to be familiar with WASM and runtime technologies. - Time/Size:\n**175 hours**. - Links:\n\n### MIDI subsystem implementation\n\n**General Description**\n\nMusical Instrument Digital Interface (MIDI) is a standard to transmit and store music, originally designed for digital music synthesizers. MIDI does not transmit recorded sounds. Instead, it includes musical notes, timings and pitch information, which the receiving device uses to play music from its own sound library.\n\n**What it gives us**\n\nPreviously, KolibriOS had limited support of MIDI, allowing to play mono-tone compositions through the system speaker. A new proper subsystem with the possibility of playing sound through dynamics and having multiple instrument support would greatly increase the possibilities of KolibriOS as a multimedia system.\n\n**Other information**\n\n- Goals:\n- Primary: Implement a MIDI-to-audio synthesizer (like fluidsynth, for example).\n- Secondary: Develop a proper compositions player with support for MIDI files.\n\n- Languages: Any, but\n**Assembly/FASM**is preferable. - Difficulty:\n**Intermediate**, you need to be familiar with MIDI format, as well as general audio signal processing. - Time/Size:\n**175 hours**. - Links:\n\n### Git client development\n\n**General Description**\n\nGit is a free and open-source version control system used to handle small to very large projects efficiently. Git is used to track changes in the source code, enabling multiple developers to work together on non-linear development.\n\n**What it gives us**\n\nGit is the most popular version control system, and it is also the version control system used in KolibriOS development. Thus, an in-system Git client will not only make the system more attractive for tech-enthusiasts, but also make development of KolibriOS and software for it much easier.\n\n**Other information**\n\n- Goals:\n- Primary: Implement a working Git client with support for main version control functionality.\n- Secondary: Add functionality of SSH authorization to work with protected repositories.\n\n- Languages: Any, but\n**Assembly/FASM**is preferable. - Difficulty:\n**Intermediate**, you need to be familiar with web-protocols, such as HTTP and SSH, as well as general software development. - Time/Size:\n**175 hours**. - Links:\n\n## Completed Ideas\n\nBelow are examples of ideas successfully completed during KolibriOS's previous participation in GSoC.\n\n### GSoC 2024\n\n[SDL2 library port](https://summerofcode.withgoogle.com/programs/2024/projects/U7cf4oma)was succesfully completed by[arnavbhatt288](https://board.kolibrios.org/memberlist.php?mode=viewprofile&u=14954).[NVMe driver implementation](https://summerofcode.withgoogle.com/programs/2024/projects/W1VYwf7j)was succesfully completed by[ramenu](https://board.kolibrios.org/memberlist.php?mode=viewprofile&u=15061).\n\nFor more information see [GSoC 2024 Results](https://wiki.kolibrios.org/wiki/GSoC_2024_Results).\nKolibriOS Project Team at [GSOC'2024](https://summerofcode.withgoogle.com/archive/2024/organizations/kolibrios-project-team).\n\n### GSoC 2016\n\n[Bit torrent client](https://summerofcode.withgoogle.com/archive/2016/projects/6132971438342144)was successfully completed by[Utsav_Chokshi](http://board.kolibrios.org/memberlist.php?mode=viewprofile&u=6843).[GUI-based FTP client](https://summerofcode.withgoogle.com/archive/2016/projects/6252078934523904)was successfully completed by[nisargshah95](http://board.kolibrios.org/memberlist.php?mode=viewprofile&u=6844).[C layer](https://summerofcode.withgoogle.com/archive/2016/projects/6693475676323840)was successfully completed by[punk_joker](https://board.kolibrios.org/memberlist.php?mode=viewprofile&u=4485).[TLS/SSL library](https://summerofcode.withgoogle.com/archive/2016/projects/4568246669803520)was successfully completed by[DenisKarpenko](https://board.kolibrios.org/memberlist.php?mode=viewprofile&u=6848).\n\nKolibriOS Project Team at [GSOC'2016](https://summerofcode.withgoogle.com/archive/2016/organizations/5678701068943360).\n\n### GSoC 2014\n\n[FT232 chip driver for KolibriOS](https://www.google-melange.com/archive/gsoc/2014/orgs/kolibrios/projects/gtament.html)was successfully completed by[gtament](https://board.kolibrios.org/memberlist.php?mode=viewprofile&u=5793).[Port NetSurf and Improve Build System](https://www.google-melange.com/archive/gsoc/2014/orgs/kolibrios/projects/ashmew2.html)was successfully completed by[ashmew2](https://board.kolibrios.org/memberlist.php?mode=viewprofile&u=6211).\n\nKolibriOS Project Team at [GSOC'2014](https://www.google-melange.com/archive/gsoc/2014/orgs/kolibrios).\n\n## Rough Guide for Prospective Contributors\n\n- As the kernel is written in FASM, ability to write and understand i386-assembly code is very useful.\n- C is also a plus as some applications/libraries and components are written in C. Also, C is useful to interface with assembly at times.\n- Familiarity with the GNU landscape like Autotools, GCC etc are also a plus to have (especially for porting software)\n- The desire to take challenging problems and solve them is also required as several parts of the code base require thought for design and implementation. (The mentors can help you with that :) )\n- Hanging out on LiberaChat's #kolibriOS and\n[our forum](https://board.kolibrios.org)where developers mostly hang out. - Languages used for communication are English and Russian (although most developers are bilingual, and you can always ask someone for help)\n- Get in touch with other developers via IRC / Forums and enjoy your stay!\n\n## I'm a potential GSoC contributor. I'm scared of all the assembly and docs here! Where should I start?! :'(\n\nStart here : [http://wiki.kolibrios.org/wiki/HowTo](http://wiki.kolibrios.org/wiki/HowTo)\nThis will help you set up KolibriOS. Easiest will be to use either Qemu or VirtualBox as most developers use it and thus will be able to help you with eventual problems. Feel free however to try something else and let us know how it goes!\n\n## I'm a potential GSoC contributor. What is this test task?!\n\nRegarding the test mentioned above, it is for assessing your current skill set and their relevance regarding the project that you want to eventually work on. In most cases, your potential mentor will assign you a task via IRC / Forum but another developer can do this as well. Meanwhile, In case you are waiting for a test task, you can go through our [bug tracker](https://git.kolibrios.org/KolibriOS/kolibrios/issues) and find a small task to work on yourself, or learn about KolibriOS by going through example code.\n\n## I want to play with the code but my college blocks Git\n\nIf you are have trouble accessing official Git repository, please do mention it on the forums. You can temporarily use this backup Git repository:\n\nOr our official GitHub mirror:\n\n## All the ideas seem interesting, But...\n\nFeel free to suggest your own idea! This is encouraged largely both in GSoC and KolibriOS. The mentors will be glad to such an idea and assess it's feasibility/usability for KolibriOS.\n\n## Great Guide! But I still don't understand X\n\nPlease read Documentation / Development pages on this Wiki. If you have any doubts, feel free to connect with other KolibriOS users and developers through Forum Chat or #kolibrios on LiberaChat.\n\nPlease ask developers / mentors on Forum Chat or IRC. Please be patient on IRC and Forum as developers are on different time zones and it might take a few hours to get back to you. You can also start a Forum thread if it is about something you feel is a general issue.\n\nAnd most importantly... Have Fun!"
  },
  {
    "name": "Blender Foundation",
    "slug": "blender-foundation",
    "tagline": "The Freedom to Create",
    "description": "Blender is a free and open source 3D creation suite, providing individuals and small teams a complete pipeline for 3D graphics, modeling, animation and games.\n\nBlender is being made by 100s of active volunteers from all around the world; by studios and individual artists, professionals and hobbyists, scientists and students, vfx experts and animators, and so on.  All of them are united by an interest to have access to a fully free/open source 3D creation pipeline. Blender Foundation supports and facilitates these goals - even employs a staff for that - but fully depends on the online community to achieve it.",
    "ideas_url": "https://developer.blender.org/docs/programs/gsoc/ideas/",
    "website_url": "https://www.blender.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "python",
      "opengl",
      "c++",
      "vulkan"
    ],
    "topic_tags": [
      "games",
      "graphics",
      "3d",
      "rendering",
      "animation"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/blender-foundation",
    "ideas_content": "# Blender Summer of Code 2026 - Ideas[¶](https://developer.blender.org#blender-summer-of-code-2026-ideas)\n\nThis page collects potential ideas and mentors for contributor projects in the summer of 2026.\n\n## Contacting us[¶](https://developer.blender.org#contacting-us)\n\nYou can contact us via our [developers\nforum](https://devtalk.blender.org/c/contributing-to-blender/summer-of-code/15) or on\n[chat.blender.org](https://chat.blender.org/#/room/#gsoc-2026:blender.org).\nFor matters you prefer to discuss in private, mail Thomas Dinges: thomas\nat blender.org.\n\n## General information for contributors and mentors[¶](https://developer.blender.org#general-information-for-contributors-and-mentors)\n\nNew to GSoC? Learn [how it works](https://summerofcode.withgoogle.com/how-it-works/) on the GSoC website.\n\nThe ideas list below provides ideas for projects that:\n\n- Have an expected project size of ~90, ~175 or ~350 working hours.\n- Implements a feature that developers have agreed would be a great improvement for Blender.\n\nSubmit your own proposal\n\nChoosing an idea from this list is *not* mandatory. Contributors are\nencouraged to submit their own proposals or modified versions of the\nideas from this page. To get an idea of what sort of project can be done for Blender and of\nthe current development direction, see:\n\n[Code Blog](https://code.blender.org/)- Design and todo tasks listed in the Workboards of\n[Blender modules](https://projects.blender.org/) - GSoC projects from previous years:\n[2025](https://developer.blender.org/2025/)-[2024](https://developer.blender.org/2024/)-[2023](https://developer.blender.org/2023/)-[2022](https://developer.blender.org/2022/)-[2021](https://developer.blender.org/2021/)-[2020](https://developer.blender.org/2020/)-[2019](https://developer.blender.org/2019/) [Release Notes](https://developer.blender.org/release_notes/)\n\n### Mentors[¶](https://developer.blender.org#mentors)\n\nA mentor should be someone with Blender coding experience, who can guide a contributor during all stages of the work, from design to implementation.\n\n### Contributors[¶](https://developer.blender.org#contributors)\n\nContributors who wish to apply should first carefully read the [Getting\nStarted page](https://developer.blender.org/getting_started/) and check if all the\nconditions to participate are met.\n\nIf by some reason you can not participate, your contribution outside of the program is still welcome! Feel free to develop an idea from the page as long as no contributor chose it.\n\nWe especially invite contributors to contribute based on their past experience and competencies, or based on their current research.\n\nNearly all project ideas will require a strong working knowledge of C and/or C++. In addition, we use Python for much of our interface code (anyone skilled in C/C++ can trivially learn enough Python to make the needed interface code changes). An exception to this are projects where only Python is required.\n\nGet Started\n\n## Ideas[¶](https://developer.blender.org#ideas)\n\n### VFX & Video[¶](https://developer.blender.org#vfx-video)\n\n#### VSE: OpenTimelineIO support[¶](https://developer.blender.org#vse-opentimelineio-support)\n\n*Description:*built-in support for OpenTimelineIO import/export within Blender VSE. Blender Studio has[experimented with it](https://studio.blender.org/blog/opentimelineio-in-blender/)in 2021, by using and extending a 3rd party addon[vse_io](https://gitlab.com/superprod/stax_suite/vse_io). It would be useful to have built-in support for this in order to support VSE interoperability within the broader video editing ecosystem.*Expected outcomes*: Blender VSE can import and export`.otio`\n\nfiles.*Skills required:*Proficient in C/C++, good familiarity with video editing workflows.*Possible mentors:*[John Kiril Swenson](https://projects.blender.org/eliphaz)*Expected project size:*350 hours*Difficulty:*medium\n\n#### VSE: Mask Editing in VSE Preview[¶](https://developer.blender.org#vse-mask-editing-in-vse-preview)\n\n*Description:*Allow creation and editing of mask datablocks directly inside the VSE preview. Currently, to use masks in the VSE, one must create them from the \"Mask\" mode in either the Image Editor or the Movie Clip Editor, which is quite hidden and unintuitive. Masks must then be manually applied to strip content with a mask modifier or effect strip. The ability to edit these datablocks directly from the Preview would speed up workflows considerably and align blender's VSE with industry standard video editors.*Expected outcomes*: New circle and square mask tools for the preview that automatically create mask modifiers on the selected strip(s). These should support drag or click to place, along with handles for scaling/rotating/translating.*Skills required:*Proficient in C/C++, familiarity with Blender UI design patterns.*Possible mentors:*[John Kiril Swenson](https://projects.blender.org/eliphaz)*Expected project size:*350 hours*Difficulty:*medium\n\n#### VSE: Strip Transition Gizmo[¶](https://developer.blender.org#vse-strip-transition-gizmo)\n\n*Description:*Allow editing fades/crossfades between neighboring strips with a transition gizmo. Transitions can only be created currently using special effect strips that are automatically lengthened to the gap (or overlap) in time between two strips. This is confusing when strips directly neighbor one another on the same channel, where a 0-length invisible strip is placed between them. Ideally, a user would be able to create fades by rightclicking handles and selecting it from the context menu, adding a transition widget that could be further adjusted. See comments on[issue #150688](https://projects.blender.org/blender/blender/issues/150688)for further discussion and design.*Expected outcomes*: Addition of a transition gizmo on strips that temporarily displays the offsets overlay when editing the fade in/out. Rightclicking the gizmo should change the transition type (wipe/gamma cross). Sound crossfades should also be supported.*Skills required:*Proficient in C/C++, familiarity with UI design patterns.*Possible mentors:*[John Kiril Swenson](https://projects.blender.org/eliphaz)*Expected project size:*350 hours*Difficulty:*medium\n\n#### Compositor: New Nodes from Geometry nodes[¶](https://developer.blender.org#compositor-new-nodes-from-geometry-nodes)\n\n*Description:*Implement compatible nodes from geometry nodes in the compositor. Node editors should be able to reuse the same nodes as much as possible. Recently, many nodes were added in geometry nodes that could also have a use case in the compositor. For example the 'Integer Math' is currently supported in geometry nodes only, but could be supported in the compositor as well. The first part of the project consists of conducting a small servey to decide which nodes should get ported and identify the consequences, e.g. a new socket type must be exposed in the compositor node API etc... The second part of the project consists in implementing the new nodes.*Expected outcomes:*Addition of more nodes in the compositor.*Skills required:*Proficient in C/C++, familiar with node editing in Blender.*Possible mentors:*[Habib Gahbiche](https://projects.blender.org/zazizizou)*Expected project size:*90-175 hours depending on the scope.*Difficulty:*easy\n\n#### Compositor/Image Editor: Improve tools for compositing[¶](https://developer.blender.org#compositorimage-editor-improve-tools-for-compositing)\n\n*Description:*Improve existing tools like Sampling tool or implement new one ones in the image editor. Recently, the default compositing workspace was changed from using the backdrop in the node editor to using a node editor and image editor. The goal of this GSoC project is to improve the image editor with the purpose of improving the compositing workflow. Ideas include:- Improve the Sampling tool by adding a gizmo and a permanent widget to copy-paste values from.\n- Implement shortcuts to show R/G/B/A channels in the image editor.\n- Implement gizmos for the existing image transforming and resizing operators.\n\n*Expected outcomes:*Improved compositing workflow by implementing gizmos and widgets in the image editor*Skills required:*Proficient in C/C++, familiar with UI design patterns*Possible mentors:*[Habib Gahbiche](https://projects.blender.org/zazizizou)*Expected project size:*175 or 350 hours depending on the scope*Difficulty:*medium\n\n### Modeling[¶](https://developer.blender.org#modeling)\n\n#### Improved Mesh Smoothing[¶](https://developer.blender.org#improved-mesh-smoothing)\n\n*Description:*Possible enhancements include:- Geometry pinning (boundaries/seams/sharp edges).\n- Custom-data preserving smooth (smooth without distorting UV's and other custom-data).\n- Frequency aware smooth (see the sculpt modes \"Mesh Filter\").\n- Volume preserving smooth (with the possibility of more advanced techniques - e.g. bilateral smoothing).\n\n*Expected outcomes:*Additional smoothing operators for mesh edit-mode.*Skills required:*Proficient in C++, Linear Algebra.*Possible mentors:*[Campbell Barton](https://projects.blender.org/ideasman42)*Expected project size:*350 hours*Difficulty:*medium\n\n#### Improved Edge Loop Editing[¶](https://developer.blender.org#improved-edge-loop-editing)\n\n*Description:*This task involves various enhancements, such as:**Loop Cut at Cursor Location:**Currently Loop Cut snaps to the middle of the face and lets you reposition after confirming. Change the behavior so position can be chosen dynamically before confirming. See[#41446](https://projects.blender.org/blender/blender/issues/41446).**\"Clone\" Support for Edge Slide:**An option for the Edge Slide tool which, when enabled, duplicates the corresponding edges first and then slides them. See[RCS#2rcbbc](https://blender.community/c/rightclickselect/2rcbbc/),[RCS#QDbbbc](https://blender.community/c/rightclickselect/QDbbbc/).**Edge Flow:**Adjusts the edge loop via spline interpolation such that it respects the flow of the surrounding geometry. See[RCS#vddbbc](https://blender.community/c/rightclickselect/vddbbc/).\n\n*Expected outcomes:*Additional loop-editing operators available in edit-mode.*Skills required:*Proficient in C++, Linear Algebra.*Possible mentors:*[Campbell Barton](https://projects.blender.org/ideasman42),[Tariq Sulley](https://projects.blender.org/Tariq-Sulley)*Expected project size:*350 hours*Difficulty:*hard\n\n#### Improved Face Filling Tools[¶](https://developer.blender.org#improved-face-filling-tools)\n\n*Description:*While Blender has some fill tools (e.g. Grid Fill, Fill Holes), there is room for additional work in this area. Possible additions include:- Adding support for filling areas that do not form a perfect grid, detecting known junction patterns (1-to-3, 2-to-4) automatically.\n- Grid Fill support for regions with 5 or more logical sides, with automatic pole insertion (vertices with 5+ edges).\n- Creating a higher-level operator that detects the current context and uses the most appropriate fill method.\n- Re-filling support to select a region and re-fill it, preserving custom-data such as UVs (already supported for Grid Fill).\n\n*Expected outcomes:*Additional fill operators for mesh edit-mode.*Skills required:*Proficient in C++, Linear Algebra.*Possible mentors:*[Campbell Barton](https://projects.blender.org/ideasman42),[Tariq Sulley](https://projects.blender.org/Tariq-Sulley)*Expected project size:*350 hours*Difficulty:*medium\n\n#### Replace Legacy Curve Evaluation for 3D Text[¶](https://developer.blender.org#replace-legacy-curve-evaluation-for-3d-text)\n\n*Description:*Replace legacy \"Curve\" based text implementation. Support 3D text objects without using Blender's curve internals.- Besides character tessellation, replacing curve features such as bevel and extrusion with implementations that don't rely on curve data structures.\n- This project should use functionality associated with geometry-nodes, to allow geometry-nodes to eventually integrate with 3D text.\n- Initial support for geometry-nodes may be possible as part of this project but is not a requirement.\n\n*Expected outcomes:*Efficient text editing that avoids redundant triangulation.*Skills required:*Proficient in C++.*Possible mentors:*[Campbell Barton](https://projects.blender.org/ideasman42)*Expected project size:*350 hours*Difficulty:*medium\n\n### Sculpt, Paint & Texture[¶](https://developer.blender.org#sculpt-paint-texture)\n\n#### General Brush Engine Improvements[¶](https://developer.blender.org#general-brush-engine-improvements)\n\n*Description:*There are many features of the sculpt brushes that can be generalized across the available brushes so that further user customization is possible. Some potential areas to tackle are as follows:- Per-brush \"opt-in\" for scene-level brush settings settings\n- Brush tip roundness (already available as part of Clay Strips Brush)\n- Customizable pressure curves for all pressure-sensitive parameters\n- Tablet tilt support (already available for a number of brushes)\n- Customizable brush toggle ability & improved toggle display\n- \"Grab\" brush anchored improvements to improve first stroke responsiveness and pressure sensitivity\n\n*Expected outcomes:*More consistent and generic settings to improve feel of current brushes.*Skills required:*Proficient in C++, Linear Algebra*Possible mentors:*[Sean Kim](https://projects.blender.org/Sean-Kim)*Expected project size:*175 ~ 350 hours*Difficulty:*medium\n\n### User Interface[¶](https://developer.blender.org#user-interface)\n\n#### Improving Regression Test Coverage[¶](https://developer.blender.org#improving-regression-test-coverage)\n\n*Description:*While there is support for testing the UI through event simulation, test coverage is low so far. A lot more parts of the UI could be covered to prevent/catch regressions, see[151680](https://projects.blender.org/blender/blender/issues/151680). Other ways to cover the Blender UI and the UI system with tests could be developed too (which might require some C++ knowledge, depending on the approach).*Expected outcomes:*Significant amount of new tests covering various features of the Blender UI. Potentially: New ways to test the UI.*Skills required:*Proficient in Python*Possible mentors:*[Julian Eisel](https://projects.blender.org/JulianEisel)*Expected project size:*90*Difficulty:*easy"
  },
  {
    "name": "Unikraft",
    "slug": "unikraft",
    "tagline": "A Fast and Secure Unikernel SDK",
    "description": "Unikraft is a fast, secure and open-source Unikernel Development Kit.\n\nBy tailoring the operating system, libraries and configuration to the particular needs of your application, it vastly reduces virtual machine and container image sizes to a few KBs, provides blazing performance, and drastically cuts down your software stack’s attack surface.\n\nUnikraft is developed in the spirit of open source: public discussions on Discord, open source licensing model using BSD-3-Clause, public development and management on GitHub.\n\nIt does so in the context of a vibrant community consisting of highly skilled software engineers, researchers, teachers, students and hobbyists. Periodic meetings, hackathons and a consistent presence in open source events are central to the well functioning of the community.\n\nWe use guidelines for development and maintenance to ensure the creation of high quality code.\n\nPublic releases are planned to happen once every two months. In general, we aim for a public release to happen at the last Monday of each odd month (January, March, May, etc.)\n\nWe welcome contributors and users on Discord and on GitHub. If you are looking for a fun technical project in the area of operating systems, virtualization, come aboard on Discord.",
    "ideas_url": "https://github.com/unikraft/gsoc/blob/staging/gsoc-2026/ideas.md",
    "website_url": "https://unikraft.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "xen",
      "golang",
      "kvm",
      "assembly language"
    ],
    "topic_tags": [
      "virtualization",
      "cloud",
      "software reuse",
      "software configurability"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/unikraft",
    "ideas_content": "---\ntitle: Google Summer of Code 2026 Ideas List\n---\n\n## Unikraft Project Ideas\n\nThank you for your interest in participating in [Google Summer of Code 2026 (GSoC26)](https://summerofcode.withgoogle.com/programs/2026)!\n\nUnikernels are a novel Operating System (OS) model providing unprecedented optimization for software services.\nThe technology offers a clean slate OS design which improves the efficiency of cloud services, IoT and embedded system applications by removing unnecessary software layers by specializing the OS image.\nOne unikernel framework which provides minimal runtime footprint and fast (millisecond-level) boot times is Unikraft, and aims as a means to reduce operating costs for all services that utilize it as a runtime mechanism.\n\nUnikraft is a Unikernel Development Kit and consists of an extensive build system in addition to core and external library ecosystem which facilitate the underlying functionality of a unikernel.\n\n## Mentors of the projects\n\nMentors will be assigned when the project is initiated.  Please feel free to reach out beforehand to discuss the project.\n\n| Mentor | Email |\n|--------|-------|\n| [Razvan Deaconescu](https://github.com/razvand) | razvand@unikraft.io |\n| [Cezar Crăciunoiu](https://github.com/craciunoiuc) | cezar@unikraft.io |\n| [Ștefan Jumărea](https://github.com/StefanJum) | stefanjumarea02@gmail.com |\n| [Răzvan Vîrtan](https://github.com/razvanvirtan) | virtanrazvan@gmail.com |\n| [Andrei Cioc](https://github.com/nurof3n) | andrei.cioc@unikraft.io |\n| [Sriprad Potukuchi](https://github.com/procub3r) | sriprad@unikraft.io |\n| [Shashank Srivastava](https://github.com/shank250) | shashank21005@gmail.com |\n\nBelow are a list of open projects for Unikraft which can be developed as part of GSoC26.\n\n---\n\n### Unikraft as a Library\n\n| | |\n|-|-|\n| **Difficulty** | 3/5 |\n| **Project Size** | Variable (175 or 350 hours) |\n| **Maximum instances** | 1 |\n| **Constraints/requirements** | Familiarity with build systems and linking, good OS concepts, Linux CLI. |\n\n#### Description\n\nAs an SDK (Software Development Kit), Unikraft provides the build system and tooling to build your application as a unikernel.\nThe application source code files are selected and then compiled, together with the unikernel source code files.\nThen they are all linked together in a final unikernel image that is run a virtual machine.\n\nThis process is complicated, as the application itself needs to adapted to the Unikraft build system.\n\nAnother approach is using the [POSIX binary compatibility layer](https://unikraft.org/docs/internals/syscall-shim) and run ELF binaries directly on top of Unikraft.\nThis, however, sacrifices performance for usability.\n\nWe propose a middle ground: build Unikraft as a static library that will then be linked to the application object files.\nThis will give good performance benefits, while simplifying the build process of applications with Unikraft.\nThere will be need to configure Unikraft and / or to work with the Unikraft build system.\n\n#### Reading & Related Material\n\n* [Unikraft Build Process](https://unikraft.org/docs/internals/build-process)\n* [Unikraft: Internals of the Build Process](https://unikraft.org/docs/internals/build-system)\n* [Bincompat Applications](https://unikraft.org/guides/bincompat)\n* [Porting Applications to Unikraft](https://unikraft.org/guides/basic-porting)\n\n---\n\n### Expanding the Unikraft Software Support Ecosystem\n\n| | |\n|-|-|\n| **Difficulty** | 3/5 |\n| **Project Size** | Variable (175 or 350 hours) |\n| **Maximum instances** | 2 |\n| **Constraints/requirements** | Basic OS concepts, familiarity with POSIX and system calls, build systems and tool stacks. |\n\n#### Description\n\nOne of the weak points of most unikernel projects has always been application support, often requiring that applications be ported to the target unikernel OS.\nWith Unikraft we have been making a strong push towards POSIX compatibility so that applications can run unmodified on Unikraft.\nWe have been doing this in two different ways:\n\n1. by adding support for the Musl libc library such that applications can be compiled against it, using their native build systems, and then linked into Unikraft\n1. through [binary-compatibility mode](https://unikraft.org/docs/concepts/compatibility), where unmodified ELFs are directly executed in Unikraft and the resulting syscalls trapped and redirected to the Unikraft core, via the [`app-elfloader`](https://github.com/unikraft/app-elfloader).\n\nThis has lead to the creation of the [application `catalog` repository](https://github.com/unikraft/catalog) where running applications and examples are brought together.\n\nThis project focuses on expanding Unikraft's software support ecosystem by [adding new applications](https://unikraft.org/docs/contributing/adding-to-the-app-catalog) to the [application `catalog` repository](https://github.com/unikraft/catalog), primarily in binary-compatibility mode.\nWhile doing this, you will also:\n\n1. implement and extend system calls\n1. add extensive testing for the application or framework that is to be included in the catalog\n1. add benchmarking scripts to measure the performance and resource consumption of the application running with Unikraft\n1. conduct synthetic tests using tools such as [the Linux Test Project](https://linux-test-project.github.io/)\n\nThe success of this project will directly impact Unikraft adoption.\nThe project length can be varied depending on which of these items are covered by the project.\n\n#### Reading & Related Material\n\n* https://www.musl-libc.org/\n* https://unikraft.org/guides/using-the-app-catalog\n* https://github.com/unikraft/catalog\n* https://unikraft.org/docs/contributing/adding-to-the-app-catalog\n\n---\n\n### Software Quality Assurance of Unikraft Codebase\n\n| | |\n|-|-|\n| **Difficulty** | 3/5 |\n| **Project Size** | Variable (175 or 350 hours) |\n| **Maximum instances** | 2 |\n| **Constraints/requirements** | C programming skills, Linux command-line experience, build tools |\n\n#### Description\n\nDuring its years of existence, Unikraft has grown in features, application support and codebase.\nAs it matures, a high quality of the code and robust behavior are a must to provide a stable solution for its user base.\n\nThe aim of this project is to assist in the software quality assurance of the Unikraft codebase, by tackling one of the following ideas:\n\n1. The use of the [`uktest` framework](https://github.com/unikraft/unikraft/tree/staging/lib/uktest) to create unit tests for [internal libraries](https://github.com/unikraft/unikraft/tree/staging/lib/) and [external libraries](https://github.com/search?q=topic%3Alibrary+org%3Aunikraft+fork%3Atrue&type=repositories).\n   Not many libraries have unit tests, those that do are mostly exceptions.\n   This will directly impact the stability of the code base and allow quick validation of new features that may break existing functionality.\n\n1. Inclusion of static and dynamic analysis tools that highlight potential spots of faulty or undefined behavior.\n\n1. The use of compiler builtins and compiler flags providing constraints on the code to increase its resilience to faulty behavior.\n\n1. Augmenting the CI/CD system used by Unikraft (based on [GitHub Actions](https://github.com/features/actions)) to feature automatic testing, validation and vetting of contributions to Unikraft repositories: core, libraries, applications.\n   Potential items are:\n   1. handling running of unikernels instead of simple builds\n   1. static analysis of images to be delivered as reports to GitHub pull requests\n   1. regression checks on performance (delivered as % change from the current upstream version)\n\nAny other project that is targeted towards increasing the robustness of Unikraft source code is welcome.\nThese will both increase the viability of Unikraft as a stable solution and increase the quality of future contributions, by enforcing good practices on submitted code.\n\n#### Reading & Related Material\n\n* [Writing Tests in Unikraft](https://unikraft.org/docs/develop/writing-tests/)\n* https://www.guru99.com/unit-testing-guide.html\n* https://docs.kernel.org/dev-tools/kunit/index.html\n* https://github.com/features/actions\n* https://unikraft.org/docs/contributing/review-process/\n\n---\n\n### Supporting macOS networking\n\n| | |\n|-|-|\n| **Difficulty** | 3/5 |\n| **Project Size** | Variable (175 or 350 hours) |\n| **Maximum instances** | 1 |\n| **Constraints/requirements** | Good Go skills, familiarity with virtualization, macOS and networking, good OS knowledge |\n\n#### Description\n\n[KraftKit](https://github.com/unikraft/kraftkit), the supporting codebase for the modular library operating system Unikraft designed for cloud native applications, provides users with the ability to build, package and run unikernels.\nAs a Swiss-army-knife of unikernel development, it eases both the construction and deployment of unikernels.\nTo this end, supporting diverse user environments and their ability to run unikernels locally supports the ultimate goal of the project.  One such environment which requires more attention is macOS.\n\nTowards better facilitating the execution of unikernel virtual machine images on macOS, this project aims to introduce new packages which interface directly with macOS environments by interfacing natively with the local networking environment such that the execution of unikernels is accessible through a more direct communication mechanisms of the host.\nUntil now, the project only supports Linux bridge networking with accommodation (albeit \"stubs\") in the codebase for Darwin.\n\n#### Reading & Related Material\n\n* https://github.com/unikraft/kraftkit/issues/841\n\n---\n\n### Supporting User-provided, Long-lived Environmental Variables for Unikraft Builds\n\n| | |\n|-|-|\n| **Difficulty** | 2/5 |\n| **Project Size** | Medium (175 hours) |\n| **Maximum instances** | 1 |\n| **Constraints/requirements** | Good Go skills, familiarity with build tools, good OS knowledge |\n\n#### Description\n\nUnikraft is a highly modular library operating system designed for the cloud.\nIts high degree of modularization allows for extreme customization and specialization.\nAs such, its tooling should not interfere with the user's desire to support such customization.\nTowards increasing the unikernel's developer's ability to customize the build whilst simultaneously automating the process of retrieving, organizing and generally facilitating the build of a unikernel based on Unikraft and its many components, the supported tooling, [kraft](https://github.com/unikraft/kraftkit), should allow for the injection of the user's environment and or additional toolchain requirements.\n\nThis project is designed to better facilitate the dynamic injection of user provided variables into Unikraft's build system through the addition of a dynamically configured toolchain towards greater customization of the unikernel build through the use of its command-line companion client tool, `kraft`.\nThis manifests itself as an injection into KraftKit's core configuration system and must propagate across the codebase appropriately.\n\nDistinct results of this addition would enable, but are not limited to: alternating the GNU Compiler Collection (GCC) version, providing alternative compile-time flags, and more.\n\n#### Reading & Related Material\n\n* https://github.com/unikraft/kraftkit/issues/673\n\n---\n\n### Unikernel Remote Builds Server\n\n| | |\n|-|-|\n| **Difficulty** | 4/5 |\n| **Project Size** | Large (350 hours) |\n| **Maximum instances** | 1 |\n| **Constraints/requirements** | Good Go skills, familiarity with virtualization, good orchestration knowledge, good networking knowledge |\n\n#### Description\n\n[KraftKit](https://github.com/unikraft/kraftkit), the cli tool used by Unikraft provides users with the ability to build, package and run unikernels.\nThese builds are currently executed locally, which may not be ideal for all users that may not own a powerful machine or may want to offload the build process to a remote server.\n\nTo this end, this project aims to introduce a new package which interfaces directly with a remote server environment by implementing a client-server architecture for remote unikernel builds.\n`kraft` will act as the client, sending build requests to a remote server, which will execute the build and send back the results to the client to place in the current directory at known paths.\nMoreover, an initial implemntation of the server needs to be created, which will be responsible for receiving build requests, executing them and sending the results back to the client, whilst cleaning up the environment after the build is done.\nThis server could also be `kraft` itself, running in server mode and listening for build requests from other `kraft` invocations.\n\n#### Reading & Related Material\n\n* https://github.com/unikraft/kraftkit/issues/2635\n\n---\n\n### Add KraftKit Support for Hyperlight\n\n| | |\n|-|-|\n| **Difficulty** | 4/5 |\n| **Project Size** | Large (350 hours) |\n| **Maximum instances** | 1 |\n| **Constraints/requirements** | Good Go skills, familiarity with virtualization, decent kernel programming knowledge |\n\n#### Description\n\n[KraftKit](https://github.com/unikraft/kraftkit), the companion tool used by Unikraft can be used also to run unikernels locally using various hypervisors.\nCurrently, KraftKit supports both QEMU and Firecracker as KVM VMMs.\nIt also supports Xen through the use of `xl` toolstack.\nTo increase support for other tools, this project aims to add support for [Hyperlight](https://github.com/hyperlight-dev/hyperlight), a new VMM using the Linux `kvm` module for lightweight virtualization.\nSimilar to both the [QEMU](https://github.com/unikraft/kraftkit/tree/staging/machine/qemu) and [Firecracker](https://github.com/unikraft/kraftkit/tree/staging/machine/firecracker) packages, a new one needs to be created for Hyperlight, such that the command `kraft run` would be able to run unikernels using Hyperlight as the underlying VMM.\nDevelopment will be incremental, starting with basic \"Hello World\" functionality, and later adding support for networking, storage and other features.\n\n#### Reading & Related Material\n\n* https://github.com/unikraft/kraftkit/issues/2636\n\n---\n\n### Enhance KraftKit's Testing Suite\n\n| | |\n|-|-|\n| **Difficulty** | 3/5 |\n| **Project Size** | Variable (175-350 hours) |\n| **Maximum instances** | 1 |\n| **Constraints/requirements** | Good Go skills, familiarity with testing, basic Linux CLI knowledge |\n\n#### Description\n\n[KraftKit](https://github.com/unikraft/kraftkit), the tool used to build, package, and run unikernels based on Unikraft, has a minimal set of tests.\nTo ensure the stability of the codebase and to prevent regressions, this project aims to enhance the testing suite of KraftKit by adding new tests for existing functionality, as well as for new features.\nSample tests exists throughout for both unit tests and integration tests, but these lack breadth.\nThe project aims to first target internal packages that require unit testing by doing a bottom-up approach.\nAt the same time, integration tests for the untested `kraft` commands need to be added as a top-down approach.\n\n#### Reading & Related Material\n\n* https://github.com/unikraft/kraftkit/issues/370\n* https://github.com/unikraft/kraftkit/issues/811\n* https://github.com/unikraft/kraftkit/issues/808\n* https://github.com/unikraft/kraftkit/issues/809\n* https://github.com/unikraft/kraftkit/issues/810\n\n---\n\n### Fine-Tuning Unikraft's Performance\n\n| | |\n|-|-|\n| **Difficulty** | 4/5 |\n| **Project Size** | Variable (175 or 350 hours) |\n| **Maximum instances** | 1 |\n| **Constraints/requirements** | Good C skills, familiarity with general operating system concepts, good testing knowledge |\n\n#### Description\n\nOver the past releases the development focus of Unikraft has been set on improving its compatibility with existing code bases and adding missing operating system features.\nThis means that less efforts were dedicated to performance-testing Unikraft, resulting in a potential loss of performance in recent releases.\nNow that Unikraft is reaching the desired level of maturity and compatibility, it is time to go back to evaluating and fine-tuning its performance.\n\nThe aim of this project is to 1) evaluate the current performance of Unikraft, 2) identify potential performance bottlenecks, and 3) address these bottlenecks through targeted patches.\n- To evaluate the performance of Unikraft, this project will base on the evaluation of the Unikraft EuroSys paper, re-running experiments with the latest release of Unikraft.\n  The first phase of the project will be to create a new repository with updated experiments that can easily be run in a push-button manner (deliverable 1).\n- Following this, bottlenecks will be identified.\n  Performance bottlenecks may lie in any Unikraft component: this will be a unique opportunity to touch on many operating system concepts.\n  Performance bottlenecks will be reported in the form of GitHub issues (deliverable 2).\n- Finally, the project will aim to provide self-contained, targeted fixes for these bottlenecks in the form of GitHub Pull-Requests (deliverable 3).\n\nThis project is a unique opportunity to learn about performance evaluation and optimization in a production-grade operating system.\nIt is also an opportunity to participate in a potential academic journal submission of Unikraft by refreshing its evaluation.\n\n#### Reading & Related Material\n\n* The Unikraft EuroSys 2021 paper (see the Evaluation, Section 5): https://dl.acm.org/doi/10.1145/3447786.3456248\n* The EuroSys 2021 evaluation repository: https://github.com/unikraft/eurosys21-artifacts\n\n---\n\n### Expanding Autokraft, Unikraft's Testing Framework\n\n| | |\n|-|-|\n| **Difficulty** | 3/5 |\n| **Project Size** | Variable (175 or 350 hours) |\n| **Maximum instances** | 2 |\n| **Constraints/requirements** | Python knowledge, Linux CLI |\n\n#### Description\n\nAutokraft](https://github.com/unikraft/autokraft) is a testing framework for validating Unikraft unikernel builds across various configurations, platforms, and environments.\nAutokraft has been part of GSoC 2025 and is now an integral part of the Unikraft ecosystem.\n\nAutokraft can benefit from various improvements to its implementation, such as:\n- parallelizing / pipelining builds and runs to decrease the total build time duration\n- testing and validating it on Windows (WSL) and macOS environments\n- improving the CI/CD pipelines to use Autokraft: when PRs are created, merged, or periodically on repository main branches\n- testing Autokraft with Xen\n- running build and runs on a remote box\n\nAdditional features are welcome.\nAs a young project, Autokraft can benefit from refactoring, code updates or other applicant-proposed features.\n\n#### Reading & Related Material\n\n* https://github.com/unikraft/autokraft\n* https://github.com/unikraft/catalog\n* https://github.com/unikraft/catalog-core\n\n---\n\n### Update Unikraft Core External Libraries\n\n| | |\n|-|-|\n| **Difficulty** | 3/5 |\n| **Project Size** | Variable (175 or 350 hours) |\n| **Maximum instances** | 2 |\n| **Constraints/requirements** | C, assembly, Linux CLI, GNU build tools |\n\n#### Description\n\nThe Unikraft core external libraries haven't been updated in the past 2 years.\nWe aim to update them to their latest version.\nThat means:\n\n- Update [`lib-musl`](https://github.com/unikraft/lib-musl) from 1.2.3 to 1.2.5 (the most recent [upstream Musl](https://musl.libc.org/) version).\n- Update [`lib-lwip`](https://github.com/unikraft/lib-lwip) from 2.1.2 to 2.2.1 (the most recent [upstream LWIP](https://savannah.nongnu.org/projects/lwip/) version).\n- Update [`lib-gcc`](https://github.com/unikraft/lib-gcc) from 7.3.0 to 14.2.0 (the most recent [upstream GCC](https://ftp.gnu.org/gnu/gcc/) version).\n- Update [`lib-libcxx`](https://github.com/unikraft/lib-libcxx) from 14.0.6 to 19.1.7 (the most recent [upstream LLVM](https://github.com/llvm/llvm-project/releases) version).\n- Update [`lib-libcxxabi`](https://github.com/unikraft/lib-libcxxabi) from 14.0.6 to 19.1.7 (the most recent [upstream LLVM](https://github.com/llvm/llvm-project/releases) version).\n- Update [`lib-compiler-rt`](https://github.com/unikraft/lib-compiler-rt) from 14.0.6 to 19.1.7 (the most recent [upstream LLVM](https://github.com/llvm/llvm-project/releases) version).\n- Update [`lib-libunwind`](https://github.com/unikraft/lib-libunwind) from 14.0.6 to 19.1.7 (the most recent [upstream LLVM](https://github.com/llvm/llvm-project/releases) version).\n\nThe update is aimed to use the [workflow for Unikraft microlibrary version](https://docs.google.com/document/d/1A-CAss5RvgYapg3YO8GNCdMki6cgq_7XG5om8nVWWGk/edit?usp=sharing).\nAs part of the update effort, we aim to also test and validate builds for the [`catalog-core`](https://github.com/unikraft/catalog-core) and [`catalog`](https://github.com/unikraft/catalog) repositories.\n\n#### Reading & Related Material\n\n* [RFC: Unikraft Microlibrary Versioning](https://docs.google.com/document/d/1A-CAss5RvgYapg3YO8GNCdMki6cgq_7XG5om8nVWWGk/edit?usp=sharing)\n\n---\n\n### Update Unikraft Application Libraries\n\n| | |\n|-|-|\n| **Difficulty** | 3/5 |\n| **Project Size** | Variable (175 or 350 hours) |\n| **Maximum instances** | 2 |\n| **Constraints/requirements** | C, assembly, Linux CLI, GNU build tools |\n\n#### Description\n\nThe Unikraft application libraries haven't been updated in the past 2 years.\nWe aim to update them to their latest upstream version.\nTarget libraries / applications are:\n\n- [`lib-nginx`](https://github.com/unikraft/lib-nginx)\n- [`lib-redis`](https://github.com/unikraft/lib-redis)\n- [`lib-sqlite`](https://github.com/unikraft/lib-sqlite)\n- [`lib-python3`](https://github.com/unikraft/lib-python3)\n- [`lib-libgo`](https://github.com/unikraft/lib-libgo)\n- [`lib-lua`](https://github.com/unikraft/lib-lua)\n\nThe update is aimed to use the [workflow for Unikraft microlibrary version](https://docs.google.com/document/d/1A-CAss5RvgYapg3YO8GNCdMki6cgq_7XG5om8nVWWGk/edit?usp=sharing).\nAs part of the update effort, we aim to also test and validate builds for the [`catalog-core`](https://github.com/unikraft/catalog-core) and [`catalog`](https://github.com/unikraft/catalog) repositories.\n\n#### Reading & Related Material\n\n* [RFC: Unikraft Microlibrary Versioning](https://docs.google.com/document/d/1A-CAss5RvgYapg3YO8GNCdMki6cgq_7XG5om8nVWWGk/edit?usp=sharing)\n\n---\n\n### Add FreeBSD Libc as Unikraft External Library\n\n| | |\n|-|-|\n| **Difficulty** | 3/5 |\n| **Project Size** | Variable (175 or 350 hours) |\n| **Maximum instances** | 1 |\n| **Constraints/requirements** | C, assembly, Linux CLI, GNU build tools |\n\n#### Description\n\nThe default Unikraft standard C library (libc) is [Musl](https://github.com/unikraft/lib-musl), a lightweight libc providing a POSIX interface.\n[FreeBSD Libc](https://github.com/freebsd/freebsd-src/tree/main/lib/libc) is the default libc used by default by FreeBSD, with a compatible license with Unikraft.\n\nThe goal of this project is have a FreeBSD libc build repository for Unikraft and build existing applications against it.\nIn the end, you would be able to build and run applications on the [`catalog-core`](https://github.com/unikraft/catalog-core) and [`catalog`](https://github.com/unikraft/catalog) repositories using the FreeBSD libc variant.\n\n#### Reading & Related Material\n\n* https://github.com/freebsd/freebsd-src/tree/main/lib/libc\n\n---"
  },
  {
    "name": "SageMath",
    "slug": "sagemath",
    "tagline": "Open-source mathematics software system",
    "description": "Mathematicians, scientists, researchers, and students need a powerful tool for their work or study. SageMath is a freely available open-source mathematical software system bundling the functionality of many software libraries, exposing their features in a common interface and extending on top of this with its own powerful algorithms. By leveraging the flexibility and universality of the underlying Python interpreter, SageMath is able to accommodate for a vast range of their requirements.\n\nThe mission of SageMath is to create a viable open-source alternative to all major proprietary mathematical software systems.\n\nPython is the main programming language inside the SageMath library and also the language of choice for all interactions with the built-in objects and functions for expressing mathematical concepts and calculations. Besides a command-line and programming-library interface, its primary user interface is a dynamic self-hosted website. From the perspective of a user, the interface language is Python, but with a thin extension built directly on top of it.\n\nAlmost all areas of mathematics are represented in SageMath, at various levels of sophistication. This includes symbolic calculus, 2D and 3D graphics, polynomials, graph theory, group theory, abstract algebra, combinatorics, cryptography, elliptic curves and modular forms, numerical mathematics, linear algebra and matrix calculations (over various rings), support for parallel computing, and a powerful coercion framework to “mix” elements from different sets for calculations. SageMath’s features also expand into neighboring fields like Statistics and Physics.",
    "ideas_url": "https://wiki.sagemath.org/GSoC/2026",
    "website_url": "https://www.sagemath.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "cython"
    ],
    "topic_tags": [
      "mathematics",
      "education",
      "research"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/sagemath",
    "ideas_content": "Visit [cloudflare.com](https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_523&utm_campaign=wiki.sagemath.org) for more information.\n\n2026-02-20 10:48:37 UTC\n\nThe origin web server is not reachable.\n\nPlease try again in a few minutes.\n\nCheck your DNS Settings. A 523 error means that Cloudflare could not reach your host web server. The most common cause is that your DNS settings are incorrect. Please contact your hosting provider to confirm your origin IP and then make sure the correct IP is listed for your A record in your Cloudflare DNS Settings page. [Additional troubleshooting information here.](https://developers.cloudflare.com/support/troubleshooting/http-status-codes/cloudflare-5xx-errors/error-523/)"
  },
  {
    "name": "Jitsi",
    "slug": "jitsi",
    "tagline": "State-of-the-art video conferencing",
    "description": "Jitsi is a set of Open Source projects which empower users to deploy secure, scalable and easy to use video conferencing platforms with state-of-the-art video quality and features.",
    "ideas_url": "https://github.com/jitsi/gsoc-ideas/blob/master/2026/README.md",
    "website_url": "https://jitsi.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "javascript",
      "java",
      "react",
      "kotlin",
      "webrtc"
    ],
    "topic_tags": [
      "video",
      "multimedia",
      "video conferencing",
      "WebRTC"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/jitsi",
    "ideas_content": "# Projects for GSoC 2026\n\nHere's the list of project ideas for GSoC 2026! Click on the title for a more detailed description.\n\n* [Chat Moderation & Editing](chat-moderation-editing.md)\n* [Jitsi Videobridge JavaScript client](jvb-js.md)\n* [Virtual Backgrounds, take 2](virtual-backgrounds-ng.md)\n* [E2EE: Replace olm with vodozemac](e2ee-vodozemac.md)\n* [Tracing calls through backend components](tracing-backend.md)\n* [External API without iframe](external-api-no-iframe.md)\n* [External API with non-serialized postMessages](external-api-structured-clone.md)\n* [Inject external streams via iframe API](inject-external-streams.md)\n* [PTZ camera support via WebRTC constraints](ptz-camera-support.md)\n* [Ultrasound experiments with ggwave (part 2)](ultrasound-ggwave.md)\n* [Rewrite Jibri to use iframe API](jibri-iframe-api.md)\n* [Document Picture-in-Picture for browser meetings](document-pip-browser.md)\n\n# Interested in applying for a project?\n\nMake sure to read the [GSoC advice pages](https://developers.google.com/open-source/gsoc/help/student-advice/) to see how to get started, and check out the [Jitsi handbook](https://jitsi.github.io/handbook/) to get yourself more familiarized with Jitsi.\n\nThink about preparing a proposal, but *do NOT share any drafts publically to avoid being plagiarized*. We don't have the resources to review drafts anyway, so please do *NOT* include them in your introduction email.\n\nUse of AI/LLMs for project proposals should be limited to language and grammar corrections only. Your proposal should be concise, well-organized, and demonstrate your genuine interest in the project.\n\n# Do you have a suggestion for a new project?\n\nIf you have a suggestion for a project that's not on our list, feel free to create an issue in this repository."
  },
  {
    "name": "Tiled",
    "slug": "tiled",
    "tagline": "A flexible level editor for everyone!",
    "description": "Tiled is a 2D engine-agnostic level editor for games. Its primary feature is to edit different types of tile maps, but it also supports free image placement as well as powerful ways to annotate levels with extra information used by the game. Tiled focuses on general flexibility while trying to stay intuitive.",
    "ideas_url": "https://github.com/mapeditor/tiled/wiki/GSoC-2026#project-ideas",
    "website_url": "https://www.mapeditor.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c++",
      "qt"
    ],
    "topic_tags": [
      "games",
      "Level Editor"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/tiled",
    "ideas_content": "# Google Summer of Code 2026\nTiled has been accepted as mentoring organization in the [Google Summer of Code](https://summerofcode.withgoogle.com/how-it-works) 2026!\n\nThis page contains the list of projects we'd suggest, but we're also open to other proposals!\n\n**Please note that Google Summer of Code projects are a full (day-) time job.**\n\n### Contents\n\n* [Project Ideas](#project-ideas)\n    * [New Hardware Renderer](#new-hardware-renderer)\n    * [Enhanced World Editing](#enhanced-world-editing)\n    * [glTF Export for Maps](#gltf-export-for-maps)\n* [Application Process](#application-process)\n* [Organization](#organization)\n\n# Project Ideas\n\nWe are open to your ideas! If you have your own ideas for improving Tiled, you are more than welcome to send them. Below are listed our suggestions, representing large areas of improvement.\n\n## New Hardware Renderer\n\nModernize the rendering engine to use the [Qt Scene Graph](https://doc.qt.io/qt-6/qtquick-visualcanvas-scenegraph.html) instead of [`QPainter`](https://doc.qt.io/qt-6/qpainter.html). This would also enable using declarative UI for describing the map view.\n\n**Expected outcome:** Tiled performs better and is more flexible thanks to a new renderer based on a modern graphics API.\\\n**Required skills:** Qt, C++ (preferred: Qt Quick, experience with modern graphics APIs)\\\n**Possible mentors:** bjorn\\\n**Expected size:** 350 hours\\\n**Difficulty:** Medium\n\nFull project description: [New Hardware Renderer](https://github.com/mapeditor/tiled/wiki/New-Hardware-Renderer)\n\n## Enhanced World Editing\n\nTiled 1.2 added displaying multiple maps within the same view by [setting up a World](https://doc.mapeditor.org/en/stable/manual/worlds/). Since Tiled 1.4, a basic \"World Tool\" was added, which enabled [basic editing of the world](https://doc.mapeditor.org/en/stable/manual/worlds/#editing-worlds). This project is about making several improvements to the world editing functionality.\n\n**Expected outcome:** Worlds are a natural and convenient part of creating game content with Tiled.\\\n**Required skills:** C++ (preferred: Qt)\\\n**Possible mentors:** bjorn, dogboydog\\\n**Expected size:** 350 hours (or 175 hours, by selecting a sub-set of listed improvements)\\\n**Difficulty:** Medium\n\nFull project description: [Enhanced World Editing](https://github.com/mapeditor/tiled/wiki/Enhanced-World-Editing)\n\n## glTF Export for Maps\n\nImplement a glTF export feature for maps, allowing them to be quickly imported for use in other frameworks without that framework needing to implement support for all of Tiled's features.\n\n**Expected outcome:** Maps can be exported in glTF format as a quick way of rendering them in multiple frameworks.\\\n**Required skills:** C++ or JavaScript (preferred: glTF)\\\n**Possible mentors:** bjorn, dogboydog\\\n**Expected size:** 350 hours (or 175 hours, for somebody who already knows glTF very well)\\\n**Difficulty:** Medium\n\nRendering a Tiled map generally consists of determining the texture coordinates for each tile and setting up a mesh for each layer and tileset. At each step, a host of Tiled-specific properties and behaviors have to be taken into account, from tileset margin and spacing to  map orientation and tile alignment.\n\nWith the growing support for glTF in many engines and frameworks, all this application-specific logic could be performed ahead of time, greatly simplifying the importing of a Tiled map in a game. Hence, this project is about writing a Tiled plugin, preferably in C++ but could also be done in JavaScript, to enable exporting a map, or an entire world, to the glTF format.\n\nSpecial considerations include how to handle tile animations, logic-related layers and in general dynamic changes to the glTF scene when used in a game. In addition, for optimal rendering performance we'll probably want to look into texture packing and creating an optimized tileset.\n\nRelated issue: [#2741](https://github.com/mapeditor/tiled/issues/2741)\n\n# Application Process\n\nIf you are interested in any of our projects and looking forward to join us in improving Tiled further, follow the below guidelines to apply.\n\n* Sign-up in our [forum](http://discourse.mapeditor.org/) and [introduce yourself](https://discourse.mapeditor.org/t/google-summer-of-code-2026/7732).\n\n* Tell us in which project you are interested.\n\n* Tell us a little bit about yourself. We are interested to hear:\n    - Why you would like to work with us.\n    - What previous programming experience you have.\n    - What projects you have worked on before.\n    - Which languages and technology you used for them.\n    - Whether you worked in a team or alone.\n    - Whether you have done any contribution to any open source project before.\n    - Whether you have any previous experience working with Git or any versioning software.\n    - Whether you have any prior experience with C++ and Qt.\n    - What project(s) you have in a public repository that we could can take a look at.\n\nNone of the above information is mandatory, but the better our impression is the more confident we will be that you can succeed in your proposal. If you have a personal website or a CV/resume online, feel free to include a link.\n\n# Organization\n\nSince Tiled's [first release](https://www.mapeditor.org/2004/06/15/tiled-030-released.html) back in 2004, it was intended to be a tile map editor generic enough to be useful for many kinds of games. Today it is used by thousands of game developers every day, because it is a free and powerful editor, independent of the engine or technology they use to develop their game.\n\nThe Tiled organization is committed to maintaining this editor and also helping others contribute any improvements they need. Tiled is also a perfect project for new developers learn the benefits of free software and get to know the related technology (Qt, C++).\n\n### Mentors\n\nThe following people are available as mentors for this year's Google Summer of Code:\n\n- [bjorn](http://discourse.mapeditor.org/u/bjorn)\n- [dogboydog](http://discourse.mapeditor.org/u/dogboydog)"
  },
  {
    "name": "Git",
    "slug": "git",
    "tagline": "Fast,Scalable,Distributed revision control system",
    "description": "Git is the most widely-used revision control system in Open Source. It is a distributed system with an emphasis on speed, data integrity, and support for distributed, non-linear workflows.\n\nMany large and successful projects use Git, including the Linux Kernel, Perl, Eclipse, Gnome, KDE, Qt, Ruby on Rails, Android, PostgreSQL, Debian, and X.org.\n\nThis organization covers projects for Git itself. Other git-based software or services are not covered by this organization.",
    "ideas_url": "https://git.github.io/SoC-2026-Ideas/",
    "website_url": "https://git-scm.com/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "shell script",
      "git",
      "c language"
    ],
    "topic_tags": [
      "version control",
      "dvcs"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/git",
    "ideas_content": "This is the idea page for Summer of Code 2026 for Git.\n\n*Please completely read the general application information\npage before reading the idea list below.*\n\n**Students**: Please consider these ideas as starting points for\ngenerating proposals. We are also more than happy to receive proposals\nfor other ideas related to Git. Make sure you have read the “Note\nabout refactoring projects versus projects that implement new\nfeatures” in the [general application information](https://git.github.io/General-Application-Information)\npage though.\n\nKindly note that considering the bandwidth of available mentors, the Git project would only mentor up to 3 or 4 contributors this year.\n\nThis is not a hard and fast rule. It may change if more community members are willing to mentor in the coming days. For instance, this may happen when a new project is proposed and some community member volunteers to mentor the same.\n\nThis project focuses on modernizing Git’s environment handling by refactoring\nthe `environment.c`\n\ncode to reduce global state. The goal is to move environment\nvariables and configuration from global scope into more appropriate local\ncontexts, primarily into the `struct repository`\n\n/ `struct repository_settings`\n\nstructure. This architectural improvement will make the codebase more\nmaintainable and potentially enable better multi-repository handling in the\nfuture.\n\nThe project involves careful refactoring of Git’s core environment handling code, requiring strong C programming skills and attention to detail. Design discussions on the mailing list to find the best way to refactor some variables will likely happen.\n\nThe contributor will identify global variables that can be moved to local scope, implement the necessary structural changes, and ensure all affected code paths continue to work correctly. This includes updating tests, fixing any regressions, and documenting the architectural changes.\n\n**Getting started:** Build Git from source, study the `environment.c`\n\nfile\nand its global variables, understand how `struct repository`\n\nand\n`struct repository_settings`\n\nwork, and submit a micro-patch to demonstrate\nfamiliarity with the codebase. Review recent mailing list discussions about\nreducing global state.\n\n*Expected Project Size*: 90 or 175 hours or 350 hours\n\n*Difficulty*: Medium\n\n*Languages*: C, shell(bash)\n\n*Possible mentors*:\n\n- Christian Couder <\n[christian.couder@gmail.com](mailto:christian.couder@gmail.com)> - Karthik Nayak <\n[karthik.188@gmail.com](mailto:karthik.188@gmail.com)> - Justin Tobler <\n[jltobler@gmail.com](mailto:jltobler@gmail.com)> - Ayush Chandekar <\n[ayu.chandekar@gmail.com](mailto:ayu.chandekar@gmail.com)> - Siddharth Asthana <\n[siddharthasthana31@gmail.com](mailto:siddharthasthana31@gmail.com)> - Lucas Seiki Oshiro <\n[lucasseikioshiro@gmail.com](mailto:lucasseikioshiro@gmail.com)>\n\n`git repo`\n\ncommandThe `git repo`\n\ncommand was introduced as part of GSoC 2025 (released in Git 2.52.0)\nto provide a cleaner interface for querying repository metadata and configuration.\nThe command currently has two sub-commands: `git repo info`\n\nfor retrieving repository\ninformation in machine-readable formats, and `git repo structure`\n\nfor displaying\nrepository statistics.\n\nSee the [mailing list discussion](https://public-inbox.org/git/20250610152117.14826-1-lucasseikioshiro@gmail.com/t/#u)\nintroducing the command and the [official documentation](https://git-scm.com/docs/git-repo)\nfor current functionality.\n\nA number of improvements could be made to both sub-commands:\n\n**For git repo info**, potential improvements include:\n\n- Remove the dependency on\n`the_repository`\n\nglobal variable - Use the category as key (e.g.,\n`git repo info layout`\n\nwould return all layout-related values) - Add path-related values currently obtained through\n`git rev-parse`\n\n(see “Options for Files” in git-rev-parse documentation):- git-dir\n- common-dir\n- toplevel\n- superproject-working-tree\n\n- Add more values currently obtained through\n`git rev-parse --git-path`\n\n:- grafts file\n- index file\n- objects directory\n- hooks directory\n- git-prefix\n- other paths adjusted by\n`update_common_dir()`\n\n\n\nSome work to add path-related values\n[has already started](https://github.com/lucasoshiro/git/compare/master...repo-info-path/),\nso completing that work might be a good starting point. A major design decision\nwill need to be made on whether to use relative or absolute paths.\n\n**For git repo structure**, functionality from\n\nThe goal of this project is to discuss possible improvements to\n`git repo`\n\nwith the community, reach an agreement about the best\npotential improvements, and then implement them. It requires the\ndesire to be involved in design discussions on the mailing list.\n\n**Getting started:** Build Git from source, experiment with `git repo info`\n\nand\n`git repo structure`\n\ncommands, study the implementation in `builtin/repo.c`\n\n,\nreview the initial GSoC proposal and discussions, compare functionality with\n`git rev-parse`\n\nand identify gaps, and submit a micro-patch to demonstrate\nfamiliarity with the codebase.\n\n**Resources:**\n\n[Initial implementation discussion](https://public-inbox.org/git/20250610152117.14826-1-lucasseikioshiro@gmail.com/t/#u)[Official git-repo documentation](https://git-scm.com/docs/git-repo)[git-rev-parse documentation](https://git-scm.com/docs/git-rev-parse)[git-sizer tool](https://github.com/github/git-sizer)[Work-in-progress branch for path-related values](https://github.com/lucasoshiro/git/compare/master...repo-info-path/)\n\n*Expected Project Size*: 90 or 175 hours or 350 hours\n\n*Difficulty*: Medium\n\n*Languages*: C, shell(bash)\n\n*Possible mentors*:\n\n- Karthik Nayak <\n[karthik.188@gmail.com](mailto:karthik.188@gmail.com)> - Justin Tobler <\n[jltobler@gmail.com](mailto:jltobler@gmail.com)> - Ayush Chandekar <\n[ayu.chandekar@gmail.com](mailto:ayu.chandekar@gmail.com)> - Siddharth Asthana <\n[siddharthasthana31@gmail.com](mailto:siddharthasthana31@gmail.com)> - Lucas Seiki Oshiro <\n[lucasseikioshiro@gmail.com](mailto:lucasseikioshiro@gmail.com)>\n\nGit’s partial clone feature allows users to clone repositories without downloading all objects immediately, which is particularly useful for very large repositories. Objects are fetched on-demand from “promisor remotes” as needed. However, over time, clients may accumulate large local blobs that are no longer needed but remain on disk, and currently there’s no easy way to reclaim this space.\n\nThis project aims to improve `git backfill`\n\n(or create a new command) to allow\nclients to remove large local blobs when they are available on a promisor remote.\nThis would help users who want to get back disk space while maintaining the ability\nto re-fetch objects when needed.\n\nThe project involves:\n\n- Designing a safe mechanism to identify which blobs can be removed\n- Implementing the removal process while maintaining repository integrity\n- Ensuring removed objects can be transparently re-fetched when needed\n- Adding appropriate safeguards and user controls\n\n**Important note:** While the project mentions `git backfill`\n\n, it is not yet\ndecided that it is right place to have this command. Other potential candidates\nfor placement are `git gc`\n\n/ `git repack`\n\n/ `git maintenance`\n\n. A design discussion\nwith the community is imminent as part of this project to finalize the most\nappropriate placement and for this command.\n\n**Getting started:** Build Git from source, set up a partial clone and experiment\nwith promisor remotes, study the existing `git-backfill`\n\ncommand (if available)\nor related functionality, understand how Git tracks and fetches objects from\npromisor remotes, review documentation on partial clones in\n`Documentation/technical/partial-clone.txt`\n\n, and submit a micro-patch to\ndemonstrate familiarity with the codebase.\n\n**Resources:**\n\n*Expected Project Size*: 175 hours or 350 hours\n\n*Difficulty*: Medium to Hard\n\n*Languages*: C, shell(bash)\n\n*Possible mentors*:\n\n- Christian Couder <\n[christian.couder@gmail.com](mailto:christian.couder@gmail.com)> - Karthik Nayak <\n[karthik.188@gmail.com](mailto:karthik.188@gmail.com)> - Justin Tobler <\n[jltobler@gmail.com](mailto:jltobler@gmail.com)> - Siddharth Asthana <\n[siddharthasthana31@gmail.com](mailto:siddharthasthana31@gmail.com)> - Ayush Chandekar <\n[ayu.chandekar@gmail.com](mailto:ayu.chandekar@gmail.com)> - Lucas Seiki Oshiro <\n[lucasseikioshiro@gmail.com](mailto:lucasseikioshiro@gmail.com)>\n\nWhen a Git repository is configured with multiple promisor remotes, there’s currently no mechanism to specify or optimize the order in which these remotes should be queried when fetching missing objects. Different remotes may have different performance characteristics, costs, or reliability, making fetch order an important consideration.\n\nThis project aims to implement a fetch ordering mechanism for multiple promisor remotes. The order could be:\n\n- Configured locally by the client\n- Advertised by servers through the promisor-remote protocol\n\nThe key challenge is designing a flexible system that allows servers to communicate their preferred fetch order to clients (to ensure optimal performance and cost management).\n\nAs this area is being worked on these days, coordination with others will likely be required.\n\n**Getting started:** Build Git from source, set up a repository with multiple\npromisor remotes and experiment with object fetching, study how Git currently\nhandles multiple remotes, review the promisor-remote protocol in\n`Documentation/gitprotocol-v2.txt`\n\n, understand partial clone implementation,\nand submit a micro-patch to demonstrate familiarity with the codebase.\n\n**Resources:**\n\n*Expected Project Size*: 175 hours or 350 hours\n\n*Difficulty*: Medium to Hard\n\n*Languages*: C, shell(bash)\n\n*Possible mentors*:\n\n- Christian Couder <\n[christian.couder@gmail.com](mailto:christian.couder@gmail.com)> - Karthik Nayak <\n[karthik.188@gmail.com](mailto:karthik.188@gmail.com)> - Justin Tobler <\n[jltobler@gmail.com](mailto:jltobler@gmail.com)> - Siddharth Asthana <\n[siddharthasthana31@gmail.com](mailto:siddharthasthana31@gmail.com)> - Ayush Chandekar <\n[ayu.chandekar@gmail.com](mailto:ayu.chandekar@gmail.com)> - Lucas Seiki Oshiro <\n[lucasseikioshiro@gmail.com](mailto:lucasseikioshiro@gmail.com)>\n\nCurrently, the promisor-remote protocol allows servers to advertise remotes that the server itself uses as promisor remotes. However, as suggested by Junio Hamano, it would be useful in some cases if servers could advertise “better-connected” remotes - remotes that might not be promisor remotes for the server but would be good choices for the client.\n\nThis enhancement would allow servers to guide clients toward optimal remote configurations, potentially improving performance and reducing load on individual servers by distributing requests across a network of remotes.\n\nThis project involves:\n\n- Extending the promisor-remote protocol to support advertising better-connected remotes\n- Implementing server-side logic to determine and advertise appropriate remotes\n- Implementing client-side handling of these advertisements\n- Designing the protocol extension with backward compatibility in mind\n- Testing with various network topologies\n\nAs this area is being worked on these days, coordination with others will likely be required.\n\n**Getting started:** Build Git from source, study the current promisor-remote\nprotocol implementation, read Junio’s suggestion in `Documentation/gitprotocol-v2.txt`\n\n,\nunderstand how Git currently advertises and uses promisor remotes, set up test\nscenarios with multiple interconnected remotes, and submit a micro-patch to\ndemonstrate familiarity with the codebase.\n\n**Resources:**\n\n*Expected Project Size*: 175 hours or 350 hours\n\n*Difficulty*: Hard\n\n*Languages*: C, shell(bash)\n\n*Possible mentors*:\n\n- Christian Couder <\n[christian.couder@gmail.com](mailto:christian.couder@gmail.com)> - Karthik Nayak <\n[karthik.188@gmail.com](mailto:karthik.188@gmail.com)> - Justin Tobler <\n[jltobler@gmail.com](mailto:jltobler@gmail.com)> - Siddharth Asthana <\n[siddharthasthana31@gmail.com](mailto:siddharthasthana31@gmail.com)> - Ayush Chandekar <\n[ayu.chandekar@gmail.com](mailto:ayu.chandekar@gmail.com)> - Lucas Seiki Oshiro <\n[lucasseikioshiro@gmail.com](mailto:lucasseikioshiro@gmail.com)>\n\n`remote-object-info`\n\ncommand for `git cat-file`\n\nFrom around June 2024 to March 2025, work was undertaken by Eric Ju to add a\n`remote-object-info`\n\nsub-command to `git cat-file`\n\n. This client-side work\nbuilds upon previous server-side work by Calvin Wan that was merged in 2021.\nThe feature allows clients to request information about objects from a remote\nrepository without downloading the full object content, which can be especially\nuseful for partial clones and large repositories.\n\nSee the [initial patch series](https://lore.kernel.org/git/20240628190503.67389-1-eric.peijian@gmail.com/)\nfor the original proposal and discussion.\n\n**The first goal** of this project is to rebase and finalize Eric Ju’s\npatch series by addressing the remaining feedback from the community review,\nso that the improved series can be merged into Git.\n\n**The second goal** is to build on top of that work to add support for\nobject type information (`%(objecttype)`\n\n). This support should be\nadded both on the server side and on the client side, extending the\nprotocol to include this metadata and making it available to users.\n\nThis project involves both protocol design and implementation work, requiring careful attention to backward compatibility and performance considerations.\n\n**Getting started:** Build Git from source, study the existing `git cat-file`\n\ncommand and its batch modes (particularly `--batch`\n\nand `--batch-check`\n\n),\nreview Eric Ju’s patch series and the community feedback in detail, understand\nCalvin Wan’s merged server-side work from 2021, study the object-info protocol\nextension in `Documentation/gitprotocol-v2.txt`\n\n, and submit a micro-patch to\ndemonstrate familiarity with the codebase.\n\n**Resources:**\n\n[Eric Ju’s patch series (June 2024)](https://lore.kernel.org/git/20240628190503.67389-1-eric.peijian@gmail.com/)[git-cat-file documentation](https://git-scm.com/docs/git-cat-file)[Git Protocol v2 documentation](https://git-scm.com/docs/gitprotocol-v2)- Calvin Wan’s server-side work (2021) - search Git mailing list archives\n\n*Expected Project Size*: 90 or 175 hours or 350 hours\n\n*Difficulty*: Medium\n\n*Languages*: C, shell(bash)\n\n*Possible mentors*:\n\n- Christian Couder < christian.couder@gmail.com >\n- Karthik Nayak < karthik.188@gmail.com >\n- Justin Tobler < jltobler@gmail.com >\n- Ayush Chandekar < ayu.chandekar@gmail.com >\n- Siddharth Asthana < siddharthasthana31@gmail.com >\n- Lucas Seiki Oshiro < lucasseikioshiro@gmail.com >\n- Chandra Pratap < chandrapratap3519@gmail.com >"
  },
  {
    "name": "Metaflow",
    "slug": "metaflow",
    "tagline": "A human centric machine learning framework",
    "description": "Metaflow is a human-friendly Python library that makes it straightforward to develop, deploy, and operate various kinds of data-intensive applications, in particular those involving data science, ML, and AI. Metaflow was originally developed at Netflix to boost the productivity of data scientists who work on a wide variety of projects, from classical statistics to state-of-the-art deep learning. \n\nMetaflow provides a unified API across the entire infrastructure stack required to execute data science projects from prototype to production.",
    "ideas_url": "https://github.com/Netflix/metaflow/blob/master/GSOC_2026_PROPOSALS.md",
    "website_url": "https://metaflow.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "kubernetes"
    ],
    "topic_tags": [
      "machine learning",
      "data science",
      "ML Ops",
      "Orchestrator"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/metaflow",
    "ideas_content": "# Metaflow GSoC 2026 Ideas List\n\nRefer to this [link](https://docs.metaflow.org/internals/gsoc-2026) in our docs \nsite for project ideas."
  },
  {
    "name": "Liquid Galaxy project",
    "slug": "liquid-galaxy-project",
    "tagline": "We code immersive and interactive apps with GEarth",
    "description": "Liquid Galaxy is a remarkable panoramic system that is tremendously compelling. It started off as a Google 20% project to run Google Earth across a small cluster of PC's and it has grown from there! \nLiquid Galaxy hardware consists of one or more computers driving multiple displays. Liquid Galaxy applications have been developed using a master/slave architecture. The view orientation of each slave display is configured in reference to the view of the master display. Navigation on the system is done from the master instance and the location on the master is broadcast to the slaves over UDP. The slave instances, knowing their own locations in reference to the master, then change their views accordingly.\nThe Liquid Galaxy Project, while making use of Google Earth software, does not develop the Google Earth code-base itself. Google Earth is not open-source software, although it is free (as in beer). Instead, the Liquid Galaxy Project works on extending the Liquid Galaxy system with open-source software both improving its administration and enabling open-source applications, so that content of various types can be displayed in the immersive panoramic environment.\nArtificial Intelligence focus:\n2026 is the year when AI is going to change the coding industry, and GSoC and the open-source projects on it, have to jump on.\nAt the Liquid Galaxy community, we’ve been using AI for years to obtain data to be shown on Google Earth for our projects, using many models and technologies. \nThis 2026, all the projects will have an Artificial Intelligence voice, and most of them will use of diferent AI models to handle queries and arrange data, starting from Google's Gemini and Gemma.",
    "ideas_url": "https://www.liquidgalaxy.eu/2026/01/gsoc-2026-project-ideas.html",
    "website_url": "https://www.liquidgalaxy.eu",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "linux",
      "android",
      "nodejs",
      "flutter",
      "Google Earth"
    ],
    "topic_tags": [
      "visualization",
      "artificial intelligence",
      "networking",
      "maps",
      "ux"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/liquid-galaxy-project",
    "ideas_content": "### GSoC 2026 Project Ideas\n\n**January 19, 2026.**\n\nFor the past 4 months, our large team of mentors and students from our different labs around the world has been talking and proposing ideas for this year's GSoC projects.\n\nNow you can finally take a look at this year's Project Ideas, crafted with some nice changes to the past editions, including an embellishment of the ideas with the powerful new AI tools from Google, in this case mostly NotebookLM, Gemini, and Nano Banana Pro.\n\nSO you have two ways to read the ideas:\n\n- Or the simple but clear\n\n[Google Sheet.](https://docs.google.com/spreadsheets/d/1qhdtQ6PZoqbwHIFDoXDMfu4MW_-dYfnBqvpDGbRV1KU/edit?usp=sharing)**To keep it clear: all the documents have the same proposals, only the NotebookLM-powered ones have amazing graphics that catch the point about the spectacularity a visualization from Liquid Galaxy is.**\n\n**Anyway, we recommend you browse first the slides, and when you have an idea of the project (Google allows you to present a maximum of three), look at the plain definition of the same idea in the Google Sheet.**\n\nAt this time, we are not going to comment further on proposals; we all have to wait till February 19 to continue the tasks (or stop). If we succeed, hopefully, plenty more info will appear here on the proposals and some new changes we have for this year's GSoC, that already have been comented in our community Meets, and are, among others:\n\n\n\n- Reward the projects with a great history telling, by the obligatory for all projects use of:\n\n. Presenting the KML's in 3D, coloured.\n\n. Incorporating AI voices in your projects.\n\n**- Allow the use of AI in your code creation and more, as stated in the**\n\n[AI Clarification Policy note,](https://www.liquidgalaxy.eu/2025/11/GSoC2026.html#ai)but implementing a self-review code process, as the Artificial Intelligence wave makes us all to work harder to detect fake work and bad non-maintainable code. Always next the guidance and supervision of your mentor and admins.\n\nAnd some more that we'll communicate if successful on GSoC this year.\n\nIf you want a spoil, just look at\n\n[Task 5](https://www.liquidgalaxy.eu/2025/11/GSoC2026.html#task5), which can be done by anyone, at anytime, but with the rules already written in the post. If you have any doubt, as always, contact us on Discord if the question is open, or by email if it's private.**We're here to help you.**"
  },
  {
    "name": "Haskell.org",
    "slug": "haskellorg",
    "tagline": "Purely functional programming language",
    "description": "Haskell is an advanced, general-purpose, purely functional programming language.  It has a strong, static type system with Hindley-Milner type inference.\n\nThe language natively supports lazy evaluation, and lets you track side effects in the type system. This leads to a concise and declarative style of programming, which differs quite a bit from conventional languages. By controlling side effects and working with immutable data, the programmer can avoid whole classes of bugs.\n\nHaskell generally compiles to fast, native code, but it can also be compiled to other targets like JavaScript (through GHCJS) or LLVM.\n\nIn Google Summer of Code, we attempt to improve not only the language, but the whole ecosystem. This includes (aside from the language itself):\n\n- Compilers\n- Commonly used libraries\n- Commonly used applications written in Haskell\n- Profilers, debuggers and other tools\n- Package managers and infrastructure\n\nWe have compiled an ideas list together with long-time Haskell users, compiler contributors and researchers, and as such we believe these are important projects for the industry and academia both.",
    "ideas_url": "https://summer.haskell.org/ideas.html",
    "website_url": "https://haskell.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "haskell",
      "ghc"
    ],
    "topic_tags": [
      "compilers",
      "programming languages",
      "functional programming",
      "programming tools"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/haskellorg",
    "ideas_content": "# GSoC 2026 Ideas\n\nThis is a list of ideas for contributors who are considering to apply to\nGoogle Summer of Code 2026 for *Haskell.org*\n\n## For project maintainers\n\nAre you working on a Haskell project and you could use the help of a\ncontributor during the summer? Consider adding it as an idea here!\nYou can contribute ideas by sending a pull request to our\n[github\nrepository](https://github.com/haskell-org/summer-of-haskell)\n([example from 2024](https://github.com/haskell-org/summer-of-haskell/commit/63f360ed17cb1a1c1aeee9a14804b337e5169d14)).\nIf you just want to discuss a possible idea,\n[please contact us](https://summer.haskell.org/contact.html).\n\nWhat is a good idea? **Anything that improves the Haskell ecosystem is\nvalid**. The GSoC rules state that it must involve writing code\nprimarily (as opposed to docs).\n\nProjects should be **concrete and small enough in scope** such\nthat they can be finished by the contributor. Past experience has\nshown that keeping projects âsmallâ is almost always a good idea.\n\n**Important changes since 2021/2022**:\nIn the past, GSoC projects were expected to take up the equivalent of full\ntime employment for a student. In 2021, this was reduced to\nhalf time positions: students were expected to work around 175 hours in a 10\nweek period. Since 2022, contributors now have the choice between a larger\n(around 350 hours) or a smaller project. Ideas should indicate in which\ncategory they fall.\n\nProjects should benefit as many people as possible â e.g. an improvement to GHC will benefit more people than an update to a specific library or tool, but both are acceptable. New libraries and applications written in Haskell, rather than improvements to existing ones, are also welcome.\n\n## For students/contributors\n\n[We have added some tips on writing a proposal here](https://summer.haskell.org/tips.html).\nPlease be aware that:\n\n- This is not an all-inclusive list, so you can apply for projects not in this list and we will try our best to match you with a mentor.\n- You can apply for up to two ideas (but only one can be accepted).\n\n# Table of Contents\n\n[Case split plugin](https://summer.haskell.org#casesplit)[Dynamic LSP capabilities](https://summer.haskell.org#dynamic-lsp-capabilities)[Goto dependency definition](https://summer.haskell.org#goto-third-party-deps)[Parquet for Haskell - A production-grade Apache Parquet reader/writer.](https://summer.haskell.org#parquet-support-for-dataframe)[Revive the support for type-class elaboration in Liquid Haskell](https://summer.haskell.org#revive-type-class-elaboration-in-lh)[UI Layout Library for Haskell - Declarative and dynamic layouts for 2D graphic frameworks](https://summer.haskell.org#ui-layout-library-for-haskell)[xeus-haskell - GHC/Wasm Backend Integration Prototype](https://summer.haskell.org#xeus-haskell-ghc-wasm)[xeus-haskell - Library Expansion and Packaging for MicroHs](https://summer.haskell.org#xeus-haskell-libraries)[xeus-haskell - Precompilation and Caching for Instant Startup](https://summer.haskell.org#xeus-haskell-performance)[xeus-haskell - Interactive Widgets for Haskell Notebooks](https://summer.haskell.org#xeus-haskell-widgets)\n\n## Case split plugin[ð](https://summer.haskell.org#casesplit)\n\nThis project will extend the Haskell Ide, HLS, by introducing a new plugin, the case split plugin.\n\nWhen writing some snippet of code on variables that can be one of a finite number of types, for example since it is an enum or algebraic datatype, we sometimes want to do different things, depending on the constructor of the variable.\n\nSee the simple code example below:\n\nHere the programmer would like a completion option which inserts all the possible types of foo instead of having to type them out themselves. The case split plugin will then offer to complete the above code snippet as shown below:\n\nThis plugin should work on enums as well as algebraic data types and also work on incomplete `case`\n\nexpressions, i.e.Â in the above example if there was already an implementation for the case of type `A`\n\nbut the other possible types of foo would still need to be handled.\nUnfortunately, implementing this functionality is complex, as it requires parsing existing code using exact printing.\nThe current idea is to use the [exact printing library](https://github.com/alanz/ghc-exactprint).\n\nThis project requires strong Haskell skills as the participant needs to gain a deep understanding of the above library, the GHC AST and the HLS codebase. Therefore they should have a good understanding of type level programming concepts such as type families. Ideally, the participant should already have experience with the GHC AST, otherwise this project will be very difficult to achieve within the timeframe.\n\nIssue: https://github.com/haskell/haskell-language-server/issues/3525\n\nContext:\n\n- https://github.com/haskell/haskell-language-server/issues/2437\n- https://github.com/haskell/haskell-language-server/pull/3338\n- https://github.com/alanz/ghc-exactprint/pull/116\n\n**Goals**\n\n- New plugin\n`hls-case-split-plugin`\n\n- Support GHC 9.14.1\n- Can casesplit on enum types\n- Can casesplit on arbitrary algebraic datatypes\n\nThis project will only accept participants with prior contributions to HLS or GHC.\n\nMentors: TBD\n\nProject size: 350hrs\n\nDifficulty: Hard\n\n## Dynamic LSP capabilities[ð](https://summer.haskell.org#dynamic-lsp-capabilities)\n\nA [capability in LSP](https://microsoft.github.io/language-server-protocol/specifications/lsp/3.17/specification/#capabilities), the Language Server Protocol describes the kind of features a Language Server offers to the client (e.g., VSCode). These capabilities are statically declared in HLS, i.e., on startup, we infer the language serverâs capabilities, based on the plugin handlers.\nHowever, HLS is highly configurable!\nIt should be possible to enable or disable features at run-time, but since HLS can only declare capabilities on startup, the editor can request features even though they are disabled in HLS!\n\nFor example, [semantic tokens](https://microsoft.github.io/language-server-protocol/specifications/lsp/3.17/specification/#textDocument_semanticTokens) is one of HLSâ experimental features which is disabled by default.\nThe client will still request semantic tokens for documents, as HLS has previously advertised the feature, leading to error messages polluting the logs and confusing the user.\nSimilarly, the `hls-cabal-plugin`\n\nimplements a language server for `.cabal`\n\nfiles within HLS, but the plugin supports noticably different features for `.cabal`\n\nfiles than for `haskell`\n\nfiles.\nThe result is that many LSP requests are rejected by HLS, confusing users.\n\nThis can be solved by introducing [dynamic capabilities](https://microsoft.github.io/language-server-protocol/specifications/lsp/3.17/specification/#client_registerCapability), capabilities that can be registered and also de-registered by HLS at runtime if a feature is disabled.\nRather than sending all capabilities on startup, HLS can check its enabled plugins, and register a capability for individual HLS features on demand.\n\nThis project will improve the support for dynamic capabilities in [ lsp](https://github.com/haskell/lsp/), and then port HLS to use dynamic capabilities where available.\nIn\n\n`lsp`\n\n, there should be the possibility to automatically infer the dynamic capabilities, similarly to how we infer the [static capabilities on startup](https://github.com/haskell/lsp/blob/master/lsp/src/Language/LSP/Server/Processing.hs#L217). Ideally, dynamic capability registration remains opaque to HLS plugins and is entirely handled by the internal mechanisms of\n\n[.](https://github.com/haskell/haskell-language-server/tree/master/ghcide)\n\n`ghcide`\n\nThis project requires strong Haskell skills, especially with type level programming concepts such as type families. As the implementation will touch many places within HLS, prior knowledge of HLS, its rule system and plugin system is highly recommended.\n\nIssue: https://github.com/haskell/haskell-language-server/issues/4084\n\n**Goals**\n\n`lsp`\n\ncan send and process dynamic registration of capabilities.`lsp`\n\ncan infer and send dynamic capability registration based on handlers`staticHandlers`\n\nvs`dynamicHandlers`\n\n\n`lsp-test`\n\ncan handle dynamic capability registrations.- HLS can register dynamic capabilities manually\n- HLS can infer dynamic capabilities\n\nThis project will only accept participants with prior contributions to HLS or `lsp`\n\n.\n\nMentors: fendor, TBD\n\nProject size: 175hrs, the scope could be expanded to 350hrs\n\nDifficulty: Medium\n\n## Goto dependency definition[ð](https://summer.haskell.org#goto-third-party-deps)\n\nHaskell-Language-Server (HLS) supports goto definition for locally implemented functions.\nBut, Haskellers often also want to know the implementation of functions when using a library from an external dependency.\nThis project will implement `goto dependency definition`\n\n, allowing programmers to inspect the implementation of dependencies from the comfort of their Ide, without having to google them or find them on hackage.\n\nGHC versions can produce [ .hie files](https://gitlab.haskell.org/ghc/ghc-wiki-mirror/-/blob/master/hie-files.md) at compilation time,\nwhich contain detailed information, as well as the sources.\nThese files can be indexed, for example by\n\n[, to provide source locations for third-party libraries, which can then be used by HLS for the âGoto Definitionâ feature.](https://github.com/wz1000/HieDb/)\n\n`hiedb`\n\nThis project will require participants to work with the notoriously difficult GHC API in HLS.\n\nThis project already has a prototype implementation in [PR #3749](https://github.com/haskell/haskell-language-server/pull/3749).\nHowever, before the PR can be finished, HLS needs to be taught to ignore files from dependencies, i.e., must not try to type check them, but rather only serve LSP requests from hiedb. The PRs [#4406](https://github.com/haskell/haskell-language-server/pull/4406) and [#4449](https://github.com/haskell/haskell-language-server/pull/4449) implement new rule types that shall ensure HLS never accidentally tries to load modules from dependencies.\n\nIssue: https://github.com/haskell/haskell-language-server/issues/708\n\nThis project requires strong Haskell skills, especially with type level programming concepts such as type families. As the implementation will touch many places within HLS, prior knowledge of HLS, its rule system and plugin system is highly recommended.\n\nThis project will only accept participants with prior contributions to HLS.\n\nMentors: fendor, wz1000\n\nProject size: 350hrs, 175hrs if experienced\n\nDifficulty: Hard\n\n## Parquet for Haskell - A production-grade Apache Parquet reader/writer.[ð](https://summer.haskell.org#parquet-support-for-dataframe)\n\nApache Parquet is the âinterchange formatâ for analytics in the modern data stack, so having a production-grade Parquet implementation in Haskell is what turns Haskell data tooling from a silo into something that plugs into how data is actually stored and moved in industry. Having a strong Parquet implementation benefits Haskell beyond âdata science librariesâ because it gives any Haskell project a modern, efficient, interoperable storage format for tabular and semi-structured data: fast column scans, good compression/encodings, and a widely-supported on-disk standard that other tools can immediately consume. In practice, this means Haskell apps can persist intermediate results, caches, feature stores, logs/telemetry aggregates in a format that scales and can be queried/validated with existing industry tools, instead of inventing bespoke binary formats or round-tripping through another language.\n\n[ dataframe](https://github.com/mchav/dataframe) already ships a working Parquet reader and includes a growing Parquet implementation. This project makes Parquet a\n\n**first-class, production-ready I/O format inside**, by:\n\n`dataframe`\n\n- hardening and extending the existing reader to handle more real-world files safely,\n- implementing a streaming Parquet writer\n- writing round trip tests for Parquet files\n- documenting a clear support matrix and performance expectations (which will eventually be added to the\n[Parquet implementation status page](https://parquet.apache.org/docs/file-format/implementationstatus/))\n\nThe work is spec-driven (Parquet file format + metadata + encodings) but deliberately scoped to ship high-quality improvements within the GSoC timeline.\n\nThe project is at least medium difficulty (~175 hours). Hardening the reader and shipping a writer with plain encoding is a moderately difficult task. It can be extended to a ~350 hour project if we extend the scope to supporting run length encoding and a streaming writer/reader.\n\n**Mentorship**\n\n- Michael Chavinda (mchav)\n- Adithya Obilisetty (adithyaov)\n\n## Revive the support for type-class elaboration in Liquid Haskell[ð](https://summer.haskell.org#revive-type-class-elaboration-in-lh)\n\n#### Goals\n\nUpdate the implementation of [Liquid Haskell](https://ucsd-progsys.github.io/liquidhaskell/) to reenable support for [type-class elaboration][].\n\n#### Background\n\nLiquid Haskell is a verification tool for Haskell programs. The programmer writes specifications for these programs, and Liquid Haskell checks if the programs actually meet the specifications.\n\nLiquid Haskell analyzes the Core language of the GHC compiler, which allows it to work with many syntactic features of Haskell that are eliminated during desugaring. One exception to this is type classes, which require Liquid Haskell to associate type class and instance definitions with dictionaries as they materialize in Core.\n\nThere are tests in the testsuite which rehearse type-class support, but\nsome of them [have been disabled](https://github.com/ucsd-progsys/liquidhaskell/blob/92c0a7eeb93045ace8a83df311c51287dee056fc/tests/tests.cabal#L2601-L2608) after upgrades to GHC introduced\nincompatibilities with the Liquid Haskell implementation. Specifically, the\ntests in question are related to type-class elaboration.\n\nThis project is about surveying the support of Liquid Haskell for reasoning\nwith type classes, updating the implementation to make it work with the latest\nGHC version, improving the documentation, and grooming the testsuite to\nreenable and complete the failing tests. This is the [corresponding issue](https://github.com/ucsd-progsys/liquidhaskell/issues/2450)\nin the Liquid Haskell repository.\n\n#### Outcomes\n\nThe main outcomes are a pull request with the implementation, tests, documentation, and the reports on the insights discovered during the project in the corresponding issue of the repository.\n\nA secondary outcome is a blogpost describing the experience and the results of the project.\n\n#### Size & Difficulty\n\nProject size should be near 175 hours. The project will require a fair amount of reading of existing Haskell code, and the GHC interfaces it uses. Familiarity with the verification mechanisms is not necessary a priori, though some user-level understanding of Liquid Haskell is going to be needed to write tests.\n\nDifficulty: intermediate\n\n#### Required Skills\n\n- Read and write technical English\n- Haskell programming basics\n\n#### Project Mentor\n\n- Facundo DomÃnguez (facundo.dominguez at tweag.io) comaintainer of Liquid Haskell\n\n## UI Layout Library for Haskell - Declarative and dynamic layouts for 2D graphic frameworks[ð](https://summer.haskell.org#ui-layout-library-for-haskell)\n\nHaskell has several low-level libraries/bindings for 2D graphics like\n[sdl3-hs](https://projects.kylelukaszek.com/sdl3-hs/) and\n[GLFW-b](https://hackage.haskell.org/package/GLFW-b).\nFurthermore, there are interactive application frameworks\nlike [Gloss](https://github.com/benl23x5/gloss),\n[Brillo](https://github.com/ad-si/Brillo),\n[Diagrams](https://diagrams.github.io), and others.\n\nHowever, they all share a common limitation: Developers must manually calculate positions and sizes for every UI element. This becomes tedious and error-prone as interfaces grow in complexity.\n\nThis project aims to create a **declarative layout library** for Haskell\nthat can be used with any 2D rendering backend.\nThe goal is to let developers describe *what* they want\n(a row of buttons, a centered panel, a sidebar next to content)\nrather than *where* each pixel goes,\ntransforming Haskellâs graphics libraries into viable foundations\nfor building real applications with proper user interfaces.\n\nThe implementation can take one of several approaches:\n\n**Extend an existing Haskell layout library**[FULE](https://github.com/pschnapp/FULE)(Functional UI Layout Engine), an experimental library for positioning UI elements that already provides container types, centering, and a monadic API[gloss-relative](https://hackage.haskell.org/package/gloss-relative), which provides relative sizing and automatic resizing for Gloss.\n\nThis would involve hardening the library, adding missing layout primitives, and creating integrations and examples for popular rendering backends.\n\n**Wrap an existing C layout engine**[Clay](https://github.com/nicbarker/clay), a high-performance library that provides flexbox-style layouts with microsecond performance.\n\nThis would involve creating Haskell FFI bindings and adapters for Haskell rendering libraries.\n\n**Implement a new pure Haskell layout engine**inspired by flexbox/CSS layout algorithms. This provides the tightest integration with Haskell idioms and avoids FFI complexity, though it requires more implementation work.\n\nAny approach should deliver:\n\n- A declarative API for building layouts (rows, columns, padding, alignment, spacing)\n- Support for common layout patterns (flexbox-style grow/shrink, fixed vs.Â flexible sizing)\n- Integration with popular Haskell 2D graphics libraries\n- Simple text measurement and wrapping support\n- Documentation and examples demonstrating typical UI patterns\n\nThe project can be scoped as a small project (~175 hours) covering a minimal layout system with rows, columns, interactions (click, hover, etc.), and basic sizing.\n\nIt could also be extended to a ~350 hour project by adding floating/overlay elements, scroll containers, responsive layouts, advanced text layouts, etc.\n\n**Mentorship**\n\n- Adrian Sieber (ad-si)\n\n## xeus-haskell - GHC/Wasm Backend Integration Prototype[ð](https://summer.haskell.org#xeus-haskell-ghc-wasm)\n\n#### Project Context\n\nAs part of the **jupyter-xeus** organization,\n[ xeus-haskell](https://github.com/jupyter-xeus/xeus-haskell) aims to provide a\nârun anywhereâ Haskell environment. While the current MicroHs backend is\noptimized for size and speed in the browser, a GHC/Wasm-backed execution mode\nwould unlock the full power of the Haskell ecosystem (Hackage). This\nresearch-intensive engineering project focuses on bridging the\n\n`xeus`\n\nC++\nframework with the emerging GHC WebAssembly backend to support more complex\nproduction workflows in the browser.#### Goals\n\n**Proof of Concept:**Extend the C++ bridge (`mhs_repl.cpp`\n\n) to route execution requests to a GHC/Wasm-compiled runtime.**Runtime Optimization:**Document and mitigate browser-specific constraints, such as bundle size, startup latency, and filesystem access.**Backend Interoperability:**Define a clean architecture to allow users to switch between the lightweight MicroHs and the full-featured GHC/Wasm backends.\n\n#### Prerequisites\n\n**Language:**Advanced Haskell (GHC extensions, FFI, and compiler internals).**Systems:**Proficiency in C++ (standard 14 or higher) for kernel-level integration.**WebAssembly:**Familiarity with Wasm runtimes, Emscripten, or the WASI standard.**Bonus:**Experience with GHCâs Javascript/Wasm backends or`xeus`\n\ncore development.\n\n**Mentors:** [Masaya Taniguchi](https://github.com/tani)\n\n**Project Size:** 350h (Large)\n\n**Difficulty:** Hard\n\n## xeus-haskell - Library Expansion and Packaging for MicroHs[ð](https://summer.haskell.org#xeus-haskell-libraries)\n\n#### Project Context\n\n[ xeus-haskell](https://github.com/jupyter-xeus/xeus-haskell) is an official\nJupyter kernel for Haskell, maintained under the\n\n**jupyter-xeus**organization. It is based on\n\n**xeus**, the native C++ implementation of the Jupyter protocol. By leveraging the MicroHs compiler,\n\n`xeus-haskell`\n\nprovides a unique experience\nthat runs both natively (Linux, macOS, Windows) and directly in the browser via\nWebAssembly (JupyterLite). This project aims to transition the kernel from a\nproof-of-concept to a robust tool for data science and education by expanding\nits library ecosystem.#### Goals\n\n**Feasibility Study:**Identify high-impact libraries (Haskell 2010 subset) that can be realistically compiled under MicroHs.**Library Expansion:**Port and validate a priority set of libraries (e.g.,`containers`\n\n,`mtl`\n\n,`bytestring`\n\n,`aeson`\n\n) for the MicroHs backend.**Automated Packaging:**Integrate with`pixi`\n\n,`conda-forge`\n\n, and`emscripten-forge`\n\nto automate CI/CD pipelines for both native and Wasm targets.**Educational Content:**Develop âGetting Startedâ notebooks that demonstrate these libraries in a zero-install JupyterLite environment.\n\n#### Prerequisites\n\n**Language:**Strong proficiency in Haskell (especially Haskell 2010 standards).**Tooling:**Familiarity with modern package management (Conda / Pixi).**Systems:**Basic understanding of CI/CD workflows (GitHub Actions).**Bonus:**Previous experience with the MicroHs compiler or contributing to`conda-forge`\n\n.\n\n**Mentors:** [Masaya Taniguchi](https://github.com/tani)\n\n**Project Size:** 175h (Medium) / 350h (Large)\n\n**Difficulty:** Medium\n\n## xeus-haskell - Precompilation and Caching for Instant Startup[ð](https://summer.haskell.org#xeus-haskell-performance)\n\n#### Project Context\n\nA key value proposition of the **jupyter-xeus** project\n[ xeus-haskell](https://github.com/jupyter-xeus/xeus-haskell) is its\nzero-install accessibility via JupyterLite. However, loading libraries in a web\nenvironment can introduce latency. This project focuses on developer ergonomics\nand performance by implementing a precompilation and caching strategy. The goal\nis to ensure that when a student or researcher opens a Haskell notebook, the\nenvironment is ready for execution instantly.\n\n#### Goals\n\n**Artifact Caching:**Develop a mechanism to precompile MicroHs core modules and third-party libraries into portable, cacheable artifacts.**Pipeline Integration:**Automate cache generation within the`emscripten-forge`\n\nand`conda-forge`\n\npackaging workflows.**Performance Benchmarking:**Establish quantitative metrics to measure cold-start vs.Â warm-start latency and ensure a smooth user experience.\n\n#### Prerequisites\n\n**Language:**Comfortable reading Haskell and C++ code.**Tooling:**Experience with build systems (Make, CMake) and shell scripting.**DevOps:**Familiarity with GitHub Actions or other automation platforms.**Bonus:**Knowledge of compiler optimization techniques or file system caching strategies.\n\n**Mentors:** [Masaya Taniguchi](https://github.com/tani)\n\n**Project Size:** 175h (Medium)\n\n**Difficulty:** Medium\n\n## xeus-haskell - Interactive Widgets for Haskell Notebooks[ð](https://summer.haskell.org#xeus-haskell-widgets)\n\n#### Project Context\n\nDeveloped under the **jupyter-xeus** umbrella,\n[ xeus-haskell](https://github.com/jupyter-xeus/xeus-haskell) already supports\nrich display outputs (HTML, LaTeX, Markdown). This project will implement\n\n**ipywidgets**compatibility, enabling truly interactive notebooks. By adding support for the Jupyter âcommâ protocol, you will allow users to create Haskell-driven GUI elementsâsuch as sliders, buttons, and dropdownsâthat can manipulate data visualizations in real-time.\n\n#### Goals\n\n**Protocol Implementation:**Implement Jupyter âcommâ messages for state synchronization between the Haskell kernel and the browser frontend.**Widget Library:**Build a developer-friendly Haskell DSL/library to instantiate and control standard widgets (Slider, Button, Text).**Interactive Demos:**Create curated notebooks demonstrating the power of interactive widgets combined with the`Display`\n\ntypeclass for teaching and data exploration.\n\n#### Prerequisites\n\n**Language:**Solid Haskell skills, specifically in state management and handling side effects.**Protocol:**Understanding of JSON-based network protocols or the Jupyter messaging spec.**Frontend:**Basic knowledge of HTML/CSS for widget rendering and styling.**Bonus:**Experience using`ipywidgets`\n\nin Python or a similar interactive system in another language.\n\n**Mentors:** [Masaya Taniguchi](https://github.com/tani)\n\n**Project Size:** 175h (Medium) / 350h (Large)\n\n**Difficulty:** Medium"
  },
  {
    "name": "Joplin",
    "slug": "joplin",
    "tagline": "The secure note taking application",
    "description": "Joplin is a note-taking app designed with strong security and privacy in mind. It features end-to-end encryption (E2EE), ensuring the notes remain protected during synchronization. Users can store notes locally or sync them via trusted services like Nextcloud, Dropbox, or self-hosted servers, retaining full data ownership.\n\nAdditionally Joplin can manage a large number of notes that can be organised using notebooks or tags, thus making it suitable to manage a knowledge base. The notes can be searched using simple or advanced queries.\n\nThe application can be customised using plugins and themes, and you can also easily create your own. It is available for Windows, Linux, macOS, Android and iOS.",
    "ideas_url": "https://github.com/joplin/gsoc/blob/master/ideas.md",
    "website_url": "https://github.com/laurent22/joplin",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "javascript",
      "react",
      "typescript",
      "electron",
      "React-Native"
    ],
    "topic_tags": [
      "security",
      "search",
      "synchronisation",
      "note-taking",
      "AI/ML"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/joplin",
    "ideas_content": "# GSoC 2026 Ideas\n\nThis year we will focus on these ideas:\n\n- **AI/ML** - Joplin enables users to manage extensive note collections, including personal notes, images, and other documents. We aim to leverage AI and ML technologies to explore and utilise this data in innovative ways.\n\n- **Security** - As users may potentially store a vast amount of private data in Joplin, security and privacy have always been of utmost importance. We aim to explore ways to further enhance security and privacy measures.\n\n- And you are welcome to suggest your own ideas!\n\n## Information for Contributors\n\nThese ideas were contributed by our developers and users. They are purposely vague or incomplete - this is because you are expected to research it and develop it to make it your own project.\n\n## List of ideas\n\n### 1. AI-supported search for notes\n\nWhen your quantity of notes grows you may reach a point where finding notes is difficult. You may know that a specific note is there somewhere but you can't remember any specific keyword that would allow you to find it.\n\nThis project is to provide an alternative AI-based search for your notes. Instead of using the existing [seach syntax](https://joplinapp.org/help/apps/search/), the user would express in English what they are looking for. For example:\n\n- It's a note about a meeting with a company from Germany in 2020 or maybe 2019\n- I need the list of tasks I wrote for the website redesign\n- Look for the note with the poetry lines about the moon\n- etc.\n\n**Expected Outcome**: This can be developed as an external application or possibly as part of the core application. This AI based search should supplement the existing search engine. Perhaps both search engine could share the same search box, and one engine or the other would be activated depending on the query. Final outcome should be an AI-based search engine.\n\n**Difficulty Level**: High\n\n**Skills Required**: TypeScript, ML/AL\n\n**Potential Mentors**: Laurent, Marph\n\n**Expected size of project**: 350 hours\n\n### 2. AI-Generated note graphs\n\nAs the user uses Joplin, he may accumulate a large number of notes and may find it difficult to know how they related to each others. We could imagine a folder containing many notes for a website project but the user might want to know what is the core idea for this project, what are the less important parts, and how all these ideas are connected to each others.\n\nThe goal of this project is to help the user organise his notes and visualise the dependencies between them using a graph.\n\nThe AI would analyse all the notes in a notebook or in sub-notebooks, categorise them, and discover how they are connected to each others.\n\nWith the above example, a note that shows a global overview of the website could be central. Then there would be a branch for UX, another one for graphics design, and yet another one for programming and technology. Each branch would be developed further with more notes containing more details for that specific topic.\n\n**Expected Outcome**: This can be developed as an external application, a plugin or possibly as part of the core application. The AI would be analyse the notes specified by the user and will create a graph to visualise the relationships between the notes.\n\n**Difficulty Level**: High\n\n**Skills Required**: TypeScript, ML/AL\n\n**Potential Mentors**: Tessus, Malek\n\n**Expected size of project**: 350 hours\n\n### 3. AI-based categorisation\n\nThe goal of this project would be to automatically categorise the user's notes. That would mean for example automatically tagging them using AI or creating notebooks and moving the notes to it. Other applications could be to discover notes that are rarely accessed and move them to an \"archive\" notebook.\n\n**Expected Outcome**: This can be developed as an external application, a plugin or possibly as part of the core application. The AI should analyse the note collection and suggest ways to categorise the notes to the user. If the user agrees, the program should apply the suggested changes. That could mean creating new tags and assigning them to notes, or creating new notebooks.\n\n**Difficulty Level**: High\n\n**Skills Required**: TypeScript, ML/AL, React\n\n**Potential Mentors**: PackElend, Tessus\n\n**Expected size of project**: 350 hours\n\n### 4. Chat with your note collection using AI\n\nSome users have very large knowledge base in Joplin, sometimes built from clipping thousands of pages. This is curated, carefully selected, and thus it would be good to have a way to \"interogate\" this content. The UI would be very similar to something like ChatGPT, except that the data would be based on the user's note collection.\n\nThe user asks a question, the AI answers, and the user can ask more questions to refine the answer.\n\n**Expected Outcome**: This can be developed as an external application or a plugin. The AI should ingest the note collection. Then a UI should be provided to allow the user to ask questions.\n\n**Difficulty Level**: Medium\n\n**Skills Required**: TypeScript, ML/AL, React\n\n**Potential Mentors**: Malek, Tessus\n\n**Expected size of project**: 350 hours\n\n### 5. Automatically label images using AI\n\nJoplin has a strong focus on [accessibility](https://discourse.joplinapp.org/t/project-2-making-joplin-more-accessible-with-wcag-2-compliance/42371). To enhance accessibility, we aim to use AI to automatically scan all images found within the notes and assign a descriptive label to each one. For instance, an image of the Mona Lisa could be labelled as \"A portrait of a woman with an enigmatic smile, featuring a soft landscape background and masterful use of sfumato shading\".\n\n**Expected Outcome**: This can be developed as an external application or a plugin. The program should scan the note collection then, for each image, it should generate a detailed description of it using AI.\n\n**Difficulty Level**: Medium\n\n**Skills Required**: TypeScript, ML/AL, React\n\n**Potential Mentors**: Laurent, Malek\n\n**Expected size of project**: 175 hours\n\n### 6. Strengthen the security of the plugin ecosystem\n\nWe would like to improve the security of Joplin's plugin ecosystem by reviewing plugins' source code. This requires changes to the plugin build and publishing process. See [RFC: Consider changing how we accept third-party plugins](https://github.com/laurent22/joplin/issues/9582) for details.\n\n**Expected Outcome**: Plugins with reviewed source code, ability to build these plugins from source on a trusted server, and a process for reviewing updates and new plugins.\n\n**Difficulty Level**: High\n\n**Skills Required**: TypeScript\n\n**Potential Mentors**: Marph, Malek\n\n**Expected size of project**: 350 hours\n\n### 7. Support for encrypted notes\n\nIn general, notes in Joplin are immediately accessible. However the user may want to lock certain sensitive notes behind a password.\n\n**Expected Outcome**: The user can choose to encrypt certain notes and associated resources. When doing so, they would have to enter a password. The note then can only be decrypted using that password.\n\n**Difficulty Level**: Medium\n\n**Skills Required**: TypeScript, Ability to use cryptographic tools and libraries, React for UI\n\n**Potential Mentors**: Tessus, Laurent\n\n**Expected size of project**: 175 hours\n\n### 8. Password strength indicator\n\nImplement a password strength indicator to help users create stronger master passwords. The indicator can visually guide users on how secure their password is when setting or changing it.\n\n**Expected Outcome**: A UI element that displays password strength as the user types. Feedback to the user on how to improve their password strength (e.g., adding numbers, special characters). Integration with an algorithm like zxcvbn to evaluate password strength.\n\n**Difficulty Level**: Easy\n\n**Skills Required**: TypeScript, React (for UI)\n\n**Potential Mentors**: PackElend, Laurent\n\n**Expected size of project**: 90 hours\n\n### 9. LAN Sync\n\nImplement device-to-device synchronisation (LAN Sync). The applications can already sync using various server, but it would be good to also allow sync fully offline by having the devices connect to each others directly.\n\n**Expected Outcome**: A new synchronisation method (we call it \"sync target\") that allows LAN Sync. It should work at a minimum on the Windows and Android apps. Ideally it should be implemented in a cross-platform way so that it works on all our supported operating systems.\n\n**Difficulty Level**: High\n\n**Skills Required**: TypeScript, Networking\n\n**Potential Mentors**: PackElend, Laurent\n\n**Expected size of project**: 175 hours\n\n## More info\n\n- Make sure you read the [Joplin Google Summer of Code Introduction](https://github.com/joplin/gsoc/blob/main/readme.md)\n- To build the application, please read [BUILD.md](https://github.com/laurent22/joplin/blob/dev/readme/dev/BUILD.md)\n- And before creating a pull request, please read the [pull request guidelines](https://github.com/joplin/gsoc/blob/main/pull_request_guidelines.md)"
  },
  {
    "name": "The OpenROAD Initiative",
    "slug": "the-openroad-initiative",
    "tagline": "Collaboratively building an OpenROAD ecosystem",
    "description": "ORI is a 501(c)(3) nonprofit that provides long-term stewardship, governance, and ecosystem leadership for the OpenROAD open-source EDA ecosystem.\nOur Vision: Making chip design open and accessible to all—building a collaborative ecosystem driven by transparency and shared innovation.\n\nOur Mission: To advance and sustain the open-source EDA ecosystem by fostering collaborative innovation across research, education, and industry—transforming ideas into silicon.",
    "ideas_url": "https://docs.google.com/document/d/1X6xxUonxgEQ_iD5G5vFp2ZOH1vbkRSspEdYrpSf4khE/edit?usp=sharing",
    "website_url": "https://www.openroadinitiative.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "verilog",
      "c++",
      "tcl",
      "OpenRoad"
    ],
    "topic_tags": [
      "ASIC design",
      "OpenROAD chip design",
      "Open EDA",
      "Open-source Design",
      "LLM chip design"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/the-openroad-initiative",
    "ideas_content": "Die Datei kann in Ihrem Browser nicht geöffnet werden, weil JavaScript nicht aktiviert ist. Aktivieren Sie JavaScript und laden Sie die Seite noch einmal.\nGSoC 2026 ORI Projects\nTab\nExtern\nFreigeben\nAnmelden\nDatei\nBearbeiten\nAnsicht\nTools\nHilfe\nBedienungshilfen\nFehlerbehebung"
  },
  {
    "name": "Ceph",
    "slug": "ceph",
    "tagline": "The Future of Storage",
    "description": "An open-source storage platform that implements storage on a single distributed computer cluster and provides a 3-in-1 interface for object-, block- and file-level storage.",
    "ideas_url": "https://ceph.io/en/developers/google-summer-of-code/",
    "website_url": "https://ceph.io/en/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "c++"
    ],
    "topic_tags": [
      "distributed systems",
      "Software-Defined-Storage"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/ceph",
    "ideas_content": "Google Summer of Code ([g.co/gsoc](http://g.co/gsoc)) is Google's mentorship program for bringing new contributors into open source communities.\n\nGoogle Summer of Code is a unique program where new contributors to open source, ages 18 and over, are paired with a mentor to introduce them to the open source community and provide guidance while they work on a real world open source project over the summer. Projects cover a wide range of fields including: Cloud, Operating Systems, Graphics, Medicine, Programming Languages, Robotics, Science, Security and many more. GSoC Contributors do earn a stipend to work on their small, (~90 hour), medium (~175 hour) or large (~350 hour) projects.\n\nGSoC is a highly competitive program, so don't wait to the last minute to prepare! GSoC Contributors should reach out to the mentors of projects that interest them once orgs are announced on February 27, 2025. Potential GSoC Contributors can apply for Ceph's projects at [g.co/gsoc](http://g.co/gsoc) from March 24th - April 8, 2025.\n\nSee the list of projects we have available for GSoC contributors and [learn how get started with contributions](https://ceph.io/en/developers/contribute/).\n\nIn addition, for each project, mentors have detailed their expectations for usage of AI tools at the end of each project description.\n\nFor any questions, contact Vallari Agrawal ([vallari.agrawal@ibm.com](mailto:vallari.agrawal@ibm.com)).\n\n## radosgw-admin UX and documentation improvements [Â¶](https://ceph.io#radosgw-admin-ux-and-documentation-improvements)\n\n**Mentor name(s):** Yuval Lifshitz, Jacques Heunis\n\n**Mentor email(s):** [ylifshit@ibm.com](mailto:ylifshit@ibm.com), [jheunis@bloomberg.net](mailto:jheunis@bloomberg.net)\n\n**Difficulty:** Advanced\n\n**Project Hours:** 350\n\n**Skills needed:** C++, (maybe python)\n\n**Subcomponent of Ceph:** RGW\n\n**Description of project:**\n\nCurrently documenting radosgw-admin commands is a manual and error prone process.\n\nAfter implementing a new command, the \"usage\" part should be updated accordingly in the code, where there could be a mismatch between the command itself and its arguments and what is documented in the usage.\n\nAfter that the man page should be updated manually, as well as the admin guide. any reference to this command in other places in our documentation is also manual.\n\nWe would like to use a more Programmatic approach towards the problem:\n\n- use a cli/args framework that support auto-generation of context-aware \"usage\" docs\n- investigate how we can use it to auto generate the man page and admin guides (maybe using some python code)\n- see if we can easily reference these command descriptions in other places in our documentation\n- all of this, while maintaining backward compatibility with the existing behavior\n- see also:\n[https://tracker.ceph.com/issues/74508](https://tracker.ceph.com/issues/74508)\n\n**Standup/weekly call mentee could attend?:** RGW standup, RGW refactoring meeting\n\n**Steps to evaluate an applicant for the project:** TBD\n\n**1-2 short paragraphs about what first 2 weeks of work would look like during the internship:** TBD\n\n**Expected Outcome:** Detailed in the description.\n\n**Rules for AI usage:** [https://gist.github.com/yuvalif/b07312c98ea74890e157594a456c6e6b](https://gist.github.com/yuvalif/b07312c98ea74890e157594a456c6e6b)\n\n## Kafka Security [Â¶](https://ceph.io#kafka-security)\n\n**Mentor name(s):** Yuval Lifshitz\n\n**Mentor email(s):** [ylifshit@ibm.com](mailto:ylifshit@ibm.com)\n\n**Difficulty:** Advanced\n\n**Project Hours:** 350\n\n**Skills needed:** Python and C++\n\n**Subcomponent of Ceph:** RGW (teuthology and rook as stretch goals)\n\n**Description of project:**\n\nBucket notification integration with Kafka is a very useful feature in the RGW. However, some security features needed for such integrations are missing. so, in this project we will try to make bucket notifications over kafka more secure.\n\nThe following features are missing:\n\n- GSSAPI\n- OAUTHBEARER\n- mtls\n- passing in CA without a file (useful for rook integration)\n\nThe main challenge in the above would be in automating the tests, so they could easily run locally,\n\n- as a stretch goal, we should make sure these tests can also run in teuthology.\n- another stretch goal would be to use the integrate the above feature into rook (this would involve some golang coding as well).\n\n**Standup/weekly call mentee could attend?:** RGW daily standup, RGW weekly refactoring meeting\n\n**Steps to evaluate an applicant for the project:** TBD\n\n**1-2 short paragraphs about what first 2 weeks of work would look like during the internship:** TBD\n\n**Expected outcome:** Detailed in the description.\n\n**Rules for AI usage:** [https://gist.github.com/yuvalif/b07312c98ea74890e157594a456c6e6b](https://gist.github.com/yuvalif/b07312c98ea74890e157594a456c6e6b)\n\n## RGW tcmalloc profiling [Â¶](https://ceph.io#rgw-tcmalloc-profiling)\n\n**Mentor name(s):** Yuval Lifshitz\n\n**Mentor email(s):** [ylifshit@ibm.com](mailto:ylifshit@ibm.com)\n\n**Difficulty:** Advanced\n\n**Project Hours:** 175\n\n**Skills needed:** Python and C++\n\n**Subcomponent of Ceph:** RGW (teuthology and rook as stretch goals)\n\n**Description of project:**\n\nAll daemons in ceph are using tcmalloc as the memory allocator to achieve better performance.\n\nHowever, while the OSD, MON, and MDS can report the memory allocation performance, the RGW does not support that (see: [https://docs.ceph.com/en/latest/rados/troubleshooting/memory-profiling/#memory-profiling](https://docs.ceph.com/en/latest/rados/troubleshooting/memory-profiling/#memory-profiling)).\n\nIn this project, we should add this reporting support to the RGW as well.\n\nAs a stretch goal, we should use the profiling information from RGW runs to tune the tcmalloc parameters so that would be more suitable for the memory use of the RGW\n\n**Standup/weekly call mentee could attend:** RGW daily standup, RGW weekly refactoring meeting\n\n**Steps to evaluate an applicant for the project:** TBD\n\n**1-2 short paragraphs about what first 2 weeks of work would look like during the internship:** TBD\n\n**Expected outcome:** Detailed in description.\n\n**Rules for AI usage:** [https://gist.github.com/yuvalif/b07312c98ea74890e157594a456c6e6b](https://gist.github.com/yuvalif/b07312c98ea74890e157594a456c6e6b)\n\n## Carbonization and UX Consistency Improvements for Ceph Dashboard [Â¶](https://ceph.io#carbonization-and-ux-consistency-improvements-for-ceph-dashboard)\n\n**Mentor name(s):** Afreen Misbah, Abhishek Desai, Dnyaneshwari Talwekar\n\n**Mentor contact:** Join Ceph Slack from [here](https://join.slack.com/t/ceph-storage/shared_invite/zt-3jlvf8f6e-45tyKGpqkkfcC9feAUpgfQ) and reach out to: @Afreen @Abhishek Desai @Dnyaneshwari Talwekar\n\n**Difficulty:** Easy\n\n**Project Hours:** 350\n\n**Skills needed:** Angular, Typescript, CSS, jest, cypress, carbon library, Frontend skills\n\n**Subcomponent of Ceph:** Dashboard\n\n**Description of project:**\n\nCeph Dashboard is Cephâs web-based management and monitoring interface built using Angular and TypeScript on the frontend, with Python on the backend. While the dashboard is feature-complete, several parts of the UI remain partially or fully non-carbonized and exhibit inconsistent UX patterns, including layouts, forms, typography, and overview pages. These inconsistencies increase maintenance complexity and negatively impact usability.\n\nThis project focuses on completing the carbonization of the Ceph Dashboard by standardizing remaining UI components using the [Carbon Design System](https://carbondesignsystem.com/). As part of this effort, an existing routed resource page patternâalready implemented for one resourceâwill be extended consistently across all relevant dashboard resources. The project also includes usability improvements and expanding frontend test coverage to ensure long-term maintainability and stability.\n\n[https://tracker.ceph.com/projects/dashboard/wiki/Contributing_to_dashboard](https://tracker.ceph.com/projects/dashboard/wiki/Contributing_to_dashboard)\n\n**Standup/weekly call mentee could attend:** 1:00 PM IST Mon-Wed & 3:00 PM IST Thur | [https://meet.jit.si/ceph-dashboard](https://meet.jit.si/ceph-dashboard)\n\n**Steps to evaluate an applicant for the project:** Writing quality code, active participation in slack, and good communication skills\n\n**1-2 short paragraphs about what first 2 weeks of work would look like during the internship:** TBD\n\n**Expected outcome:**\n\nBy the end of the project, the Ceph Dashboard will have a fully carbonized and UX-consistent frontend, with standardized routed resource pages across all major resources, improved usability workflows, and expanded frontend test coverage. The result will be a more maintainable, user-friendly dashboard aligned with Carbon design standards and easier for future contributors to extend.\n\n**Rules for AI usage:** TBD"
  },
  {
    "name": "Submitty",
    "slug": "submitty",
    "tagline": "Homework Autograding and Course Management Tools",
    "description": "Submitty is an open source programming assignment submission system with secure and automated testing and grading, efficient manual TA/instructor grading, and additional tools for overall course management and communication between students and instructional staff. Submitty was launched by the Rensselaer Center for Open Source Software (RCOS) in 2014.\n\nhttps://github.com/Submitty/\n\nKey Features\n\n+ Secure testing of many programming languages: Python, C/C++, Java, etc.\n+ Customizable automated grading with immediate feedback to students, and optional hidden or randomized tests.\n+ Advanced grading tools: static analysis, unit testing, code coverage, memory debuggers, networked assignments, custom Docker containers, and screenshots/GIFs of graphics programs.\n+ Individual or team assignments submitted by drag-and-drop or version control.\n+ Correct mistakes through multiple submissions, flexible ``late day’’ policy.\n+ Interface for complementary instructor/TA manual grading, regrade requests, anonymized peer grading.\n+ Instructor bulk upload of scanned .pdf exams, QR code name matching, pdf annotation.\n+ Supports course material hosting, term grades spreadsheet, plagiarism detection.\n+ Integrated discussion forum, email announcements, lecture polling, office hours queue, and student activity dashboard.\n+ Scales to multiple courses, thousands of students, multiple instructors and TAs per course.\n+ Open-source, free to use, install on your own hardware, or VPS.\n\nSubmitty has been used at a half dozen other universities and we aim to grow to more users and developers.  The courses using Submitty cover the undergraduate and graduate curriculum from introductory programming courses, intermediate and advanced theory courses, popular junior/senior electives with team projects and written reports, and specialized graduate courses.\n\nWe regularly present our work at the annual ACM SIGCSE conference.",
    "ideas_url": "https://submitty.org/developer/getting_started/project_ideas",
    "website_url": "https://submitty.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "postgresql",
      "javascript",
      "c++",
      "php"
    ],
    "topic_tags": [
      "education",
      "visualization",
      "web",
      "privacy/security",
      "communication"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/submitty",
    "ideas_content": "**We are thrilled to announce that Submitty has been accepted to Google\nSummer of Code (GSoC) 2026.**\n\n*See also: How to Apply to Submitty for Google Summer of Code 2026*\n\nThe project ideas listed below target a variety of different topics and require different levels of prior experience. The scope of these projects varies, and may require different overall time commitments (varying full-time-work-equivalent from 1 month to 3 months). We are also interested in project proposals based on other topics from our list of open bugs and feature requests.\n\nProspective Submitty contributers are encouraged to\njoin our\n[Zulip server](https://submitty.org/contact) to meet the Submitty mentors and other new\ndevelopers. You may also submit questions or comments\non specific issues through our\n[Submitty GitHub Issue Tracker](https://github.com/Submitty/Submitty/issues).\n\n\n-\n**Interactive User Interfaces With Vue.js**Submitty primarily uses server-side rendering via Twig. jQuery is used extensively throughout the site to add interactivity, but it is insufficient for the most complex pages. Instead, we we are moving forward with a redesign and refactor to\n\n[Vue.js](https://vuejs.org/)for pages such as the TA grading interface, discussion forum, office hours queue, and rainbow grades customization interface. The goal of this project is to explore how we can add and improve interactivity to specific pages and support future development efforts involving the use of Vue.js within Submitty’s codebase.*Expected Outcomes*: This project is flexible in both scope and size. A successful proposal should include detailed information about the specific pages and components to be converted, including time estimates for the proposed conversion projects and common core logic improvements. Participants will gain a better understanding of the challenges involved in introducing new technologies to a large existing codebase, gain experience architecting a key part of a large project, and grow their knowledge of modern web frameworks.[Recent & Ongoing Work to Incorporate Vue.js](https://github.com/Submitty/Submitty/pulls?q=is%3Apr+vue)\n\n[Open Issues related to Vue.js](https://github.com/Submitty/Submitty/issues?q=is%3Aissue%20state%3Aopen%20vue%20)*Skills & Experience Required*: Moderate to advanced programming skills, preferably with experience using modern client-side web frameworks.*Possible Mentors*: Justin Manion, William Allen, Chris Reed, Barb Cutler\n\n*GSoC Project Size*: 175 or 350 hours\n\n*Difficulty Level*: medium to challenging -\n**Expand Testing of the Manual/TA Rubric Grading Interface**[Overview of Rubric Grading Interface](https://submitty.org/grader/rubric_grading/index)Our TA grading interface is elaborate, highly-featured, and customizable. However, the interface is visually overwhelming to new graders and new instructors. We would like to simplify the default environment configuration and improve the on-page documentation to make Submitty more intuitive for new users.\n\nFurthermore, some of our TA grading features are not adequately tested by automated unit and end-to-end (Cypress) regression testing. Our development environment includes a large variety of synthetic data for testing, but the coverage of that data for our large and growing feature set is incomplete. The scripts to randomly generate this synthetic data should be refactored to allow for more flexibility and control to ensure we can adequately test all new and existing functionality.\n\n[Open Issues related to TA Grading](https://github.com/Submitty/Submitty/issues?q=is%3Aopen+is%3Aissue+label%3A%22TA+Grading+%2F+TA+UI%22)\n\n[Open Issues related to Synthetic Sample Data](https://github.com/Submitty/Submitty/issues?q=is%3Aopen+is%3Aissue+label%3A%22Sample+Data%22)\n\n[Related Prior GSoC Project: Cameron Peterson](https://submitty.org/developer/google_summer_of_code/2023_Cameron_Peterson)\n\n[Related Prior GSoC Project: Rahul Vishwakarma](https://submitty.org/developer/google_summer_of_code/2024_Rahul_Vishwakarma)*Expected Outcomes*: The primary goals for this project include the expansion of our automated testing of the TA Grading pages and to patch bugs uncovered by this improved testing. The project may be expanded in scope to additionally propose and execute small or modest user interface revisions that enhance the TA experience, especially for graders who are new to the interface and grading process.*Skills & Experience Required*: Some programming experience, willingness to learn web and database development and the Cypress end-to-end automated testing framework. Having served as a teaching assistant with grading experience design will be beneficial.*Possible Mentors*: William Allen, Cameron Peterson, Barb Cutler\n\n*GSoC Project Size*: 90 or 175 hours\n\n*Difficulty Level*: introductory to medium -\n**Refactor and Performance Improvements for the Manual/TA Rubric Grading Interface**[Overview of Rubric Grading Interface](https://submitty.org/grader/rubric_grading/index)The Manual/TA rubric grading interface is elaborate, highly-featured, and customizable; however, the performance of these webpages is problematic for large courses due to inefficient database queries and server communication delays to load data that could/should be asynchronous. The manual/TA rubric pages could benefit from a significant technology refactor to use\n\n[Vue.js](https://vuejs.org/), for example.We also have quality of life and efficiency feature requests for\n\n*power user*graders and instructors teaching large enrollment courses with a sizeable team of teaching assistants and graders. Some of the advanced features include: Automated redaction of student names to facilitate anonymized grading, dynamic indicators to show when another grader is actively viewing/grading this student, and streamlining grading by showing individual pages of a student exam rather than the entire .pdf.[Open Issues related to TA Grading](https://github.com/Submitty/Submitty/issues?q=is%3Aopen+is%3Aissue+label%3A%22TA+Grading+%2F+TA+UI%22)\n\n[Related Prior RCOS Project: Alexander Lavallee](https://submitty.org/developer/rensselaer_center_for_open_source/2025_Alexander_Lavallee)*Expected Outcomes*: This project would first prepare a detailed software design plan for an organized, multi-stage incremental refactor of the manual/TA rubric pages and follow with the execution/implementation of a significant portion of the new design. The project could include the extension and/or updating of our automated end-to-end (Cypress) testing and patching bugs uncovered by this testing (as described in the previous project idea). The project should include benchmarking along the way to ensure that the refactor is improving the performance of the Manual/TA Rubric Grading interface. The general interface for TA/Manual grading should remain similar, but the project may include small user interface revisions.*Skills & Experience Required*: Web and database development experience and general software design and implementation experience. Experience with end-to-end automated testing (Cypress) and having served as a teaching assistant with grading experience design is beneficial but not required.*Possible Mentors*: William Allen, Barb Cutler\n\n*GSoC Project Size*: 175 or 350 hours\n\n*Difficulty Level*: medium to challenging -\n**Notebook Builder: UI To Streamline Instructor Configuration of Automated Grading**Our system for automated testing and grading of student work is very powerful, but the configuration process that instructors must navigate is complex and time-consuming. While we provide a number of illustrative examples, the development of a new autograding configuration is overwhelming – even for an instructor with prior experience. The primary method for creating an autograding configuration is to prepare a\n\n`config.json`\n\nfile (and any necessary additional files) and upload or store these files on the server file system. We have a prototype Web GUI interface we call the “Notebook Builder” but the current state of the feature is undocumented and functionality is limited. We would like to improve and expand this feature to facilitate instructor creation of basic and moderate complexity autograding configurations.[Assignment Autograding Configuration Instructions](https://submitty.org/instructor/autograding/specification)\n\n[Notebook Assignment Configuration](https://submitty.org/instructor/assignment_configuration/notebook)\n\n[Tutorial Autograding Configuration Examples](https://github.com/Submitty/Tutorial/tree/main/examples)This project will involve multiple modules of Submitty including web UI development, integration, documentation, additional tutorial examples, and extending output generation to instructor solutions in compiled languages.\n\n[Open Issues related to Autograding](https://github.com/Submitty/Submitty/labels/Autograding)\n\n[Open Issues related to Notebook / Notebook Builder](https://github.com/Submitty/Submitty/issues?q=is%3Aopen+is%3Aissue+label%3A%22Notebook+%2F+Notebook+Builder%22)\n\n[Related Prior GSoC Project: Sahil Suman](https://submitty.org/developer/google_summer_of_code/2024_Sahil_Suman)\n\n[Related Prior RCOS Project: Justin Manion](https://submitty.org/developer/rensselaer_center_for_open_source/2025_Justin_Manion)*Expected Outcomes*: The primary focus of the project is the revision and expansion of the Notebook Builder UI to increase the number of autograding features that are supported. The UI should be easy-to-use for instructors of non-computer-science/non-programming courses and also instructors of courses with introductory to moderate programming assignments. The size and scope for a proposal in this area is flexible, depending on the time commitment and prior skills of the applicant.*Skills & Experience Required*: Some programming experience, willingness to learn web and database development. Prior experience with user interface design and an eye for quality user design are beneficial. Having served as a teaching assistant or instructor with experience in programming assignment design will be beneficial but not required.*Possible Mentors*: Justin Manion, Barb Cutler, Chris Reed\n\n*GSoC Project Size*: 90 or 175 or 350 hours\n\n*Difficulty Level*: introductory or medium -\n**Expansion of Examples and Documentation of Intermediate and Advanced Autograding Features**Our system for automated testing and automated grading of student work is very powerful and highly-customizable, but the documentation for our moderate and advanced autograding features is incomplete. While we provide a number of autograding examples, some of the examples are out-of-date and do not represent our current suggested best practices.\n\n[Assignment Autograding Configuration Instructions](https://submitty.org/instructor/autograding/specification)\n\n[Submitty Autograding Tutorial Examples](https://github.com/Submitty/Tutorial)\n\n[Additional Autograding Examples](https://github.com/Submitty/Submitty/tree/master/more_autograding_examples)\n\n[Related Prior GSoC Project: Drumil Patel](https://submitty.org/developer/google_summer_of_code/2019_DrumilPatel)We would like to reduce the learning curve for new instructors and provide more tutorial examples of autograding for instructors teaching courses of any level. Automated testing and automated grading can be used in introductory programming courses in middle and high schools, including AP Computer Science. It can also be used by programming-intensive intermediate and upper level / senior university-level systems coursework. Assignments that require can be configured with custom Docker Images to provide access to specific programming languages and libraries.\n\n[Open Issues related to Docker Image Autograding](https://github.com/Submitty/Submitty/issues?q=label%3A%22Docker+Container+Autograding%22+)\n\n[Docker Images for Autograding Common Programming Languages](https://github.com/Submitty/DockerImages/tree/main)\n\n[Example Custom Docker Images University](https://github.com/Submitty/DockerImagesRPI/tree/main/dockerfiles)\n\n[Sample Java Assignments](https://submitty.org/instructor/autograding/sample_assignments)\n\n[Related Prior GSoC Project: Nithish Reddy Banda](https://submitty.org/developer/google_summer_of_code/2024_Nithish_Reddy_Banda)*Expected Outcomes*: The project should begin with a review and organization of existing sample and tutorial assignments and current autograding functionality documentation. Out-of-date or underdeveloped autograding configuration examples should be expanded as necessary, and features that are missing documentation and examples should be identified (e.g., generated random input and output from instructor solution, customized docker containers, autograding graphical output, autograding) and resolved by creating new examples. Finally, we would like to create and support a resource for the community of crowd-sourced complete programming assignments/exercises with included autograding configuration.*Skills & Experience Required*: Moderate to advanced programming experience, willingness to learn web and database development. Having served as a teaching assistant or instructor with experience in programming assignment design will be beneficial.*Possible Mentors*: Chris Reed, Barb Cutler\n\n*GSoC Project Size*: 175 or 350 hours\n\n*Difficulty Level*: medium to challenging -\n**AI/ML to Enhance and Streamline Manual / TA Grading**The use of a unified and retroactively editable rubric for manual/TA grading can ensure consistency when grading large courses, especially when more than one grader is working on a single problem or assignment. However, it is usually still necessary for the graders to inspect the student work one-at-a-time and it can be difficult for the grader to remember the details of all previously graded assignments and recognize patterns that should be graded similarly. Furthermore, the process of manual grading is time-consuming and thus detailed and thoughtful constructive feedback to each individual is often not possible.\n\n[Overview of Rubric Grading Interface](https://submitty.org/grader/rubric_grading/index)The goal of this project is to explore the potential to leverage Artificial Intelligence and Machine Learning (AI/ML) to reduce the burden of manual grading in large courses with either programming or non-programming assignments. Automatically organizing student submissions into groups that contain similar patterns and have common strengths or flaws can ensure that student work is assessed consistently and students receive appropriate and in-depth feedback to aid their learning.\n\nThe Submitty project includes related technology for the static analysis of student’s code and tools to screen for plagiarism in both student-submitted plain text assignments and software. Note that the Submitty static analysis and plagiarism tools have been tested and validated with datasets of sample student submissions; however, for privacy and confidentiality reasons, these datasets are not and cannot be part of the Submitty open-source materials.\n\n[Autograding using Static Analysis](https://submitty.org/instructor/autograding/static_analysis/index)\n\n[Plagiarism Detection](https://submitty.org/instructor/course_management/plagiarism)*Expected Outcomes*: Detailed design plan for the integration of an AI/ML framework into Submitty for the analysis and clustering the assignment submissions by students based on common patterns in the text and/or code. Implementation of a prototype AI/ML tool to detect common patterns in student submissions and present this information to the grader in an organized way to allow streamlined bulk grading and feedback within the manual/TA grading interface. As time permits (and based on the scope and time commitment) evaluation of the effectiveness of this technique on real world data and the potential for improving the efficiency of the manual/TA grading process and the quality/accuracy and quantity of useful constructive feedback to students.*Skills & Experience Required*: Coursework and/or professional experience in AI/ML and modern AI/ML technology. Moderate to advanced programming experience, and willingness to learn web and database development. Having served as a teaching assistant for a large course with manual grading experience design will be beneficial.*Possible Mentors*: Barb Cutler, William Allen\n\n*GSoC Project Size*: 175 or 350 hours\n\n*Difficulty Level*: medium to challenging -\n**Other Topics**The Submitty team welcomes GSoC project proposals on other topics requested by our student, TA, and instructor users. We track requests for new features in our\n\n[Submitty GitHub Issue Tracker](https://github.com/Submitty/Submitty/issues). A successful application would select one or more issues of moderate scope proportional to the applicant’s time commitment and prior experience. Be sure to join our[Zulip server](https://submitty.org/contact)to meet the Submitty mentors and other new developers and discuss your interests and project plans.*Skills & Experience Required*: Some prior programming experience, willingness to learn web and database development, and additional specific skills as appropriate.*Possible Mentors*: Barb Cutler, William Allen, Justin Manion, Cameron Peterson, Chris Reed, Shail Patel, Matthew Peveler, Preston Carman\n\n*GSoC Project Size*: 90 or 175 or 350 hours\n\n*Difficulty Level*: introductory to medium to challenging\n\n\nSee also:"
  },
  {
    "name": "KubeVirt",
    "slug": "kubevirt",
    "tagline": "Building a virtualization API for Kubernetes",
    "description": "KubeVirt is a virtual machine management extension for Kubenetes, allowing you to create and manage virtualised workloads natively alongside container workloads. It does this by adding virtualization resources through the Kubernetes Custom Resource Definition API.\n\nKubeVirt is a Cloud Native Computing Project (CNCF) incubating project.",
    "ideas_url": "https://github.com/kubevirt/community/wiki/Google-Summer-of-Code-2026",
    "website_url": "https://kubevirt.io",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "golang",
      "grpc"
    ],
    "topic_tags": [
      "virtualization",
      "containers",
      "kubernetes"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/kubevirt",
    "ideas_content": "# Google Summer of Code 2026\n\n\"Google Summer of Code (GSoC) is a global, online program that brings new contributors into open source software organizations.\" - [Google Summer of Code Contributor Guide](https://google.github.io/gsocguides/student/)\n\nThe KubeVirt community is applying to be a Google Summer of Code organization, to provide mentorship opportunity to applicants interested in learning about open source software development in the cloud native ecosystem. \n\nSee the [Google Summer of Code website](https://summerofcode.withgoogle.com/) for more information about the program.\n\n## Key Dates\n\nFeb 19: List of accepted organizations announced <br />\nFeb 19 – Mar 15: Potential contributors discuss project application ideas with organizations <br />\nMar 31: Contributor application deadline <br />\nApr 30: Accepted GSoC contributor projects announced <br />\nMay 1 – May 24: Community Bonding Period <br />\nMay 25 – Aug 24: The Summer of Code!\n\nSee the [Google Summer of Code timeline](https://developers.google.com/open-source/gsoc/timeline) for more detailed timeline information.\n\n## Project Ideas\n\nKubeVirt is proposing the following project ideas as starting points for GSoC contributors to develop their own project applications.\n\n### 1. Title: Early Enablement of CBOR\n<!-- **GitHub issue**: https://github.com/kubevirt/community/issues/ -->\n\n**Description** <br />\nKubernetes 1.32 introduced Alpha support of CBOR (Concise Binary Object Representation) for CRDs, promising a more compact format and further aiding scalability of Kubernetes and related projects.\n\nKubeVirt aAs a project based on Kubernetes, KubeVirt can leverage this new format to possibly harvest some performance gains. The goal of this project is to build a proof of concept, integrating CBOR for our client-go, as well as enabling testing for our Scale and Performance Special Interest Group (SIG-scale) testing, paving the way for adoption once the feature graduates in Kubernetes.  \n  \nA successful candidate will work with the SIG-scaleSpecial Interest Group in order to adapt the new format and implement an evaluation framework to determine possible gains.  \n\n**Goal** <br />\nThe main goal of this project is to create a VEP (design proposal in kubevirt/enhancements repository), integrate CBOR into Kubevirt and ensure that all functionality is preserved.  \nTo validate the usefulness of the PoC you will need to provide benchmark data and summarization if the performance gain is significant for the adoption. \n\n**Impact** <br />\nThis project enables KubeVirt to evaluate the potential performance benefits of the new CBOR format introduced in Kubernetes 1.32. By implementing a proof of concept and a benchmarking framework, you will provide the necessary data to determine if this change improves our scalability. The process of writing a VEP and integrating these changes offers practical experience with Kubernetes API internals and the governance of a large open source project.\n\n\n**Project requirements** <br />\nProject size: Medium – Large <br />\nDifficult: TBA <br />\nRequired skills: GoLang <br />\nDesired skills: Testing, Kubernetes  <br />\nMentors: <Felix Matouschek [fmatouschek@redhat.com](mailto:fmatouschek@redhat.com)>, <Ľuboslav Pivarč [lpivarc@redhat.com](mailto:lpivarc@redhat.com)>, <Victor Toso [victortoso@redhat.com](mailto:victortoso@redhat.com)>\n\n**See the [GitHub issue](https://github.com/kubevirt/community/issues/) for more information on the project, how to get started, and to ask questions.**\n\n\n### 2. Adapting [k8s.io/apiserver](http://k8s.io/apiserver) in KubeVirt\n<!-- **GitHub issue**: https://github.com/kubevirt/community/issues/ -->\n\n**Description** <br />\nIn the Kubernetes world it is common practice to use the [k8s.io/apiserver](http://k8s.io/apiserver) library to build secure and maintainable API servers. However, KubeVirt is historically using its own API server implementation which resulted in additional effort maintaining it, especially when addressing security issues or adopting new versions and features.\n\n  \nThe goal for this project is to create a proof of concept that shows how KubeVirt’s API could be migrated to the [k8s.io/apiserver](http://k8s.io/apiserver) library. \n\n**Goal** <br />\nThe main objective is to write a comprehensive VEP (design proposal in kubevirt/enhancements repository), accompanied by a Proof of concept. The design and implementation needs to cover all needs of KubeVirt’s API, such as streaming, webhooks, etc.\n\n**Impact** <br />\nThis project explores a path to modernize KubeVirt’s API layer by adopting the standard k8s.io/apiserver library. By proving feasibility through a PoC and a design proposal (VEP), you will ensure KubeVirt adheres to upstream security standards and reduce the burden of maintaining a custom API implementation. You will gain deep experience with the core libraries used to build Kubernetes, learning how to handle complex requirements like streaming and webhooks in a cloud native environment.\n\n**Project requirements** <br />\nProject size: Large (350 hours) <br />\nDifficult: TBA <br />\nRequired skills: GoLang <br />\nDesirable skills: Testing, Kubernetes <br />\nMentors: <Ľuboslav Pivarč [lpivarc@redhat.com](mailto:lpivarc@redhat.com)>, <Felix Matouschek [fmatouschek@redhat.com](mailto:fmatouschek@redhat.com)>\n\n**See the [GitHub issue](https://github.com/kubevirt/community/issues/) for more information on the project, how to get started, and to ask questions.**\n\n### 3. Component base testing framework\n<!-- **GitHub issue**: https://github.com/kubevirt/community/issues/ -->\n\n**Description** <br />\nToday, KubeVirt contains a comprehensive unit and e2e/functional testing suites and frameworks. While unit tests provide a good guarantee of functioning small, well scoped logic, the e2e suite ensures users flows are covered and not regressing with new changes. \n\nThe component testing framework should bridge these 2 types of tests and bring the best of both. By testing each component in isolation (only with direct dependencies) we want to bring fast, easy to write and not so resource intensive tests as unit tests but provide higher guarantees similar to e2e tests where larger scope of logic is tested (the component).\n\n**Goal** <br />\nThe goal for this project is to write a re-usable framework for component testing and implement a small test suite for one component. As part of the outcome the contributor should socialize this new framework with the community and provide necessary guidelines and documentation in order for community members to increase the usage and coverage. \n\n**Impact** <br />\nThis framework optimizes the KubeVirt testing pyramid by bridging the gap between unit and E2E suites. It reduces CI resource consumption and flakiness by validating complex logic in isolation, providing a faster feedback loop for developers. For the contributor, this presents an architectural challenge of designing a scalable testing infrastructure and driving community consensus on a new standard, rather than simply writing test cases.\n\n**Project requirements** <br />\nProject size: Medium – Large <br />\nDifficulty: TBA <br />\nRequired skills: Golang <br />\nDesirable skills: Testing, Kubernetes <br />\nMentor: <Felix Matouschek [fmatouschek@redhat.com](mailto:fmatouschek@redhat.com)>, <Ľuboslav Pivarč [lpivarc@redhat.com](mailto:lpivarc@redhat.com)> \n\n**See the [GitHub issue](https://github.com/kubevirt/community/issues/) for more information on the project, how to get started, and to ask questions.**\n\n### 4. Declarative validation\n<!-- **GitHub issue**: https://github.com/kubevirt/community/issues/ -->\n\n**Description** <br />\nToday, KubeVirt developers need to write all validation logic by hand, making it harder to reuse common rules and hard to review the API, as validation is part of API compatibility. In recent years KubeVirt also integrated multiple architectures to the codebase, effectively multiplying these validations and today it’s integrating a multi-hypervisor support, which will further multiply the versions of validations.  \n  \nTo alleviate the cost of adding new validations, architectures and hypervisors, the goal of this project is to explore the adoption of declarative validations in KubeVirt. The validation needs to support writing distinguish validations per architecture x hypervisors.   \n\n**Goal** <br />\nThe goal of the project is to build a path forward for adopting the declarative validation and implementing at least one hypervisor, architecture combination in order to showcase feasibility of the solution. As these changes are significantly large for the project a comprehensive VEP (design proposal in kubevirt/enhancements repository) should be included in outcomes.\n\n**Impact** <br />\nAdopting declarative validation modernizes KubeVirt's API strategy, replacing manual checks with scalable rules to handle the soon expanding matrix of architectures and hypervisors. This reduces maintenance burden and simplifies API reviews. For the contributor, the project offers practical experience with current Kubernetes API standards and the opportunity to author and drive a major design proposal (VEP) for a complex distributed system.\n\n\n**Project requirements** <br />\nProject size: Medium – Large <br />\nDifficulty: TBA <br />\nRequired skills: Golang <br />\nDesirable skills: Testing, Kubernetes <br />\nMentor: <Ľuboslav Pivarč [lpivarc@redhat.com](mailto:lpivarc@redhat.com)>, <Felix Matouschek [fmatouschek@redhat.com](mailto:fmatouschek@redhat.com)>\n\n**See the [GitHub issue](https://github.com/kubevirt/community/issues/) for more information on the project, how to get started, and to ask questions.**\n\n### 5. Build System Evaluation\n<!-- **GitHub issue**: https://github.com/kubevirt/community/issues/ -->\n\n**Description** <br />\nToday, KubeVirt relies on [Bazel](https://bazel.build/about/intro) to manage its complex, polyglot build requirements. While Bazel provided essential hermeticity, reproducibility and cross-language support during a period of relative immaturity in Go and Docker tooling, the ecosystem has since shifted. Currently, Bazel serves as a complex layer that few contributors can comfortably navigate, creating friction.\n\n\n**Goal** <br />\nThe goal of the project is to resolve the \"Bazel vs. Native\" debate through a rigorous technical evaluation. The evaluation will consist of determining whether the current \"Bazel-heavy\" infrastructure still serves the project's goals of contributor accessibility and maintenance efficiency.\n\nThe outcomes will include a comprehensive audit of Bazel and its use in KubeVirt, a VEP (design proposal in kubevirt/enhancements repository) that will determine the project's future build direction, and finally, a POC according to the results of the VEP in the form of either an alternative Bazel replacement or a modernization of Bazel in the project.\n\n**Impact** <br />\nKubeVirt is at a critical scale where build-system friction directly slows down important patches and feature velocity. By addressing that issue, this project will lower the moat and allow more contributors access to a very important yet often neglected part of KubeVirt. For the contributor, this project offers the opportunity to author and drive a major VEP that spans multiple working groups in KubeVirt and essentially changes a fundamental part of it, as well as practical experience in designing and implementing a modern build system for a relatively complex codebase.\n\n\n**Project requirements** <br />\nProject size: Large (350 hours) <br />\nDifficulty: TBA <br />\nRequired skills: Golang, Bash <br />\nDesirable skills: Build systems, Kubernetes <br />\nMentor: <Felix Matouschek [fmatouschek@redhat.com](mailto:fmatouschek@redhat.com)>, <Adi Aloni [aaloni@redhat.com](mailto:aaloni@redhat.com)>\n\n**See the [GitHub issue](https://github.com/kubevirt/community/issues/) for more information on the project, how to get started, and to ask questions.**\n\n<!--  ### 6. \n**GitHub issue**: https://github.com/kubevirt/community/issues/\n\n**Description** <br />\n\n**Goal** <br />\n\n\n**Impact** <br />\n\n\n\n**Project requirements** <br />\nProject size: 350 hours <br />\nDifficulty: Medium <br />\nRequired skills: Golang, Bash <br />\nDesirable skills: Build systems, Kubernetes <br />\nMentor: Ľuboslav Pivarč lpivarc@redhat.com, \n\n**See the [GitHub issue](https://github.com/kubevirt/community/issues/) for more information on the project, how to get started, and to ask questions.** -->\n\n### Custom project proposals\n\nYou can submit your own project idea by emailing the [kubevirt-dev Google Group](https://groups.google.com/forum/#!forum/kubevirt-dev) and CC'ing Andrew Burden <aburden@redhat.com> and Petr Horáček <phoracek@redhat.com>.\n\nIf a mentor from the KubeVirt community supports the proposed project idea, we can add it to the KubeVirt project ideas list.\n\n## Our stance on using AI for submissions\nBefore submitting, please read and understand the [KubeVirt AI Contribution Policy](https://github.com/kubevirt/community/blob/main/ai-contribution-policy.md). \n\nAI assistance is becoming part of our ecosystem and we understand how it can be used for helping improve written submissions and assist in project work, however we have a strong requirement for the human to always be involved and in control. As the author, you need to completely understand and be able to verify the code you are submitting for review. If your project application is thought to be mostly AI-generated, it will likely not be considered. \n\nWe run interviews with all promising candidates during the application process, and if selected you will have regular meetings with your mentors throughout the program.\n\n## Prerequisites\n* You have read and understood [our stance on the use of AI](https://github.com/kubevirt/community/wiki/Google-Summer-of-Code-2026/_edit#our-stance-on-using-ai-for-submissions) in this program. \n* Join our [kubevirt-dev](https://kubernetes.slack.com/messages/kubevirt-dev) slack channel and introduce yourself\n* Have submitted 3 or more PRs in our org; at least 2 of which have been approved. These can be bug fixes and/or docs patches.\n* You have access to x86/amd64 architecture in order to run test clusters for verification. Note that it is possible to run these tests on Mac devices however we will not be able to assist in setup or troubleshooting.\n* (Suggested) Send a draft proposal and seek feedback from one of the attached mentors.\n* (Suggested) Join the weekly [KubeVirt Community Call](https://calendar.google.com/calendar/u/0/embed?src=kubevirt@cncf.io) and introduce yourself. \n\n## How and where to find help\nFirst, try to check [KubeVirt documentation](https://github.com/kubevirt/kubevirt/tree/main/docs), we cover many topics and you might already find some of the answers. If there is something unclear, feel free to open an issue and a PR. This is already a great start to getting in touch with the process. <br />\nFor questions related to KubeVirt and not strictly to the GSoc program, try to use the [#kubevirt-dev Slack channel](https://kubernetes.slack.com/archives/C0163DT0R8X) in the [Kubernetes workspace](https://slack.kubernetes.io/) and [GitHub issues](https://github.com/kubevirt/kubevirt/issues) as much as possible. Your question can be useful for other people, and the mentors might have a limited amount of time. It is also important to interact with the community as much as possible. <br />\nYou can also search the Slack channel archive to see if others have previously encountered the same issue.\n\nIf something doesn't work, try to document the steps and how to reproduce the issue as clearly as possible. The more information you provide, the easiest is for us to help you. If you open an issue in KubeVirt, this already guides you with a template with the kind of information we generally need.\n\n## Tips on how to begin\n1. Install KubeVirt and deploy KubeVirt VMs following the [getting started guide](https://github.com/kubevirt/kubevirt/blob/main/docs/getting-started.md)\n2. Look for [good-first issues](https://github.com/kubevirt/kubevirt/issues?q=is%3Aopen+is%3Aissue+label%3Agood-first-issue) and try to solve one to get familiar with the project (if there isn’t a PR linked to it, feel free to pick it)\n3. Read through our [General contributing guide](https://kubevirt.io/user-guide/contributing/) and our [Developer contributing guide](https://github.com/kubevirt/kubevirt/blob/main/CONTRIBUTING.md) for understanding of community expectations and further tips on how to get started with the project. \n\n## How to submit the proposal\nThe preferred way is to create a google doc and share it with the mentors (slack or email work). If for any reason, google doc doesn't work for you, please share your proposal by email. Early submissions have higher chances as they will be reviewed on multiple iterations and can be further improved.\n\n## What the proposal should contain\nThe design and your strategy for solving the challenge should be concisely explained in the proposal. Which components you anticipate touching and an example of an API are good starting points. The updates or APIs are merely a draft of what the candidate hopes to expand and change rather than being final. The details and possible issues can be discussed during the project with the mentors that can help to refine the proposal.\n\nThe submission should have adequate detail for the review team to consider the approach and be confident that the author has come to understand the community and the project itself, and that the author has an understanding of the work they will undertake. \n\nIt is not necessary to provide an introduction to Kubernetes or KubeVirt; instead, candidates should demonstrate their familiarity with KubeVirt by describing in detail how they intend to approach the task.\n\nMentors may find it helpful to have a schematic drawing of the flows and examples to better grasp the solution. They will select a couple of good proposals at the end of the selection period and this will be followed by an interview with the candidate.\n\nThe proposal can have a free form or you can get inspired by the [KubeVirt design proposals](https://github.com/kubevirt/enhancements/tree/main/veps) and [template](https://github.com/kubevirt/enhancements/blob/main/veps/NNNN-vep-template/vep.md). However, it should contain a draft schedule of the project phases with some planned extra time to overcome eventual difficulties."
  },
  {
    "name": "HumanAI",
    "slug": "humanai",
    "tagline": "AI for the Arts and the Humanities",
    "description": "Machine learning and Artificial Intelligence techniques can be broadly applicable and transferable across many domains. The goals of HumanAI projects are to grow the open-source community in machine learning for the domains of the Arts, Social Sciences and Humanities in addressing various important societal challenges and introducing and transferring the knowledge and tools of machine learning across these disciplines.",
    "ideas_url": "https://humanai.foundation/activities/gsoc2026.html",
    "website_url": "http://humanai.foundation",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "machine learning",
      "c++",
      "data analysis",
      "artificial intelligence"
    ],
    "topic_tags": [
      "machine learning",
      "artificial intelligence",
      "ai",
      "Arts",
      "Humanities"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/humanai",
    "ideas_content": "In 2026 HumanAI plans to participate in the program as a GSoC umbrella organization. The HumanAI organization will broaden student participation in machine learning projects over a wide variety of arts and humanities fields. HumanAI participants will be mentored by domain experts and artists at top research universities and laboratories on research projects at the cutting edge of arts and humanities. Projects span a wide range of domains, including arts, music, languages, history, choreography, theatre, literature etc.\n\nIn 2026 GSoC students work with their mentors to produce open-source codes that apply machine learning solutions to art and humanities. Projects span three evaluation periods that allow for students and mentors to collaborate on their project and evaluate student progress. Detailed rules for the GSOC program can be found [here](https://summerofcode.withgoogle.com/rules/).\nInterested students should look at the ideas page and contact the mentors. Candidates will be asked to complete an evaluation test for each project they apply to demonstrate the skills needed for the respective projects.\nIn the next step, students will produce a proposal which will be evaluated for final student selection.\n\nPlease see the [official GSoC Timeline](https://summerofcode.withgoogle.com/how-it-works/)\n\nThe ArtExtract project aims at using artificial intelligence in combination with multi-spectral imaging techniques to gain insight in ancient paintings and other form of fine art. |\n|\n\nAutoEIT is an applied machine learning project focused on automating the scoring of the Elicited Imitation Task (EIT), a research tool used to measure global language proficiency. The EIT is widely respected and is available for free in several languages, but the current workflow requires manual audio transcription and human scoring—slow, tedious, and error‑prone. This project aims to build an end‑to‑end system that will: Process raw audio files, perform accurate voice‑to‑text transcription, and automatically evaluate responses using a standardized scoring rubric.\n\nWhile AI is re-shaping many facets of life today, its impact on the arts has garnered a particular interest by the general public. AI-generated artistic outputs are growing increasingly sophisticated, but artists themselves are too often left out of the development process for such tools, yielding a stark societal divide between AI developers and the artists who inspire them. Moreover, dance as an artistic discipline has been historically overlooked and misunderstood by the AI community. The mission of this project is to put dancers and technologists directly in conversation to construct radical new tools for AI-enabled choreography that are both state-of-the-art and artist-led.\n\nThe Healing Stones project aims at using AI in combination with existing digital scan models of fragments to develop a means for reconstructing fragmented cultural heritage artifacts in a virtual space.\n\nThe Mission of the Institute for Social Science Research (ISSR) at the University of Alabama is to promote and support high-quality social science research across various disciplines. The ISSR aims to foster interdisciplinary collaboration, to provide resources and support for social science research, and to contribute to the advancement of knowledge and understanding of social phenomena.\n\nThe Late Antiquity Modeling Project (LAMP) is an international, interdisciplinary research collective. LAMP uses computational methods to reconstruct the embodied experiences of ancient buildings and landscapes. In so doing, the project crafts more accurate and embodied histories of religious communities across geographic and temporal contexts. Of particular interest to LAMP is how these embodied reconstructions might be leveraged to rewrite the history of the first centuries of Christianity. Our current project centers on the late antique necropolis of El Bagawat in Egypt’s Kharga Oasis. We are interested in developing machine learning approaches that will: 1) determine the pathways taken between buildings within the site, as well as recovering pathways no longer visible, and 2) allow to determine the visibility and audibility of any given point at the site from a particular location.\n\nRenAIssance encompasses the use of optical character recognition (OCR) to digitize text sources that have not yet been targeted by existing tools. Its purpose is to explore machine learning techniques to enable OCR on a variety of materials that have never been digitized before. Additionally, RenAIssance aims to develop a comprehensive end-to-end tool for text recognition, streamlining the entire pipeline from image preprocessing to text extraction. It also seeks to establish a standardized benchmarking framework by collecting a common validation dataset, allowing for accurate ranking and evaluation of all previously developed models.\n\nIn recent years the world has seen that effective and efficient modeling of global health epidemics is critically important. This project aims to develop an openly available tool which can rapidly model potential epidemics by using machine learning to determine the parameters of a SIR epidemic model.\n\nColav ([https://github.com/colav](https://github.com/colav)) is a colaboratory for the development of computational social sciences and digital humanities. Our main contributions are in the development of computational strategies to evaluate research and advance the knowledge of science, technology, and innovation dynamics. We do innovative research for the management of data processing, especially data related to the creation of scholarly, scientific, and technological knowledge, contribute to open science policies and strategies, and the development of research metrics and assessment tools.\n\nThe |\n|\n\nThe University of Antioquia (Spanish: Universidad de Antioquia), also called UdeA, is a public, departmental, coeducational, research university located primarily in the city of Medellín, Antioquia.\n\nThe University of California, Berkeley, is a public land-grant research university in Berkeley, California. It was established in 1868 and is the state’s first land-grant university and the founding campus of the University of California system.\n\nBrown University is a private Ivy League research university in Providence, Rhode Island, founded in 1764.\n\nAt [CERN](https://home.cern), the European Organization for Nuclear Research, physicists and engineers are probing the fundamental structure of the universe. They use the world’s largest and most complex scientific instruments to study the basic constituents of matter – the fundamental particles.\n\nIIT Delhi, officially the Indian Institute of Technology Delhi, is a public institute of technology located in Delhi, India. It is one of the 23 Indian Institutes of Technology created to be Centre of Excellence for India’s training, research and development in science, engineering and technology.\n\nThe Universidad Externado de Colombia (Externado University of Colombia) is a private university in Bogotá, Colombia. As well as being a member of the Unión de Universidades de América Latina, UDUAL, and the Asociación Internacional de Universidades, AIU., it is a founding member of the Asociación Colombiana de Universidades, ASCUN.\n\nFermi National Accelerator Laboratory (Fermilab), located just outside Batavia, Illinois, near Chicago, is a United States Department of Energy national laboratory specializing in high-energy particle physics.\n\nFlorida International University (FIU) is a public research university with its main campus in University Park, Florida. Founded in 1965 by the Florida Legislature, the school opened its doors to students in 1972. FIU is a constituent part of the State University System of Florida.\n\nThe Flatiron Institute is an American internal research division of the Simons Foundation, launched in 2016. The mission of the Flatiron Institute is to advance scientific research through computational methods, including data analysis, theory, modeling, and simulation.\n\nUniversity of Florida is a public institution that was founded in 1853.\n\nFlorida State University is a public institution that was founded in 1851.\n\nGoogle LLC is an American multinational technology company focusing on artificial intelligence, online advertising, search engine technology, cloud computing, computer software, quantum computing, e-commerce, and consumer electronics.\n\nThe University of Tennessee, Knoxville, (or The University of Tennessee; UT; UT Knoxville; or colloquially UTK or Tennessee) is a public land-grant research university in Knoxville, Tennessee, United States. Founded in 1794, two years before Tennessee became the 16th state, it is the flagship campus of the University of Tennessee system, with ten undergraduate colleges and eleven graduate colleges.\n\nNorthern Illinois University (NIU) is a public research university in DeKalb, Illinois, United States.\n\nNortheastern University (NU or NEU) is a private research university with its main campus in Boston, Massachusetts. Established in 1898, it was founded by the Boston Young Men’s Christian Association as an all-male institute before being incorporated as Northeastern College in 1916, gaining university status in 1922.\n\nThe University of Illinois Urbana-Champaign (U of I, Illinois, University of Illinois, or UIUC) is a public land-grant research university in Champaign and Urbana, Illinois. It is the flagship institution of the University of Illinois system and was established in 1867.\n\nYale University is a private Ivy League research university in New Haven, Connecticut. Founded in 1701, Yale is the third-oldest institution of higher education in the United States, and one of the nine colonial colleges chartered before the American Revolution.\n\n[Prof. Sergei Gleyzer, AI](http://sergeigleyzer.com/)\n\n[Prof. Xabier Granja, Modern Languages](https://xgranja.people.ua.edu/)\n\n[Prof. Emanuele Usai, AI](https://emanueleusai.com)\n\n[Prof. Despina Stavrinos, Social Sciences, Psychology](https://psychology.ua.edu/people/despina-stavrinosa/)\n\n*HumanAI GSoC Admins* [human-ai@cern.ch](mailto:human-ai@cern.ch)"
  },
  {
    "name": "Kotlin Foundation",
    "slug": "kotlin-foundation",
    "tagline": "Advance the Kotlin programming language",
    "description": "Kotlin is a concise, modern, and versatile programming language designed for multiple platforms.\n\nThe Kotlin Foundation, established by JetBrains and Google, later welcomed Meta, Uber, Gradle, Touchlab, Block, and Kotzilla. Together, we promote and advance Kotlin across multiple platforms, including Android, iOS, web, desktop, and server-side.\n \nCurrently, 100+ engineers from JetBrains and Google contribute to the core Kotlin project, alongside 350+ independent contributors and thousands more supporting the broader Kotlin ecosystem.\n\nThe Kotlin Foundation is committed to protecting, promoting, and advancing the evolution of the Kotlin language.",
    "ideas_url": "https://kotlinlang.org/docs/gsoc-2026.html",
    "website_url": "https://kotlinfoundation.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "gradle",
      "kotlin",
      "jvm",
      "Parsers & Compilers",
      "Multiplatform"
    ],
    "topic_tags": [
      "compilers",
      "programming languages",
      "software development",
      "libraries",
      "Programming & Build Tools"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/kotlin-foundation",
    "ideas_content": "# Google Summer of Code with Kotlin 2026\n\nThis article contains the [list of project ideas](https://kotlinlang.org#project-ideas) for Google Summer of Code with Kotlin 2026, and [contributor guidelines](https://kotlinlang.org#kotlin-contributor-guidelines-for-google-summer-of-code-gsoc)\n\n## Kotlin contributor guidelines for Google Summer of Code (GSoC)\n\n### Getting started\n\nCheck out the\n\n[GSoC FAQ](https://developers.google.com/open-source/gsoc/faq)and the[program announcement](https://summerofcode.withgoogle.com/).Familiarize yourself with the Kotlin language:\n\nThe official\n\n[Kotlin website](https://kotlinlang.org/)is a great place to start.Read the official\n\n[documentation](https://kotlinlang.org/getting-started.html)to get a better understanding of the language.Take a look at the Kotlin courses on\n\n[JetBrains Academy](https://lp.jetbrains.com/academy/learn-kotlin/)or the Android team's[Training options](https://developer.android.com/courses/).Follow the\n\n[Kotlin X](https://twitter.com/kotlin)or[Kotlin Bluesky](https://bsky.app/profile/kotlinlang.org)accounts to stay up to date on the latest news and developments.Check out the\n\n[Kotlin YouTube channel](https://www.youtube.com/@Kotlin)for tutorials, tips, and the latest updates.\n\nGet to know the Kotlin open source community:\n\nExplore the general\n\n[Kotlin contribution guidelines](https://kotlinlang.org/contribute.html).[Join the Kotlin Slack channel](https://surveys.jetbrains.com/s3/kotlin-slack-sign-up)to connect with other developers and get help with any questions you may have.[Join the #gsoc channel](https://slack-chats.kotlinlang.org/c/gsoc)to ask questions and get support from the GSoC team.\n\n\n### How to apply\n\nCheck out the\n\n[project ideas](https://kotlinlang.org#project-ideas)and select the one you would like to work on.If you are not familiar with Kotlin,\n\n[read the introductory info on the Kotlin website](https://kotlinlang.org/getting-started.html).Refer to the\n\n[GSoC contributor guidelines](https://google.github.io/gsocguides/student/writing-a-proposal).Apply via the\n\n[GSoC website](https://summerofcode.withgoogle.com/).We suggest that you write a working code sample relevant to the proposed project. You can also show us any code sample that you are particularly proud of.\n\nDescribe why you are interested in Kotlin and your experience with it.\n\nIf you participate in open source projects, please reference your contribution history.\n\nIf you have a GitHub, Twitter account, blog, or portfolio of technical or scientific publications, please reference them as well.\n\nDisclose any conflicts with the GSoC timeline due to other commitments, such as exams and vacations.\n\n\n\nThank you! We look forward to reading your applications!\n\n## Project ideas\n\n### Kotlin Compiler Fuzzer (Kai) [Hard, 350 hrs]\n\nIn recent years, fuzzing has become a widely used technique for finding complex bugs in software. The Kotlin compiler is no exception: previous fuzzing efforts resulted in more than 200 deduplicated bugs across different compiler subsystems.\n\nHowever, the existing fuzzer implementation is now obsolete and cannot be reasonably evolved further. The goal of this project is to build a new Kotlin compiler fuzzer, Kai, from scratch, based on previous experience and modern tools and techniques.\n\nThe main goal of this internship is to establish a solid foundation for future development of the fuzzer. The focus areas include:\n\nDesigning a fuzzer architecture that supports pluggability\n\nSelecting tools for generating, mutating, and processing Kotlin code\n\nDefining reliable ways to detect compiler failures\n\nDesigning proper workflows for collecting, classifying, and handling discovered issues\n\n\nAs a deliverable, we aim to create a prototype Kotlin compiler fuzzer that is modular and easy to evolve, unlike a monolithic implementation. Finding real compiler bugs would be a great bonus, but it is not the primary goal of this internship.\n\nIf you have preliminary questions about the project, contact the mentor at: marat.akhin [at] jetbrains.com\n\nExpected outcomes\n\nA prototype Kotlin compiler fuzzer with a pluggable architecture that supports future evolution.\n\nSkills required (must-have)\n\nProficiency in Kotlin or another JVM-based language\n\nTechnical English sufficient for reading relevant papers and documentation\n\nBasic understanding of compilers\n\n\nSkills required (nice-to-have)\n\nFamiliarity with fuzzing or other forms of program analysis\n\nExperience with Kotlin compiler plugins, IDE plugins, or other pluggable systems\n\nExperience with greenfield developer tooling projects\n\n\nWhat you will learn\n\nHands-on experience with compiler fuzzing\n\nHow internal developer tooling is designed and built\n\nHow to design and implement pluggable systems\n\n\nPossible mentor\n\nMarat Akhin, JetBrains\n\nTasks for applicants\n\nTask #1\n\n\nDescribe, at a high level, how you envision the architecture of a Kotlin compiler fuzzer.Task #2\n\n\nBased on the architecture from Task 1, which components are most important for pluggability, and why?Task #3\n\n\nBased on the architecture from Task 1, do you see opportunities to use LLMs or AI? If so, where and how?Task #4\n\n\nHow would you test the fuzzer itself? Is back-testing possible? If yes, how?Task #5 (Bonus)\n\n\nChoose one component from the architecture in Task 1 and describe how it could be implemented in more detail.\n\nFor example, which tools, libraries, or algorithms could be used?\n\n### Swift-to-Kotlin interop (PoC) [Hard, 350 hrs]\n\nModern software projects rarely live in a single language ecosystem. On Apple platforms, Swift is the primary language, while Kotlin is widely used for shared and cross-platform business logic. However, there is currently no straightforward way to import Swift APIs directly into Kotlin.\n\nIn this project, you will build on an existing open-source Swift–Java bridge and add Kotlin/Native as a target runtime. This includes designing how Swift APIs are exposed to Kotlin/Native, how calls cross the Swift/Kotlin boundary, and how object lifetimes are managed across runtimes.\n\nThe goal is to create a proof of concept for Swift-to-Kotlin/Native interop, document design decisions and trade-offs, and evaluate limitations and future directions.\n\nExpected outcomes\n\nA proof of concept for Swift-to-Kotlin/Native interop, with documented design decisions, trade-offs, limitations, and future directions.\n\nSkills required (must-have)\n\nCurrently pursuing or recently completed a degree in Computer Science or a related field\n\nFamiliarity with Swift\n\nInterest in programming languages and interoperability\n\n\nSkills required (nice-to-have)\n\nFamiliarity with Kotlin\n\n\nPossible mentor\n\nArtem Olkov, JetBrains\n\nTasks for applicants\n\nTask #1\n\n\nFork the[swift-java](https://github.com/swiftlang/swift-java)repository and extend it with a new target that generates Kotlin sources.Task #2 (Optional)\n\n\nExtend the previous task by making the generated Kotlin code callable using the existing JNI or FFM runtime.\n\n### Tail call support in the Kotlin/Wasm backend [Medium, 90 hrs]\n\nThis project focuses on integrating the tail call proposal into the Kotlin/Wasm backend. The intern will design and implement tail call support and evaluate its impact through benchmarking.\n\nExpected outcomes\n\nDesign and implementation of tail call support for Kotlin/Wasm, with benchmarks and evaluation.\n\nSkills required (preferred)\n\nGeneral familiarity with interpreters and compilers, and interest in optimization and benchmarking.\n\nPossible mentor\n\nCharlie Zhang, JetBrains\n\n### Kotlin Education landscape report [Medium, 175 hrs]\n\nKotlin is taught and used in educational settings worldwide. This project aims to create a structured, up-to-date overview of where and how Kotlin is taught.\n\nExpected outcomes\n\nA “Kotlin in Education” report highlighting trends and gaps\n\nReusable datasets for internal and public use\n\nInput for future strategy\n\n\nSkills required (preferred)\n\nResearch and data analysis skills\n\nInterest in programming education and developer ecosystems\n\n\nPossible mentor\n\nKsenia Shneyveys, JetBrains"
  },
  {
    "name": "MetaCall",
    "slug": "metacall",
    "tagline": "Simplifying the embedding of programming languages",
    "description": "When working with different technologies and developers of different programming languages, the productivity of the entire team worsens due to the lack of interoperability and communication between them. If the developers need two technologies which are written in different programming languages, for instance, a C/C++ library called from NodeJS, the team usually needs to port to one of the two languages or write a wrapper around them. Maintaining a port of a library or the plumbing code is frequently error-prone, time-consuming, and does not add any value to the final product.\n\nThe main objective of MetaCall is to provide a transparent interoperability in both ways, no matter what language you are using, so you feel like you are using a library written in the same language but in fact, it may be written in C, NodeJS or any other language.\n\nMetaCall currently provides a mechanism to introspect the types and function signatures, which allows us to provide this type info to the caller language. You can have type safety and at the same time avoid boilerplate in both directions.\n\nIt addresses the main shortcomings of embedding independent languages separately. Having a common implementation with a plugin architecture allows you to implement newer languages without rewriting more code. With a single solution you get C#, Ruby, Python or any other language you prefer. We can improve the core continuously and add new languages.\n\nFinally, we are using the polyglot runtime in cloud computing so we take advantage of the interoperability capabilities and allow to build complex polyglot distributed systems with ease. It is possible to build monolithic and mono-repo projects that can be distributed and scaled separately through our Function as a Service built on top of MetaCall, allowing the developer to maximize the productivity without the need of DevOps plumbing or thinking about intercommunication protocols and architectural details.",
    "ideas_url": "https://github.com/metacall/gsoc-2026",
    "website_url": "https://metacall.io",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "c++",
      "rust",
      "nodejs",
      "docker"
    ],
    "topic_tags": [
      "cloud",
      "polyglot",
      "faas",
      "languages",
      "ffi"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/metacall",
    "ideas_content": "List of project ideas for contributors applying to the Google Summer of Code program in 2026 (GSoC 2026).\n\nPlease always refer to the [official timeline](https://developers.google.com/open-source/gsoc/timeline).\n\nFirst of all, and if you have not done that yet, read [the contributor guide](https://google.github.io/gsocguides/student/) which will allow you to understand all this process and how the program works overall. Refer to its left side menu to quick access sections that may interest you the most, although we recommend you to read everything.\n\nThis is a required step unless you have dived in into the existing codebase and understood everything perfectly (very hard) and the idea you prefer is on the list below.\n\nIf your idea is not listed, please discuss it with the mentors in the available [contact channels](https://github.com/metacall/gsoc-2026?tab=readme-ov-file#find-us). We're always open to new ideas and won't hesitate on choosing them if you demonstrate to be a good candidate!\n\n- You're committing to a project and we may ask you to publicly publish your weekly progress on it.\n- We will repeatedly ask you to give feedback on our mentorship and management.\n- You wholeheartedly agree with the\n[code of conduct](https://github.com/metacall/core/blob/develop/.github/CODE_OF_CONDUCT.md). - You must tell us if there's any proposed idea that you don't think would fit the timeline or could be boring (yes, we're asking for feedback).\n\nWe recommend you to follow [Google's guide to Writing a Proposal](https://google.github.io/gsocguides/student/writing-a-proposal) as we won't be too harsh on the format and we won't provide any template. But hey, we're giving you a starting point!\n\nYou can send the proposal link to any readable format you wish: Google Docs, plain text, in markdown... and preferably hosted online, accessible with a common browser without downloading anything.\n\nWe **highly recommend you to ask for a review** anytime to the community or mentor candidates before the contributor application deadline. It's much easier if you get feedback early than to wait for the last moment.\n\nIn order to fit properly our organization standards of how to use AI, [you can check here our policy](https://github.com/metacall/gsoc-2026/blob/main/AI-USAGE-POLICY.md).\n\nYou can also propose your own.\n\n**Skills**: C/C++, Programming Language Parsers\n\n**Expected size of the project**: Medium (175 hours)\n\n**Difficulty rating**: Medium\n\n**Description**:\n\nMetaCall Core right now implements support for multiple languages and it provides runtime instrospection by multiple methodologies. This allows to have information for executing the calls in a type safe manner when possible, or list the functions, classes or objects that are loaded into it. This minimal information is only usable for the runtime normally. There is cases like Intellisense or Function Mesh projects, we need to provide a standard tool for generating ASTs from multi-language projects. In this project we will be using a tool like [Tree Sitter](https://tree-sitter.github.io/tree-sitter/) for generating an AST with all the dependency tree between multiple languages. This will be crucial for representing mixed programming language projects in an unified way, so this can be later on consumed by our Visual Studio Code plugin for having Intellisense or by the Function Mesh for breaking down a project in other subparts and distributing the workload.\n\n**Expected outcomes**:\n\n- Cross-platform tool and library written in C/C++ that can be used as a CLI or from a simple C API that can be embeeded into other projects for parsing programming languages supported by MetaCall Core.\n- It should be able to list all the functions and classes exported by any language.\n- It should be able to create a dependency tree of a multi-language project.\n\n**Possible mentors**: Thomas Rory Gummerson, Vicente Eduardo Ferrer Garcia, Fernando Vaño Garcia, Gil Arasa Verge.\n\n**Resources**:\n\n- Tree Sitter Documentation:\n[https://tree-sitter.github.io/tree-sitter/](https://tree-sitter.github.io/tree-sitter/) - Tree Sitter C API:\n[https://github.com/tree-sitter/tree-sitter/blob/master/lib/include/tree_sitter/api.h](https://github.com/tree-sitter/tree-sitter/blob/master/lib/include/tree_sitter/api.h) - Tree Sitter Tutorial:\n[https://dev.to/shrsv/making-sense-of-tree-sitters-c-api-2318](https://dev.to/shrsv/making-sense-of-tree-sitters-c-api-2318)\n\n**Skills**: C/C++, Distributed Systems, Networking, Compiler Design\n\n**Expected size of the project**: Large (350 hours)\n\n**Difficulty rating**: High\n\n**Description**:\n\nThis project focuses on converting monolithic applications into scalable microservices by making each function or module a separate service. By utilizing a Remote Procedure Call (RPC) loader, the goal is to enable functions to communicate across multiple servers, yet appear as local calls to developers. Inspired by Erlang’s distributed computing model, the system would create a seamless environment where developers can build applications that scale effortlessly, without worrying about the complexities of distributed systems. The core challenge is to develop a compiler or runtime system capable of identifying and switching between servers dynamically based on function calls, ensuring minimal overhead for the developer while maximizing system performance and scalability.\n\n**Expected outcomes**:\n\n- A functional distributed mesh system that abstracts communication complexities for developers.\n- A compiler or runtime capable of identifying function placement on servers dynamically.\n- A scalable system that can be easily integrated into existing monolithic codebases.\n- Comprehensive documentation and a guide for integrating existing applications into the mesh architecture.\n\n**Possible mentors**: Thomas Rory Gummerson, Vicente Eduardo Ferrer Garcia, Fernando Vaño Garcia, Gil Arasa Verge, Jose Antonio Dominguez.\n\n**Resources**:\n\n- MetaCall Express FaaS RPC Example:\n[https://github.com/metacall/express-faas-rpc-example](https://github.com/metacall/express-faas-rpc-example) - MetaCall Protocol:\n[https://github.com/metacall/protocol](https://github.com/metacall/protocol) - MetaCall RPC Loader:\n[https://github.com/metacall/core/tree/develop/source/loaders/rpc_loader](https://github.com/metacall/core/tree/develop/source/loaders/rpc_loader)\n\n**Skills**: C/C++, Debugging, Tooling, CI/CD, Low-level Instrumentation\n\n**Expected size of the project**: Small (90 hours)\n\n**Difficulty rating**: High\n\n**Description**:\n\nThis project aims to significantly improve code coverage reporting and memory tracking reliability across platforms. The current memory tracking mechanism is very basic and cannot detect leaks in detail, making debugging difficult and reducing developer productivity. Additionally, several tests fail on specific architectures such as ARM64 and PPC64, often without meaningful error messages, and these failures are hard to reproduce locally since they only appear in CI virtualized environments.\n\nThe project will explore extending support of existing tools such as Valgrind and AddressSanitizer (ASan) to improve memory leak detection, diagnostics, and reporting. In parallel, it will investigate and implement a custom lightweight instrumentation layer tailored to the project’s runtime, allowing fine-grained tracking of allocations, deallocations, and execution paths without destabilizing the application. A strong focus will be placed on observability, improving logs, traces, and error reporting in CI environments to make elusive bugs easier to detect and reproduce.\n\n**Expected outcomes**:\n\n- Improved memory tracking system that reports leaks without crashing the application.\n- Better integration and evaluation of Valgrind and ASan for automated testing and diagnostics.\n- A custom code instrumentation mechanism for memory usage and code coverage tracking.\n- Enhanced observability in CI pipelines, especially for ARM64 and PPC64 architectures.\n- Clear, actionable error messages and documentation for debugging hard-to-reproduce issues.\n\n**Possible mentors**: Thomas Rory Gummerson, Vicente Eduardo Ferrer Garcia, Fernando Vaño Garcia, Gil Arasa Verge, Mostafa Wael Kamal.\n\n**Resources**:\n\n- Sanitizer Setup:\n[https://github.com/metacall/core/blob/a370a7f0fb7b1d70dec04d48d3e713e8fc3f1058/cmake/CompileOptions.cmake#L112](https://github.com/metacall/core/blob/a370a7f0fb7b1d70dec04d48d3e713e8fc3f1058/cmake/CompileOptions.cmake#L112) - Valgrind Setup:\n[https://github.com/metacall/core/blob/a370a7f0fb7b1d70dec04d48d3e713e8fc3f1058/source/tests/CMakeLists.txt#L55](https://github.com/metacall/core/blob/a370a7f0fb7b1d70dec04d48d3e713e8fc3f1058/source/tests/CMakeLists.txt#L55) - Memory Tracker:\n[https://github.com/metacall/core/blob/a370a7f0fb7b1d70dec04d48d3e713e8fc3f1058/source/reflect/include/reflect/reflect_memory_tracker.h](https://github.com/metacall/core/blob/a370a7f0fb7b1d70dec04d48d3e713e8fc3f1058/source/reflect/include/reflect/reflect_memory_tracker.h)\n\n**Skills**: TypeScript, Testing, CI/CD\n\n**Expected size of the project**: Small (90 hours)\n\n**Difficulty rating**: Medium\n\n**Description**:\n\nThis project focuses on completing and stabilizing the existing MetaCall Deploy and MetaCall FaaS (Function as a Service) infrastructure. Unlike previous years where MetaCall FaaS required a full reimplementation, the core functionality is now largely in place, and the remaining work consists of resolving pending issues, completing unimplemented features, and finalizing the developer workflow.\n\nMetaCall FaaS enables developers to locally test cloud functions in an environment that closely mimics the production MetaCall FaaS platform. This is a critical component of the MetaCall ecosystem, as it allows developers to validate distributed polyglot applications before deployment. At the moment, the project has partial test coverage (9 tests passing, 6 pending), and several issues remain open that block a fully usable release.\n\nThe project will involve fixing failing and pending tests, polishing the TypeScript implementation, and improving the integration between MetaCall Deploy, MetaCall FaaS, and the MetaCall CLI. While the project is closely related to DevOps, it also requires hands-on work in the TypeScript codebase and coordination with MetaCall Protocol to ensure code reuse and consistency.\n\n**Expected outcomes**:\n\n- Completion of pending features in MetaCall Deploy and MetaCall FaaS.\n- All tests passing, with improved test coverage and stability.\n- A reliable local FaaS environment for testing MetaCall projects.\n- Improved integration with MetaCall CLI for a smoother developer workflow.\n- Updated documentation describing usage, limitations, and deployment flow.\n\n**Possible mentors**: Thomas Rory Gummerson, Jose Antonio Dominguez, Alexandre Gimenez Fernandez, Param Siddharth, Raj Aryan.\n\n**Resources**:\n\n- MetaCall FaaS (TypeScript):\n[https://github.com/metacall/faas](https://github.com/metacall/faas) - MetaCall Deploy:\n[https://github.com/metacall/deploy](https://github.com/metacall/deploy) - MetaCall FaaS Dashboard:\n[https://dashboard.metacall.io](https://dashboard.metacall.io) - MetaCall Protocol:\n[https://github.com/metacall/protocol](https://github.com/metacall/protocol) - Video - Deploying Functions into MetaCall FaaS:\n[https://www.youtube.com/watch?v=2RAqTmQAWEc](https://www.youtube.com/watch?v=2RAqTmQAWEc)\n\n**Skills**: Rust, TypeScript, React, Server-Side Rendering, CI/CD\n\n**Expected size of the project**: Large (350 hours)\n\n**Difficulty rating**: Medium\n\n**Description**:\n\nThis project focuses on enhancing the MetaCall SSR (Server-Side Rendering) server, which allows high-performance React rendering on the backend across multiple programming languages. While the project has proven its potential in performance benchmarks, it currently faces a number of challenges, including failing tests and stability issues in development mode.\n\nThe goal is to stabilize the existing implementation, resolve bugs, and improve the overall developer experience. Key objectives include fixing the failing tests, addressing issues specific to development mode (such as hot reloading, error handling, and debugging), and making MetaSSR fully functional for building and deploying websites in a production environment.\n\nThe project will involve deep work in both Rust and TypeScript to ensure seamless integration between the languages. Additionally, it will improve the error reporting, enhance the testing framework, and streamline CI/CD workflows to ensure reliability and scalability for the MetaCall SSR server.\n\n**Expected outcomes**:\n\n- A stable and fully functional MetaCall SSR server with a reliable development mode.\n- Fixed failing tests and improved test coverage.\n- Improved error handling and debugging experience.\n- Seamless integration of React on the backend with minimal friction in deployment.\n- Enhanced CI/CD pipelines for automated testing and deployment.\n\n**Possible mentors**: Thomas Rory Gummerson, Vicente Eduardo Ferrer Garcia, Gil Arasa Verge, Mostafa Wael Kamal, Alexandre Gimenez Fernandez, Param Siddharth, Jose Antonio Dominguez, Raj Aryan.\n\n**Resources**:\n\n- MetaSSR Repository:\n[https://github.com/metacall/metassr](https://github.com/metacall/metassr) - Previous work:\n[https://github.com/metacall/gsoc-2023?tab=readme-ov-file#rust-actix--typescript-react-server-side-rendering-tsx-framework](https://github.com/metacall/gsoc-2023?tab=readme-ov-file#rust-actix--typescript-react-server-side-rendering-tsx-framework)\n\n**Skills**: Rust\n\n**Expected size of the project**: Medium (175 hours)\n\n**Difficulty rating**: Hard\n\n**Description**:\n\nFew years ago [Rust Loader was implemented](https://github.com/metacall/gsoc-2022?tab=readme-ov-file#rust-loader-support) but the code has became outdated due to nature of Rust Compiler unstable API / ABI. This year the code was cleaned, all dependencies were deleted and it was able to compile and run again inside the CI but the version of the compiler supported is still very old (nightly-2021-12-04). The idea of this project is to update to the latest version and add more tests and examples with tutorials. It will be also interesting to find a portable version, or at least to prevent depending on unstable Rust Compiler API (although I am not sure this is possible). Showing examples of mixing Rust and C++ would or script languages using Rust directly without need of using macros in the original Rust code would be also interesting, also [updating existing examples](https://github.com/metacall/python-rust-melody-example). Adding support for more types will be also interesting.\n\n**Expected outcomes**: Implement a fully functional version of the Rust Loader with the latest compiler API. Extend the functionalities that are not implemented and provide more tests and examples with some tutorials about how to use it. Update existing tutorials using Rust Loader.\n\n**Possible mentors**: Vicente Eduardo Ferrer Garcia, Fernando Vaño Garcia, Gil Arasa Verge, Thomas Rory Gummerson.\n\n**Resources**:\n\n- MetaCall Rust Loader Code:\n[https://github.com/metacall/core/tree/a370a7f0fb7b1d70dec04d48d3e713e8fc3f1058/source/loaders/rs_loader](https://github.com/metacall/core/tree/a370a7f0fb7b1d70dec04d48d3e713e8fc3f1058/source/loaders/rs_loader) - Previous Work:\n[metacall/core#443](https://github.com/metacall/core/issues/443)\n\n**Skills**: GitHub Actions, C/C++, CMake Build System, Homebrew, Guix, Windows Package Managers\n\n**Expected size of the project**: Medium (175 hours)\n\n**Difficulty rating**: Medium\n\n**Description**:\n\nMetaCall Core has support for C by using `libffi`\n\n, `libclang`\n\nand `tcc`\n\n. This is widely tested in Linux on the `metacall/core`\n\nCI but lacks the implementation for MacOs and Windows. The objective of this project is to provide testing support in the Core for [Windows](https://github.com/metacall/core/pull/458) and [MacOs](https://github.com/metacall/core/pull/445) platforms, and once this is done we should implement this in the Distributables repositories. For this requirement, we will need to implement it in Guix (Linux), Homebrew (MacOs) and manually installing with Batch (Windows). It is not easy because the task requires knowledge of CMake build system and knowledge about different architectures. It willl be difficult but the final result of this is that we will be to bootstrap metacall itself with this. All the platforms will contain metacall.h and the metacall library and we can generate the API of metacall itself for multiples languages by using the C Loader. The explanation of this idea itself can be difficult because we are assuming some previous basic knowledge on MetaCall Core, but if you are intereseted you can ask in our chat groups for further explanation.\n\n**Expected outcomes**: MacOs and Windows C Loader support in the Core and the distribution of the C Loader for Windows, MacOs and Linux. We should able to run things like: `metacall test.c`\n\n, once this is implemented.\n\n**Possible mentors**: Vicente Eduardo Ferrer Garcia, Fernando Vaño Garcia, Gil Arasa Verge, Param Siddharth, Mostafa Wael Kamal, Raj Aryan.\n\n**Resources**:\n\n- Previous Work:\n[metacall/core#458](https://github.com/metacall/core/pull/458)&[metacall/core#445](https://github.com/metacall/core/pull/445) - Known Issues:\n[metacall/core#442](https://github.com/metacall/core/issues/442) - Guix\n`libclang`\n\n:[https://git.savannah.gnu.org/cgit/guix.git/tree/gnu/packages/llvm.scm#n2160](https://git.savannah.gnu.org/cgit/guix.git/tree/gnu/packages/llvm.scm#n2160) - Guix\n`tcc`\n\n:[https://packages.guix.gnu.org/packages/tcc/](https://packages.guix.gnu.org/packages/tcc/) - Guix\n`libffi`\n\n:[https://packages.guix.gnu.org/packages/libffi](https://packages.guix.gnu.org/packages/libffi)\n\n**Skills**: Artificial Intelligence, Model Context Protocol, Serverless Architectures, API Design, JSON, Context Management, Cloud Platforms, Python or TypeScript\n\n**Expected size of the project**: Medium (175 hours)\n\n**Difficulty rating**: Medium\n\n**Description**:\n\nThis project aims to integrate the Model Context Protocol (MCP) into MetaCall’s Deploy and FaaS modules, enabling context-aware serverless function deployments. MCP facilitates sharing context between models, which is essential for AI/ML-driven workflows where models maintain or adapt their state across invocations. The integration will focus on storing and propagating context data across functions, allowing seamless state transfer in multi-runtime serverless environments.\n\nThe outcome will include a fully functional API for managing and sharing model context, along with middleware to handle context serialization and propagation in cloud-native environments. This functionality will be published as a reusable component, enabling other MetaCall users to deploy context-aware functions.\n\n**Expected outcomes**:\n\n- Implement a minimal project that can be used for Claude or similar LLMs from Visual Studio Code or Antigravity that allows to deploy functions, list the existing ones, or run them locally in multiple languages.\n- Documentation and integration for the project in order to make it ready to use for other developers.\n- Testing for verifying that the tooling works and it's future proof.\n\n**Possible mentors**: Jose Antonio Dominguez, Alexandre Gimenez Fernandez, Param Siddharth, Mostafa Wael Kamal, Raj Aryan.\n\n**Resources**:\n\n- Model Context Protocol Documentation:\n[https://modelcontextprotocol.io/docs/getting-started/intro](https://modelcontextprotocol.io/docs/getting-started/intro) - Model Context Protocol SDK:\n[https://modelcontextprotocol.io/docs/sdk](https://modelcontextprotocol.io/docs/sdk) - MetaCall Deploy:\n[https://github.com/metacall/deploy](https://github.com/metacall/deploy) - MetaCall FaaS:\n[https://github.com/metacall/faas](https://github.com/metacall/faas) - MetaCall Dashboard:\n[https://metacall.io/dashboard](https://metacall.io/dashboard) - Video - Deploying Functions into MetaCall FaaS:\n[https://www.youtube.com/watch?v=2RAqTmQAWEc](https://www.youtube.com/watch?v=2RAqTmQAWEc)\n\n**Skills**: Cross-platform Development, C/C++, Build Systems, Shell Scripting (Bash), PowerShell, CI/CD, Toolchains\n\n**Expected size of the project**: Medium (175 hours)\n\n**Difficulty rating**: Medium\n\n**Description**:\n\nThis project aims to significantly expand MetaCall’s platform and architecture support beyond its current scope. At present, MetaCall supports Linux across multiple architectures (amd64 variants, 386, arm, arm64, riscv64), Windows using the MSVC toolchain, and macOS on both Intel and Apple Silicon. While this already covers many use cases, there is strong interest in supporting additional platforms and environments to improve adoption and portability.\n\nThe main goal of this project is to add first-class support for new targets such as Windows via MinGW and Cygwin, as well as additional operating systems like Android and FreeBSD. This involves adapting the build and environment setup logic to correctly detect, configure, and compile MetaCall on these platforms.\n\nA key constraint of the project is that all platform logic must be implemented inside the portable environment setup scripts ([./tools/metacall-environment.sh](https://github.com/metacall/core/blob/565bcbfd785442c2155a89661de0b2b0d125fdf3/tools/metacall-environment.sh) and [./tools/metacall-environment.ps1](https://github.com/metacall/core/blob/565bcbfd785442c2155a89661de0b2b0d125fdf3/tools/metacall-environment.ps1). This ensures that platform support is not tightly coupled to GitHub Actions or any specific CI provider, and that developers can reproduce builds locally with the same tooling used in CI.\n\nIn parallel, the project will design and add CI pipelines to automatically build and test MetaCall on all supported platforms and architectures. This will help catch platform-specific regressions early and improve overall reliability.\n\n**Expected outcomes**:\n\n- Support for additional Windows environments, including MinGW and Cygwin.\n- Initial support for new platforms such as Android and FreeBSD.\n- Refactored and extended metacall-environment scripts to handle platform detection and setup in a portable way.\n- CI pipelines covering all supported platforms and architectures.\n- Documentation describing platform requirements, limitations, and setup instructions.\n\n**Possible mentors**: Vicente Eduardo Ferrer Garcia, Fernando Vaño Garcia, Gil Arasa Verge, Thomas Rory Gummerson.\n\n**Resources**:\n\n- MetaCall Environment Scripts:\n- MetaCall Core Repository:\n[https://github.com/metacall/core](https://github.com/metacall/core) - Cross-compilation and Toolchain Documentation (GCC, Clang, MinGW, Android NDK)\n\n**Skills**: Zig, Systems Programming, C\n\n**Expected size of the project**: Small (90 hours)\n\n**Difficulty rating**: Medium\n\n**Description**:\n\nThe goal of this project is to create a new Port for MetaCall in Zig, allowing Zig programs to call and integrate other languages like JavaScript, Python, Ruby, and more. This project will require designing and implementing the Zig port from scratch, leveraging Zig's unique features such as comptime to simplify and improve the API's ergonomics for end users. This project will need to implement all supported types of MetaCall, also async APIs and different loading methodologies. Key aspects to be addressed:\n\n- Language Interoperability: Develop the necessary bindings and functionality to enable Zig to call functions from other supported MetaCall languages.\n- API Design: Use comptime to build a concise, ergonomic, and type-safe API that makes it easy for developers to integrate MetaCall into their Zig projects.\n- Build System: Ensure the port supports using an already installed version of MetaCall without requiring a full recompilation.\n- Testing and Documentation: Include extensive tests, documentation, and usage examples.\n- Memory Safety: Pay special attention to avoiding memory leaks and ensuring safe integration with Zig's memory model.\n\nAdditionally, the project should produce a basic tutorial or article showcasing the Zig port, providing examples of how it can be used to create polyglot applications.\n\n**Expected outcomes**:\n\n- A fully functional Zig port for MetaCall that supports calling multiple languages.\n- Comprehensive documentation, tests, and usage examples.\n- A tutorial or article demonstrating how developers can use the Zig port to build polyglot applications.\n\n**Possible mentors**: Thomas Rory Gummerson, Vicente Eduardo Ferrer Garcia, Fernando Vaño Garcia, Gil Arasa Verge.\n\n**Resources**:\n\n- Prior Work:\n[https://github.com/metacall/core/tree/5b592ac0e9a8e498e3e706623d0a788276f566e0/source/ports/zig_port](https://github.com/metacall/core/tree/5b592ac0e9a8e498e3e706623d0a788276f566e0/source/ports/zig_port) - MetaCall Core:\n[https://github.com/metacall/core](https://github.com/metacall/core) - Zig Documentation:\n[https://ziglang.org/documentation/master/](https://ziglang.org/documentation/master/)\n\nThe three chats are bridged by Matrix (messages sent from one, on the main room/channel, can be seen from all)."
  },
  {
    "name": "VideoLAN",
    "slug": "videolan",
    "tagline": "Open Source Multimedia for everyone!",
    "description": "The VideoLAN project is led by and composed of a team of volunteers who believe in the power of open source to rock the multimedia world. We produce multimedia software notably the famous VLC media player as well as designated libraries and codecs.",
    "ideas_url": "https://wiki.videolan.org/SoC_2026/",
    "website_url": "https://www.videolan.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "c++",
      "qt",
      "assembly",
      "video"
    ],
    "topic_tags": [
      "audio",
      "streaming",
      "video",
      "codecs",
      "media database"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/videolan",
    "ideas_content": "# SoC 2026\n\n[Jump to navigation](https://wiki.videolan.org#mw-head)\n\n[Jump to search](https://wiki.videolan.org#p-search)\n\nThis page gives the current list of ideas for VideoLAN project, for the [Google Summer Of Code 2026](https://summerofcode.withgoogle.com) program.\n\nThe list is long, but it is not exhaustive, and not limitative. Feel free to apply with **your own idea!**, we love original ideas and value them.\n\n## Contents\n\n[1 Introduction & Information](https://wiki.videolan.org#Introduction_.26_Information)[2 How to Start](https://wiki.videolan.org#How_to_Start)[3 Ideas for VLC & libVLC](https://wiki.videolan.org#Ideas_for_VLC_.26_libVLC)[3.1 Advanced Audio Filters](https://wiki.videolan.org#Advanced_Audio_Filters)[3.2 VLC Qt interface redesign](https://wiki.videolan.org#VLC_Qt_interface_redesign)[3.3 VLC Skins2 interface update](https://wiki.videolan.org#VLC_Skins2_interface_update)[3.4 VLC macOS interface redesign](https://wiki.videolan.org#VLC_macOS_interface_redesign)[3.5 VLC watchOS port](https://wiki.videolan.org#VLC_watchOS_port)[3.6 Add back netsync module](https://wiki.videolan.org#Add_back_netsync_module)[3.7 VLC iOS UI update](https://wiki.videolan.org#VLC_iOS_UI_update)[3.8 Android Medialibrary cache management](https://wiki.videolan.org#Android_Medialibrary_cache_management)[3.9 Qt integration tests](https://wiki.videolan.org#Qt_integration_tests)[3.10 Update the Lua integration](https://wiki.videolan.org#Update_the_Lua_integration)[3.11 Port the remote access webserver to VLC Desktop](https://wiki.videolan.org#Port_the_remote_access_webserver_to_VLC_Desktop)[3.12 demux Rust bindings and AVI module for VLC](https://wiki.videolan.org#demux_Rust_bindings_and_AVI_module_for_VLC)[3.13 integrate checkasm tooling and improve existing asm coverage](https://wiki.videolan.org#integrate_checkasm_tooling_and_improve_existing_asm_coverage)[3.14 Vulkan video filters: tonemapping and subtitles](https://wiki.videolan.org#Vulkan_video_filters:_tonemapping_and_subtitles)[3.15 Vulkan video filters: deinterlace, adjust and others](https://wiki.videolan.org#Vulkan_video_filters:_deinterlace.2C_adjust_and_others)[3.16 libvlc Wayland API](https://wiki.videolan.org#libvlc_Wayland_API)[3.17 Lua Declarative UI Framework for Extensions](https://wiki.videolan.org#Lua_Declarative_UI_Framework_for_Extensions)[3.18 Lua API HTTP bindings](https://wiki.videolan.org#Lua_API_HTTP_bindings)[3.19 Lua Script Test Harness](https://wiki.videolan.org#Lua_Script_Test_Harness)[3.20 Use vcpkg contribs](https://wiki.videolan.org#Use_vcpkg_contribs)\n\n[4 Ideas for VLC dependencies](https://wiki.videolan.org#Ideas_for_VLC_dependencies)[5 Other short ideas for VLC & libVLC](https://wiki.videolan.org#Other_short_ideas_for_VLC_.26_libVLC)[6 Ideas for VideoLAN infrastructure](https://wiki.videolan.org#Ideas_for_VideoLAN_infrastructure)[7 Ideas for dav1d and dav2d](https://wiki.videolan.org#Ideas_for_dav1d_and_dav2d)[8 Ideas for libplacebo](https://wiki.videolan.org#Ideas_for_libplacebo)\n\n## Introduction & Information\n\nThis page covers the [VideoLAN](https://wiki.videolan.org/VideoLAN/) program as a mentoring organization for [Google Summer of Code](http://code.google.com/soc/), in order to improve [VLC](https://wiki.videolan.org/VLC/), [VLMC](https://wiki.videolan.org/VLMC/) and [dav1d](https://code.videolan.org/videolan/dav1d) (or the [libVLC](https://wiki.videolan.org/LibVLC/) engine), but also the VideoLAN infrastructure and some other related projects.\n\nWe have projects in **C**, **C++**, **Rust**, **ASM**, **JS**, **Wasm**, **Go**, **Obj-C**, **GPU Shaders**, **C#**, **Java/Kotlin** and **Swift**.\n\n### Summer of Code\n\nGoogle Summer of Code is a way for anyone to work on open source projects and become top developers, while being paid by Google.\n\n[VideoLAN](https://wiki.videolan.org/VideoLAN/) was a *Google Summer of Code* mentoring organization in [2007](https://wiki.videolan.org/SoC_2007/), [2008](https://wiki.videolan.org/SoC_2008/), [2009](https://wiki.videolan.org/SoC_2009/), [2010](https://wiki.videolan.org/SoC_2010/), [2011](https://wiki.videolan.org/SoC_2011/), [2013](https://wiki.videolan.org/SoC_2013/), [2016](https://wiki.videolan.org/SoC_2016/), [2017](https://wiki.videolan.org/SoC_2017/), [2018](https://wiki.videolan.org/SoC_2018/), [2019](https://wiki.videolan.org/SoC_2019/), [2020](https://wiki.videolan.org/SoC_2020/), [2021](https://wiki.videolan.org/SoC_2021/), [2022](https://wiki.videolan.org/SoC_2022/), [2023](https://wiki.videolan.org/SoC_2023/), [2024](https://wiki.videolan.org/SoC_2024/) and [2025](https://wiki.videolan.org/SoC_2025/).\n\nThis page lists some ideas for Summer of Code projects on **dav1d**, **dav2d**, **libVLC** and [VLC media player](https://wiki.videolan.org/VLC_media_player/), but also on *VLC infrastructure* projects.\n\nWe accept ideas also on other multimedia projects related to [VLC media player](https://wiki.videolan.org/VLC_media_player/).\n\n### VLC & libVLC\n\n[VLC media player](https://wiki.videolan.org/VLC_media_player/) is a cross-platform multimedia player, encoder and streamer application. It is one of the most successful open-source projects worldwide.\n\n[VLC media player](https://wiki.videolan.org/VLC_media_player/) is downloaded at an approximate monthly rate of 25 millions from the main website and that's not including third-party distributions (Linux)!\n\nYou can find more information on [VLC on Wikipedia](http://en.wikipedia.org/wiki/VLC_media_player) or on this [wiki](https://wiki.videolan.org/Main_Page/).\n\nThe engine of VLC is **libVLC**, and is used by **VLMC** and mobile versions of VLC.\n\n### dav1d / dav2d\n\n**dav1d** is the reference AV1 decoder that is shipped inside VLC, Chrome, Edge, Firefox, Windows and macOS/iOS.\n\n**dav2d** is the reference AV2 decoder that is all new.\n\nThose are very low-level codec, mostly written in C and assembly.\n\n### Summer of Code rules\n\nIf selected and developed, SoC projects for dav1d and VLC will be included in later releases.\n\nAll projects are covered by the GPL (v2+) or LGPL (v2.1+) licenses depending on the module. Projects on dav1d and dav2d are BSD licensed.\n\nThe VideoLAN [Code of Conducts](https://wiki.videolan.org/CoC/) applies to all Summer projects.\n\n## How to Start\n\n### Find an idea\n\nFirst, you need to find an idea.\n\nThis current page gives you a list of ideas. Those ideas are **NOT exhaustive**: you can bring your own idea! Some of the best ideas we've ever had were **custom** ideas!\n\nThe duration of the projects is indicative, and can be adapted, if needed.\n\n**TALK** to the team to get more ideas.\n\n### Submit your idea\n\nYou need to submit your idea on the *Google Summer of Code* platform.\n\nYou should do so, very quickly, even before having finished compilation and the next steps, so that we can give you early feedback.\n\n### Compile VLC or libVLC\n\nThis may sound trivial, but it's harder than many expect. You must compile the project you want to work on.\n\nSee [https://wiki.videolan.org/Category:Building/](https://wiki.videolan.org/Category:Building/) for more informations.\n\nYou should come on [IRC](https://wiki.videolan.org/IRC/) to get help to compile.\n\n### Provide a small patch\n\nTo demonstrate your skills, share a small patch with us. This will let you become familiar with [Git](https://wiki.videolan.org/Git/), in case you don't know it already and our process on [our gitlab](https://code.videolan.org).\n\n### Let's get in touch\n\nIf you have a doubt, are not sure about anything or want clarification, please get in touch with us.\n\nWe have 3 major communication channels:\n\n- Our\n[mailing-lists](https://mailman.videolan.org/mailman/listinfo)to discuss patches and further development related topics; - Furthermore, we have our\n[web forums](http://forum.videolan.org)for VLC-related end-user support - a VLMC section will be created once the product is published. - Finally, there is our IRC channel\n*#videolan*(for libVLC) and*#vlmc*on the*libera*network. It's open to any kind of discussion. Usage issues, questions how to compile VLC/VLMC, getting to know the fellow developers, etc.\n\n# Ideas for VLC & libVLC\n\n## Advanced Audio Filters\n\n**Project Description**:\nWe are looking for a skilled audiophile that knows a lot about audio theory and practice to work on new audio filters for VLC.\n\n**Duration**: 350h\n\n**Tasks to do**:\n\n- SRS WoW like or other 3D effects;\n- channels mixing, notably upmixing, like Prologic-II;\n- tracks mixing, and transitions;\n- scriptable new audio filters in lua and enable users to create whatever audio filtering function they want in a Lua script;\n- LADSPA or other libraries integration.\n\n**Requirements**:\nThis project needs some good audio knowledge and good C experience.\n\n**Qualification task:**\nPort any audio filter from MPlayer\n\n*Proposed mentor: unidan *\n\n## VLC Qt interface redesign\n\n**Project Description**:\nThe VLC interface is quite outdated on Linux and Windows. It has a lot of features, but some are not properly exposed.\n\nWe are currently reworking the interface, but we need help.\n\n**Duration**: 350h\n\n**Scope of the tasks to do**:\n\nUse the new designs shared on the mailing list, and help developping part of those, using **Qml**.\n\nThis new interface is simpler, more user friendly, and has a better \"media center\" feel into it.\n\nIt requires integration with the media library and with the current interface.\n\nQml is the technology needed to improve the current UI.\n\n**Requirements**:\nThis project requires **Qt/C++** knowledge, and qml would be a nice plus.\n\n*Proposed mentor: Pierre*\n\n## VLC Skins2 interface update\n\n**Project Description**:\nThe VLC Skins2 interface was not updated for the latest interface and core changes for the media player and playlist engine yet.\n\nWe are currently reworking the interface, but we need help. Fixing the Winamp skins compatibilities would be nice.\n\n**Duration**: 350h\n\n**Scope of the tasks to do**:\n\n- wayland integration\n- video integration rework (like Qt interface)\n- medialibrary integration\n\n**Requirements**:\nThis project requires **Qt/C++** knowledge, and qml would be a nice plus.\n\n*Proposed mentor: Pierre*\n\n## VLC macOS interface redesign\n\n**Project Description**:\nThe VLC interface is quite outdated on macOS and we are currently in the process of re-writing it to give it a modern feel, but also to integrate recent additions to libvlc regarding playback control and library management.\n\nThis project for the summer is to rework heavily this interface to make it beautiful and useful again.\n\n**Duration**: 350h or 175h\n\n**Scope of the tasks to do**:\n\nThere is a full design already done and tested.\n\nThe major hurdle is to actually implement it the way we want it to be. The iOS/tvOS interface is simpler, more user friendly, and has a better \"media center\" feel into it, which influenced what we want to achieve on the Mac. Note that the objective is to use AppKit. UIKit will not be part of this project.\n\nIterating from the current UI and closely collaborating with the team currently working on it is a requirement.\n\n**Requirements**:\nThis project requires **Obj-C** knowledge, a thorough understanding of OOP and proven previous Mac development experience. You cannot use swift for this project.\n\n*Proposed mentor: David Fuhrmann, Felix Paul Kühne*\n\n## VLC watchOS port\n\n**Project Description**:\nVLCKit recently added support for playback of audio files on watchOS with support for http streams coming in a future update. The idea is to create a new, standalone app for watchOS that can play local files on device with a good way to synchronize those either from a computer or the app on the companion iPhone. The UI development needs to be done in SwiftUI following the restrictions of the platform.\n\n**Duration**: 350h\n\n*Proposed mentor: Diogo Simao Marques, Felix Paul Kühne*\n\n## Add back netsync module\n\n**Project Description**:\nUse the new vlc clock to add back the netsync module\n\n**Duration**: 350h\n\n**Scope of the tasks to do**:\n\n- Use a new network protocol: RTP Midi\n- Expose some vlc_clock APIs to be used by \"control\" module\n- Plug the vlc_clock API inside the new module\n\n**Requirements**:\nVery good C knowledge\n\n*Proposed mentor: Thomas Guillem*\n\n## VLC iOS UI update\n\n**Project Description**:\nWe're currently in the process of rewriting and updating the entire UI for VLC iOS\n\nThere is a lot of components that need refactoring and need to get an updated UI.\n\nThe Android port of VLC has done most of that and was successful. We need the same level of features.\n\n**Duration**: 350h or 175h\n\n**Tasks to do**:\n\n- Get an overview of the current App and components that need an update\n- Refactor and give the appropriate components a new look\n- See what is missing compared to the Android version\n- Code it :\n\n**Requirements**:\nThis project requires **Obj-C** and **Swift** knowledge and ideally knowledge of writing tests for iOS but this can be learned.\n\n*Proposed mentor: Felix Paul Kühne, Diogo Simao Marques *\n\n## Android Medialibrary cache management\n\n**Description:**\nfor upcoming features, the Android port (first and then all the ports) will need a medialibrary caching mechanism. [https://code.videolan.org/videolan/medialibrary/-/issues/293](https://code.videolan.org/videolan/medialibrary/-/issues/293)\n\nUsing the new libvlc HTTP client, the medialibrary should be able to download a media, save its download state in the DB and expose all the needed APIs to the ports.\n\n**Duration**: 350h\n\n**Tasks to do:**\n- Write the full API\n- Download/delete local files\n- Persist the state in the DB\n- Send the download events\nRequirements: This projects requires C++ and SQL knownledge. Java/JNI knowledge can help to (but can be learned)\n\nProposed mentor: Alaric Senat, Nicolas Pomepuy\n\n## Qt integration tests\n\n**Project Description**:\nIn order to improve the robustness of our application, we would like to develop integration tests for the Qt interfac.e The goal being to ensure that new features and refactors won't break other parts of the UI.\n\n**Duration**: 350h or 175h\n\n**Scope of the Tasks to do**:\n\n- study existing solutions used in other open-source projects (\n[https://invent.kde.org/sdk/selenium-webdriver-at-spi](https://invent.kde.org/sdk/selenium-webdriver-at-spi)) - adapt test framework to our environment\n- write sample test cases\n- study CI integration feasibility (Linux and/or Windows tests)\n\n**Requirements**:\nThis project requires Qt/C++ and some scripting language (pyhton?) knowledge, Qml would be a nice plus.\n\n*Proposed mentor: Pierre*\n\n## Update the Lua integration\n\n**Project description**:\nThe current extension implementation in Lua needs more love to make them first class citizen (they are currently loaded by GUI instead of the core).\n\n**Duration**: 350h\n\n**Tasks to do**:\n\n- update libvlccore to load Lua extensions instead of the GUI\n- work on a better descriptive abstraction for lua stream parsers extensions which needs to extract data from the webpage. (currently done by manual read())\n- more testing infrastructure for the scripts\n\n**Requirements**:\n\n- Lua and C knowledge, c++ is a plus\n\n**Proposed mentor**: Alexandre Janniaux\n\n## Port the remote access webserver to VLC Desktop\n\n**Description**:\nTo remotely access and control a VLC instance, a webserver has been developped for VLC Android. The goal is to port it to VLC desktop.\n\n**Duration**: 350h\n\n**Tasks to do**:\n\n- Extract the web client code from the VLC for Android reprository to a dedicated one\n- Write the server part in VLC desktop using lua scripts\n- Adapt the client to be compatible with the new VLC desktop web server\n\n**Requirements**:\n\n- js, Vue, lua, websockets\n\n**Proposed mentor**: Nicolas\n\n## demux Rust bindings and AVI module for VLC\n\nVLC has already its first Rust (logger) module: [https://code.videolan.org/videolan/vlc/-/commit/e8e46b0d915d153a58d002c9d6f19a7dbdfeeca9](https://code.videolan.org/videolan/vlc/-/commit/e8e46b0d915d153a58d002c9d6f19a7dbdfeeca9)\n\nThere was a proposal to add several Rust bindings and example: [https://code.videolan.org/videolan/vlc/-/merge_requests/2738](https://code.videolan.org/videolan/vlc/-/merge_requests/2738)\n\nTasks\n\n- Adapt demux API Rust bindings to upstream VLC\n- Add a new AVI demux module to test the new bindings (Using the nom crate:\n[https://crates.io/crates/nom/](https://crates.io/crates/nom/))\n\n**Duration**: 350h\n\n**Requirements**: Good C knowledge and very good Rust knowledge\n\n**Proposed mentors**: Thomas Guillem and Alexandre Janniaux\n\n## integrate checkasm tooling and improve existing asm coverage\n\n**Description**:\nVLC has some amount of existing assembly (yadif, video chroma) but we lack test coverage for it and also could use more for newer architectures\n\n**Tasks to do**:\n\n- Integrate checkasm for validation (against a C baseline) and benchmarking (similarly to what's done in dav1d)\n- Convert the existing assembly to use it\n- Add new optimizations for things like audio/video format conversions, filters and also for newer arch's (riscv etc.)\n\n**Duration**: 175h or 350h\n\n**Proposed mentors**: Marvin Scholz, Nathan Egge, Tristan Matthews\n\n## Vulkan video filters: tonemapping and subtitles\n\n**Description**:\n\nVLC has a work-in-progress Vulkan video output (branch), but it is missing features that already exist in the OpenGL output. This project focuses on integrating libplacebo tonemapping and implementing subtitle rendering through the Vulkan pipeline.\n\n**Duration**: 350h\n\n**Tasks to do**:\n\n- libplacebo tonemapping: use the libplacebo API to generate Vulkan shaders for HDR tonemapping, and integrate them into VLC's Vulkan rendering pipeline;\n- subtitles handling: implement a Vulkan subtitle renderer (texture upload, blending, render pass integration), based on the existing OpenGL implementation.\n\nRequirements: This project requires good C knowledge, good Vulkan knowledge, and familiarity with graphics pipelines. OpenGL experience is a plus for reading the reference implementation.\n\n**Proposed mentors**: Thomas Guillem\n\n## Vulkan video filters: deinterlace, adjust and others\n\n**Description**:\nContinuing the work on VLC's Vulkan video output (branch), this project ports the remaining video filters from the OpenGL output to Vulkan. This includes the deinterlace filter and adjust-style filters (brightness, contrast, saturation, etc.).\n\n**Duration**: 350h\n\n**Tasks to do**:\n\n- deinterlace filter: port the existing deinterlace filter to Vulkan, using Vulkan compute or fragment shaders for multi-field temporal processing;\n- adjust and other video filters: port adjust (brightness, contrast, saturation, gamma) and other video filters to Vulkan shaders;\n- all existing OpenGL video filters should be ported.\n\nRequirements: This project requires good C knowledge, good Vulkan and OpenGL knowledge, and experience writing GPU shaders (GLSL/SPIR-V).\n\n**Proposed mentors**: Thomas Guillem\n\n## libvlc Wayland API\n\nIn order to allow easy integration of VLC video rendering into application that uses Wayland, similarly to what we provide for X11 or HWND.\n\n**Duration**: 175h\n\n**Scope of the Tasks to do**:\n\n- Provide a method to expose external Wayland surface and additional mechanisms to libvlc.\n\n- Write a sample application to illustrate how to use the API\n\n**Requirements**: This project requires some good C experience\n\n**Proposed mentor**: Pierre Lamot\n\n## Lua Declarative UI Framework for Extensions\n\n**Project Description**:\n\nThe current dialog API available to Lua extensions is limited to a small set of widgets (labels, buttons, text inputs, checkboxes, dropdowns, lists) placed on a fixed grid, making it difficult to build rich extension interfaces.\n\nWe want to replace this with a modern declarative UI model inspired by SwiftUI and Jetpack Compose, where the extension describes its interface as a function of state and the framework handles rendering and updates.\n\n**Duration**: 350h\n\n**Scope of the tasks to do**:\n\nThe project involves designing a new vlc.ui Lua module where extensions declare their interface using nested widget constructor calls that return a description table rather than imperatively creating widgets one by one. A reactive state primitive (vlc.ui.state()) should use Lua metatables to track writes and mark the UI as dirty for re-rendering.\n\nOn the C side, a bridge in modules/lua/libs/ui.c will walk the Lua widget tree, diff it against the previous tree, and emit create/update/remove operations toward a platform renderer. The initial renderer target is the Qt/QML interface, mapping abstract widgets (column, row, text, button, text_field, toggle, slider, dropdown, list, image, progress) to their QML equivalents. The framework should support layout containers with spacing, alignment and flexible sizing, a small set of semantic styles (title, body, caption, primary, destructive) rather than raw values, and efficient list rendering with a row template function.\n\nThe old vlc.dialog API must remain functional for backward compatibility. Porting one or two existing extensions to the new API will serve as validation.\n\n**Requirements**:\n\nThis project requires strong **C** knowledge for the bridge and tree diffing\nlogic, familiarity with **Lua** and its C API for the module implementation,\nand some experience\n\nwith **Qt/QML** for the renderer side. Understanding of reactive UI paradigms\n(SwiftUI, Compose, React) is strongly recommended.\n\n\n*Proposed mentor: 'Alexandre Janniaux (espresso)'*\n\n## Lua API HTTP bindings\n\n**Project Description**:\nTo make interacting with REST APIs in Lua easier and support other HTTP verbs than just GET, we need bindings\nfrom the VLC HTTP library to our Lua script API.\n\nThis projects goal is to add a simple Lua API to do HTTP GET, POST and HEAD requests and possibly some more abstract service API, depending on project duration.\n\n**Duration**: 350h or 175h\n\n**Scope of the tasks to do**:\n\nVLC already has a mostly complete HTTP API that is able to do HTTP(s) requests and handle the reply. The main task for this GSoC will involve around how to expose this very low level API in a ergonomic and easy to use fashion as Lua APIs for our Lua scripts to use. Abstract around the session handling and cookie handling and provide ways to properly construct a HTTP request from Lua, with custom HTTP headers, if desired, and a way to fetch the reply status, headers, and read the body content.\n\nSome minor changes to the VLC HTTP library might be necessary in some cases.\n\n**Requirements**:\nThis project requires strong **C** and **Lua** API knowledge, a thorough understanding of how Lua bindings and the HTTP protocol works.\n\n*Proposed mentor: Marvin Scholz, Alexandre Janniaux*\n\n## Lua Script Test Harness\n\n**Project Description**:\n\nVLC and the community ship Lua scripts (playlist parsers, service discovery, extensions, art fetchers) but has no way to test them outside of a running VLC instance. When a website changes its markup, the corresponding playlist parser breaks silently and the problem is only discovered through user bug reports.\n\nWe want a lightweight test harness that can load and exercise VLC Lua scripts against fixture data without requiring a VLC build at all.\n\n**Duration**: 175h or 350h\n\n**Scope of the tasks to do**:\n\nThe core idea is to build a standalone binary that embeds a Lua interpreter, registers the same `vlc.*` module tables that VLC exposes to scripts, but backs them with mock implementations instead of real VLC core calls.\n\nA recording mode where a patched VLC session captures real HTTP responses as fixture files would make it easy to turn bug reports into reproductible regression tests for lua writers.\n\nThe deliverable is a test runner that can be use to start the different scripts,\nlike: vlc-lua-mock --mode=playlist --input [http://playlist.url/foo.m3u8](http://playlist.url/foo.m3u8) playlist.lua\nand support extensions, and provide a \"mock\" framework to lua to be able to run\nunittests as well.\n\n**Requirements**: This project requires C or Rust knowledge for refactoring,\ncompiling and linking against VLC's Lua binding sources and writing mock\nbackends, and some **Lua** knowledge for the test framework, fixture engine,\nand writing the actual tests.\n\nFamiliarity with test frameworks and test methodology is a plus.\n\n*Proposed mentor: 'Alexandre Janniaux (espresso)'*\n\n## Use vcpkg contribs\n\n**Project Description**:\nVLC depends on 130 contrib packages that are external libraries used by VLC and its modules.\nA lot of these packages are also available in package systems like vcpkg. This could be an alternative way\nto build VLC by using common packages. This would allow more native builds of VLC, especially on Windows\n(ie without relying on a POSIX shell).\n\nThe meson build system is capable of using vcpkg packages although it's not the default mode of vcpkg.\n\nThis projects goal is to add support for as many packages as possible in the vcpkg system to match the existing contribs.\n\n**Duration**: 350h or 175h\n\n**Scope of the tasks to do**:\n\nThe main task will be to add package dependencies in vcpkg for all the platforms we support and then adapting the patches found in contribs to the same packages found in vcpkg. This should be usable from our meson build system.\n\n**Requirements**:\nThis project requires knownledge of **meson**, **make** and **CMake** and package dependencies.\n\n*Proposed mentor: Steve Lhomme, Marvin Scholz*\n\n# Ideas for VLC dependencies\n\n## Cloud integration for desktop\n\n**Project Description**:\nWe want to be able to access Cloud Storage services (Dropbox, Google Drive and so on) in the VLC application.\n\n**Duration**: 350h or 175h\n\n**Scope of the Tasks to do**:\n\n- revive libcloudstorage\n- integrate libcloudstorage inside VLC\n- write sample test cases\n\n**Requirements**:\nThis project requires C++ knowledge.\n\n*Proposed mentor: Pierre*\n\n## Improve libnoidea and integrate in VLC\n\n**Project description**:\nImprove the libnoidea project supporting the NDI protocol to support more formats.\n\n**Duration**: 350h\n\n**Tasks to do**:\n\n- Study the NDI protocol, notably more recent versions, and implement and test and integrate inside VLC.\n\n**Requirements**:\n\n- NDI understanding\n- C knowledge.\n\n**Proposed mentor**: j-b\n\n## libmicrodns refactoring\n\nOur current mDNS discoverer is working, but is not so respectful of the RFC. Possible improvements include:\n\n- Device TTL support\n- Device removal detection\n- Better request pacing\n- Delegate socket interactions to the caller\n- Unit testing\n- Fuzzing\n\n**Requirements**: This project require **C** knowledge, as well as system programming skills\n\n**Duration**: 175h\n\n*Proposed mentor*: tguillem\n\n## libspatialaudio acceleration\n\nOur current libspatialaudio is working, but we need it to become faster\n\nWork to be done\n\n- Plug checkasm\n- Profile functions\n- Write x86 or ARM assembly to make it faster\n- Test\n- Repeat\n\n**Requirements**: This project require **C** knowledge, as well as system programming skills\n\n**Duration**: 175h\n\n*Proposed mentor*: tguillem\n\n## Improve the LibVLCSharp developer experience and ecosystem\n\nlibVLCSharp provides .NET bindings for libVLC and enables building cross-platform media applications in C#.\n\nThis GSoC project aims to improve the developer experience around LibVLCSharp by providing better documentation, practical UI samples, improved NuGet packaging, and stronger automated testing and CI.\n\nWork to be done\n\n- Audit and improve existing documentation and API guides\n- Write developer-focused tutorials and usage examples\n- Provide modern sample applications (WPF, WinUI/MAUI or cross-platform UI)\n- Improve NuGet packaging and versioning\n- Enhance CI to automatically build, test, and publish packages\n- Add unit and integration tests for playback scenarios\n- Improve overall project structure and contributor onboarding\n\n**Requirements**: This project requires C# and .NET knowledge. Familiarity with cross-platform development, CI systems, and multimedia concepts is a plus.\n\n**Duration**: 175h\n\n*Proposed mentor*: Martin\n\n## Improve the VLC for Unity developer experience and ecosystem\n\nVLC for Unity is the native Unity plugin that bridges LibVLCSharp with LibVLC for performance oriented video rendering in Unity3D applications and games.\n\nWork to be done\n\n- macOS universal build support: Add automated macOS universal (Intel + Apple Silicon) builds to ensure seamless compatibility and distribution across all modern Mac hardware.\n- Build cool demos and prototypes: Develop polished demo projects and prototypes that showcase real-world use cases such as streaming, in-game cutscenes, and immersive/360° playback to accelerate adoption.\n- tvOS / Linux support: Extend the plugin to tvOS and Linux with tested native builds and documented setup steps to broaden platform coverage.\n- Deeper Unity Editor integration: Implement VLC configuration tools inside the Unity Editor to simplify setup.\n- CI and automated testing improvements: Introduce automated tests to prevent regressions, and maintain reliability across all supported platforms.\n\n**Requirements**: This project requires C# and Unity knowledge. Familiarity with cross-platform development, CI systems, and multimedia concepts is a plus.\n\n**Duration**: 175h\n\n*Proposed mentor*: Martin\n\n# Other short ideas for VLC & libVLC\n\nThose ideas are not detailed, but they are ideas that we could help to spring new ideas. We can help work with you to make those more detailed.\n\nThose ideas should be **175h** long\n\n- Improve id3 tag and metadata handling in VLC\n- Bridge module for GMI'C or other video filters\n- Automated Testing Environment like ffmpeg Fate (port ?) for demuxing, non-hw decoding\n- Integrate libavfilter in VLC\n- Provide setups for popular streaming services / sout templates (ui ?)\n- Improve cue support in VLC\n\n# Ideas for VideoLAN infrastructure\n\n## Improve the VideoLAN crash reporter in Go and Vue.js\n\nThe idea is to improve the current crash reporter of VLC, called [CrashDragon](https://code.videolan.org/videolan/CrashDragon).\n\nThe tasks are the following:\n\n- Review the current code\n- Improve the API in Go\n- Write a new Vue.js frontend\n\nThose will be done in **Go** and **JS**\n\n**Duration**: 350h\n\n*Proposed mentor: David and j-b*\n\n# Ideas for dav1d and dav2d\n\n## dav1d RISC-V optimizations\n\nImproving the performance of the AV1 decoder is very important for VLC and the whole ecosystem.\n\nIt requires to:\n\n- Understand of RISC-V assembly\n- Understand a bit what a video decoder is\n- Write RISC-V functions\n\n**Requirements**: This project requires **C** and **ASM** knowledge, as well as system programming skills\n\n**Duration**: 175h\n\nContact 'j-b'\n\n\n\n## dav2d RISC-V optimizations\n\nImproving the performance of the AV2 decoder is very important for VLC and the whole ecosystem.\n\nIt requires to:\n\n- Understand of RISC-V assembly\n- Understand a bit what a video decoder is\n- Write RISC-V functions\n\n**Requirements**: This project requires **C** and **ASM** knowledge, as well as system programming skills\n\n**Duration**: 175h\n\nContact 'j-b'\n\n\n\n## dav2d ARM optimizations\n\nImproving the performance of the AV2 decoder is very important for VLC and the whole ecosystem.\n\nThis is less complex than what it seems!\n\nIt requires to:\n\n- Understand of ARM assembly\n- Understand a bit what a video decoder is\n- Write ARM functions\n\n**Requirements**: This project requires **C** and **ASM** knowledge, as well as system programming skills\n\n**Duration**: 175h\n\nContact 'j-b'\n\n## dav1d statistics extractions\n\nThe [dav1d](https://code.videolan.org/videolan/dav1d) AV1 decoder is a new high performance AV1 decoder by\nVideoLAN.\n\nCurrent open source tools for AV1 analysis use instrumentation in the reference decoder [libaom](https://aomedia.googlesource.com/aom) to extract decode-time metadata for display and reporting, but support for sophisticated analysis is lacking.\n\nTo speed development of AV1 tools like the rav1e, it would be helpful to add similar decoder metadata extraction APIs to the dav1d decoder so that rapid testing of encoder algorithms is easier. This includes the ability to quickly produce statistics, visualizations and other reporting that can be used for tuning encoder parameters or guiding development. Advanced ideas include adding similar encoder metadata API to rav1e that add encode-time visualizations.\n\n**Requirements**: This project requires **C** knowledge.\n\n**Duration**: 175h\n\nContact 'unlord'\n\n# Ideas for libplacebo\n\n## Direct3D 11 backend\n\n**Project Description:**\n\nlibplacebo uses a GPU abstraction with a number of backends. The goal would be to add a new backend based on Direct3D 11, since Vulkan and OpenGL support on Windows are often of limited quality, especially for older hardware.\n\nLots of example code for how this implementation would look can be found [as part of the mpv project ](https://github.com/mpv-player/mpv/blob/master/video/out/d3d11/ra_d3d11.c).\n\nLarge parts can be copy/pasted and adapted to the libplacebo API.\n\n**Tasks to do:**\n\n- Add a new `pl_gpu` backend based on Direct3D 11\n- Integration into the build system, test framework and CI infrastructure\n\n**Requirements:**\n\n- Knowledge of\n**C**as well as, ideally, graphics API fundamentals. (But the latter can be learned as part of the project) - Ability to develop and test on Windows\n\n**Duration**: 175h\n\nContact 'haasn'\n\n## Dolby Vision Profile 5 (IPT-PQ)\n\n**Project Description:**\n\nDolby IPT-PQ is a HDR color space similar to ITU-R ICtCp, but with proprietary Dolby modifications (reshaping algorithm). Your goal is to implement this reshaper in the form of a GLSL shader, using knowledge from known Dolby patents and dumped headers.\n\n**Tasks to do:**\n\n- Figure out, and (if necessary) reverse engineer the stream format for the Dolby reshaping algorithm described in several of their patents.\n- Implement this algorithm in GLSL\n- Integration into libplacebo (optional)\n- Test against reference implementations of Dolby Vision profile 5\n\n**Requirements:**\n\n- Knowledge of\n**GLSL**and**C**. Knowledge of colorspaces in general is an obvious plus, but the theory here is not important - only the implementation. - (Possibly) Ability to reverse engineer any still-unknown or differing-from-patents parts of the stream headers.\n\nKnowledge of libplacebo internals is not required, since the skeleton code for this already exists - what's missing is the reshaping algorithm.\n\n**Duration**: 350h\n\nContact 'haasn'\n\n## GPU motion interpolation (mvtools)\n\n**Project Description**\n\nYour goal is to develop GPU shaders for motion-adaptive frame interpolation in the style of [mvtools]([https://github.com/dubhater/vapoursynth-mvtools](https://github.com/dubhater/vapoursynth-mvtools)).\n\nThis is an open-ended project. If not completed, any progress towards this goal is good enough.\n\n**Sub-goals:**\n\n- Recreate the motion vector search algorithms from MAnalyze\n- Implement the pixel masking and pixel flow algorithms from MFlowFps\n\nThese can be tackled and complete out-of-order.\n\n**Requirements:**\n\n- Good knowledge of both C and GLSL, especially compute shaders and other GPGPU techniques. (CUDA or OpenCL skills also transfer, though the shader will have to be GLSL)\n- Ideally, general knowledge of video processing techniques (e.g. motion vector search) - at least enough to be able to understand what mvtools code is doing.\n\n**Duration**: 350h\n\nContact 'haasn'\n\n\n\n\n\n|\n|"
  },
  {
    "name": "dora-rs",
    "slug": "dora-rs-tb",
    "tagline": "Simplify robotic apps with AI",
    "description": "DORA (Dataflow-Oriented Robotic Architecture) is middleware designed to streamline and simplify the creation of AI-based robotic applications. It offers low latency, composable, and distributed dataflow capabilities. Applications are modeled as directed graphs, also referred to as pipelines.",
    "ideas_url": "https://github.com/dora-rs/dora/wiki/GSoC_2026",
    "website_url": "https://dora-rs.ai",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "ros",
      "c++",
      "rust"
    ],
    "topic_tags": [
      "middleware",
      "Embodied AI",
      "Python Robotics",
      "Autonomous Drive",
      "Robot Dataflow"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/dora-rs-tb",
    "ideas_content": "Dora is a dataflow-based, low-latency middleware designed to revolutionize the development of robotic applications. In the field of robotics, where efficiency and speed are crucial, Dora stands out by supporting multiple programming languages, including Python, Rust, C, and C++. This multi-language support enables developers from diverse backgrounds to contribute and innovate.\n\nThe following is a list of projects suggested for GSoC 2026. These projects aim to further expand Dora's capabilities, enhance its usability, and contribute to the growth of the global robotics community.\n\n# Project #1: Testing & Simulation Infrastructure\n\n# Theme 3: AI Developer Experience & Tooling\n\n**Action:** Provide a rich set of pre-built nodes and tools tailored for AI development.\n\n**Details:** Accelerate the development of AI applications by providing ready-made components and insights.\n\n**Why:** Developers shouldn't have to reinvent the wheel for common AI tasks like inference or data preprocessing.\n\n**What:** A suite of AI-focused tools and nodes.\n\n**How:**\n\n1. **Optimized Inference Nodes:** Create and maintain nodes for popular inference runtimes (e.g., dora-onnx, dora-tensorrt, dora-tflite).\n\n2. **Data-Centric Tooling:** Enhance dora-record and dora-replay to facilitate the creation of high-quality datasets for model training and fine-tuning from real-world robot data.\n\n3. **Performance Tooling:** Enhance dora stats and dora inspect to provide detailed AI-specific metrics, such as inference latency, GPU utilization, and memory usage per node.\n\n**Description**\nThe lack of a formal testing strategy beyond unit tests is a major gap for a robotics framework. This project aims to provide developers with the visibility, control, and isolation needed to effectively test and debug DORA dataflows. A robust testing infrastructure is essential for building reliable robotic applications.\n\n**Expected Outcomes**\n* **Creating `dora-test-utils` library** with mock implementations for DORA APIs (`send`, `receive`, `subscribe`, state management) to enable isolated unit testing with standard frameworks (pytest, cargo test).\n* **Implementing scenario-based integration testing** leveraging the `dora-record`/`dora-replay` workflow for regression testing.\n* **Developing programmatic control APIs** in Python and Rust SDKs to programmatically load, start, stop, pause, resume dataflows, inject data, observe outputs, and inspect state from test scripts.\n* **Creating specialized test harness nodes** including `dora-test-source` (emit test data), `dora-test-sink` (capture output for assertions), and `dora-assertion-node` (in-dataflow assertions).\n* **Building debugging probe nodes** including `dora-print-node`, `dora-save-node`, `dora-throttle-node`, and `dora-breakpoint-node` for runtime debugging.\n* **Writing comprehensive documentation** with examples demonstrating testing patterns and best practices.\n\n**Resources**. <br>\nhttps://github.com/dora-rs/dora <br>\n\n**Skills required/preferred**. Rust, Python, Testing frameworks, DORA\n\n**Difficulty rating**.   medium\n\n**Expected size:**  350h\n\n\n# Project #2: Package & Dependency Management\n\n**Description**\nThe current `node-hub` approach will not scale as a simple folder and leads to dependency conflicts. This project addresses the critical need for robust package and dependency management to foster a thriving, multi-language DORA ecosystem, ensuring reproducibility, discoverability, and security.\n\n**Expected Outcomes**\n* **Formalizing DORA Node Package Specification** with a language-agnostic `Dora.toml` or `dora-node.yaml` defining name, version, language, entrypoint, dependencies, capabilities, and checksum or within `Cargo.toml` or `pyproject.toml`.\n* **Designing a centralized node registry** with HTTP/HTTPS server storing node metadata and packaged artifacts, authentication for publishing, and search/discovery API.\n* **Enhancing `dora build`** to parse dataflows, resolve dependencies (local cache then registry), compile Rust/C/C++ nodes, prepare isolated Python environments, and generate lock files (`dora-lock.yml`).\n* **Implementing `dora publish` and `dora install` commands** for publishing and fetching nodes from the registry.\n* **Implementing runtime isolation** with dedicated Python `venv` per node and proper RPATH/LD_LIBRARY_PATH handling for compiled nodes.\n* **Adding security mechanisms** including cryptographic signatures for packages and vulnerability scanning integration.\n* **Writing comprehensive documentation** covering package creation, publishing, and consumption workflows.\n\n**Resources**. <br>\nhttps://github.com/dora-rs/dora <br>\nhttps://doc.rust-lang.org/cargo/ <br>\n\n**Skills required/preferred**. Rust, Python, Package management, DORA\n\n**Difficulty rating**.   hard\n\n**Expected size:**  350h\n\n\n# Project #3: Distributed State Management\n\n**Description**\nDORA is primarily stateless, which limits its applicability for many robotics tasks like SLAM that require persistent state. This project implements a distributed state store for the daemon, eliminating it as a single point of failure and enabling more complex robotic applications.\n\n**Expected Outcomes**\n* **Integrating a distributed state backend** using either `DataFusion` `openraft` (pure-Rust Raft implementation) with `sled` key-value store.\n* **Implementing daemon cluster formation** where multiple `dora-daemon` instances replicate state using Raft consensus.\n* **Refactoring daemon to be stateless** by redesigning it to rely entirely on the distributed store for persistent state, watching for desired state changes and reconciling with actual state.\n* **Defining and exposing state schema** formalizing the schema for control plane state (dataflow definitions, runtime status, daemon health) with clear APIs.\n* **Implementing node-level state APIs** including `node.get_state()` and `node.set_state()` for application-level persistent state.\n* **Creating failover tests** demonstrating daemon high availability and state consistency.\n* **Writing documentation** covering cluster setup and state management patterns.\n\n**Resources**. <br>\nhttps://github.com/dora-rs/dora <br>\nhttps://github.com/datafuselabs/openraft <br>\n\n**Skills required/preferred**. Rust, Distributed systems, Consensus algorithms, DORA\n\n**Difficulty rating**.   hard\n\n**Expected size:**  350h\n\n\n# Project #4: dora-studio: GUI for dataflow management\n\n**Description**\nTo build a truly modern and accessible ecosystem, DORA needs to move beyond a CLI-only interface. This project creates a unified interface that seamlessly integrates a visual dataflow editor with an interactive operations console, providing a single pane of glass for the entire application lifecycle.\n\n**Expected Outcomes**\n* **Exposing a public control plane API** by documenting and exposing the coordinator's gRPC services as a stable, versioned API with gRPC-Web proxy for browser access.\n* **Developing the \"Operate\" view** with an interactive console for deploying, monitoring, and controlling running dataflows including live topic inspection, node lifecycle control, and OpenTelemetry trace visualization.\n* **Developing the \"Design\" view** with a drag-and-drop canvas for visually building, configuring, and saving DORA dataflows with node library browser.\n* **Implementing real-time updates** using WebSocket or Server-Sent Events for live dataflow status and metrics.\n* **Publishing JavaScript/TypeScript SDK** for the control plane API to enable third-party tooling.\n* **Creating user documentation** with tutorials for using the web platform.\n\n**Resources**. <br>\nhttps://github.com/dora-rs/dora-studio <br>\nhttps://opentelemetry.io/ <br>\n\n**Skills required/preferred**. rust, DORA\n\n**Difficulty rating**.   hard\n\n**Expected size:**  350h\n\n# Project #4: Refactor Getting Started Documentation\n\n **Description**\nCurrently the getting started is demonstrating only a limited amount of the capabilities of dora-rs but it could be great to showcases additional features. \n\n**Resources**. <br>\nhttps://dora-rs.ai<br>\nhttps://github.com/dora-rs/dora<br>\nhttps://github.com/dora-rs/dora-hub <br>\n\n**Skills required/preferred**. rust, DORA\n\n**Difficulty rating**.   Medium\n\n**Expected size:**  100h\n\n\n# Project #5: Clean up unused features from dora-rs\n\n**Description**\nCurrently within dora-rs, we implemented some experimental features that is not used any longer and it could be great if someone could help us refactor dora-rs.\n\n**Skills required/preferred**. rust, DORA\n\n**Difficulty rating**.   Medium\n\n**Expected size:**  100h"
  },
  {
    "name": "FOSSology",
    "slug": "fossology",
    "tagline": "Open Source License Compliance by OSS",
    "description": "FOSSology is an open source license compliance software system and toolkit. As a toolkit you can run license, copyright and export control scans from the command line. As a system, a database and web UI are provided to give you a compliance workflow. License, copyright and export scanners are tools used in the workflow.",
    "ideas_url": "https://github.com/fossology/fossology/discussions/3267",
    "website_url": "https://fossology.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "postgresql",
      "c/c++",
      "go",
      "php"
    ],
    "topic_tags": [
      "automation",
      "spdx",
      "license compliance",
      "nlp",
      "compliance automation"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/fossology",
    "ideas_content": "# Google Summer of Code 2026 application #3267\n\n[shaheemazmalmmd](https://github.com/shaheemazmalmmd)started this conversation in\n\n[Ideas](https://github.com/fossology/fossology/discussions/categories/ideas)\n\n-\n\n|\nHello all! FOSSology as an org is planning to apply for Since 2022, there are some changes made by Google in the program. You can read more about it on - Three sized projects are acceptable by program:\n- Small sized projects (~90 hour)\n- Medium sized projects (~175 hours)\n- Large projects (~350 hours)\n- The program is open to 18 years and older people.\n- No longer limited to college students only.\n- Flexible time lines between 12 and 22 weeks.\nAlso, starting this year, 2026, Google has strong advice about the usage of Generative AI in the GSoC program. Please check them at: **For Mentoring Orgs:**[Usage of AI tooling in Google Summer of Code 2026 (for Mentoring Orgs)](https://docs.google.com/document/d/1jglptdn_DovOxjwuhzORn3QhYoeBcToS7ymk3IIWHKY/edit?usp=sharing)**For Contributors:**[Guidance for GSoC Contributors using AI tooling in GSoC 2026 doc](https://docs.google.com/document/d/1t9GcIBnNXPNO6klRQvU8pL8-uV6afzLo6JUAM299suA/edit?usp=sharing)\nBased on the suggestions from Google, FOSSology has following guidelines for GSoC contributors: -\n**Usage of AI in proposal writing:**The proposal writing is a core part of the GSoC program and it should never be offloaded to the AI completely. This is the place where you would most probably meet the organization for the first time and show your creativity, so use this space wisely.- Generative AI usage is allowed, but to do tasks like formatting, rearranging, etc.\n- Usage of Generative AI is strictly prohibited for creating the proposal idea itself (includes the end goal, the approach) and proposal will be penalized if such usage found.\n-\n**Usage of AI in coding:**We have seen in previous contributions that people do not install FOSSology at all while they are working on their contributions. If you cannot see the tool, if you cannot test your changes, how can you validate the changes you have done are correct. It then becomes the responsibility of the maintainer to do a thorough testing, always, which takes more time than for the person contributing the changes. AI also does not know everything. Even if you are using coding agents to help you, but you cannot provide them the right input, their output will only be garbage.- For you first few PR, we require you to provide evidence of FOSSology installation by providing information like FOSSology version, screenshot/example output from the changes.\n- Taking help from AI is fine, but completely relying on it is not good for the project and for you.\n- Take suggestions from the AI, but always understand changes before pushing them. If you cannot understand the code generated, do not push it.\n- If you are pushing the code, you are responsible for it, it does not matter a human wrote it or an AI. Thus, take your contributions seriously. We like to work with humans more than machines.\n- If the code changes are not clear and without any human explanation, the maintainers hold the rights to close the PR without further explanation.\n-\n**Acceptance criteria:**FOSSology previously did not have defined acceptance criteria, in order to keep the application process open and accessible to everyone. However, over the past year, this approach resulted in a large number of proposals that became difficult to manage effectively. Therefore, starting this year, we are introducing the following criteria that proposals/contributor must meet in order to be considered:- There should be at least one contribution with significant enough changes (simple typo fix for example do not qualify).\n- If you could not have created a PR, you should at least had communicated with one of the Org member and they should vouch for you.\n- Prior to final submission of proposal, applicants must have their proposal draft reviewed by an Org member.\nPlease feel free to drop any questions here (or start a new discussion) you have regarding the program, you want to submit a proposal idea, you want to be mentor in the program, etc. While submitting a project idea, please tag it to be \"Medium\" or \"Large\" sized and who you'll prefer working on it \"student\" or \"professional\". [https://google.github.io/gsocguides/mentor/defining-a-project-ideas-list](https://google.github.io/gsocguides/mentor/defining-a-project-ideas-list)[https://google.github.io/gsocguides/mentor/making-your-ideas-page](https://google.github.io/gsocguides/mentor/making-your-ideas-page)[https://google.github.io/gsocguides/student/](https://google.github.io/gsocguides/student/)[https://opensource.googleblog.com/2024/10/celebrating-20-years-google-summer-of-code-nurturing-next-generation-contributors.html](https://opensource.googleblog.com/2024/10/celebrating-20-years-google-summer-of-code-nurturing-next-generation-contributors.html)\nYou can also check the detailed documentation of previous students from Here is the list of the people who would be volunteering as mentors & org-admins for GSoC-2026. [@EttingerK](https://github.com/EttingerK)(OrgAdmin)[@shaheemazmalmmd](https://github.com/shaheemazmalmmd)(OrgAdmin)[@GMishx](https://github.com/GMishx)(OrgAdmin)[@Kaushl2208](https://github.com/Kaushl2208)(Mentor)[@hastagAB](https://github.com/hastagAB)(Mentor)[@avinal](https://github.com/avinal)(Mentor)[@its-sushant](https://github.com/its-sushant)(Mentor)[@JanAltenberg](https://github.com/JanAltenberg)(Mentor)[@sjha2048](https://github.com/sjha2048)(Mentor)[@soham4abc](https://github.com/soham4abc)(Mentor)\nWant to mentor this GSoC-2026? Please contact OrgAdmins. |\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n## Replies: 13 comments 13 replies\n\n-\n\n|\nSome useful links for contributors who Are first time here : - Basic workflow -\n[https://www.youtube.com/watch?v=TZqU5ZALI7U](https://www.youtube.com/watch?v=TZqU5ZALI7U) - Installation -\n[https://github.com/fossology/fossology/wiki/Install-from-Source](https://github.com/fossology/fossology/wiki/Install-from-Source) - Good first issues -\n[https://github.com/fossology/fossology/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22](https://github.com/fossology/fossology/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22) - Slack channel -\n[https://fossology.slack.com/](https://fossology.slack.com/)\n|\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n-\n\n## Idea!## Title: Enhancing Nirjas & Atarashi for Accurate, Scalable License Intelligence## Goal: Improve license detection modal of Atarashi, create a new model in Nirjas to classify comments and integrate it to Atarashi.Open-source compliance tools rely heavily on accurate extraction and identification of license information embedded within source code. As software ecosystems grow and diversity, traditional rule-based and heuristic-driven approaches struggle with noisy inputs, partial license texts, modified headers, and non-standard comment formats. - Nirjas focuses on extracting comments from source code across multiple programming languages.\n- Atarashi performs license identification using Machine Learning techniques using extracted text against known license data.\nWhile both tools are effective, their current architectures leave room for improvement in accuracy, scalability, and intelligence. This proposal aims to introduce machine learning–driven classification, improved language support, and structured inference logic to significantly enhance license detection quality. -\nChallenges in Current Nirjas Workflow - All extracted comments are treated equally, regardless of whether they are actual license text, developer comments, or unrelated documentation.\n- License files (e.g., LICENSE, COPYING) represent an edge case and are not consistently handled alongside source comments.\n- Support for newer or less common programming languages is limited, reducing coverage.\n- This results in noisy downstream inputs and unnecessary computation in license identification stages.\n-\nChallenges in Current Atarashi Workflow - License identification is performed on the entire file content, including irrelevant or misleading text.\n- There is no structured classification of license families or prioritization when multiple licenses are detected.\n- Ambiguous or partial license texts are not handled with explicit confidence-based decision logic.\n- These issues lead to false positives, ambiguous results, and reduced trust in automated conclusions.\n-\nProposed Improvements to Nirjas\n-\nMachine Learning–Based Comment Classification - A dedicated machine learning model will be designed and integrated into Nirjas to intelligently classify extracted comments.\n- Valid license-related comments\n- Non-license source code comments\n- Noise (e.g., TODOs, documentation blocks, metadata)\n-\nExpanded Programming Language Support - Nirjas will be extended to support additional programming languages that are currently not handled.\n- Modular comment-extraction rules to allow easy onboarding of new languages.\n- Special handling for license file edge cases, where the entire file may represent license text rather than comments.\n- Unified abstraction to normalize comment outputs across languages.\n- Proposed Improvements to Atarashi\n-\nComment-Driven License Identification - Instead of analyzing the full file content, Atarashi will:\n- Consume only license-relevant comments extracted and classified by Nirjas.\n- Ignore irrelevant or noisy text blocks.\n- This shifts Atarashi from a brute-force comparison approach to a signal-driven inference pipeline.\n-\nLicense Family & Priority Classification - Classify detected licenses into license families (e.g., GPL, MIT, Apache).\n- Assign license priority based on:\n- Existing license identifications\n- Known compatibility rules\n- Project-level conclusions\n-\nML-Based License Identification Using Minerva Dataset - A machine learning classification model will be trained using the Minerva license dataset.\n- Classify arbitrary license text into known license labels.\n- Input:\n- Arbitrary license text snippets\n- Full license texts\n- Partial or truncated headers\n- Commented or reformatted versions\n- Slightly modified license language\n- Output:\n- One or more license labels with associated confidence scores\n- OR an explicit UNKNOWN classification\n|\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n-\n\n## Idea!## Title: Report Aggregation for Compliance## Goal: A new project \"Report Aggregation for Compliance\" which shall be integrated with FOSSology & SW360 if needed to ease and manage multiple reports.With the introduction of regulations such as the Today, compliance artifacts are often generated as multiple independent reports for example: - ReadMeOSS\n- SPDX 2.3\n- SPDX 3.0\n- CycloneDX / CLIXML\nThese reports are produced at different stages, by different tools, and for different scopes. Manually managing and reconciling them is time-consuming. -\nCurrent Challenges - Compliance data is fragmented across multiple reports\n- No easy way to merge, track, or evolve combined reports\n- Any update in a single report requires manual rework\n- This creates friction for compliance teams and increases regulatory risk.\n-\nProposed Solution: - Introduce a Report Aggregator Tool that enables organizations to combine multiple compliance reports into a single, authoritative report, while preserving traceability and editability. (Many reports in → One aggregated, report out)\n- Allow users to merge N number of reports into a single consolidated report\n- Support common formats listed above\n- Transparent Aggregation View (UI)\n- Clearly show which reports are merged\n- Display the source and contribution of each report\n- Allow users to inspect merged data at a high level\n- Users should be able to edit or correct information in the aggregated report\n- Changes should be traceable to maintain accountability\n- Incremental Updates & Change Propagation\n- If a source report changes, the system should:\n- Detect the update\n- Allow seamless incorporation into the aggregated report\n- Avoid rebuilding reports from scratch\n- If a source report changes, the system should:\n-\nEcosystem Integration - Integration with FOSSology\n- Aggregate outputs from multiple uploads or projects into one report.\n- Integration with SW360\n- Align aggregated reports with component and project metadata.\n- Integration with FOSSology\n|\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n-\n\n## Idea!## Title: Enhanced Reuse Agent for Intelligent License Reuse## Goal: Create a new agent once all the agents are finished scanning in FOSSology to draw statistics, analyze type of change in files, load diff tree view, show risks etc..-\nSmart Reuse of Cleared Components - Reusing previously cleared components is a powerful feature, but the current workflow places the burden on the user to manually search and select matches.\n- Introduce a Smart Reuse / Suggested Matches mechanism\n- System automatically searches for previously cleared components that closely match the current upload\n- Suggested reuse options are presented proactively to the user\n-\nEnhanced Reuse agent - Introduce an Enhanced Reuse Agent that runs automatically when the user selects the reuse option, providing clear, actionable insight into differences between previously cleared components and their newer versions.\n- The agent automatically compares the previously cleared version (v1) with the new version (v2) - New Diff tree view.\n- Show number of licenses detected (Histogram) in v1 vs v2\n- Highlight whether new licenses were introduced or existing ones changed (in different colors)\n- Draw statistics (% of new licenses added compared to scanner findings in old upload)\n- Number of lines changed Whether changes affect comments or license-relevant sections (per-file in New Diff tree view) / file itself is new.\n- Provide a focused view of Especially changes within comments or source code.\n- User shall have a option to decide all the files based upon source code change/ decide all new files with adding license text.\n-\nUI & REST-Level Transparency - What changed\n- Where it changed\n- Statistics and all the implemented features from Enhanced Reuse Agent\n|\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n-\n\n## Idea!## Title: Decoupling Copyright, Email, URL/Author from current Scanner## Goal: Separate out copyright,email,url, author information from copyright scanner to individual scanners.Currently, copyright, email, URL, and author extraction are triggered together, despite serving different purposes and having different levels of importance. - Observed Reality:\n- Clearing experts heavily rely on copyright information\n- Email, URL, and author data are used less frequently and mainly for specific investigations\n- Proposed Change:\n- Split the existing combined agent into:\n- A dedicated Copyright Agent (enabled by default)\n- Separate Metadata Agents (Email / URL / Author), enabled only when needed\n|\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n-\n\n## Idea!## Title: New Hybrid View creation & Re-grouping of FOSSology’s Agent Topology## Goal: To create new hybrid view (Licenses + Copyrights) for both tree view and single file view and also re-group the related agents.Over time, FOSSology has evolved into a powerful platform with multiple specialized agents such as Nomos, Monk, Ojo, License Deciders, and others. While this provides flexibility, it also introduces overhead for users, especially clearing experts and newcomers, who must understand which agent to run for basic license detection. This proposal introduces a user-centric abstraction layer that simplifies license scanning workflows while preserving the power and configurability of existing agents under the hood and also ease the clearing expert's time on navigation & reviewing multiple tabs. -\nUnified License Detection Abstraction - Users see a single primary action: License Detection, License Detection with Auto Deciders.\n- The system internally orchestrates relevant agents based on best practices\n- Users are no longer required to understand or select individual license agents\n- License Detection with Auto Deciders. shall have a shatter to understand which Auto Deciders are selected. and these shall be configurable via user's pages.\n-\nHybrid view (Licenses + Copyrights) - The single file view shall also contain license and copyright evidence. and user can clean/add/update these.\n- Have a folder tree with blue & red buttons to indicate the clearing.\n- Integrate drag and drop functionality to copy the clearing decisions from one file to another.\n- Have a histogram feature to accommodate license groups in the current upload.\n- Have a file view page with highlights of all the findings (licenses + copyrights + keywords + ECC).\n- Create a new READMEOSS format with (License associated with copyrights)\n- All the features shall be implemented to access via REST API as well.\n## Refer the basic design structure of the page.\n|\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n-\n\n## Idea!## Title: FOSSology & LicenseDb UX and UI design## Goal: Redesign the FOSSology & LicenseDb UX and UI to modernize its interface and enhance user-friendliness.## Understand the Primary Users**Identify user personas**: Determine who the key users of FOSSology are, such as developers, compliance officers, or open-source contributors.**Analyze pain points**: Conduct surveys, interviews, or user studies to understand the challenges users face while using the current system.\n## Analyze the Current Interface**Evaluate usability issues**: Identify areas where the current interface is difficult to use or navigate.**Highlight outdated design elements**: Assess visual components and workflows that no longer align with modern design standards or user expectations.\n## Identify Redesign Requirements**Define goals**: Establish clear objectives for the redesign, such as improving efficiency, accessibility, or ease of use.**Prioritize features**: Focus on addressing critical pain points and implementing high-impact improvements.\n## Design Reusable Components**Catalog interface elements**: List existing components and determine which can be updated or replaced.**Ensure consistency**: Create reusable design components to maintain a cohesive user experience and simplify scalability.\n## Draft Layouts and Workflows**Streamline user journeys**: Map out key workflows to reduce complexity and improve navigation.**Prototype layouts**: Create wireframes or mockups to visualize potential improvements and gather early feedback.\n## Establish a Cohesive Design System**Define visual guidelines**: Standardize elements such as colors, typography, and spacing for a unified aesthetic.**Componentize the UI**: Build a library of modular components for easier development and maintenance.\n## Gather Feedback and Refine**Conduct usability testing**: Engage users to validate the new designs and identify areas for improvement.**Iterate based on feedback**: Refine layouts, workflows, and components to ensure the redesign meets user needs effectively.\n**Contact: |\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n-\n\n## Idea!## Title: Rewrite FOSSology UI using NextJS## Goal: Rewrite FOSSologyUI using NextJS- Existing\n[code](https://github.com/fossology/fossologyUI)is old. in the last years GSoC some part of work has been changed to accommodate the new design. - One shall adopt to the changes made last year and carryforward the rest of the design.\n- Implementation of new API'S to existing code if needed.\n- Implementation designed templates.\n|\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n-\n\n## Idea!## Title: Improve CycloneDX support and update CycloneDX exports to spec version 1.7## Goal: Update and extend the existing CycloneDX report generation## Reasoning: To make use of the overlap between license compliance and cybersecurity requirements it would help many users to improve CycloneDX report generation- Identifiy and address gaps in the currenty implementation (currently license texts and copyright notices seem to be missing)\n- Identify and address requirements from other tools, so exports can easily be reused\n- Update to spec version 1.7 (Currently spec version 1.4 is supported)\n- Support importing CycloneDX documents\n|\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n-\n\n## Idea!## Title: Autonomous Tool Intelligence Assistant leveraging Agentic AIThe goal of this project is to design and develop an The system is expected to reduce the cognitive and operational burden on maintainers, improve user experience during setup and usage, and create a sustainable mechanism for consolidating and evolving project knowledge over time. ## Problem StatementAs open-source projects grow, knowledge becomes increasingly fragmented and difficult to manage. Critical information is spread across: - Documentation (wikis, Markdown, reStructuredText)\n- Issue trackers and pull requests\n- Source code and implementation details\nThis fragmentation leads to several recurring challenges: - New users struggle with onboarding and setup, often encountering known issues\n- Contributors find it difficult to understand feature behavior and code structure\n- Maintainers repeatedly answer similar questions and triage duplicate issues\n- Documentation becomes outdated or inconsistent with the codebase\nWhile recent LLM-based chatbots can retrieve answers from documentation, they are largely ## Proposed SolutionWe propose building an Instead of a single conversational bot, the system should be designed as a The assistant should be able to: - Guide users through onboarding and common workflows\n- Identify and recommend solutions for frequently occurring setup and usage problems\n- Help developers and contributors navigate project features and their implementation\n- Continuously improve and curate project knowledge\n## What We Want to Achieve## 1. Improved User Onboarding- Enable new users to understand features and workflows through guided, interactive assistance\n- Reduce setup failures by proactively identifying known configuration or environment issues\n- Provide context-aware recommendations based on project version and usage scenario\n## 2. Faster and More Reliable Problem Resolution- Surface known issues and solutions from historical discussions\n- Reduce time spent manually searching through documentation and issue trackers\n- Decrease duplicate issue creation by directing users to existing resolutions\n## 3. Better Developer and Contributor Experience- Make it easier to explore and understand the project without deep prior knowledge\n- Connect high-level features to relevant parts of the codebase and documentation\n- Lower the entry barrier for new contributors\n## 4. Sustainable Knowledge Consolidation- Identify gaps, inconsistencies, or outdated information in documentation\n- Encourage continuous improvement of project knowledge\n- Ensure that insights gained from user interactions and issues are not lost\n## Scope and ExpectationsThe project is expected to focus on Some aspects, such as deep code reasoning or fully automated documentation updates, may be exploratory. However, the overall design and development should be done with these future extensions in mind. ## Why This Matters NowOpen-source projects are growing in scale and complexity faster than their support and maintenance capacity. At the same time, recent advances in large language models and agentic systems make it feasible to move beyond static documentation and reactive chatbots. This is the right moment to explore an - Users increasingly expect interactive, context-aware help rather than manual documentation search\n- Maintainers face burnout due to repetitive support and issue triage tasks\n- Knowledge loss occurs when insights from issues and discussions are not systematically consolidated\n- Agentic AI enables systems that can reason, adapt, and improve over time rather than merely retrieve answers\nBy addressing these challenges now, the project can proactively shape how AI is responsibly integrated into open-source maintenance workflows, instead of retrofitting solutions later. ## Benefits for the Community## For Users- Faster onboarding and reduced frustration during setup and early usage\n- Easier access to accurate, up-to-date information\n- A more approachable and interactive support experience\n## For Contributors- Lower barrier to entry when understanding project structure and behavior\n- Reduced dependency on maintainers for basic guidance\n- Clearer pathways to becoming productive contributors\n## For Maintainers- Fewer duplicate issues and repetitive support questions\n- Better visibility into common user pain points\n- A scalable support model as the community grows\n## Long-Term Community Impact- Improved project sustainability and maintainability\n- Stronger contributor retention through better onboarding\n- A reusable blueprint for applying agentic AI responsibly in open-source ecosystems\n## Skills Needed**Programming:**Python**Machine Learning:**Knowledge of LLMs, Agentic Behaviour, RAG**Data Engineering:**Knowledge base creation and retrieval**Documentation Standards:**Familiarity with reStructuredText, Markdown, and related formats\n|\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n-\n\n|\nThe core problem was that FOSSology, running in a Docker container, only sees the internal HTTP connection. By respecting the |\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n-\n\n## Idea!## Title: Integrate licenselynx to FOSSology & LicenseDb## Goal: To have a alias names of each license stored in fossology & licenseDb- In Current implementation of FOSSology, agents create licenses even though they are alias of some existing license. Idea is to extend the agents to accommodate alias names and do not create duplicates.\n- Integrate licenselynx(\n[https://github.com/licenselynx/licenselynx](https://github.com/licenselynx/licenselynx)) project to FOSSology & LicenseDb to get the alias names and store it in the database. - Fix the remining issues in\n[feat(spdx-expression): License Expression Support #2771](https://github.com/fossology/fossology/pull/2771)and add identifications to known expressions in nomos agent.\n|\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n-\n\n## Idea!## Title: Archiving in FOSSology## Goal: Add a feature to the Maintenance Agent to archive upload data and regenerate the associated information when needed.- To have a archiving feature where user can select at least one year's data to be archived from UI using maintenance agent.\n- Agent creates a schema file of that one years records (Upload, decision and file information) and Its related files from file system.\n- Agent Creates a downloadable Zip file with all the data.\n- If the user wants to reimport. The zip file shall be used as a source to do the reimport again to FOSSology.\n|\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)"
  },
  {
    "name": "preCICE",
    "slug": "precice",
    "tagline": "The coupling library for multi-physics simulations",
    "description": "preCICE is an open-source coupling library and ecosystem for general partitioned multi-physics and multi-scale simulations, including surface and volume coupling.\n\nPartitioned means that preCICE couples existing programs/solvers capable of simulating a subpart of the complete physics involved in a simulation. This allows for the high flexibility that is needed to keep a decent time-to-solution for complex coupled problems.\n\nThe software offers convenient methods for transient equation coupling, communication, time interpolation, and data mapping.",
    "ideas_url": "https://precice.org/community-contribute-open-projects.html",
    "website_url": "https://precice.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "python",
      "shell",
      "c++"
    ],
    "topic_tags": [
      "scientific computing",
      "simulation"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/precice",
    "ideas_content": "## Context\n\nIn case you skipped the [home page](https://precice.org/index.html),\npreCICE is a *coupling library* for **numerical simulations** (think meshes, iterative solution, FEM, CFD)\nand an *ecosystem* of related components.\nScientists take independent numerical simulation codes and make them work together on a more complex simulation,\nwhich none of the individual codes could do alone.\nFor this, they use one of the many *adapters* (think plugins for various simulation codes), or directly the core library.\nWhile the latter is written in **C++**, more languages are relevant (**Python, Julia, Matlab, C, Fortran, and Rust**).\npreCICE is primarily used on **Linux** systems, with a growing user-base on macOS and Windows.\n\nMost of the preCICE development has been happening in a university context,\nand student projects have played a vital role: Just look at the [list of contributors](https://precice.org/community-contributors.html).\nWe are working on [GitHub](https://github.com/precice/), and we accept contributions by everyone.\nWe review pull requests trying to improve their quality together and bring them in line with the current project needs,\nwhich can sometimes be a long but rewarding experience.\nIn the university context, we also closely mentor students,\nwe encourage participation in team events such as our coding days,\nand several students have so far participated in workshops, conferences, and publications, or even done their PhD in the team.\n\nIf you want to contribute with a student project (typically a thesis), see the [university groups behind preCICE](https://precice.org/about.html).\nThis page highlights a few specific projects that are not directly suitable for a thesis ([thesis-suitable issues in the core library](https://github.com/precice/precice/issues?q=is%3Aissue%20state%3Aopen%20label%3Athesis)), but are also a bit more than a [good first issue](https://github.com/precice/precice/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22good%20first%20issue%22).\nSome of these projects we advertise publicly, in programs such as the Google Summer of Code.\n\n**Tip:**Are you looking for or offering a thesis / PhD / other related job? Have a look also at\n\n[our forum](https://precice.discourse.group/c/jobs/13).\n\n## Google Summer of Code\n\nThe [Google Summer of Code](https://summerofcode.withgoogle.com/) is *“a global, online program focused on bringing new contributors into open source software development. GSoC Contributors work with an open source organization on a 12+ week programming project under the guidance of mentors.”*.\n\nFor 2026, we have prepared the following topics, for different sets of skills.\nSince this is our first year, and since we are a rather small project, we might not be able to accommodate applicants to all of these projects.\nBefore applying, introduce yourself in the [forum](https://precice.discourse.group/c/jobs/gsoc/15) and let us know more about your background and motivation:\n\n- What motivates you spend this summer in GSoC instead of doing anything else?\n- What interests you most about our project?\n- Will you have any other commitments (e.g., work or study) while working on the project?\n- What previous experience do you have with the respective technologies?\n- What previous experience with Git and GitHub do you have, if any?\n\nAdditionally, show us what you have tried already (see “entry test” in each project and feel free to go beyond that), to support your application. If you have contributed anything to any preCICE repository, definitely mention this here.\n\nWe will contact you via replies and/or private messages in the forum, to find out together if these topics are a good fit. You can alternatively ask quick questions in the [Matrix chat](https://matrix.to/#/#precice_lobby:gitter.im?web-instance[element.io]=app.gitter.im). Don’t miss the [guidelines](https://precice.org#general-guidelines) at the bottom of this page.\n\n### Project: Website modernization\n\nThis website is built with [Jekyll](https://jekyllrb.com/),\na straight-forward static site generator that has served us well,\nbut now starts to feel a bit restrictive\n([GitHub repository](https://github.com/precice/precice.github.io), [documentation]docs-meta-overview.html)).\nWe envy the dark theme, the nice footer that showcases contributions, and the nice search engine support\nwhen we look at the documentation of other community projects, such as [GitLab](https://docs.gitlab.com/user/) or [Docker](https://docs.docker.com/get-started/).\nWe also required some hacky jekyll plugins to integrate multiple repositories into one jekyll website, which are a bit error-prone.\nOur technology stack is also a bit outdated:\nFor example, the front-end is using [Bootstrap](https://getbootstrap.com/docs/) 3.3.7, with some custom CSS on top.\nWe have done some [preliminary work](https://github.com/orgs/precice/projects/22/views/1) porting to hugo,\nbut web development is not what we are good at.\nAs a first step, we would like to [upgrade to a newer Bootstrap version](https://github.com/precice/precice.github.io/issues/691).\nAfter that, we would like to switch to the [Hugo static site generator](https://gohugo.io/),\naiming to have a framework that we can upgrade and maintain with minimal effort.\n\n**Entry test:** To figure out if this is for you, try [building the website locally](https://github.com/precice/precice.github.io/blob/master/README.md)\nand adding and styling some new element in the [landing page](https://github.com/precice/precice.github.io/blob/master/content/index.html).\nBe creative!\n\n- Skills required: Web development (Jekyll/Hugo + CSS, JS)\n- Project size: Medium (175h)\n- Difficulty: Easy/Intermediate - Requires upgrading the front-end framework and porting existing content from one framework and stack to another, but will be driven primarily by you on the “how”.\n- Mentors:\n[Frédéric Simonis](https://github.com/fsimonis)and[Gerasimos Chourdakis](https://github.com/MakisH)\n\n### Project: System tests improvements\n\nWhile the core library has several unit and integration tests,\nsome issues only show up when running complete simulations.\nFor this reason, preCICE has [system tests](https://precice.org/dev-docs-system-tests.html),\nwhich choose and install components from the ecosystem in Docker containers,\nrun complete simulations, and compare the numerical results against references.\nThese tests are integrated into the [GitHub Actions](https://docs.github.com/en/actions) CI infrastructure of preCICE.\nWhile the system tests are already running every night and on many pull requests, several improvements are possible ([related issues](https://github.com/precice/tutorials/issues?q=is%3Aissue%20state%3Aopen%20label%3Asystemtests)):\nrunning (much) faster test cases, running multiple test cases in parallel, better communicating what went wrong, integrating more repositories, and the list of possibilities goes on.\n\n**Entry test:** To figure out if this is for you, [run the system tests locally](https://precice.org/dev-docs-system-tests.html#running-specific-test-suites) and [add one more tutorial to the tests](https://precice.org/dev-docs-system-tests.html#adding-tutorials).\n\n- Skills required: Python, Docker, GitHub Actions\n- Project size: Medium (175h) - Depending on the availability, small or large are also possible\n- Difficulty: Intermediate - Requires combining multiple technologies and has an impact in multiple repositories, but includes mostly small and clear work packages.\n- Mentors:\n[Gerasimos Chourdakis](https://github.com/MakisH)- Fallback:[Frédéric Simonis](https://github.com/fsimonis)\n\n### Project: Error messages with configuration context\n\nThe core library needs a [preCICE configuration file](https://precice.org/configuration-overview.html),\nwhich currently needs to be written manually (we are working on higher-level configuration tools as well).\nWhen one configures something wrong, preCICE throws an error message with details and recommendations (think git).\nIn this project, we want to attach context to these error messages,\nreferring to specific lines in the configuration file\n(similarly to how a compiler would refer to code lines with errors):\nsee the [related issue](https://github.com/precice/precice/issues/751).\n\n**Entry test:** To figure out if this is for you, try [building preCICE from source](https://precice.org/installation-source-preparation.html),\nrunning the [elastic tube 1D tutorial](https://precice.org/tutorials-elastic-tube-1d.html),\nand modifying the [configuration file](https://github.com/precice/tutorials/blob/master/elastic-tube-1d/precice-config.xml)\nto trigger an error (e.g., remove one of the `<data>`\n\ntags).\nThen, locate and modify the error message in the source code, to provide more information.\n\n- Skills required: C++\n- Project size: Small (90h)\n- Difficulty: Intermediate - Requires significant modifications to the C++ codebase, but with limited impact to/from other work.\n- Mentors:\n[Frédéric Simonis](https://github.com/fsimonis)- Fallback:[Benjamin Uekermann](https://github.com/uekerman)\n\n### Project: Clean multi-step configuration\n\nThe core library parses its [configuration file](https://precice.org/configuration-overview.html) using the [libxml2 library](https://gitlab.gnome.org/GNOME/libxml2/-/wikis/home).\nThe way this currently works is a bit rigid and the configuration of objects is directly tied to this parsing.\nInstead, we could do this in multiple stages, introducing an additional abstract syntax tree, which we could then use as a layer for additional checks,\nor to parse the configuration in a predefined order.\nIn this project, we want to refactor the configuration code to introduce a confguration AST (structured types), generated from the XML AST (nested tags and their attributes) built with libxml2.\nSee the [related issue](https://github.com/precice/precice/issues/982).\n\n**Entry test:** To figure out if this is for you, try the same as in the [project idea above](https://precice.org#project-error-messages-with-configuration-context).\n\n- Skills required: C++\n- Project size: Medium (175h)\n- Difficulty: Intermediate/Hard - Requires refactoring or modifying large parts of the C++ codebase, but with limited impact to/from other work.\n- Mentors:\n[Frédéric Simonis](https://github.com/fsimonis)- Fallback:[Benjamin Uekermann](https://github.com/uekerman)\n\n## General guidelines\n\n- Be creative, be proactive, and make your project your own.\n- When writing (e.g., a pull request description), think of writing to colleagues with the same questions as you when you started.\n- We welcome all kinds of modern tools for assisting with code development, but we do value the human factor: we want to see your work, in your own words, and we trust that you understand what you contribute. No need to impress, we are happy to help understand every concept together!"
  },
  {
    "name": "The FreeBSD Project",
    "slug": "the-freebsd-project",
    "tagline": "An OS for servers to embedded devices",
    "description": "FreeBSD is an operating system renowned for its advanced networking capabilities, robust security features, and exceptional performance. It is used across a wide spectrum of computing environments, ranging from the most heavily trafficked websites to desktop computers and embedded devices. Our source code is the foundation for well-known products such as the Sony PlayStation, Junos (the operating system powering Juniper routers), and elements of Apple's macOS. Additionally, FreeBSD runs on servers at Netflix that stream terabits of video content every second.\n\nThe FreeBSD Project has a rich history spanning over 30 years, originating in 1993 but rooted in work from the Berkeley Computer Systems Research Group dating back to 1978.  Over the years, our codebase has undergone continuous development and played an important role in developing essential software components used by numerous open-source projects. Examples include bsnmp, jemalloc, libarchive, and OpenPAM.\n\nFreeBSD maintains an active mentoring program to welcome new developers into our vibrant community. With approximately 300 developers with write access to our repositories and numerous other contributors, our community thrives on collaboration and shared expertise. Many of our past Google Summer of Code contributors have transitioned into becoming key members of the FreeBSD development team.\n\nCommunication within the FreeBSD community occurs through various channels, including mailing lists, forums, blogs, IRC channels, and user groups, all listed on our main website.",
    "ideas_url": "https://wiki.freebsd.org/SummerOfCodeIdeas",
    "website_url": "https://www.freebsd.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "llvm",
      "assembly",
      "make",
      "POSIX shell"
    ],
    "topic_tags": [
      "virtualization",
      "operating system",
      "Embedded System"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/the-freebsd-project",
    "ideas_content": "# Making sure you're not a bot!\n\nLoading...\n\nYou are seeing this because the administrator of this website has set up Anubis to protect the server against the scourge of AI companies aggressively scraping websites. This can and does cause downtime for the websites, which makes their resources inaccessible for everyone.\n\nAnubis is a compromise. Anubis uses a Proof-of-Work scheme in the vein of Hashcash, a proposed proof-of-work scheme for reducing email spam. The idea is that at individual scales the additional load is ignorable, but at mass scraper levels it adds up and makes scraping much more expensive.\n\nUltimately, this is a placeholder solution so that more time can be spent on fingerprinting and identifying headless browsers (EG: via how they do font rendering) so that the challenge proof of work page doesn't need to be presented to users that are much more likely to be legitimate.\n\nPlease note that Anubis requires the use of modern JavaScript features that plugins like JShelter will disable. Please disable JShelter or other such plugins for this domain."
  },
  {
    "name": "DeepChem",
    "slug": "deepchem",
    "tagline": "Democratize AI for drug discovery.",
    "description": "We democratize access to AI tools for drug discovery and other scientific applications of deep learning more broadly. We also maintain a collection of scientific datasets for benchmarking and building new deep learning architectures along with an extensive open source collection of scientific machine learning tutorials. DeepChem has a strong educational component and partners with a broad range of academic and governmental institutions.",
    "ideas_url": "https://github.com/deepchem/deepchem/discussions/4703",
    "website_url": "https://www.deepchem.io",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "numpy",
      "pytorch",
      "HuggingFace"
    ],
    "topic_tags": [
      "artificial intelligence",
      "chemistry",
      "biology",
      "materials science",
      "Drug Discovery"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/deepchem",
    "ideas_content": "-\n\n|\nWe have a lot of newcomers coming onto here. Welcome to the community! I am scoping out potential projects for GSoC 2026 (remember we have to apply to get in, so no guarantee DeepChem will be selected yet). Here are some tentative project directions (I will update this forums post as we get new ideas): **Symbolic machine learning**\n**Description**: We want to implement a symbolic regression capability in PyTorch that we can use in DeepChem (we prefer not to call to a Julia backend like PySR). Think of something like[https://arxiv.org/abs/2305.01582](https://arxiv.org/abs/2305.01582)except implemented in PyTorch.\n**Skills Required**: PyTorch experience, some mathematical background\n**Expected Outcomes**: (1) A robust implementation of a symbolic regression system using PyTorch within DeepChem, (2), Comprehensive benchmarks comparing the proposed system against standard tools like PySR, .\n**Potential Mentors**: Aryan, Shreyas, Bharath\n**Expected Size**: Medium\n**Expected Difficulty**: Medium**MLIP support**\n**Description**: Implement a MLIP model as a TorchModel in DeepChem. Make sure to leverage existing deepchem equivariance tools and not to just call out to an external framework. For reference see,[https://github.com/instadeepai/mlip](https://github.com/instadeepai/mlip), but we want to do a full implementation in pytorch\n**Expected Outcomes**: (1) A robust implementation of a MLIP such as Nequip or MACE using PyTorch within DeepChem leveraging DeepChem's existing equivariant architecture, (2), Comprehensive benchmarks testing the MLIP on standard tests like force correctness or stability of small molecular dynamics simulations.\n**Skills Required**: PyTorch, some mathematical background\n**Potential Mentors**: Jose\n**Expected Size**: Medium or Large\n**Expected Difficulty**: Hard**LLM support for 7B models in DeepChem**\n**Description**: Make a Olmo model in DeepChem[https://huggingface.co/allenai/OLMo-7B](https://huggingface.co/allenai/OLMo-7B)using the`HuggingFaceModel` wrapper in DeepChem. Should be able to train/run inference with Olmo. Make sure you support the ability to do generation, regression, and classification and have the ability to continue pretraining on molecular data.\n**Expected Outcomes**: (1) A robust implementation of Olmo in DeepChem using the`HuggingFaceModel` wrapper. (2) Demonstration of how to do fine-tuning for classification/regression/generation and (3) the ability to perform additional pretraining on molecular datasets.\n**Skills Required**: HuggingFace, PyTorch\n**Potential Mentors**: Riya, Harindhar\n**Expected Size**: Medium or Large\n**Expected Difficulty**: Medium**Implement RFDiffusion, RFDiffusion-2**\n**Description**: Implement RFDiffusion/RFDiffusion2 or other protein design models in DeepChem. Implementations should be end-to-end in PyTorch and interface with standard DeepChem abstractions such as TorchModel and DeepChem datasets\n**Expected Outcomes**: (1) A clean implementation of RFDiffusion/RFDiffusion2 in DeepChem using torch model. Should leverage existing equivariance primitives. (2) Benchmarking of the model on standard protein generation tests/tasks to validate performance.\n**Skills Required**: PyTorch, some background in biology and mathematics\n**Potential Mentors**: Rishi, Jose, Bharath\n**Expected Size**: Medium or Large\n**Expected Difficulty**: Hard**Improve DFT support in DeepChem**\n**Description**: DeepChem has preliminary density functional theory support ([https://arxiv.org/abs/2309.15985](https://arxiv.org/abs/2309.15985)). Build on this! Can you solve new systems, make this scale better, implement other xc-functions? Can you model more complex systems like reactions?\n**Expected Outcomes**: (1) Add a new concrete functionality to DeepChem's DFT support. For example, implement a new XC-functional. You may suggest reasonable alternatives (2) Benchmark this new capability on an appropriate choice of system and validate against existing DFT tools like GPAW or PySCF.\n**Skills Required**: PyTorch, some background in chemistry or quantum mechanics\n**Potential Mentors**: Rakshit, Aryan, Bharath\n**Expected Size**: Small, Medium, or Large\n**Expected Difficulty**: Medium**Improve materials machine learning in DeepChem**\n**Description**DeepChem has simple crystal graph convolutions and lattice adsorption model support from a few years ago. Test these models on real systems and improve them. We encourage you to explore generative models such as[https://arxiv.org/abs/2110.06197](https://arxiv.org/abs/2110.06197). Possibly implement new papers from the last few years such as MACE. Please make sure to do implementations in DeepChem using standard tools like TorchModel.\n**Expected Outcomes**: (1) Implement a new model for materials machine learning such as MACE or Crystal Diffusion Variational Autoencoders in DeepChem using TorchModel. Please leverage DeepChem's existing equivariance utilities as needed. (2) Benchmark this system on a suitable scientific dataset.\n**Skills Required**: PyTorch, some background in materials science\n**Potential Mentors**: Aryan, Bharath\n**Expected Size**: Medium or Large\n**Expected Difficulty**: Medium**Single Cell and DNA Foundation Models**\n**Description**: Implement a single cell or DNA foundation model in DeepChem. Using the existing ChemBERTa and MolFormer models as a guide. I.e, use HuggingFace as a backend, but make sure to integrate fully with DeepChem pretraining and fine-tuning infrastructure. Also need to inherit from TorchModel and DeepChem datasets\n**Expected Outcomes**: (1) Implement a single cell or DNA foundation model in DeepChem leveraging`HuggingFaceModel` (2) Implement tokenizers or other needed utlities in DeepChem. (3) Benchmark this model on a suitable dataset.\n**Skills Required**: HuggingFace, PyTorch\n**Potential Mentors**: Rishi, Harindhar\n**Expected Size**: Medium or Large\n**Expected Difficulty**: Medium**Differentiable FEM, FVM**:\n**Description**: Implement a differentiable finite element method or finite volume method in DeepChem. Here are couple potential references[https://arxiv.org/abs/2506.18427](https://arxiv.org/abs/2506.18427),[https://arxiv.org/abs/2307.02494](https://arxiv.org/abs/2307.02494). Make sure to benchmark against standard FEM/FVM solvers. Also make sure to use standard DeepChem abstractions such as TorchModel and deepchem datasets.\n**Expected Outcomes**: (1) Implement a finite element method (or finite volume method) as a well designed utility function. This must use PyTorch and be end-to-end-differentiable (2) Provide an implementation of a mesh datastructure for use in the finite element method. (3) Run benchmarks to demonstrate differentiability.\n**Skills**: PyTorch, numerical methods\n**Potential Mentors**: Rakshit, Abhay\n**Expected Size**: Medium or Large\n**Expected Difficulty**: Hard**Robust Bi-directional Translation Between SMILES and IUPAC Nomenclature**\n**Description**: Accurate conversion between systematic IUPAC names and SMILES strings is a fundamental requirement for many chemistry-AI workflows. While current state-of-the-art models like Claude show promise in understanding chemical structures, they are prohibitively expensive for processing millions of molecules in research databases. Furthermore, general-purpose models often lack the necessary precision for complex chemical structures, frequently hallucinating names or failing to correctly interpret stereochemistry and complex ring systems. This project seeks a robust and scalable solution for the bi-directional translation of these identifiers. This is an open-ended challenge where contributors are encouraged to propose and evaluate various architectures. (Potential directions include sequence-to-sequence (Seq2Seq) transformers, specialized graph-to-string architectures, or hybrid rule-based and machine learning approaches.) The primary focus is on achieving high chemical fidelity and computational efficiency compared to proprietary frontier LLM models.\n**Expected Outcomes**: (1) A robust implementation of a SMILES-to-IUPAC and IUPAC-to-SMILES translation system within DeepChem, (2), Comprehensive accuracy benchmarks comparing the proposed solution against existing tools and general-purpose LLMs, (3) Support for a wide range of chemical entities, including those with complex branching and stereocenter definitions, (4) A pre-trained model or set of weights available for the DeepChem community.\n**Skills Required**: Strong Python programming skills, Experience in machine learning, particularly sequence modeling or natural language processing (NLP), Knowledge of cheminformatics tools such as RDKit, OpenBabel, or PubChem APIs, Understanding of the rules governing IUPAC nomenclature and SMILES syntax.\n**Difficulty**: Medium to Hard\n**Potential Mentors**: Shreyas, Bharath\nIf you are looking to apply this year, please start scoping out these directions. The more work you do up front, the more likeley we will pick you! I will restart office hours in limited format by the start of next year once fully back from paternity leave (at least 1 day a week)\nThis post is mirrored on |\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n## Replies: 9 comments\n\n-\n\n|\nHii sir I’ve chosen to focus on two of the proposed directions: 7B LLM support in DeepChem and RFDiffusion / protein design models. I know the org selection results aren’t out yet, but I wanted to share my interest early. I’m already looking through the relevant DeepChem abstractions and the OLMo and RFDiffusion codebases so I can be ready with a concrete, well-scoped proposal if DeepChem is selected. Looking forward to contributing if things move forward. |\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n-\n\n|\nHi |\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n-\n\n|\nHi |\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n-\n\n|\nHi I’m planning to explore a small DeepChem native prototype, likely starting with a minimal HuggingFace Model integration, and open an exploratory PR to get familiar with the codebase If there are any design constraints or suggested entry points you’d recommend, I’d be happy to take those into account. Looking forward to contributing and learning from the process. |\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n-\n\n|\nHi I am very interested in the I am a Mechanical Engineering graduate with extensive experience in structural and thermal simulations (ANSYS/ABAQUS), which now made me curious about the formulas behind it. Now I've found myself here researching FEM formulations on DeepCharm. This fall, I will also be starting my Master's in Advanced Mechanical Engineering and Robotics in Japan (as a MEXT scholar), with a research focus on Embodied AI. I view differentiable physics as the key to bridging the sim-to-real gap, specifically for co-optimizing physical morphology alongside control policies. To understand the mathematical and software challenges involved in integrating FEM with automatic differentiation, I have built a proof-of-concept suite from scratch using PyTorch: Repository Branch --> In this repository, I implemented: - 1D Poisson Solver: Manual assembly of stiffness matrices and load vectors using the weak formulation (Galerkin method).\n- Inverse Heat Conduction: A differentiable simulator that recovers thermal conductivity from noisy measurement data via gradient descent.\n- 2D Differentiable Mesh: A triangular mesh generator where node coordinates are learnable parameters, optimized for element quality (aspect ratio) and area conservation.\nThe code includes comprehensive unit tests (pytest) and follows DeepChem's contribution guidelines (flake8/mypy). I would welcome any feedback on this implementation approach to understand how I can improve myself for the upcoming project. Best regards, |\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n-\n\n|\nHi I am deeply interested in -\nSingle Cell and DNA Foundation Models support in DeepChem : -\nImprove materials machine learning in DeepChem\nI have more than 3 years of experience in training and developing Foundational models. I would love to make this support for DNA Foundational model in DeepChem. It would very well fit into my area of expertise just applied to a new field. I have previously worked in ML Research roles at Adobe and YC startups. Also I have helped in developed foundation models in diffusion space before which have been accepted at top conferences like ICLR and WACV. Currently I also have a first author paper under review in ICML 2026. So this is something which directly falls under something I am tremendous expertise it. I will try to start with the implementation of \"Crystal Diffusion Variational Autoencoders in DeepChem using TorchModel\" : to see what are the technical caveats in this. Thank you |\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n-\n\n|\nHi I’m very interested in the Single Cell Foundation Models direction for GSoC 2026. I have experience working with PyTorch and transformer-based models, as well as single-cell RNA-seq data. I’ve been reviewing DeepChem’s HuggingFaceModel and TorchModel abstractions to understand how pretraining and fine-tuning workflows are structured within DeepChem. I’m particularly interested in exploring how a single-cell foundation model could be integrated cleanly using the existing HuggingFaceModel wrapper while aligning with DeepChem’s Dataset and TorchModel APIs. I plan to begin with small contributions around the HuggingFace integration to familiarize myself with DeepChem’s review and CI process before drafting a detailed proposal. Looking forward to contributing. Cheers, |\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n-\n\n|\nHey Regards |\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)\n\n-\n\n|\nHi mentors , I’m Utkarsh, a student contributor interested in the LLM support for 7B models / OLMo in DeepChem GSoC 2026 project. I’ve already started contributing to DeepChem and recently opened this PR fixing HuggingFace checkpoint saving issues and HF tests: 👉 PR: I’m interested to work specifically on the OLMo + HuggingFaceModel integration project, and I’ve begun reading hf_models.py, ChemBERTa, and the TorchModel checkpoint flow to understand the current architecture. I’d really appreciate your guidance on: What would be the best first technical milestone for OLMo integration? Are there any existing design expectations or pitfalls I should be aware of? Would you recommend starting with inference support first, or classification/regression heads? |\n\nBeta\nWas this translation helpful?\n[Give feedback.](https://github.com)"
  },
  {
    "name": "FFmpeg",
    "slug": "ffmpeg",
    "tagline": "Record, convert and stream audio & video",
    "description": "FFmpeg is the leading multimedia framework, able to decode, encode, transcode, mux, demux, stream, filter and play pretty much anything that humans and machines have created. It supports the most obscure ancient formats up to the cutting edge. No matter if they were designed by some standards committee, the community or a corporation. It is also highly portable: FFmpeg compiles, runs, and passes our testing infrastructure FATE across Linux, Mac OS X, Microsoft.",
    "ideas_url": "https://trac.ffmpeg.org/wiki/SponsoringPrograms/GSoC/2026",
    "website_url": "https://ffmpeg.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "git",
      "asm"
    ],
    "topic_tags": [
      "audio",
      "video",
      "subtitles",
      "multimedia"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/ffmpeg",
    "ideas_content": "# Making sure you're not a bot!\n\nLoading...\n\nYou are seeing this because the administrator of this website has set up Anubis to protect the server against the scourge of AI companies aggressively scraping websites. This can and does cause downtime for the websites, which makes their resources inaccessible for everyone.\n\nAnubis is a compromise. Anubis uses a Proof-of-Work scheme in the vein of Hashcash, a proposed proof-of-work scheme for reducing email spam. The idea is that at individual scales the additional load is ignorable, but at mass scraper levels it adds up and makes scraping much more expensive.\n\nUltimately, this is a placeholder solution so that more time can be spent on fingerprinting and identifying headless browsers (EG: via how they do font rendering) so that the challenge proof of work page doesn't need to be presented to users that are much more likely to be legitimate.\n\nPlease note that Anubis requires the use of modern JavaScript features that plugins like JShelter will disable. Please disable JShelter or other such plugins for this domain."
  },
  {
    "name": "Gemini CLI",
    "slug": "gemini-cli",
    "tagline": "Gemini CLI brings the power of Gemini directly into your terminal",
    "description": "The Gemini CLI team maintains the Gemini CLI OSS project in order to deliver a high-quality, state-of-the-art agent to a large, global user base. Maintainers manage a set of public and internal (Google) backlog goals, open source community contributions, and build/release infrastructure.",
    "ideas_url": "https://docs.google.com/document/d/1iaMZliqwUn-ACyZAbgzdXmDiQZ7l5gp8UQIIY2BnPO8/edit?usp=sharing",
    "website_url": "https://geminicli.com",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "typescript",
      "GenAI",
      "MCP",
      "Software Agent",
      "A2A"
    ],
    "topic_tags": [
      "developer tools",
      "GenAI"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/gemini-cli",
    "ideas_content": "Die Datei kann in Ihrem Browser nicht geöffnet werden, weil JavaScript nicht aktiviert ist. Aktivieren Sie JavaScript und laden Sie die Seite noch einmal.\nGemini CLI Summer Of Code 2026 - Ideas List\nTab\nExtern\nFreigeben\nAnmelden\nDatei\nBearbeiten\nAnsicht\nTools\nHilfe\nBedienungshilfen\nFehlerbehebung"
  },
  {
    "name": "Boa",
    "slug": "boa",
    "tagline": "An ECMAScript engine written in Rust",
    "description": "Boa is an open-source, embeddable JavaScript engine written in Rust. The project aims to provide a correct, safe, and performant implementation of the ECMAScript specification, with a strong focus on long-term maintainability and developer ergonomics.\n\nBoa is designed to be used as a library, enabling developers to embed JavaScript into Rust applications, tooling, and experimental runtimes. The project emphasizes clear internal architecture, rigorous testing, and close alignment with the evolving ECMAScript standard.\n\nDevelopment is community-driven and spans multiple areas of language runtime engineering, including parsing, bytecode compilation, virtual machine execution, garbage collection, performance optimization, and specification conformance. Boa is actively developed and used as a platform for exploring modern JavaScript engine design in a memory-safe systems programming language.\n\nIn 2026 Boa's work has been used in browsers such as Google Chrome and Node.js to implement Temporal, you can read more about this in https://boajs.dev/blog/2025/09/24/temporal-release. Boa has also been used as an implementation to help drive standards within TC39 (the standards committee behind JavaScript).",
    "ideas_url": "https://boajs.dev/roadmap",
    "website_url": "https://boajs.dev/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "javascript",
      "rust"
    ],
    "topic_tags": [
      "compilers",
      "web",
      "performance",
      "interpreters"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/boa",
    "ideas_content": "# Roadmap 2026\n\n## Garbage Collector Redesign and Integration[](https://boajs.dev#garbage-collector-redesign-and-integration)\n\n- Difficulty: Hard\n- Duration: 350 hours\n- Required Skills: Rust, memory management, data structures\n- Preferred Skills: Garbage collection algorithms, language runtimes\n\n### Description[](https://boajs.dev#description)\n\nBoa currently uses a prototype garbage collector, with experimental work happening in the separate [Oscars repository](https://github.com/boa-dev/oscars). While functional, the GC architecture needs significant redesign to better support performance, maintainability, and future language features.\n\nThis project focuses on evaluating, refining, and integrating a production-ready garbage collector into Boa.\n\n### Expected Outcomes[](https://boajs.dev#expected-outcomes)\n\n- Analyze the current GC design and limitations\n- Improve or redesign the GC architecture (e.g. tracing strategy, allocation model, rooting)\n- Integrate the improved GC into Boa’s runtime\n- Add stress tests and benchmarks for GC behavior\n- Produce documentation explaining the design and trade-offs\n\n### Possible Extensions[](https://boajs.dev#possible-extensions)\n\n- Incremental or generational GC strategies\n- GC-aware optimizations in the VM\n- Tooling to visualize heap and GC activity\n\n### Project Discussion:[](https://boajs.dev#project-discussion)\n\n[Matrix Boa/GC](https://matrix.to/#/!ESLxDMqdSvKbprdiyg:matrix.org?via=matrix.org&via=rrogal.ski&via=t2bot.io)\n[Matrix Boa/General](https://matrix.to/#/!ZBLAwGpYvzsLqZAZZg:matrix.org?via=matrix.org&via=t2bot.io&via=mozilla.org)\n\n## Public API Audit and 1.0 Stabilization[](https://boajs.dev#public-api-audit-and-10-stabilization)\n\n- Difficulty: Medium\n- Duration: 175–200 hours\n- Required Skills: Rust, API design\n- Preferred Skills: SemVer, library maintenance, documentation\n\n### Description[](https://boajs.dev#description-1)\n\nBoa is approaching its 1.0 release. A key requirement for this milestone is ensuring that our public APIs are well-defined, intentional, and stable, as breaking changes become significantly more costly after 1.0. This project focuses on auditing Boa’s public API surface, identifying areas that may cause long-term maintenance or compatibility issues, and helping prepare the engine for a stable 1.0 release.\n\n### Expected Outcomes[](https://boajs.dev#expected-outcomes-1)\n\n- Identify and document all public-facing APIs (types, traits, functions, feature flags)\n- Review APIs for stability, consistency, and long-term viability\n- Propose improvements or refactors to reduce future breaking changes\n- Help resolve or unblock remaining items needed for the 1.0 milestone\n- Improve documentation around public APIs and versioning guarantees\n\n### Possible Extensions[](https://boajs.dev#possible-extensions-1)\n\n- Introduce tooling or CI checks to detect accidental public API changes\n- Improve feature gating or visibility (pub vs pub(crate)) across the codebase\n- Assist in defining Boa’s post-1.0 stability and deprecation policy\n\n## JavaScript Engine Performance Improvements[](https://boajs.dev#javascript-engine-performance-improvements)\n\n- Difficulty: Medium–Hard\n- Duration: 175–350 hours\n- Required Skills: Rust, profiling, algorithms\n- Preferred Skills: Compiler or VM internals, benchmarking\n\n## Open Issue:[](https://boajs.dev#open-issue)\n\n[https://github.com/boa-dev/boa/issues/4524](https://github.com/boa-dev/boa/issues/4524)\n\n### Description[](https://boajs.dev#description-2)\n\nPerformance is a core goal of Boa. While already competitive in many areas, there are clear opportunities to improve execution speed, memory usage, and startup time.\n\nThis project focuses on identifying performance bottlenecks and implementing targeted optimizations across the VM, bytecode execution, and runtime systems.\n\n### Expected Outcomes[](https://boajs.dev#expected-outcomes-2)\n\n- Much improved results on boajs.dev/benchmarks\n- Identify high-impact performance bottlenecks\n- Implement measurable optimizations (e.g. faster bytecode dispatch, improved data structures)\n- Add or improve benchmarks to prevent regressions\n- Document performance changes and results\n\n### Possible Extensions[](https://boajs.dev#possible-extensions-2)\n\n- Reduced allocation pressure and memory churn\n- Improve documentation and tooling for profiling and benchmarking\n\n### Project Discussion[](https://boajs.dev#project-discussion-1)\n\n## ECMAScript Conformance and Spec Compliance[](https://boajs.dev#ecmascript-conformance-and-spec-compliance)\n\n- Difficulty: Medium\n- Duration: 175 hours\n- Required Skills: Rust, reading specifications\n- Preferred Skills: JavaScript engine internals\n\n### Description[](https://boajs.dev#description-3)\n\nBoa already performs well on ECMAScript conformance tests, but maintaining and improving compliance is an ongoing effort as the specification evolves.\n\nThis project focuses on closing remaining gaps, improving correctness in edge cases, and strengthening test coverage.\n\n### Expected Outcomes[](https://boajs.dev#expected-outcomes-3)\n\n- Identify areas where Boa diverges from the ECMAScript specification\n- Implement missing or partially compliant features\n- Improve or expand test coverage\n- Reduce known test failures and inconsistencies\n- Document tricky or non-obvious spec decisions\n\n### Possible Extensions[](https://boajs.dev#possible-extensions-3)\n\n- Focus on a specific ECMAScript feature set (e.g. async, modules, Intl groundwork)\n- Improve error reporting and diagnostics for spec failures\n\n## Developer Tooling and Engine Observability[](https://boajs.dev#developer-tooling-and-engine-observability)\n\n- Difficulty: Medium\n- Duration: 175 hours\n- Required Skills: Rust, tooling, debugging\n- Preferred Skills: Runtime diagnostics, profiling tools\n\n### Description[](https://boajs.dev#description-4)\n\nAs Boa grows, better tooling is needed to understand and debug engine behavior. This project focuses on improving observability for developers working on the engine.\n\n### Expected Outcomes[](https://boajs.dev#expected-outcomes-4)\n\n- Improve logging and diagnostics in the VM and runtime\n- Add optional tracing or debug modes\n- Improve internal metrics (allocation counts, GC timing, bytecode execution stats)\n- Document tooling for contributors and users\n\n### Possible Extensions[](https://boajs.dev#possible-extensions-4)\n\n- Debug-friendly execution modes\n- Performance and memory visualization tooling\n- Integration with existing Rust profiling tools"
  },
  {
    "name": "The P4 Language Consortium",
    "slug": "the-p4-language-consortium",
    "tagline": "Evolve the programmable data plane ecosystem!",
    "description": "Programming Protocol-independent Packet Processors (P4) is a domain-specific language for network devices, specifying how data plane devices (switches, NICs, routers, filters, etc.) process packets.\n\nBefore P4, vendors had total control over the functionality supported in the network. And since networking silicon determined much of the possible behavior, silicon vendors controlled the rollout of new features (e.g., VXLAN), and rollouts took years.\n\nP4 turns the traditional model on its head. Application developers and network engineers can now use P4 to implement specific behavior in the network, and changes can be made in minutes instead of years.",
    "ideas_url": "https://github.com/p4lang/gsoc/blob/main/2026/ideas_list.md",
    "website_url": "https://p4.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "llvm",
      "c++",
      "linux kernel",
      "mlir",
      "ebpf"
    ],
    "topic_tags": [
      "networking",
      "programming language",
      "compiler",
      "AI/ML Networking",
      "networking security"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/the-p4-language-consortium",
    "ideas_content": "# P4 GSoC 2026 Ideas List\n\n## Application process\n\nPlease check our [Contributor Guidance](/materials/contributor_guidance.md) for detailed instructions.\n\n## Potential mentors\n\n⭐ = available as primary mentor\n\n1. ⭐ Jamal Hadi Salim ([@jhsmt](https://github.com/jhsmt), jhs@mojatatu.com)\n2. ⭐ Jaehyun Lee ([@jaehyun1ee](https://github.com/jaehyun1ee), 99jaehyunlee@kaist.ac.kr)\n3. ⭐ Jiaxin Lin ([@jxlin-lock](https://github.com/jxlin-lock), jiaxinl@cornell.edu)\n4. ⭐ Mingyu Ma ([@Mingyumaz](https://github.com/Mingyumaz), mingyu.ma@tu-dresden.de)\n5. ⭐ Matthew Lam ([@matthewtlam](https://github.com/matthewtlam), matthewtlam@google.com)\n6. ⭐ Peng Qian ([@dawndusk0508](https://github.com/dawndusk0508), peng.qian@ox.ac.uk)\n7. ⭐ Takeaki Oura([@iHalt10](https://github.com/iHalt10), ihalt10@icloud.com)\n8. ⭐ Victor Nogueira ([@vbnogueira](https://github.com/vbnogueira), victor@mojatatu.com)\n9. ⭐ Zhiyuan Guo ([@depctg](https://github.com/depctg), zhiyuang@cornell.edu)\n10. ⭐ Fabian Ruffy ([@fruffy](https://github.com/fruffy), fruffy@nyu.edu)\n11. Ali Imran ([@ALI11-2000](https://github.com/ALI11-2000), imranali@umich.edu)\n12. Anton Korobeynikov ([@asl](https://github.com/asl), anton@korobeynikov.info)\n13. Bili Dong ([@qobilidop](https://github.com/qobilidop), bilid@google.com)\n14. Davide Scano ([@Dscano](https://github.com/Dscano), d.scano89@gmail.com)\n15. Evangelos Haleplidis ([@evhalep](https://github.com/evhalep), ehalep@mojatatu.com)\n\n## FAQ\n\nNote: you = contributors, we = mentors.\n\n**Q1: Some mentors are listed as primary mentor for multiple projects. How does that work?**\n\nFor the application phase, we'd like to present more options for you to choose from. Eventually, depending on the applications received, they will decide on at most 1 project to commit to as a primary mentor.\n\n**Q2: What do our project difficulties mean?**\n\n[diffi-easy]: https://img.shields.io/badge/Difficulty-Easy-green\n[diffi-medium]: https://img.shields.io/badge/Difficulty-Medium-blue\n[diffi-hard]: https://img.shields.io/badge/Difficulty-Hard-red\n\n- ![diffi-easy]: Basic coding skills are sufficient.\n- ![diffi-medium]: CS undergraduate level knowledge/skills are required.\n- ![diffi-hard]: Deeper and more specialized knowledge/skills are required.\n\n**Q3: Project sizes are specifided in hours. How many weeks do they correspond to?**\n\n[size-s]: https://img.shields.io/badge/Size-90_hour-green\n[size-m]: https://img.shields.io/badge/Size-175_hour-blue\n[size-l]: https://img.shields.io/badge/Size-350_hour-red\n\n- ![size-s]: 8 weeks\n- ![size-m]: 12 weeks\n- ![size-l]: 12 weeks\n\n**Q4: Some projects have an \"alternative qualification task\" section. What does that mean?**\n\nIt means for that specific project, instead of the general qualification task, you shall complete the alternative qualification task described in that section.\n\n**Q5: Some \"alternative qualification task\" section says \"demonstrate your XYZ skills through contributions to\". What does that mean?**\n\nIt means we expect you to have made relevant contributions in order to demonstrate your XYZ skills. In your applicaiton, please briefly describe your contributions, and attach related links (e.g. pull requests on GitHub).\n\n## Project ideas\n\n### Index\n\n**Category 1: Core P4 Tooling**\n  - [Under Review] [Project 1.1: Modernizing the P4 Software Switch BMv2](#project-1.1)\n\n**Category 2: Exploratory P4 Tooling**\n  - [Project 2.1: Realistic Traffic Manager and Queueing Architecture for P4 Switch Simulation in ns-3 (P4sim)](#project-2.1)\n  - [Project 2.2: Polyglot P4TC: Python and Rust API Wrappers for Linux TC-based P4](#project-2.2)\n  - [Project 2.3: PCIe TLP Communication Framework using P4](#project-2.3)\n  - [Project 2.4: P4MLIR Exporter: Generate Valid P4 from P4HIR](#project-2.4)\n\n**Category 3: P4 Research**\n  - [Project 3.1: Alkali-P4MLIR: Bridging P4 and SmartNICs Through MLIR Dialect Conversion Between Alkali IR and P4MLIR](#project-3.1)\n  - [Project 3.2: Tutorial documentation for P4-SpecTec: A P4 specification mechanization framework](#project-3.2)\n  - [Project 3.3: Integrating P4-based In-Network Machine Learning framework into P4Pi](#project-3.3)\n\n---\n\n### <a name='project-1.1'></a> Project 1.1: Modernizing the P4 Software Switch BMv2 [⤴️](#index)\n\n**Note**\n\nThis project proposal is [under review](https://github.com/p4lang/gsoc/issues/87). Project description changes are expected.\n\n**Basic info**\n\n![diffi-medium] ![size-m]\n\n- Potential mentors\n  - Primary: Matthew Lam\n  - Support: Bili Dong\n- Skills\n  - Required: Git, C++\n  - Preferred: Bazel, P4\n- Discussion thread: Github Issue Tracker, Zulip\n\n**Alternative qualification task**\nPresently, BMv2 can only be built with CMake. The goal is to modernize BMv2 and get it to build using Bazel 8.5.0 and deploy a Github workflow runs the unit tests for [simple_switch_grpc](https://github.com/p4lang/behavioral-model/tree/main/targets/simple_switch_grpc).\n\n1. Add support for [Bazel 8.5.0](https://bazel.build/versions/8.5.0/run/build) to BMv2's simple_switch_grpc. An example P4 repository that uses Bazel is [P4Runtime](https://github.com/p4lang/p4runtime).\n2. Create a Github workflow that caches, builds, and runs the unit tests. An example P4 repository that has a Github workflow set up is [P4C](https://github.com/p4lang/p4c/blob/7d367760701056cfa4fe0321f62914c0e79a6214/.github/workflows/ci-bazel.yml).\n\nCreate a PR under https://github.com/p4lang/behavioral-model.\n\n**Project description**\nBMv2 is a P4-based packet processor that has not been well maintained over the years due to lack of accessibility, slow builds/tests, lack of readability and complexity. One factor contributing towards the lack of accessibility is the difficulty of setting up the project prior to development.\n\nThere are many different enhancements to the repository that can be made including: \n* Extending support for BMv2 to build using Bazel\n* Refactoring BMv2 to use Google style guide (https://google.github.io/styleguide/cppguide.html)\n    * Absl Integration\n    * Discourage exceptions (use status-based error propagation)\n    * Use smart pointer over manual memory\n    * Explicit constructors\n    * Flatten the directory structure\n    * Deprecating unused features\n* Converting textual logs that manually track the packet through the pipeline into a structured and programmatic form (e.g. .proto) \n    * Can read more information [here](https://github.com/p4lang/gsoc/blob/main/2025/ideas_list.md#project-2). \n\n\n**Expected outcomes**\n* Building BMv2 using Bazel will make it easier to set up, manage dependencies, and faster builds and tests\n* Improving readability of BMv2 and reducing complexity of the repository\n*  Structured packet trace outputs supported in BMv2.\n\n**Resources**\n* BMv2: https://github.com/p4lang/behavioral-model\n\n---\n\n### <a name='project-2.1'></a> Project 2.1: Realistic Traffic Manager and Queueing Architecture for P4 Switch Simulation in ns-3 (P4sim) [⤴️](#index)\n\n**Basic info**\n\n![diffi-hard] ![size-l]\n\n- Potential mentors\n  - Primary: Mingyu Ma \n  - Support: Davide Scano\n- Skills\n  - Required: C++, Git\n  - Preferred: ns-3, P4, networking simulation\n- Discussion thread: GitHub issue tracker, Zulip\n\n**Alternative qualification task**\n\n1. Skeleton dummy switch model in [ns-3](https://www.nsnam.org/)\n\nImplement a minimal “skeleton” dummy switch model in ns-3 according to the current P4sim Plan A architecture:\n\n- The switch should support a configurable number of ports.\n- Each egress port should be able to attach a configurable [`Traffic Manager/traffic control`](https://github.com/p4lang/tutorials/tree/master/exercises/calc) module.\n- The focus is on designing and implementing the port-level `NetDevice` structure in ns-3, rather than full packet processing logic.\n- The implementation should be submitted to a public GitHub repository.\n\nThis skeleton switch will serve as the architectural starting point for the full project.\n\n2. Running a P4 tutorial program on P4sim\n\nChoose one of the following P4 tutorial exercises and make it runnable on P4sim:\n\n- [`source_routing`](https://github.com/p4lang/tutorials/tree/master/exercises/source_routing)\n- [`calc`](https://github.com/p4lang/tutorials/tree/master/exercises/calc)\n\nThe task includes:\n\n- Writing the ns-3 simulation scripts and set up the network connnection,\n- Adapting the P4 program to P4sim,\n- Verifying correct functionality in the ns-3 simulation environment,\n- Submitting the implementation as a pull request to the P4sim repository\n\n**Project description**\n\nModern programmable switches based on P4 (e.g., Intel Tofino, Broadcom ASICs) employ sophisticated traffic management architectures, including multiple queues per output port, strict or weighted scheduling, and accurate modeling of packet transmission delays. However, current P4 switch simulators (P4sim, bmv2 and so on) rely on simplified designs, often using a single centralized traffic manager or a single queue per port.\n\n<img width=\"700\" alt=\"image\" src=\"assets/P4sim-arch.png\">\n\n*Figure 1: Architecture of the P4 switch model in P4sim.*\n\nThis project aims to redesign and extend the P4 switch model in ns-3 to provide a realistic traffic management architecture aligned with real hardware designs and the PSA (Portable Switch Architecture) model.\n\n<img width=\"700\" alt=\"image\" src=\"assets/P4sim-compare.png\">\n\n*Figure 2: Currents status and Plan A for switch model.*\n\nThe main idea is to move the traffic manager from a centralized pipeline into per-egress-port components, where each port maintains its own queue set and scheduler. The project will also integrate ns-3’s existing queueing and scheduling modules to avoid reimplementing well-tested mechanisms.\n\nKey design aspects include:\n\n- Per-port egress traffic managers instead of a single global manager.\n- Configurable traffic manager, reuse the code of [Traffic Control Layer](https://www.nsnam.org/docs/models/html/traffic-control.html).\n- Explicit modeling of packet serialization delay based on link bandwidth.\n- Configurable ingress and egress pipeline processing delays.\n- Full compatibility with PSA-style ingress/egress pipelines.\n\nThe new architecture will enable accurate evaluation of congestion, queue buildup, scheduling policies, and latency in networks using P4-programmable switches.\n\n**Expected outcomes**\n\n- A refactored P4 switch architecture in ns-3 with per-port traffic managers.\n- Support for configurable Traffic control in egress ports.\n- Configurable ingress and egress pipeline processing delays.\n- Documentation and usage examples.\n- Example simulation scenarios demonstrating queueing behavior and congestion effects.\n\n**Resources and References**\n\n- [P4sim](https://dl.acm.org/doi/10.1145/3747204.3747210) and [github](https://github.com/HapCommSys/p4sim)\n- Intel / Barefoot Networks – [*Tofino Native Architecture (Public Version)*](https://raw.githubusercontent.com/barefootnetworks/Open-Tofino/master/PUBLIC_Tofino-Native-Arch.pdf)  \n- P4 Switch Architecture and Traffic Manager ([P4 Workshop 2021 slides](https://opennetworking.org/wp-content/uploads/2021/05/2021-P4-WS-Vladimir-Gurevich-Slides.pdf))  \n- Hot Chips 29 – [*P4 Programmable Switch Architecture Tutorial*](https://old.hotchips.org/wp-content/uploads/hc_archives/hc29/HC29.20-Tutorials-Pub/HC29.20.1-P4-Soft-Net-Pub/HC29.21.100-P4-Tutorial.pdf)  \n  \n---\n\n### <a name='project-2.2'></a> Project 2.2: Polyglot P4TC: Python and Rust API Wrappers for Linux TC-based P4 [⤴️](#index)\n\n**Basic info**\n\n![diffi-medium] ![size-m]\n\n- Potential mentors\n  - Primary: Jamal Hadi Salim, Victor Nogueira\n  - Support: Evangelos Haleplidis\n- Skills\n  - Required: Git, C, Python, Rust\n  - Preferred: Technical writing, Linux, background in programming languages\n- Discussion thread: GitHub issue tracker, Zulip\n\n**Alternative qualification task**\n\n1. Run the P4TC tutorial\n\nThis project will involve a bit of familiarity and understanding of [P4TC](https://github.com/p4tc-dev/linux-p4tc-pub).\nWith that in mind, it will be useful for the student to look into [p4tc-tutorials-pub](https://github.com/p4tc-dev/p4tc-tutorial-pub).\n\nThis will amount to:\n- Cloning the repo.\n- Spawning a vagrant VM which runs Ubuntu on top of a P4TC-enabled kernel.\n- Running the examples available in the [p4tc-examples-pub](https://github.com/p4tc-dev/p4tc-examples-pub) directory.\n\nThis directory contains example programs that perform simple networking tasks using P4TC.\nAll those examples have READMEs explaning how to run them and the expected results.\nRunning these examples will be paramount for the student to understand and get familiarised with the P4TC environment.\n\n**Project description**\n\nP4TC is a Linux Traffic Control (TC) based implementation of the P4 programming model. Today, P4TC is implemented almost entirely in C, spanning kernel datapath code (linux-p4tc-pub) and user-space tooling (iproute2-p4tc-pub). Interaction with P4TC pipelines is primarily done via the tc CLI and generated shell scripts, which limits accessibility for developers working in higher-level or safer languages.\n\nThis project proposes adding **Python and Rust control-plane API wrappers** for P4TC. The goal is to expose P4TC concepts such as pipelines, tables, actions, and runtime updates through idiomatic Python and Rust libraries, while reusing the existing C implementation and keeping the kernel datapath unchanged.\n\nThe project will be based on an existing **stable C API layer** for the P4TC control-plane interactions and build:\n\n- A **Python wrapper** (via ctypes or cffi)\n- A **Rust wrapper** (via bindgen \\+ safe abstractions)\n\n**High Level Architecture Overview**\n\nThere are 2 steps involved in setting up P4TC.\n\n- Provisioning (once)  \n  - Load the templates generated by the compiler for a program  \n  - Attach the program to one or more ethernet ports and direction  \n- Engage in runtime control  \n  - Issue CRUD commands on table entries  \n  - Subscribe and receive events \n\nThe workflow is illustrated below\n\n<img alt=\"image\" src=\"assets/p4tc_api_arch.png\">\n\nIn summary, we can break down provisioning (as of today) in the following steps:\n\n1. A developer writes a P4 program  \n2. Compiler generates  \n   1. the datapath eBPF programs,   \n   2. a template shell script for provisioning  \n   3. a JSON file for introspection during runtime commands  \n3. The operator runs the template shell script which manifests the P4 program constructs in the kernel   \n4. The operator loads the eBPF datapath programs, attaching them to specific ports\n\nAfter step \\#4 is complete, the P4 program’s runtime is active but has only default policy (if any). The control plane application can participate in runtime operations.\n\nBelow we illustrate how the runtime layout would look like. The “P4 runtime objects” are manifested during the provisioning process in step \\#3. The ebpf/XDP code is loaded in step \\#4 above.\n\n<img alt=\"image\" src=\"assets/p4tc_runt_arch.png\">\n\nAs illustrated, the sample control application interacts with the P4 runtime objects dictating the operations of the P4 programs.\n\nBelow we show the P4TC CRUDSP(*Create*, *Read*, *Update*, *Delete*, *Subscribe*, *Publish*) application interfaces. *Publish* is generated by the kernel side and the rest are initiated in the control plane application.\n\n<img alt=\"image\" src=\"assets/p4tc_crudps_breakdown.png\">\n\nSuppose that the user loaded a P4 program called myprog which has the following table:\n\n```\ntable nh_table {\n    key = {\n        hdr.ipv4.srcAddr : exact @tc_type (\"ipv4\");\n    }\n    actions = {\n        send_nh;\n        drop;\n    }\n    size = PORT_TABLE_SIZE;\n    const default_action = drop;\n}\n\n...\naction send_nh(@tc_type(\"dev\") PortId_t port_id, @tc_type(\"macaddr\") bit<48> dmac, @tc_type(\"macaddr\") bit<48> smac) {\n    hdr.ethernet.srcAddr = smac;\n    hdr.ethernet.dstAddr = dmac;\n    send_to_port(port_id);\n}\n```\n\nBelow is an example code using the C API which provisions the P4 program and adds an entry in *nh\\_table*.\n\n```c\n#include <p4tc_runtime_api.h>\n#include <p4tc_common.h>\n\n#define PNAME \"myprog\"\n#define TNAME \"cb/nh_table\"\n#define TMPL_DIR \"/path/to/tmpl/\"\n#define FULL_TBL_PATH PNAME \"/table/\" TNAME\n\nint main(int argc, char **argv)\n{\n    struct p4tc_runt_tbl_attrs *table_entry;\n    struct pipe_config pipe_config = {};\n    struct p4tc_runt_act_attrs *action;\n    char *ip_addr = \"10.10.10.1\";\n    struct p4tc_runt_ctx *ctx;\n    struct p4tc_attrs *table;\n    struct p4tc_key *key;\n    int ret;\n\n    /* Provision */\n    pipe_config.name = PNAME;\n    pipe_config.template_dir = TMPL_DIR;\n    ret = p4tc_provision(&pipe_config);\n    if (ret < 0)\n        return -1;\n\n    /* Create a table key that will hold 10.10.10.1 */\n    key = make_key(FULL_TBL_PATH, ip_addr);\n    if (!key)\n        return -1;\n\n    /* Create a context struct that uses netlink as its transport */\n    ctx = p4tc_runt_ctx_create(P4TC_TML_OPS_NL);\n    if (!ctx)\n        return -1;\n\n    /* Allocate table that will hold one or more table entries+actions\n     * to be used in a create command.\n     */\n    ret = -1;\n    table = p4tc_attrs_create(PNAME, P4TC_OBJ_RUNTIME_TABLE);\n    if (!table)\n        goto ctx_destroy;\n\n    /* create a table entry on the table */\n    table_entry = p4tc_alloc_table_entry(table, key, P4TC_ENTITY_TC);\n    if (!table_entry)\n        goto free_attrs;\n\n    /* Allocate table entry action object */\n    action = p4tc_create_runt_action(table_entry, \"cb/send_nh\", \"port_id=eth0\",\n                     \"dmac=01:02:03:04:05:06\",\n                     \"smac=07:08:09:0A:0B:0C\");\n    if (!action)\n        goto free_attrs;\n\n    /* Call p4tc_create which will send the runtime create message. NULL\n     * param is cookie returned in the response callback further down.\n     */\n    ret = p4tc_create(ctx, table, NULL);\n    if (ret < 0)\n        goto free_attrs;\n\n    /* Call response handling function. A NULL callback means\n     * that the default callback (which just prints the echoed back\n     * data) will be used. The third parameter (1) indicates the number of\n     * expected response messages.\n     */\n    ret = p4tc_resp_handle(ctx, NULL, 1);\n\nfree_attrs:\n    p4tc_attrs_free(table, NULL);\nctx_destroy:\n    p4tc_runt_ctx_destroy(ctx);\n    return ret;\n}\n```\n\n**Expected Outcomes / Deliverables**\n\nThe goal of this project is to create Python and Rust API wrappers for the P4TC control plane implemented in C. This API will have binding for functions responsible for both the provisioning and runtime phases described in the previous section. The deliverables are the following:\n\n1. **Python API Wrapper**\n\n   * Python package (e.g., p4tc\\_py)\n\n   * Object-oriented interface examples:\n\n     * p4tc.provision(pipeline\\_name=PNAME, template\\_dir=TMPL\\_DIR)\n\n     * ctx \\= p4tc.context(transport=\"netlink\")\n\n     * table \\= ctx.table(PNAME, \"cb/nh\\_table\")\n\n     * entry = table.entry(\n                    key=\"10.10.10.1\",\n                    action = {\n                        name=\"cb/send_nh\",\n                        params={\n                            \"port_id\": \"eth0\",\n                            \"dmac\": \"01:02:03:04:05:06\",\n                            \"smac\": \"07:08:09:0A:0B:0C\"\n                        }\n                    }\n       )\n\n     * Response error handling\n\n2. **Rust API Wrapper**\n   - Rust crate (e.g., p4tc-rs)\n   - Safe abstractions over FFI bindings:\n     - let mut ctx \\= Context::new(Transport::Netlink)?;\n     - let mut table \\= ctx.table(PNAME, p4tc::objType::RuntimeTable);\n     - table.add\\_entry(p4tc::Key::new(\\&table\\_path, \"10.10.10.1\").with\\_action(action))\n\n3. **Examples and Documentation**\n   - End-to-end examples in Python and Rust\n   - Comparison with existing tc / shell workflows\n   - Build and usage instructions\n\nThe following two examples are meant to provide a sense of what this project intends to accomplish and not represent the final result of the project. \n\n**Example python code:**\n\n```py\nimport p4tc\n\n# Constants\nPNAME = \"myprog\"\nTNAME = \"cb/nh_table\"\nTMPL_DIR = \"/path/to/tmpl/\"\n\ndef main():\n    # 1. Provisioning\n    # Abstraction: A static helper function or singleton configuration\n    # Raises P4TCError on failure automatically.\n    p4tc.provision(\n        pipeline_name=PNAME, \n        template_dir=TMPL_DIR\n    )\n\n    # 2. Context Creation\n    # Abstraction: usage of 'with' ensures p4tc_runt_ctx_destroy is called \n    # automatically, even if errors occur inside the block.\n    with p4tc.context(transport=\"netlink\") as ctx:\n        \n        # 3. Create the Table/Transaction Object\n        # Abstraction: We objectify the \"Table\" concept.\n        # This wraps p4tc_attrs_create.\n        table = ctx.table(pipeline=PNAME, table_path=TNAME)\n\n        # 4. Create Entry and Action\n        # Abstraction: The key creation and entry allocation are merged into\n        # a high-level 'entry' method.\n        # Action parameters are passed as native Python dictionaries.\n        entry = table.entry(\n                    key=\"10.10.10.1\",\n                    action = {\n                        name=\"cb/send_nh\",\n                        params={\n                            \"port_id\": \"eth0\",\n                            \"dmac\": \"01:02:03:04:05:06\",\n                            \"smac\": \"07:08:09:0A:0B:0C\"\n                        }\n                    }\n        )\n\n        # 5. Submit (Create)\n        # Abstraction: Wraps p4tc_create. \n        # The 'response_handler' argument defaults to a standard printer if None.\n        ctx.create(table)\n\n        # 6. Handle Response\n        # In a high-level API, this might be blocking by default \n        # or return a Future object.\n        ctx.process_responses(count=1)\n\nif __name__ == \"__main__\":\n    try:\n        main()\n    except p4tc.Error as e:\n        print(f\"An error occurred: {e}\")\n```\n\n**Similar example in rust:**\n\n```rust\nuse p4tc::{Action, Config, Context, TableRef, Transport};\nuse std::path::Path;\n\n// Constants\nconst PNAME: &str = \"myprog\";\nconst TNAME: &str = \"cb/nh_table\";\nconst TMPL_DIR: &str = \"/path/to/tmpl/\";\n\nfn main() -> Result<(), p4tc::Error> {\n    // 1. Provisioning\n    // Abstraction: Builder pattern for configuration struct.\n    let config = Config::builder()\n        .name(PNAME)\n        .template_dir(Path::new(TMPL_DIR))\n        .build();\n\n    p4tc::provision(&config)?;\n\n    // 2. Context Creation\n    // Abstraction: Strong typing for Transport (enum).\n    // The 'ctx' variable implements Drop, handling p4tc_runt_ctx_destroy automatically.\n    let mut ctx = Context::new(Transport::Netlink)?;\n\n    // 3. Prepare the Table and Key\n    // Abstraction: We create a strongly typed reference to the table.\n    let table_path = format!(\"{}/table/{}\", PNAME, TNAME);\n\n    // This object owns the memory for the request.\n    let mut table = ctx.table(PNAME, p4tc::ObjType::RuntimeTable);\n\n    // 4. Create Entry & Action\n    // Abstraction: Method chaining (Fluent Interface) for adding parameters.\n    let action = Action::new(\"cb/send_nh\")\n        .param(\"port_id\", \"eth0\")\n        .param(\"dmac\", \"01:02:03:04:05:06\")\n        .param(\"smac\", \"07:08:09:0A:0B:0C\");\n\n    // Add entry to the batch\n    // 'key' logic is handled internally or via a helper Key::from_string\n    table\n        .add_entry(p4tc::Key::new(&table_path, \"10.10.10.1\"))\n        .with_action(action);\n\n    // 5. Submit (Create)\n    // Abstraction: The 'send' consumes the 'batch' (move semantics),\n    // ensuring we don't use the freed attributes again.\n    ctx.create(table)?;\n\n    // 6. Handle Response\n    // Passing 'None' implies default handler.\n    ctx.handle_response(None, 1)?;\n}\n```\n\n**Resources**  \nThese are the core repos where P4TC development happens:\n\n- Linux kernel integration (P4TC kernel code): [https://github.com/p4tc-dev/linux-p4tc-pub](https://github.com/p4tc-dev/linux-p4tc-pub)\n- User-space tooling support in iproute2: [https://github.com/p4tc-dev/iproute2-p4tc-pub](https://github.com/p4tc-dev/iproute2-p4tc-pub)\n- Tutorials and setup examples: [https://github.com/p4tc-dev/p4tc-tutorial-pub](https://github.com/p4tc-dev/p4tc-tutorial-pub)\n- P4TC examples (sample P4 programs): [https://github.com/p4tc-dev/p4tc-examples-pub](https://github.com/p4tc-dev/p4tc-examples-pub)\n- Project documentation: [https://github.com/p4tc-dev/docs](https://github.com/p4tc-dev/docs)\n- Traffic Control test executor: [https://github.com/p4tc-dev/tc-executor](https://github.com/p4tc-dev/tc-executor)\n- Static website repo (project homepage): [https://github.com/p4tc-dev/www-p4tc](https://github.com/p4tc-dev/www-p4tc)\n\nYou can explore all P4TC repos from the organization page here: [https://github.com/p4tc-dev](https://github.com/p4tc-dev)\n\n**Full Publication Metadata**\n- *Introducing P4TC — A P4 implementation on Linux Kernel using Traffic Control* — EuroP4 workshop paper (2023)\n  [https://dl.acm.org/doi/10.1145/3630047.3630193](https://dl.acm.org/doi/10.1145/3630047.3630193)\n\n---\n\n### <a name='project-2.3'></a> Project 2.3: PCIe TLP Communication Framework using P4 [⤴️](#index)\n\n**Basic info**\n\n![diffi-hard] ![size-l]\n\n- Potential mentors\n  - Primary: Takeoki Oura\n  - Support: Ali Imran\n- Skills\n  - Required: SystemVerilog (or Verilog) programming with Xilinx Vivado, Git\n  - Preferred: P4 language, PCIe protocol knowledge\n  - Discussion thread: GitHub issue tracker, Zulip\n\n**Alternative qualification task**\n\n- Please demonstrate your FPGA skills through contributions to any of the following (Required):\n  - Any personal project that has used Xilinx Vivado tools\n  - Any existing Xilinx FPGA projects\n  - If you have access to Alveo or similar devices, you may explore the following projects and submit a report (other projects are also acceptable):\n    - [VNP4 Framework](https://github.com/iHalt10/vnp4_framework): Framework for integrating Vitis Networking P4 IP with OpenNIC\n    - [PCIe Subsystem for AMD Xilinx](https://github.com/iHalt10/pcie_subsystem): SystemVerilog modules for PCIe TLP control and DMA transfer\n    - These projects will help you gain the necessary knowledge for this GSoC project. If you have any questions about compilation, operation, or code reading during the application period, feel free to ask.\n\n- Please demonstrate your P4 knowledge through contributions to any of the following (Optional):\n  - Any existing P4 project\n  - Any personal project that incorporates P4\n\n- Please demonstrate your PCIe knowledge through contributions to any of the following (Optional):\n  - Any existing PCIe-related projects\n  - Any personal project that involves PCIe protocol or hardware design\n  - A report or investigation document about PCIe mechanisms and TLP packets\n    - You may refer to resources such as the [PCIe UltraScale+ IP Product Guide (PG213)](https://docs.amd.com/r/en-US/pg213-pcie4-ultrascale-plus) or other AMD Xilinx PCIe IP specification documents\n\n**Project description**\n\nAlthough P4 is designed to be \"Protocol-independent,\" current practical applications are primarily concentrated on network protocols such as Ethernet, IP, and TCP, with no existing examples of application to low-layer device interconnect protocols like PCIe.\n\nThis project aims to demonstrate P4's true versatility by implementing a framework for processing **PCIe Transaction Layer Packets (TLP)** using P4 on AMD Xilinx FPGAs. By combining AMD's **Vitis Networking P4 IP** and **PCIe UltraScale+ IP**, we will develop FPGA hardware logic and P4 programs capable of analyzing, controlling, and forwarding PCIe TLP.\n\n![hardware design](assets/pcie-tlp-p4-hardware-design.png)\n\n*Figure: hardware design showing PCIe TLP processing through P4 engine*\n\nThe project consists of two phases:\n\n**Phase 1 (Required): Basic TLP Processing in Conventional DMA Transfer**\n\nIn standard PCIe DMA transfers (Endpoint → Host Memory → Endpoint), we will process TLP with P4:\n\n- Parse/Deparse RQ/CQ/RC/CC descriptors (128bit/96bit)\n- Identify and process Memory Read/Write Requests\n- Collect transaction statistics\n- Advanced control using P4 Externs (if needed)\n\n**Application Example:** By converting Ethernet packets to TLP in the P4 engine and directly writing to DMA regions, the PCIe device can be recognized by Linux with any PCIe Class Code (NVMe, GPU, Custom Device, etc.) rather than as a NIC. This enables P4 end users to select arbitrary PCIe devices instead of treating them as network interfaces.\n\n**Phase 2 (Optional - Challenging Goal): PCIe Peer-to-Peer (P2P) Communication**\n\nDirect TLP exchange between devices, bypassing host memory (Endpoint A → PCIe Switch → Endpoint B), provides:\n\n- Host memory bandwidth savings\n- Latency reduction\n- CPU overhead reduction\n\nP4 will implement:\n- PCIe Switch routing control (Address-Based and ID-Based Routing)\n- PCIe TLP access control\n- QoS and traffic management\n\n**Technical Challenges:**\n\nP2P communication faces hardware constraints including PCIe Switch/Root Complex support, IOMMU configuration, and ACS (Access Control Services) limitations. Feasibility verification is an important outcome of this project. While PCIe specifications support P2P and the PCIe UltraScale+ IP provides necessary functionality, system-wide operation verification is required.\n\n**Project Completion Criteria:**\n\nDue to time constraints, complete implementation of all features may not be feasible within the GSoC period. Therefore, the project will be considered complete when simple demo applications are successfully running.\n\n- **Phase 1 Demo Application:** A simple demonstration where a register write (CQ) triggers P4 processing, which then performs a DMA write (RQ) to a designated memory region. The PCIe device is recognized by Linux with a custom Class Code (not as a NIC), demonstrating that P4 can control basic PCIe operations.\n\n- **Phase 2 Demo Application (if Phase 2 is achieved):** A working demonstration where data is transferred directly between two PCIe endpoints (e.g., two Alveo FPGAs) via PCIe Switch, bypassing host memory, with P4 controlling the routing.\n\nPhase 1 is definitely achievable and has academic and practical value in itself as \"applying P4 to non-network protocols.\" Phase 2 is a challenging goal built on Phase 1's foundation, expanding performance improvements and PCIe device application possibilities. Both outcomes have significance in presenting new application domains to the P4 community.\n\n**Expected outcomes**\n\n- **P4 Program for PCIe TLP Processing**\n  - Parsers/Deparsers for all TLP descriptor types (RQ/CQ/RC/CC)\n  - P4 program that enables demo applications to function\n  - Routing logic implementation (Optional - Phase 2)\n\n- **SystemVerilog Integration Logic**\n  - TLP preprocessing and postprocessing modules\n  - Top-level integration with PCIe UltraScale+ IP and Vitis P4 IP\n\n- **Demo Applications**\n  - Arbitrary PCIe Class Code configuration demo (Required - Phase 1)\n  - P2P communication demo (Optional - Phase 2)\n\n- **Documentation**\n  - Design documents\n  - Final project report\n\n- **All deliverables will be published as open source on GitHub**\n\n**Resources and References**\n\n- AMD Xilinx IPs:\n    - [PCIe UltraScale+ IP](https://www.amd.com/en/products/adaptive-socs-and-fpgas/intellectual-property/pcie4-ultrascale-plus.html): TLP transmission/reception, AXI Stream interface\n    - [Vitis Networking P4](https://www.amd.com/en/products/adaptive-socs-and-fpgas/intellectual-property/ef-di-vitisnetp4.html): Hardware execution of P4 programs\n\n- Related Projects by Mentor:\n    - [PCIe Subsystem for AMD Xilinx](https://github.com/iHalt10/pcie_subsystem): DMA transfer and TLP control using PCIe UltraScale+ IP\n    - [VNP4 Framework](https://github.com/iHalt10/vnp4_framework): Framework for integrating Vitis Networking P4 with OpenNIC\n    - [VNP4 Runtime Server](https://github.com/iHalt10/vnp4_runtime_server): P4Runtime-compliant gRPC server for Vitis Networking P4 IP\n\n---\n\n### <a name='project-2.4'></a> Project 2.4: P4MLIR Exporter: Generate Valid P4 from P4HIR [⤴️](#index)\n\n**Basic info**\n\n![diffi-medium] ![size-m]\n\n- Potential mentors\n  - Primary: Fabian Ruffy\n  - Support: Anton Korobeynikov\n- Skills\n  - Required: MLIR, C++\n  - Preferred: P4, P4C, compiler testing (lit, knowledge of golden testing)\n- Discussion thread: https://github.com/p4lang/p4mlir-incubator/pull/168\n- A bit more information: [slides](https://p4.org/wp-content/uploads/2024/11/204-P4-Workshop-P4HIR_-Towards-Bridging-P4C-with-MLIR-P4-Workshop-2024.pdf)\n\n**Alternative qualification task**\n\n- Please demonstrate your MLIR skills through contributions to any of the following projects:\n  - [P4MLIR](https://github.com/p4lang/p4mlir) itself.\n  - Any other MLIR-based compiler project.\n  - Your personal project is also fine.\n- Make sure your contributions could demonstrate your knowledge of MLIR concepts & internals.\n\n**Project description**\n\nThe P4MLIR project's goal is to provide an alternative compiler implementation for the P4 language, implementing using the LLVM MLIR framework (https://mlir.llvm.org/).\n\nP4MLIR provides a high-level MLIR dialect (`P4HIR`) for P4 compilers. This project targets a robust exporter specifically for the P4HIR dialect that can translate P4HIR back into valid, idiomatic P4 code. An exporter like this has several applications: transpiling (converting other languages into P4 code), debugging (checking the representation of a P4 program after transforming it), validation (ensuring transformed code remains semantically equivalent).\n\nThe goal of this GSoC project specifically is to build a reliable exporter pass (`export_to_p4.cpp`) that exports P4HIR to correct P4. The exporter must handle a wide range of P4 constructs, preserve annotations and parameter directions, and emit source compatible with `p4test`. The goal is to make the exporter usable as a standalone tool or as part of a compiler pipeline.\n\nSince P4MLIR is a moving target, the precise set of tasks will be finalized with mentors, but may include:\n\n- Extend the exporter coverage for missing P4 constructs (e.g., tables, actions, parsers, controls, enums, annotations).\n- Correctly handle corner cases of the language.\n- Improve type/parameter rendering, name stability, and declaration ordering. Make the P4 generation more idiomatic.\n- Add or refine exporter tests in `test/Translate` and ensure `p4test` can compile all example generated test programs.\n- Integrate the exporter and the reference file generation with existing CMake/lit workflows.\n\n**Expected outcomes**\n\n- Full coverage of all P4 programs in the P4HIR test suite.\n- A robust P4 exporter that can handle export the IR of complex P4 programs, such as [dash-pipeline-v1model-bmv2.p4](https://github.com/p4lang/p4c/blob/main/testdata/p4_16_samples/dash/dash-pipeline-v1model-bmv2.p4) or [fabric.p4](https://github.com/p4lang/p4c/blob/main/testdata/p4_16_samples/fabric_20190420/fabric.p4).\n- Documentation of exporter behavior, limitations, and usage.\n\n**Resources**\n\n- P4MLIR: https://github.com/p4lang/p4mlir\n- P4C: https://github.com/p4lang/p4c\n- MLIR: https://mlir.llvm.org/\n---\n\n### <a name='project-3.1'></a> Project 3.1: Alkali-P4MLIR: Bridging P4 and SmartNICs Through MLIR Dialect Conversion Between Alkali IR and P4MLIR. [⤴️](#index)\n\n![diffi-medium] ![size-m]\n\n**Basic info**\n\nPotential mentors\n+ Primary: Jiaxin Lin, Zhiyuan Guo\n+ Support: Anton Korobeynikov, Bili Dong \n\nSkills\n+ Required: [MLIR](https://mlir.llvm.org/)\n+ Preferred: P4, P4C, P4MLIR\n+ Discussion thread: TBD\n\n**Alternative qualification task**\n\nPlease demonstrate your MLIR skills through contributions to any of the following projects:\n+ [P4MLIR](https://github.com/p4lang/p4mlir-incubator) or [Alkali](https://github.com/utnslab/Alkali) itself.\n+ Any other MLIR-based compiler project.\n+ Your personal project is also fine.\nMake sure your contributions demonstrate your knowledge of MLIR concepts & internals.\n\n**Project description**\n\nAlkali(published at NSDI'25) is a compiler infrastructure for SmartNICs, delivering both functional and performance portability across a wide range of SmartNIC hardware. It centers on a unified intermediate representation (IR), a common set of optimization and transformation passes, and an automated network-application parallelization pipeline. Currently, the Alkai repo contains a frontend for C, and code generation for the following backends: Verilog(FPGA), MicroC(Netronome), and LLVM(ARM DPDK/RiscV).\nThis project aims to extend the existing Alkali infrastructure to support the P4 front-end language and the P4-based SmartNIC backend.\n\n<img width=\"700\" alt=\"image\" src=\"assets/alkali-p4mlir-alkali.png\">\n\nThere is a P4-specific MLIR dialect [P4HIR](https://github.com/p4lang/p4mlir-incubator), which implements dialect operations corresponding to P4 constructs and can be used to support the P4 front-end language and the P4-based SmartNIC backend in Alkali. In this project, instead of individually translating P4 sources to and from multiple SmartNIC programming languages (e.g., Verilog, microC), P4 programs could first be converted into P4MLIR and then transformed via operator-to-operator conversion to and from the Alkali IR. As both representations are defined within the MLIR framework, the conversion process can be semantically preserving, incremental, and engineering-maintainable, with support from the MLIR infrastructure.\n\nIn the world of MLIR, those language-to-language translations are modeled within the framework of [dialect conversion](https://mlir.llvm.org/docs/DialectConversion/). The major goals of this project include building the dialect conversion passes for both directions: 1) a pass to convert the P4MLIR into Alkali IR, which effectively enables programming diverse SmartNIC hardware using P4, and 2) a pass to convert Alkali IR into P4MLIR, which effectively enables the general Alkali programs and optimization passes on P4-enabled SmartNIC pipelines. \n\nThe precise set of tasks within the project includes:\n- Implementation of dialect conversion components, including type conversions, static operator conversions, control flow conversion, etc.\n- Implement an analysis conversion pass from `P4HIR` to `ep2` dialect.\n- Implement an analysis conversion pass from `ep2` to `P4HIR` dialect.\n  + Implementation of analysis passes, dynamically deciding which operations are legalizable from Alkali IR to P4.\n  + Implementation of the pre-conversion transformation pipeline within Alkali IR, including applying the existing passes and building new transformation passes.\n  + Implementation of generic P4 performance model within Alkali.\n  + Integration of the Alkali compiler optimization pipeline for `P4HIR` target. \n\nAs both P4MLIR and Alkali are experimental and under active development, the dialect interface, including operator definitions, analysis and optimization passes, and other parts, could be changed along with the development of the project to fit the project's needs. The exact list of tasks is to be determined with mentors.\n\n**Expected outcomes**\n\n+ Implementation of the bi-directional dialect conversion pass.\n+ Document the changes made.\n\n**Resources**\n\n- Alkali: https://github.com/utnslab/Alkali\n- Alkali Paper: https://www.usenix.org/conference/nsdi25/presentation/lin-jiaxin \n- P4MLIR: https://github.com/p4lang/p4mlir\n- P4C: https://github.com/p4lang/p4c\n- MLIR: https://mlir.llvm.org/\n\n---\n\n### <a name='project-3.2'></a> Project 3.2: Tutorial documentation for P4-SpecTec: A P4 specification mechanization framework [⤴️](#index)\n\n**Basic info**\n\n![diffi-medium] ![size-m]\n\n- Potential mentors\n  - Primary: Jaehyun Lee\n  - Support: -\n- Skills\n  - Required: Git, OCaml\n  - Preferred: Technical writing, Docker, background in programming languages\n- Discussion thread: GitHub issue tracker, Zulip\n\n**Alternative qualification task**\n\n- The P4C compiler has an existing issue regarding compile-time known-ness of directionless action parameters: https://github.com/p4lang/p4c/issues/5405. The same issue is also present in P4-SpecTec. The current mechanized specification blindly treats directionless parameters as compile-time known, without proper checking of whether the directionless parameter is for an action.\n- Create a PR to P4-SpecTec that resolves this issue by amending the mechanized specification to properly check for action parameters.\n\n**Project description**\n\n[P4-SpecTec](https://github.com/kaist-plrg/p4-spectec/tree/concrete) is a framework for mechanizing the P4 language specification. Unlike the current official P4-16 language specification which is written in natural language, P4-SpecTec provides a specification language for formally and mechanically defining the syntax and semantics of P4. This approach offers several benefits.\n\n- Ambiguities in natural language specifications can be avoided.\n- The specification can be executed and tested against actual P4 programs, thus giving assurance on its correctness.\n- The specification can also be processed and transformed into various backend representations. For instance, P4-SpecTec currently offers a [specification document backend](https://kaist-plrg.github.io/p4-spectec/P4-16-spec-new.html) that generates a human-readable specification document from the formal specification.\n\nThe goal of P4-SpecTec is to eventually augment, or even replace, the current official P4-16 language specification. For this vision to be realized, it is crucial that P4 developers and researchers can easily understand and use P4-SpecTec. Thus, the goal of this project is to create **comprehensive tutorial documentation** for P4-SpecTec.\n\nTo proivde an intuitive understanding of what *mechanized specification* is and how P4-SpecTec works, consider the following example. The snippet below shows an actual mechanized specification for typing P4 conditional statements:\n\n```plaintext\nsyntax conditionalStatement =\n  | IF `( expression ) statement\n  | IF `( expression ) statement ELSE statement\n\nrelation Stmt_ok:\n  cursor typingContext flow |- statement : typingContext flow statementIR\n  hint(input %0 %1 %2 %3)\n  hint(prose_in \"typing\" %3#\", under cursor\" %0#\", typing context\" %1#\", and abstract control flow\" %2)\n  hint(prose_out \"\\nthe typing context\" %4#\",\\nthe abstract control flow\" %5#\",\\nand the typed statement\" %6)\n\nrulegroup Stmt_ok/conditionalStatement {\n\n  rule Stmt_ok/non-else:\n    p TC f |- IF `( expression_cond ) statement_then\n            : TC f (IF `( typedExpressionIR_cond ) statementIR_then)\n    ---- ;; type check condition expression\n    -- Expr_ok: p TC |- expression_cond : typedExpressionIR_cond\n    ---- ;; fetch annotation\n    ---- ;; the condition must be a boolean type\n    -- if typeIR_cond = $type_of_typedExpressionIR(typedExpressionIR_cond)\n    -- if BOOL = $canon_typeIR(typeIR_cond)\n    ---- ;; check then statement\n    -- Stmt_ok: p TC f |- statement_then : TC_then f_then statementIR_then\n\n  rule Stmt_ok/else:\n    p TC f |- IF `( expression_cond ) statement_then ELSE statement_else\n            : TC f_post (IF `( typedExpressionIR_cond ) statementIR_then\n                       ELSE statementIR_else)\n    ---- ;; type check condition expression\n    -- Expr_ok: p TC |- expression_cond : typedExpressionIR_cond\n    ---- ;; fetch annotation\n    ---- ;; the condition must be a boolean type\n    -- if typeIR_cond = $type_of_typedExpressionIR(typedExpressionIR_cond)\n    -- if BOOL = $canon_typeIR(typeIR_cond)\n    ---- ;; check then and else statements\n    -- Stmt_ok: p TC f |- statement_then : TC_then f_then statementIR_then\n    -- Stmt_ok: p TC f |- statement_else : TC_else f_else statementIR_else\n    -- if f_post = $join_flow(f_then, f_else)\n\n}\n```\n\nThe above specification formally defines what is described in Section 12.6 of the current language specification:\n\n> The conditional statement uses standard syntax and semantics familiar from many programming languages. However, the condition expression in P4 is required to be a Boolean (and not an integer).\n\nThe mechanized specification is written in terms of inference rules, where each rule corresponds to a small fragment of the overall specification. Rule `non-else` specifies how to type-check an `if` statement without an `else` branch, while rule `else` specifies that of an `if-else` statement. An inference rule is comprised of inputs, premises (the lines prefixed with `--`), and outputs (or results). For the `non-else` rule, the inputs are the typing context `TC`, the cursor `p` indicating the current scope, the return indicator `f`, and the statement `IF ( expression_cond ) statement_then`. Given these inputs, the premises specify the conditions that must hold for the output to be derived. In this case, the premises require that the condition expression type-checks to a Boolean type, and that the `then` statement also type-checks. If these premises are satisfied, we can conclude that the entire `if` statement type-checks as the specified output. \n\n<img width=\"700\" alt=\"image\" src=\"assets/p4spectec.jpg\">\n\nAdditionally, because the specification itself is written in a specification language, it can be executed and tested. That is, if we implement an interpreter for the specification language, we can run the above specification on actual P4 programs. For a mechanized specification of the P4 language type system, this enables type-checking real P4 programs against the formal specification. P4-SpecTec also specifies the dynamic semantics of P4, making it possible to execute P4 programs for a given input packet.\n\nFinally, the specification can be transformed into a human-readable prose document, as illustrated below:\n\n<img width=\"700\" alt=\"image\" src=\"assets/p4spectec-prose.jpg\">\n\nAlthough P4-SpecTec already provides above features, it is currently difficult for new users to get started with P4-SpecTec due to the lack of tutorial documentation. Thus, in this project, we will create tutorial documentation that helps new users understand what mechanized specification is, how P4-SpecTec works, and how it can be used to extend or modify the P4 language specification.\n\nAs a reference, Wasm-SpecTec, a mechanization framework for the WebAssembly (Wasm) language, is already an official Wasm specification authoring toolchain. It includes a hands-on tutorial that guides users through specifying a small subset of Wasm, called nano_wasm. This tutorial walks users through the entire process of writing a mechanized specification, executing it, and generating a human-readable specification document. Inspired by this approach, we will develop similar tutorial documentation for P4-SpecTec, starting with defining a small subset of P4, named nano-P4.\n\nThe tutorial documentation is expected to include hands-on examples for nano-P4, as well as Docker images to help users easily set up and use P4-SpecTec.\n\n**Expected outcomes**\n\n- A mechanized specification for nano-P4 using P4-SpecTec.\n- Tutorial documentation for P4-SpecTec, describing how to specify nano-P4, execute the specification, and generate a specification document.\n- Docker images for easy setup and usage of P4-SpecTec.\n\n**Resources**\n\n- P4-SpecTec repository: https://github.com/kaist-plrg/p4-spectec/tree/concrete\n- P4 Developer Day talk on P4-SpecTec: https://youtu.be/2BhqyE7c-Pw?si=NWfp5JAg7nmi8ise\n- Reference project: Wasm-SpecTec\n  - https://github.com/Wasm-DSL/spectec\n  - https://github.com/Wasm-DSL/spectec/tree/main/spectec/doc\n\n---\n### <a name='project-3.3'></a> Project 3.3: Integrating P4-based In-Network Machine Learning framework into P4Pi [⤴️](#index)\n\n**Basic info**\n\n![diffi-medium] ![size-m]\n\n- Potential mentors\n  - Primary: Peng Qian\n  - Support: -\n- Skills\n  - Required: Python, P4, Git, Bash, Programmable data planes, Basic Linux networking  \n  - Preferred: Machine Learning basics (training/inference workflows) p4c, p4c-dpdk\n- Discussion thread: GitHub issue tracker, Zulip\n\n**Alternative Qualification Task**\n\n- Complete an end-to-end [Planter](https://github.com/In-Network-Machine-Learning/Planter) workflow, including data loading, training an existing ML module, automatic generation of target-specific P4 dataplane code, and deployment on a BMv2 environment for functional testing and evaluation.\n\n**Project Description**\n\n[P4Pi](https://github.com/p4lang/p4pi) is a Raspberry Pi–based integrated P4 environment that has been widely used for teaching and research on programmable data planes. It provides a low-cost and reproducible platform for experimenting with P4 programs and software switches.\n\nWhile P4Pi is well suited for teaching traditional P4-based packet processing, it currently lacks native support for machine-learning-enhanced networking workflows. [Planter](https://github.com/In-Network-Machine-Learning/Planter) is an in-network machine learning framework that enables training and inference of lightweight ML models close to the data plane. Planter adopts a modular, target-oriented design that supports mapping ML models to different programmable datapath targets and automatically generates target-specific P4 dataplane logic from trained models.\n\nThis project proposes to integrate P4-based in-network machine learning into P4Pi by incorporating Planter into the existing P4Pi software stack.\n\n**Benefits to the Community**\n\n- Adds native support for in-network machine learning to P4Pi  \n- Enables hands-on teaching of P4 and ML co-design on low-cost hardware  \n- Lowers the barrier for students and researchers to explore ML-assisted networking with P4  \n- Provides reusable examples and documentation for research prototyping  \n\n\n**Work Plan** \n\n**1. Planter–P4Pi Target Integration and p4c-dpdk Support**\n\n- Extend Planter’s existing `src/targets` abstraction by adding a new target adapter for the p4c-dpdk backend.\n- Implement automatic target-specific P4 code generation for the p4c-dpdk backend, enabling Planter-generated ML logic to be compiled and executed via the existing p4c-dpdk toolchain.\n- For each supported ML module, develop corresponding target-level test code to automatically validate correctness and compatibility with the p4c-dpdk datapath.\n\n\n**2. Extension of In-Network ML Algorithm Modules**\n\n- Extend Planter’s ML algorithm library by implementing one to two additional ML modules that have been identified in prior Planter-related research as promising candidates for further exploration.\n- Integrate these new ML modules into the existing Planter workflow, including model configuration, code generation, and target-specific mapping.\n\n\n**3. P4Pi-Based DPDK Software Switch Examples**\n\n- Develop end-to-end example applications on the P4Pi platform that demonstrate ML-assisted packet processing using a DPDK-based software switch.\n- Validate that ML inference results are correctly reflected in P4 control-plane updates and datapath behavior.\n\n\n**4. System Configuration, Packaging, and Automation**\n\n- Develop setup scripts and configuration files to automate deployment of the integrated Planter–P4Pi environment on Raspberry Pi.\n- Package Planter as an integrated component of the P4Pi system, including a pre-configured P4Pi system image for out-of-the-box experimentation.\n\n**5. Testing, Documentation, and Teaching Materials**\n\n- Develop teaching-oriented examples and step-by-step lab exercises (e.g., flow classification, anomaly detection).\n- Write clear documentation describing the system architecture, usage workflow, and extension points for future research and teaching.\n\n**Deliverables**\n\n- A P4Pi system image with Planter integrated, enabling out-of-the-box in-network ML experiments  \n- At least two end-to-end in-network ML example applications on P4PI platform\n- Automated setup and configuration scripts  \n- Teaching-oriented documentation and tutorials  \n\n\n**References**\n\n1. P4Pi: A Raspberry Pi–based P4 Teaching and Research Platform.  \n   https://github.com/p4lang/p4pi\n\n2. Planter: In-Network Machine Learning Framework.  \n   https://github.com/In-Network-Machine-Learning/Planter\n\n3. p4c-dpdk Backend Documentation and Source Code.  \n   https://github.com/p4lang/p4c/tree/main/backends/dpdk\n---"
  },
  {
    "name": "The Libreswan Project",
    "slug": "the-libreswan-project",
    "tagline": "Encrypting the Internet with IKE / IPsec VPN",
    "description": "Libreswan implements the IKE and IPsec standards for VPN.  These standards have been created and are still maintained at the Internet Engineering Task Force (IETF) in the IPsecME Working Group.  Libreswan is used as a remote access VPN as well as site-to-site and cloud encryption.",
    "ideas_url": "https://github.com/libreswan/libreswan/wiki/GSoC-2026-Code-Project-Ideas",
    "website_url": "https://libreswan.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "kernel",
      "nss",
      "RFCs",
      "libevent"
    ],
    "topic_tags": [
      "vpn",
      "ipsec",
      "ikev2"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/the-libreswan-project",
    "ideas_content": "[Libreswan](http://github.com/libreswan) is an [Internet Key\nExchange](https://www.rfc-editor.org/rfc/rfc7296.html) (IKE)\nimplementation that runs on Linux, FreeBSD, NetBSD and OpenBSD.\n\nWhile the original IKE and IPsec protocols were drafted in 1998, the\nneed to deal with an ever changing and increasingly hostile world,\ndrives the continuous evolution of these standards.  New features,\nsuch as hybrid post-quantum key exchange, are being added; while old\nfeatures, such as support for weak cryptographic algorithms are been\nremoved.  For more background on Libreswan see the [History\nPage](./History).\n\nThe Project Ideas listed below have been selected by Libreswan's core\ndevelopers with this evolution in mind.  They provide both a technical\nchallenge, and a way to participate in The Internet's development.\nThe mentors also have a personal interest in seeing these projects\nthrough to completion.\n\nIf you see a project that looks interesting then see the [Contributor\nGuidance](./GSoC-Contributor-Guidance) for next steps.  If you just\nhave questions, then please feel free to contact us; either on the\n[developer mailing\nlist](https://lists.libreswan.org/mailman/listinfo/swan-dev) or the\n**\\#libreswan** channel on the **LiberaChat IRC** network.  You can\nalso email **gsoc at libreswan.org** which is not public.\n\nIt isn't a requirement at you pick one of the ideas below - we also\nwelcome new ideas.  For instance, additional draft RFCs that could\nform the basis of a project can be found\n[here](https://datatracker.ietf.org/wg/ipsecme/documents/))!\n\n## Add Support For Announcing Authentication Methods To Libreswan\n\n**Required Skills:** C, UNIX programming\n\n**Preferred Skills:** Network protocols, Cryptographic fundamentals, RFC interpretation\n\n**Libreswan Mentors:** Andrew Cagney, Paul Wouters\n\n**Project size:** 175 hours\n\n**Difficulty:** Medium\n\n**Draft RFC:** [Announcing Supported Authentication Methods in IKEv2](https://tools.ietf.org/html/draft-smyslov-ipsecme-ikev2-auth-announce)\n\n### Description\n\nCurrently, during an IKEv2 negotiation, both peers will select the\npeer's authentication method independently.  These authentication\nmethods might not be the same.  Depending on the authentication method\nsupport received from the peer, adjust the authentication if multiple\nare supported.  Additionally, if the authentication method uses\ncertificates, filter the allowed authentication methods based on the\nalgorithms used in the certificate chain.\n\nPlease note that this is an internet standards draft.  Someone\nimplementing this might find issues with the draft protocol for which\nthey would need to communicate with the author of the draft to\nresolve.\n\nThe deliverables are:\n\n- addition to Libreswan's configuration (ipsec.conf), including\n  documentation (ipsec.conf.8)\n\n- modifications to negotiate the new mechanism\n\n- modifications to select the applicable authentication method\n\n- additions to the test-suite\n\nThe proposal should address each of these areas.\n\n\n## Use all exchanged messages when computing the authentication MAC\n\n**Required Skills:** C, UNIX programming\n\n**Preferred Skills:** Network protocols, Cryptographic fundamentals, RFC interpretation\n\n**Libreswan Mentors:** Andrew Cagney, Paul Wouters\n\n**Project size:** 175 hours\n\n**Difficulty:** Medium\n\n**Draft RFC:** [Downgrade Prevention for the Internet Key Exchange Protocol Version 2 (IKEv2)](./https://datatracker.ietf.org/doc/draft-ietf-ipsecme-ikev2-downgrade-prevention)\n\n### Description\n\nIKEv2, when authenticating a peer, computes the MAC (message\nauthentication code) using only two of the four messages that have\nbeen exchanged during the IKE negotiation.  This proposed RFC adds an\nextension so that an authenticated peer uses all four of the exchanged\nmessages in the MAC calculation.\n\nPlease note that this is an internet standards draft.  Someone\nimplementing this might find issues with the draft protocol for which\nthey would need to communicate with the author of the draft to\nresolve.\n\nThe deliverables are:\n\n- addition to Libreswan's configuration (ipsec.conf), including\n  documentation (ipsec.conf.8)\n\n- modifications to negotiate the new mechanism\n\n- modifications to (conditionally) compute the new MAC\n\n- additions to the test-suite\n\nThe proposal should address each of these areas.\n\n\n## Add HOST-TO-HOST support on BSD\n\n**Required Skills:** C, UNIX programming\n\n**Preferred Skills:** Network protocols, BSD networking, PFKEY_V2\n\n**Mentors:** Andrew Cagney\n\n**Project size:** 90 hours\n\n**Difficulty:** Medium\n\n### Description\n\nWith a host-to-host connection between two peers, all traffic (with\nthe exception of IKE control messages) is encapsulated in ESP.\n\nWhile this feature is supported on Linux, support is missing in\nLibreswan on the BSDs (FreeBSD, NetBSD, and OpenBSD).\n\nThe deliverable are:\n\n- modification to the PFKEY V2 code to support host-to-host\n  connections on at least one of FreeBSD or NetBSD\n\n- additions to the test-suite\n\n- (if time permits) modifications and test-suite additions for the\n  remaining BSDs.\n\nThe proposal should address each of these areas.\n\n\n## Improve the ACQUIRE to IKE policy lookup by making use of the `policy.index`\n\n**Required Skills:** C, UNIX programming\n\n**Preferred Skills:** Network protocols, Linux networking, XFRM\n\n**Mentors:** Andrew Cagney, Paul Wouters, Tuomo Soini\n\n**Project size** 175 hours\n\n**Difficulty** Medium\n\n### Description\n\nIPsec policies can be installed in the kernel to be \"on demand\".  When\na packet hits the IPsec subsystem and it matches an \"on demand\"\npolicy, the user-land IKE daemon is notified by the kernel so it can\ninitiate an IKE connection to the target destination.  The\nnotification, which is called an `acquire`, contains the protocol, and\nsource and destination addresses.\n\nThe `acquire` notification contains an additional field called\n`policy.index`.  Currently, when an \"on demand\" policy is installed in\nthe kernel, this field is set to `0`.  This means that when the IKE\ndaemon receives an `acquire` from the kernel, it has to do its own\nsource/dest based lookup to determine which connection should be\ninitiated.  The goal of this project is to change this by assigning a\nunique `policy.index` number to each connection with an \"on demand\"\npolicy, and install that in the kernel.\n\nOne complication is with connections that are part of an\n(opportunistic) group.  As part of handling the `acquire` these\nconnections clone themselves into new connections.  Since these clones\ncannot share the `policy.index` these policies need to be modified\nbefore being resend to the kernel.\n\nThe deliverables are:\n\n- modify the XFRM code to specify a unique policy.index in the kernel,\n  and use the policy.index value when looking for connections\n\n  the `reqid` may be a useful unique value\n\n- modify commands to display this unique value\n\n  and as needed, update the test-suite\n\n- produce a test result with the change showing no regressions\n\n  Since the change is under the hood, and affects all Linux tests,\n  specific test cases may not be needed."
  },
  {
    "name": "Cuneiform Digital Library Initiative (CDLI)",
    "slug": "cuneiform-digital-library-initiative-cdli",
    "tagline": "Curating humanity’s earliest written history",
    "description": "The Cuneiform Digital Library Initiative (CDLI) is a global collaboration of Assyriologists, museum curators, and historians working together to make the world’s earliest written records accessible online. CDLI focuses on cuneiform inscriptions dating back to the very beginning of writing around 3350 BC. Today, more than 500,000 such artifacts are held in museums and private collections worldwide, and CDLI has already digitally catalogued over 350,000 of them, helping researchers and the public explore humanity’s oldest written heritage.",
    "ideas_url": "https://gitlab.com/cdli/framework/-/wikis/Google-Summer-of-Code-GSoC-2026-Cuneiform-Digital-Library-Initiative-(CDLI)-ideas-list",
    "website_url": "https://cdli.earth",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "mysql",
      "javascript",
      "docker",
      "php",
      "SCSS"
    ],
    "topic_tags": [
      "data",
      "linguistics",
      "History",
      "culture",
      "assyriology"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/cuneiform-digital-library-initiative-cdli",
    "ideas_content": "On this page you will find project ideas for Google Summer of Code 2026. We currently offer four projects in total: 2 350-hour projects and 2 175-hour projects. You can learn more about these projects by joining the community and discussing them with mentors\n\n## Disclaimer: AI Usage and Community Participation\n\nCDLI expects contributors to be transparent about any use of AI tools during the proposal and contribution period. AI can be used as a learning or productivity aid, but all submitted work must be reviewed, understood, and explainable by the contributor. Selection decisions focus on the contributor’s understanding, engagement, and ability to actively participate in the community.\n\n- Any use of AI tools must be disclosed by the contributor\n- Raw or unreviewed AI-generated content is not acceptable\n- Contributors must be able to clearly explain any code or text they submit\n- Active participation in the CDLI community is required (asking questions, discussions, communication with mentors)\n- Proposals are only one part of evaluation; engagement and demonstrated understanding carry significant weight\n\n## Page Contents\n\n[1. Getting Started](https://gitlab.com#getting-started)[2. About the Cuneiform Digital Library Initiative](https://gitlab.com#2-about-the-cuneiform-digital-library-initiative)[3. List of Potential Project Ideas](https://gitlab.com#3-list-of-potential-project-ideas)-\n[4. 350 Hour Projects](https://gitlab.com#350-hour-projects) -\n[5. 175 Hour Projects](https://gitlab.com#175-hour-projects) [6. Mentors](https://gitlab.com#6-mentors)\n\n## 1. Getting Started\n\n*Please go through Getting Started carefully. If you get blocked, feel free to reach out to Nisheal.*\n\n-\nJoin our community and GSoC contact page:\n\n\n[Join the Community and GSoC Contact](https://gitlab.com/cdli/framework/-/wikis/Join-the-Community-and-GSoC-Contact) -\nRead our proposal guide:\n\n\n[Writing a GSoC proposal for CDLI](https://gitlab.com/cdli/framework/-/wikis/Writing-a-GSoC-proposal-for-CDLI)\n\nOnce you’ve joined the community, feel free to post your questions in the **#gsoc** channel.\n\n## 2. About the Cuneiform Digital Library Initiative\n\nThe Cuneiform Digital Library Initiative (CDLI) enables the collection, preservation, and accessibility of image files, textual annotation, and metadata for ancient Near Eastern artifacts inscribed with cuneiform. With over 334,000 artifacts, CDLI hosts approximately two-thirds of all known cuneiform sources worldwide. Data is publicly available at [https://cdli.earth](https://cdli.earth) and serves scholars, students, museum staff, and learners.\n\nCDLI is central to Assyriological research, functioning as a data hub and repository. The platform receives ~3,000 monthly users across 10,000 sessions and 100,000 pageviews, with 78% returning visitors.\n\nCDLI brings together developers, language scientists, ML engineers, and cuneiform specialists to build tools for linguistic analysis and translation. Current efforts focus on framework modernization and machine translation of ancient languages using NLP and Linked Open Data.\n\n## 3. List of Potential Project Ideas\n\nThis year we offer a small set of focused projects. We look forward to shaping them together based on contributor interests and open needs.\n\n### 350 Hour Projects\n\n### 175 Hour Projects\n\n## 4.1 Revamping CDLI Mobile App (React Native) – 350h\n\n**Mentors:** [Daksh Paleria](https://gitlab.com#daksh-paleria) (Ex GSoC | SDE, Blinkit), [Nisheal John](https://gitlab.com#nisheal-john) (Head of Engineering | SellerGeni AI)\n\nDifficulty: Medium - Hard\n\nProject Size: 350 hours\n\n#### Project Overview\n\nThe Cuneiform Digital Library Initiative (CDLI) currently maintains separate Android and iOS tablet applications that allow users to explore curated cuneiform tablet collections, view artifact images, read metadata, and access featured highlights. These applications are actively used by researchers, educators, and the public.\n\nOver time, maintaining two independent mobile codebases has become increasingly difficult. Feature development is duplicated, bug fixes must be applied twice, and keeping both platforms in sync requires significant effort.\n\nThis project proposes rebuilding the CDLI tablet applications using React Native, enabling a single shared codebase for Android and iOS while preserving existing functionality. At the same time, the application will be tightly integrated with the CDLI framework and admin panel so tablet content can be managed centrally and delivered directly to mobile users.\n\nThe result will be a production-ready cross-platform tablet application backed by a unified content management pipeline.\n\n#### Project Goals\n\nBuild a single React Native application for Android and iOS that replaces the existing native apps and connects directly to the CDLI framework and admin panel, allowing curators to manage tablet content centrally while users consume it through a modern mobile experience.\n\n#### Deliverables\n\nThe student will implement a React Native application that allows users to browse curated tablet collections, swipe between artifacts, view high-resolution tablet images with zoom support, and read associated metadata in an interactive reading panel.\n\nThe application will provide:\n\n- Browsing of curated tablet collections\n- Swipe-based navigation between artifacts\n- High-resolution image viewing with pinch-to-zoom\n- Search for tablets by title or keywords\n- Highlighted featured content\n- Sharing tablet links through messaging, email, and social apps\n- Onboarding and About screens\n- Help and Feedback submission\n- Local image caching for performance\n- Responsive layouts for phones and tablets in portrait and landscape\n- Proper navigation handling including Android back behavior\n- Splash screen and branding\n- Graceful handling of poor network connectivity\n\nThe same project also includes building and integrating the framework admin panel used to manage tablet content. This allows curators and contributors to create, edit, and delete tablet entries from a web interface.\n\nAdmin panel functionality includes:\n\n- Managing tablet entries (create, update, delete)\n- Uploading and displaying artifact images\n- Editing tablet metadata, descriptions, and publish dates\n- Input validation and formatting\n- Listing entries with pagination and search\n- Ordering content by date for mobile delivery\n- Returning structured JSON responses consumed by the mobile app\n\nUpdates made through the admin panel will immediately reflect in the React Native application without requiring redeployment.\n\n#### Expected Outcomes\n\nBy the end of GSoC:\n\n- CDLI will have a single React Native application replacing both Android and iOS apps\n- All existing user-facing functionality will be preserved\n- Tablet content will be centrally managed through the admin panel\n- Mobile apps will consume live framework data\n- Maintenance overhead will be significantly reduced\n- Future development will be faster and easier\n\n## 4.2 Search & Discovery Improvements – 350h\n\n**Mentors:** [Vedant Wakalkar](https://gitlab.com#vedant-wakalkar) (Ex GSoC | SDE, Jio)\n\n**Difficulty:** Medium - Hard\n\n**Project Size:** 350 hours\n\n### Project Overview\n\nThe Main search CDLI Framework currently uses Elasticsearch for search inside its CakePHP backend. While it works, indexing is heavy, updates are inefficient, and many search pages still depend on database queries. Even small data changes can trigger large reindex jobs, making the system slower and harder to scale.\n\nThis project modernizes CDLI search by migrating to OpenSearch and redesigning indexing to be incremental and event driven. Instead of rebuilding full indexes, only the records affected by a change will be updated. At the same time, more application data will be moved into OpenSearch so search and listing views can be served directly from the index rather than the relational database.\n\nIt involves redesigning how data flows from the database into the search layer, refactoring backend APIs, and updating frontend search behavior so OpenSearch becomes the primary system for searching, filtering, sorting, and pagination. The database remains the source of truth for writes and detailed records.\n\n### Project Goals\n\n- Migrate from Elasticsearch to OpenSearch while preserving existing search functionality.\n- Redesign indexing to be incremental, so only changed records are updated instead of rebuilding large indexes.\n- Introduce event-driven synchronization using database create/update/delete events.\n- Move key searchable and display-ready data into OpenSearch, including:\n- core entity fields (publications, collections, proveniences, periods, inscriptions)\n- commonly used filters and sort fields\n- permission and visibility fields\n- related metadata needed to render search result pages without extra DB queries\n\n- Refactor backend search APIs so OpenSearch becomes the primary source for:\n- keyword search\n- filtering\n- sorting\n- pagination\n\n- Update frontend search views to consume the new APIs and fully rely on OpenSearch-powered results.\n- Prepare the architecture for future improvements such as relevance tuning, highlighted matches, autocomplete, and search suggestions.\n\n### Deliverables\n\n- OpenSearch integration with carefully designed index mappings for all major searchable entities.\n- Migration of existing Elasticsearch logic and query builders to OpenSearch.\n- A production-ready indexing pipeline that supports:\n- incremental updates\n- partial reindexing of related records when shared metadata changes\n- safe retries and idempotent operations\n\n- A background indexing process that reacts to database changes and updates only impacted OpenSearch documents.\n- Refactored backend search endpoints that fully use OpenSearch for search and listing pages.\n- Expanded OpenSearch documents that include denormalized fields required for UI display, filters, and sorting, reducing database dependency.\n- Frontend search updates to support faster filtering, pagination, and richer result presentation.\n- Developer documentation covering:\n- OpenSearch setup\n- index design\n- indexing workflows\n- reindexing strategies\n- local development environment\n\n\n### Expected Outcomes\n\n- Significantly faster search performance, with OpenSearch handling search workloads instead of the database.\n- Efficient, reliable indexing where only changed data is updated.\n- Reduced database load on search-heavy pages.\n- A cleaner and more maintainable search architecture.\n- A system ready for future scale, larger datasets, and advanced discovery features.\n- Clear documentation so contributors can extend search without deep coupling to database queries.\n\n### Required Skills\n\n- Strong backend development experience (PHP preferred, CakePHP a plus)\n- Familiarity with search engines (Elasticsearch or OpenSearch)\n- Experience with data modeling and indexing concepts\n- Experience with background jobs or event-driven systems is a plus\n\n## 5.1 CDLI MCP Server and Agent – 175h\n\n**Mentors:** [Jayanth Kumar](https://gitlab.com#jayanth-kumar) (IIT Bombay | CTO, Stealth), [Émilie Pagé-Perron](https://gitlab.com#emilie-page-perron) (Assyriologist & Digital Scholar | Engineer, Archaeology Data Service)\n\nDifficulty: Medium–Hard\n\nProject Size: 175 hours\n\n### Project Overview\n\nCDLI already provides a framework API client that gives programmatic access to its data. However, using this data in AI workflows still requires custom integrations and manual effort. This project aims to change that by building a Model Context Protocol (MCP) server on top of the existing client, turning CDLI into a set of discoverable tools that AI agents can use directly.\n\nThe MCP server will expose practical CDLI capabilities such as searching by artifact ID, transliteration text, period, or location, along with fetching related metadata like museum collections and bibliographic references. Instead of hardcoding integrations, agents will be able to discover these tools at runtime and call them when needed.\n\nTo demonstrate this in practice, a small demo agent using an open-source language model will be created. The agent will use MCP tools to answer CDLI-related questions, fetch transliterations and metadata, and export datasets. This enables scholars, students, and cultural heritage workflows to interact with CDLI using natural language while still receiving precise, structured data.\n\nThe outcome is a reusable MCP layer that makes CDLI easily accessible to AI systems and research tools.\n\n### Project Goals\n\n- Build a production-ready MCP server on top of the existing CDLI framework API client.\n- Expose CDLI functionality as a registry of tools that agents can discover and use in real time.\n- Support structured search and retrieval across common CDLI use cases such as artifact lookup, transliterations, periods, and proveniences.\n- Ensure tool responses are consistent and predictable, so language models can safely build on them.\n- Add pagination and batch support to handle large result sets efficiently.\n- Develop a lightweight agent that uses these tools to perform real research tasks, not just demos.\n\n### MCP Tools\n\n**Search**\n\nProvide full-text and filtered search using existing CDLI endpoints, including artifact IDs, transliteration text, period, and location. Results are returned in structured formats that agents can easily refine.\n\n**Access Metadata**\n\nAllow agents to fetch complete records or selected metadata fields, including linked information such as museum collections and bibliographic references. Support batch requests for multiple artifacts.\n\n**Export**\n\nEnable exporting search results or selected artifacts as JSON or CSV. Users can choose fields and generate citation-ready outputs for further study or sharing.\n\n### Deliverables\n\n- An MCP server built on top of the current CDLI API client.\n- MCP tools for search, metadata access (including links and references), and export.\n- Environment-based configuration and authentication.\n- Pagination, batching, and clear error handling across all tools.\n- A small demo agent powered by an open-source model that:\n- discovers MCP tools at runtime\n- makes structured calls for CDLI queries\n- turns tool responses into readable answers and exports\n\n\nExample workflows demonstrating:\n\n- summarizing groups of artifacts\n- retrieving transliterations across tablets\n- extracting timelines by region\n- generating bibliographic overviews\n\n### Expected Outcomes\n\n- CDLI becomes accessible through MCP for any compatible client, without custom integrations.\n- Users and agents can reliably search, retrieve, and export CDLI content in a standard way.\n- AI workflows gain grounded access to CDLI data instead of relying on hallucinated knowledge.\n- A working agent demonstrates real-world interaction with CDLI through MCP.\n- A strong foundation is created for future AI-powered CDLI applications and research tools.\n\n### Skills Required\n\n- TypeScript or Python\n- REST API integration\n- MCP server and tool design\n- JSON schema and input validation\n- Working with open-source language models\n- Understanding of search concepts like filtering and pagination\n- Linux and Docker fundamentals\n\n## 5.2 Scalable Email Infrastructure – 175h\n\n**Mentors:** [Vishv Kakadiya](https://gitlab.com#vishv-kakadiya) (Ex GSoC | SDE-2, Microsoft)\n\n**Difficulty:** Easy-Medium\n\n**Project Size:** 175 hours\n\n### Project Overview\n\nThe CDLI framework currently sends emails directly during web requests. This tightly couples application performance with SMTP availability, making email delivery fragile and hard to debug. There is also limited visibility into which emails were sent, failed, or retried, and templates are basic and inconsistent.\n\nThis project aims to redesign the email system into a reliable, background-driven pipeline with better templates, delivery tracking, and basic spam protection. The work will build on the existing Postfix relay setup and focus on practical improvements using mostly open-source tools.\n\nBy the end of the project, email will become a first-class, observable system rather than a side effect of user actions.\n\n### Project Goals\n\n- Move email sending out of the request lifecycle and into background jobs, ensuring user actions never block on SMTP delays or failures.\n- Introduce retry logic and structured failure handling so important emails are not silently dropped.\n- Improve email presentation through consistent layouts and responsive HTML templates, while maintaining plain-text fallbacks.\n- Provide basic analytics and visibility into email activity, including delivery status, failures, and backlog.\n- Add protection against abuse by rate-limiting sensitive email flows and enforcing consistent sender policies.\n- Strengthen operational reliability with health checks, clearer configuration errors, and better logging.\n\n### Deliverables\n\n- Background email processing using a queue (Redis or database-backed) and a dedicated worker.\n- Refactored application email flows to enqueue jobs instead of sending directly.\n- Retry support with backoff and a record of failed emails that can be reviewed or retried manually.\n- A shared email design system with reusable layouts for existing messages (welcome, password reset, admin notifications).\n- An admin-facing dashboard showing sent, failed, and pending emails, along with basic error details.\n- Rate limiting for password reset and similar endpoints to prevent spam or accidental floods.\n- Enforced sender rules to improve deliverability (single From domain with Reply-To support).\n- Improved Postfix configuration for safer relaying and TLS enforcement to the upstream SMTP provider.\n- Health checks for the mail pipeline and documentation covering setup, debugging, and common failure scenarios.\n\n### Expected Outcomes\n\n- Faster and more stable application behavior since email delivery no longer blocks user requests.\n- Higher email reliability through retries and clearer failure reporting.\n- Better-looking, consistent emails that improve user experience.\n- Increased transparency into email operations, making debugging and monitoring straightforward.\n- Reduced risk of spam, abuse, and misconfiguration-related outages.\n- A cleaner and more maintainable email architecture that can be extended in the future.\n\n### Skills Required / Preferred\n\n**Required**\n\n- PHP and basic CakePHP knowledge\n- SQL and database fundamentals\n- Docker and Linux basics\n\n**Preferred**\n\n- Experience with queues or background workers\n- Familiarity with Postfix or SMTP concepts\n- HTML email design\n- Logging or metrics systems\n- Basic security concepts such as rate limiting and input validation\n\n## 6. Mentors\n\n*Use the community communication channels to reach out to mentors.*\n\n-\n#### Émilie Pagé-Perron\n\nAssyriologist & Digital Scholar | Engineer, Archaeology Data Service\n\n\n[https://epageperron.info/](https://epageperron.info/) -\n#### Nisheal John\n\nEx GSoC | Head of Engineering, SellerGeni AI\n\n\n[https://github.com/NishealJ](https://github.com/NishealJ) -\n#### Jayanth Kumar\n\nIIT Bombay | CTO, Stealth\n\n\n[https://jaykmr.com/](https://jaykmr.com/) -\n#### Vishv Kakadiya\n\nEx GSoC | SDE-2, Microsoft\n\n\n[https://www.linkedin.com/in/vishv07/](https://www.linkedin.com/in/vishv07/) -\n#### Vedant Wakalkar\n\nEx GSoC | SDE-2, Jio\n\n\n[https://www.linkedin.com/in/karna98/](https://www.linkedin.com/in/karna98/) -\n#### Daksh Paleria\n\nEx GSoC | SDE, Blinkit\n\n\n[https://www.linkedin.com/in/daksh-paleria-606211190/](https://www.linkedin.com/in/daksh-paleria-606211190/) -\n**TBD by 18/02/26, Status: Shortlisting** -\n**TBD by 18/02/26, Status: Shortlisting**"
  },
  {
    "name": "Synfig",
    "slug": "synfig",
    "tagline": "Open-source 2D animation software",
    "description": "Synfig is a 2D open-source animation software. It is capable to produce vector artwork and also can work with bitmap images.\n\nThe main concept of Synfig is \"tweening\" - you can define object positions or shapes of vector objects at certain points of time and program will interpolate in-between frames automatically. You can also use bones to control your animation on higher level.\n\nWith Synfig you can easily create motion graphics and cut-out animations for product explanation videos, tutorial videos, and more.",
    "ideas_url": "https://github.com/synfig/synfig-docs-dev/blob/master/docs/gsoc/2026/ideas.rst",
    "website_url": "https://synfig.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "c++",
      "gtk",
      "gtkmm"
    ],
    "topic_tags": [
      "2d/3d graphics",
      "animation",
      "vector graphics"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/synfig",
    "ideas_content": ".. _ideas:\n\nIdeas List\n=====================\n\n\nThis year we plan to apply to Google Summer of Code. Currently we are looking for project ideas. If you are a contributor, you are welcome to explore existing project ideas towards the GSoC application phase. There are ways to reach out to mentors, and many projects have lists of newcomer friendly issues you can start from. Contributors are also welcome to propose their own project ideas.\n\nProjects Ideas\n--------------\n\nSynfig Android Version (350hrs)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n**Description:**\nThis project aims at providing a solid ground for a Synfig Android version. It aims to do so through two main parts.\n\n1- Prototype UI (Using Qt for android) that uses synfigapp and -in turn- synfig-core\n\nThere are two main goals here:\n1. To have a basic android UI for synfig working. \n2. While making this prototype certain parts of the synfig api would be fixed. Which would make SynfigApp and Synfig-Core able to be used with any other UI not just the current gtkmm UI (synfig-studio).\n\n2- Add more features to the UI\nSynfig is quite a huge application. Most likely this app would start with only very basic needed synfig features added. Then gradually adding more features from synfig-studio to the new prototype UI.\n\n**Where to begin:**\n\n1. Start out by understanding and gathering the basic features for animation in synfig. In your proposal include these features and expand on how you plan to include them. \n2. Research the available mobile/tablet animation apps and prototype a ui design using any ui design software (e.g. canva). This is not required but it will definetly help your proposal.\n\n\n**Expected outcome**\n\n- Prototype Synfig Android Version\n- Improved synfig-app and (possibly) synfig-core that can work with any other UI.\n\n**Difficulty:** Medium/High\n\n**Skills required/preferred:** C++, gtkmm, Qt, using Qt for Android\n\n**Possible mentor(s):** `Mohamed Adham <https://github.com/mohamedAdhamc>`_ , `Rodolfo Ribeiro <https://github.com/rodolforg>`_\n\n**Expected size of project:** 350 hours\n\nExporter to Spine file format (175hrs)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n**Description:**\n\nThe goal of this project is to implement a feature in Synfig Studio that enables exporting skeleton-based animations to the Spine file format.\nThis would allow users to seamlessly transfer their Synfig animations, those created using bone-based rigs and skeleton systems, to Spine for additional refinement or game engine integration.\nThis would involve creating an export function in Synfig that outputs the necessary JSON or binary format that Spine can read.\nThe project will ensure that all essential animation data, such as bone movements, and keyframe timing, are accurately preserved during the export.\nThus, users can leverage Synfig's powerful animation tools while taking advantage of Spine's advanced features, such as runtime support in various game engines.\n\n**Where to begin:**\n\n1. Check Synfig skeleton layer code\n2. Check Spine JSON format (https://en.esotericsoftware.com/spine-json-format)\n3. Try to add new menu option \"Export to Spine format\" to Skeleton layer, which should create basic Spine JSON file.\n\n**Expected outcome**\n\n* A fully functional export tool in Synfig Studio capable of converting skeleton-based animations into the Spine file format.\n\n* The exported Spine file should retain all key elements of the animation, including bones, mesh deformation, and animation keyframes.\n\n* The ability to open and refine the exported Spine animation in Spine's editor or integrate it directly into a game engine.\n\n* Plus: Import Spine file to Synfig :)\n\n**Difficulty:** Medium\n\n**Skills required/preferred:** Python (or C++), XML and JSON, understanding of Synfig's animation system, especially skeleton-based animation and bone rigs, and Synfig file format.\n\n**Possible mentor(s):** `Rodolfo Ribeiro <https://github.com/rodolforg>`_ , `Mohamed Adham <https://github.com/mohamedAdhamc>`_\n\n**Expected size of project:** 175 hours\n\n\nNew audio backend (175h)\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n**Description:**\n\nCurrently we use MLT++ as our audio playback framework, but we do not use none of its features but simple audio mixing (volume and delay).\nThe intention here is to replace it with its own backend: SDL (SDL_audio, specifically) in both versions: the classic SDL2 and the new SDL3.\n\n**Where to begin:**\n\n1. Check how to play audio from file with SDL2 AND SDL3.\n2. Take a look how we use audio in SoundProcessor class.\n3. Try to allow our both building systems to select what audio backend we want: none, MLT++, SDL2 or SDL3.\n\n**Expected outcome:**\n\n* Remove MLT++ dependency;\n\n* Be able to reproduce audios in SynfigStudio, but via SDL2 or SDL3 (choose in building/compilation time)\n\n* Be able to export video+audio via ffmpeg target, but via SDL2 or SDL3 (choose done in building/compilation time)\n\n**Dificulty:** Medium\n\n**Skills required/preferred:** C++, SDL2/SDL3 audio playback\n\n**Possible mentor(s):** `Rodolfo Ribeiro <https://github.com/rodolforg>`_ , `Mohamed Adham <https://github.com/mohamedAdhamc>`_\n\n**Expected size of project:** 175 hours\n\n2D Free-Form Deform (175h)\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n**Description:**\n\nAllow artist to set up a grid and animate by deforming on moving this lattice points.\n\n**Where to begin:**\n\n1. Check Skeleton Deformation layer works\n\n2. Check how handles work (duckmatic class)\n\n**Expected outcome:**\n\n* A new deformation layer by grid, not by bones.\n\n* Visual control points to deform.\n\n**Dificulty:** Medium\n\n**Skills required/preferred:** C++.\n\n**Possible mentor(s):** `Rodolfo Ribeiro <https://github.com/rodolforg>`_ , `Mohamed Adham <https://github.com/mohamedAdhamc>`_\n\n**Expected size of project:** 175 hours\n\n\nPropose a Project\n------------------\nIf you have a project idea, edit the \"Project Ideas\" section below by filling the required details and sending a pull request (this page is editable at  https://github.com/synfig/synfig-docs-dev/blob/master/docs/gsoc/2025/ideas.rst), even if you could not mentor (we will find a mentor).\n\n**Required information for project proposal**\n\n::\n\n    A descriptive title (175 or 350 hrs)\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    **Description**\n\n    A brief description about the project\n\n    **Expected outcome**\n\n    What benefit this deliver?\n\n    **Difficulty** Easy | Medium | High\n\n    **Skills required/preferred:** Knowledge Prerequisite\n\n    **Possible mentor(s):** Put your name if you are willing to mentor + other mentors.\n\n    **Expected size of project:** 90, 175 or 350 hours\n\n*Please mention the following as comment on your proposal pr*\n\n:Your name: :)\n:Your profile: github | linkedin | etc\n:Your role: I am a making this proposal as a <student | mentor | community member | contributor | etc>\n\nContacts\n--------\n\nhttps://www.synfig.org/contact/"
  },
  {
    "name": "Data for the Common Good",
    "slug": "data-for-the-common-good",
    "tagline": "Connect. Share. Discover.",
    "description": "Data for the Common Good is dedicated to building communities, platforms, and ecosystems that maximize the potential of data to drive discovery and improve human health. Headquartered in the Department of Pediatrics at the University of Chicago, our team of experts works with collaborators all over the world to connect and share useful, high-quality data between institutions, groups, and countries to increase opportunities for discovery.",
    "ideas_url": "https://chicagopcdc.github.io/GSoC/ideas",
    "website_url": "https://commons.cri.uchicago.edu",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "kubernetes",
      "reactjs",
      "terraform"
    ],
    "topic_tags": [
      "web",
      "health",
      "data",
      "infrastructure",
      "software"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/data-for-the-common-good",
    "ideas_content": "Instructions [here](https://chicagopcdc.github.io/GSoC/proposal).\n\nTitle |\nEnhancing the SMART on FHIR Backend for Patient-Controlled Data Sharing |\nDescription |\nThe goal of this project is to improve and extend the backend of a SMART on FHIR application that empowers patients to autonomously access, share, and manage their electronic health records (EHR). The application serves as a data interoperability layer, allowing users to seamlessly transfer their healthcare data to meet various needs, such as research participation, second opinions, or personal health tracking. |\nExpected Outcomes |\nOne or both of the following: Improving the integration with diverse FHIR servers and refining data transformation capabilities. Building APIs or plugins to support additional healthcare applications and third-party services. |\nSkills |\nJava, python |\nMentors |\nTBD - One of the Senior Developer in the team. |\nProject Size |\n350 hours |\nRating |\nmedium |\n\nTitle |\nEnhancing the SMART on FHIR Frontend for Patient-Controlled Data Sharing |\nDescription |\nThis project aims to improve the frontend user interface for a SMART on FHIR application that enables patients to autonomously access, manage, and share their electronic health records (EHR). The focus is on making the UI more intuitive, accessible, and user-friendly, ensuring a seamless experience for users connecting to the backend service. This project build and enhance last year project. |\nExpected Outcomes |\nExtend support to more EHR provider connections. |\nSkills |\nJavascript, Node |\nMentors |\nTBD - One of the Senior Developer in the team. |\nProject Size |\n350 hours |\nRating |\nmedium |\n\nTitle |\nEnhancing a FHIR Resource Tabular Viewer for Efficient Data Exploration |\nDescription |\nThis project aims to enhance a FHIR Resource Tabular Viewer, an application that transforms complex, nested FHIR data structures into an easy-to-navigate tabular format. This tool will allow users—such as researchers, clinicians, and developers—to efficiently search, filter, and analyze FHIR resources, improving accessibility and usability of healthcare data. This project build and enhance last year project. |\nExpected Outcomes |\nEnhanced resource management and visualization and extend support to more data source, like local file, and S3 buckets. |\nSkills |\nPython, Javascript |\nMentors |\nTBD - One of the Senior Developer in the team. |\nProject Size |\n350 hours |\nRating |\nmedium |\n\nTitle |\nEnhancing a Chatbot for Generating GraphQL and Custom Queries for Cohort Descriptions |\nDescription |\nThis project aims to enhance a chatbot powered by ChatGPT or another large language model (LLM) that allows users to describe a cohort of patients and automatically generates GraphQL queries or custom queries based on the input for the\n|\n\nImprove the GraphQL generator for simple and complex query conformed to PCDC data model Evaluation: evaluate the output against saved GraphQL queries (filterset) Develop GraphQL generator as a part of Interactive chatbot - Agent for capturing various user intent/needs and routing the requests to tools Tool 1: general inquiry Tool 2: Browsing documentation (currently in progress) Tool 3: Generating GraphQL Any function, that would be useful in cohort discovery\n\nTitle |\nData Density Heatmap Application |\nDescription |\nThe goal of this project is to develop a web-based heatmap visualization tool that represents the completeness and distribution of data across an entire dataset. The application will display data “density” by GraphQL node types and their specific attributes, enabling users to quickly identify areas with high or low data availability. This tool is intended to support researchers and data managers in assessing dataset quality and guiding curation efforts. |\nExpected Outcomes |\nA fully functional, configuration-driven heatmap application that dynamically generates visualizations from live GraphQL endpoints. |\nSkills |\nJavascript, D3 (or similar visualization libraries) |\nMentors |\nTBD - One of the Senior Developer in the team. |\nProject Size |\n350 hours |\nRating |\nmedium |\n\nTitle |\nEnhance GEARBOx trial matching page |\nDescription |\nThis project aims to create a new user experience. The current implementation has teh user looking at a list of all available trials related questions, and has to respond to as many as possible with the available data by scrolling a very long column. The new version will have a typeahead search or a dropdown with search where the user can search and select only the filter he has data for. |\nExpected Outcomes |\nNew working UI page |\nSkills |\nPython, Typescript |\nMentors |\nTBD - One of the Senior Developer in the team. |\nProject Size |\n350 hours |\nRating |\nmedium |\n\nTitle |\nGenerating decision tree (or flow chart) |\nDescription |\nGenerating decision tree (or flowchart) from free-text and GEARBOx Doccano annotation data. |\nExpected Outcomes |\nDecision tree in json format used in admin UI in order to determine priority and order of criteria. Map to patient data: synthetic patient data or EHR data (If patient data is available). |\nSkills |\nPython, Typescript |\nMentors |\nTBD - One of the Senior Developer in the team. |\nProject Size |\n350 hours |\nRating |\nmedium |"
  },
  {
    "name": "Meshery",
    "slug": "meshery",
    "tagline": "the extensible, collaborative, Kubernetes manager",
    "description": "As a self-service engineering platform, Meshery enables collaborative design and operation of cloud and cloud native infrastructure.\n\nMeshery is for all cloud and cloud native infrastructure.  Kubernetes-centric. Kubernetes not required.\n\nInfrastructure diversity is a reality for any enterprise. Whether you’re running a single Kubernetes cluster or multiple Kubernetes clusters, on one cloud or multiple clouds, you’ll find that Meshery supports your infrastructure diversity (or lack thereof).\n\nMeshery is for engineering teams. Whether you are a Platform Engineer, Site Reliability Engineer, DevOps Engineer, Developer, or Operator, Meshery provides a platform for you to collaborate on the design and operation of your cloud native infrastructure.\n\nWhether making a Day 0 adoption choice, a Day 1 configuration and provisioning, or maintaining a Day 2 deployment, Meshery has useful capabilities in either circumstance. Targeted audience for Meshery project would be any technology operators that leverage Cloud and cloud native infrastructure.\n\nMeshery is like Google Docs for DevOps. Using Meshery extensions you can freely collaborate across projects and team with multi-player infrastructure design and operation.\n\nMeshery enables cloud native best practices with design patterns and the Meshery Catalog. Through Models, Meshery describes infrastructure under management, enabling you to define cloud native designs and patterns and then to export those designs and share within the Meshery Catalog.",
    "ideas_url": "https://meshery.io/programs/gsoc/2026",
    "website_url": "https://meshery.io",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "javascript",
      "golang",
      "kubernetes",
      "ai",
      "visual design"
    ],
    "topic_tags": [
      "collaboration",
      "devops",
      "Platform Engineering",
      "cloud native infrastructure",
      "infrastructure as design"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/meshery",
    "ideas_content": "Docs\nCatalog\nPlayground\nCommunity\nParticipate\nCalendar\nNewcomers\nPrograms\nMailing Lists\nRecognition\nDiscussion forums\nGitHub\nSlack\nYoutube\nResources\nTalks and Trainings\nBlog\nExtensions\nContributing\nBranding\nGetting Started"
  },
  {
    "name": "Qubes OS",
    "slug": "qubes-os-f3",
    "tagline": "A reasonably secure operating system",
    "description": "Qubes OS is a security- and privacy-focused free-and-open-source operating system that provides a safer platform for communications, information management, and general computing.",
    "ideas_url": "https://doc.qubes-os.org/en/latest/developer/general/gsoc.html#project-ideas",
    "website_url": "https://qubes-os.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "python",
      "xen"
    ],
    "topic_tags": [
      "security",
      "privacy",
      "OS"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/qubes-os-f3",
    "ideas_content": "# Google Summer of Code (GSoC)[](https://doc.qubes-os.org#google-summer-of-code-gsoc)\n\n## Information for Students[](https://doc.qubes-os.org#information-for-students)\n\nThank you for your interest in participating in the [Google Summer of Code program](https://summerofcode.withgoogle.com/) with the [Qubes OS team](https://www.qubes-os.org/team/). You can read more about the Google Summer of Code program at the [official website](https://summerofcode.withgoogle.com/) and the [official FAQ](https://developers.google.com/open-source/gsoc/faq).\n\nBeing accepted as a Google Summer of Code contributor is quite competitive. If you are interested in participating in the Summer of Code please be aware that you must be able to produce code for Qubes OS for 3-5 months. Your mentors, Qubes developers, will dedicate a portion of their time towards mentoring you. Therefore, we seek candidates who are committed to helping Qubes long-term and are willing to do quality work and be proactive in communicating with your mentor.\n\nYou don’t have to be a proven developer – in fact, this whole program is meant to facilitate joining Qubes and other free and open source communities. The Qubes community maintains information about [contributing to Qubes development](https://doc.qubes-os.org/introduction/contributing.html#contributing-code) and [how to send patches](https://doc.qubes-os.org/code/source-code.html#how-to-send-patches). In order to contribute code to the Qubes project, you must be able to [sign your code](https://doc.qubes-os.org/code/code-signing.html).\n\nYou should start learning the components that you plan on working on before the start date. Qubes developers are available on the [mailing lists](https://doc.qubes-os.org/introduction/support.html#qubes-devel) for help. The GSoC timeline reserves a lot of time for bonding with the project – use that time wisely. Good communication is key, you should plan to communicate with your team daily and formally report progress and plans weekly. Students who neglect active communication will be failed.\n\n### Overview of Steps[](https://doc.qubes-os.org#overview-of-steps)\n\nJoin the\n\n[qubes-devel list](https://doc.qubes-os.org/introduction/support.html#qubes-devel)and introduce yourself, and meet your fellow developersRead\n\n[Google’s instructions for participating](https://developers.google.com/open-source/gsoc/)and the[GSoC Student Manual](https://google.github.io/gsocguides/student/)Take a look at the list of ideas below\n\nCome up with a project that you are interested in (and feel free to propose your own! Don’t feel limited by the list below.)\n\nRead the Contributor Proposal guidelines below\n\nWrite a first draft proposal and send it to the qubes-devel mailing list for review\n\nSubmit proposal using\n\n[Google’s web interface](https://summerofcode.withgoogle.com/)ahead of the deadline (this requires a Google Account!)Submit proof of enrollment well ahead of the deadline\n\n\nComing up with an interesting idea that you can realistically achieve in the time available to you (one summer) is probably the most difficult part. We strongly recommend getting involved in advance of the beginning of GSoC, and we will look favorably on applications from prospective contributors who have already started to act like free and open source developers.\n\nBefore the summer starts, there are some preparatory tasks which are highly encouraged. First, if you aren’t already, definitely start using Qubes as your primary OS as soon as possible! Also, it is encouraged that you become familiar and comfortable with the Qubes development workflow sooner than later. A good way to do this (and also a great way to stand out as an awesome applicant and make us want to accept you!) might be to pick up some issues from [qubes-issues](https://github.com/QubesOS/qubes-issues/issues) (our issue-tracking repo) and submit some patches addressing them. Some suitable issues might be those with tags [“help wanted” and “P: minor”](https://github.com/QubesOS/qubes-issues/issues?q=is%3Aissue%20is%3Aopen%20label%3A%22P%3A%20minor%22%20label%3A%22help%20wanted%22) (although more significant things are also welcome, of course). Doing this will get you some practice with [qubes-builder](https://doc.qubes-os.org/building/qubes-builder-v2.html), our code-signing policies, and some familiarity with our code base in general so you are ready to hit the ground running come summer.\n\n### Contributor proposal guidelines[](https://doc.qubes-os.org#contributor-proposal-guidelines)\n\nA project proposal is what you will be judged upon. Write a clear proposal on what you plan to do, the scope of your project, and why we should choose you to do it. Proposals are the basis of the GSoC projects and therefore one of the most important things to do well.\n\nBelow is the application template:\n\n```\n# Introduction\nEvery software project should solve a problem. Before offering the solution (your Google Summer of Code project), you should first define the problem. What’s the current state of things? What’s the issue you wish to solve and why? Then you should conclude with a sentence or two about your solution. Include links to discussions, features, or bugs that describe the problem further if necessary.\n# Project goals\nBe short and to the point, and perhaps format it as a list. Propose a clear list of deliverables, explaining exactly what you promise to do and what you do not plan to do. “Future developments” can be mentioned, but your promise for the Google Summer of Code term is what counts.\n# Implementation\nBe detailed. Describe what you plan to do as a solution for the problem you defined above. Include technical details, showing that you understand the technology. Illustrate key technical elements of your proposed solution in reasonable detail.\n# Timeline\nShow that you understand the problem, have a solution, have also broken it down into manageable parts, and that you have a realistic plan on how to accomplish your goal. Here you set expectations, so don’t make promises you can’t keep. A modest, realistic and detailed timeline is better than promising the impossible.\nIf you have other commitments during GSoC, such as a job, vacation, exams, internship, seminars, or papers to write, disclose them here. GSoC should be treated like a full-time job, and we will expect approximately 40 hours of work per week. If you have conflicts, explain how you will work around them. If you are found to have conflicts which you did not disclose, you may be failed.\nOpen and clear communication is of utmost importance. Include your plans for communication in your proposal; daily if possible. You will need to initiate weekly formal communications such as a detailed email to the qubes-devel mailing list. Lack of communication will result in you being failed.\n# About me\nProvide your contact information and write a few sentences about you and why you think you are the best for this job. Prior contributions to Qubes are helpful; list your commits. Name people (other developers, students, professors) who can act as a reference for you. Mention your field of study if necessary. Now is the time to join the relevant mailing lists. We want you to be a part of our community, not just contribute your code.\nTell us if you are submitting proposals to other organizations, and whether or not you would choose Qubes if given the choice.\nOther things to think about:\n* Are you comfortable working independently under a supervisor or mentor who is several thousand miles away, and perhaps 12 time zones away? How will you work with your mentor to track your work? Have you worked in this style before?\n* If your native language is not English, are you comfortable working closely with a supervisor whose native language is English? What is your native language, as that may help us find a mentor who has the same native language?\n* After you have written your proposal, you should get it reviewed. Do not rely on the Qubes mentors to do it for you via the web interface, although we will try to comment on every proposal. It is wise to ask a colleague or a developer to critique your proposal. Clarity and completeness are important.\n```\n\n## Project Ideas[](https://doc.qubes-os.org#project-ideas)\n\nThese project ideas were contributed by our developers and may be incomplete. If you are interested in submitting a proposal based on these ideas, you should contact the [qubes-devel mailing list](https://doc.qubes-os.org/introduction/support.html#qubes-devel) and associated GitHub issue to learn more about the idea.\n\n```\n### Adding a Proposal\n**Project**: Something that you're totally excited about\n**Brief explanation**: What is the project, where does the code live?\n**Expected results**: What is the expected result in the timeframe given\n**Difficulty**: easy / medium / hard\n**Knowledge prerequisite**: Pre-requisites for working on the project. What coding language and knowledge is needed?\nIf applicable, links to more information or discussions\n**Size of the project**: either 175 hours (medium) or 350 hours (large)\n**Mentor**: Name and email address.\n```\n\n### Qubes as a Vagrant provider[](https://doc.qubes-os.org#qubes-as-a-vagrant-provider)\n\n**Project**: Qubes as a Vagrant provider\n\n**Brief explanation**: Currently using Vagrant on Qubes requires finding an image that uses Docker as isolation provider and running Docker in a qube, or downloading the Vagrantfile and manually setting up a qube according to the Vagrantfile. This project aims at simplifying this workflow. Since introduction of Admin API, it’s possible for a qube to provision another qube - which is exactly what is needed for Vagrant. [Related discussion](https://groups.google.com/d/msgid/qubes-devel/535299ca-d16a-4a70-8223-a4ac6be4be41%40googlegroups.com)\n\n**Expected results**:\n\nDesign how Vagrant Qubes provider should look like, including:\n\nmethod for running commands inside (ssh vs qvm-run)\n\n\nWrite a Vagrant provider able to create/start/stop/etc a VM\n\nDocument how to configure and use the provider, including required qrexec policy changes and possibly firewall rules\n\nWrite integration tests\n\n\n**Difficulty**: medium\n\n**Knowledge prerequisite**:\n\nRuby\n\nVagrant concepts\n\n\n**Size of the project**: 350 hours\n\n**Mentor**: [Wojtek Porczyk](https://www.qubes-os.org/team/), [Marek Marczykowski-Górecki](https://www.qubes-os.org/team/)\n\n### System health monitor[](https://doc.qubes-os.org#system-health-monitor)\n\n**Project**: System health monitor\n\n**Brief explanation**: A tool that informs the user about common system and configuration issues. Some of this is already available, but scattered across different places. See related issues: [6663](https://github.com/QubesOS/qubes-issues/issues/6663), [2134](https://github.com/QubesOS/qubes-issues/issues/2134) (see issues linked to it).\n\n**Expected results**:\n\na tool / service that checks for common issues and things needing user attention, for example:\n\nsome updates to be applied (separate widget already exists)\n\nrunning out of disk space (separate widget already exists)\n\nrunning out of memory\n\ninsecure USB configuration (USB in dom0)\n\nsome system VM crashed\n\n…\n\n\na GUI that provides terse overview of the system state, and notifies the user if something bad happens\n\n\n**Difficulty**: medium\n\n**Knowledge prerequisite**:\n\nPython\n\nbasic knowledge about systemd services\n\nPyGTK (optional)\n\n\n**Size of the project**: 350 hours\n\n### Mechanism for maintaining in-VM configuration[](https://doc.qubes-os.org#mechanism-for-maintaining-in-vm-configuration)\n\n**Project**: Mechanism for maintaining in-VM configuration\n\n**Brief explanation**: Large number of VMs is hard to maintain. Templates helps with keeping them updated, but many applications have configuration in user home directory, which is not synchronized.\n\n**Expected results**:\n\nDesign a mechanism how to\n\n*safely*synchronize application configuration living in user home directory (`~/.config`\n\n, some other “dotfiles”). Mechanism should be resistant against malicious VM forcing its configuration on other VMs. Some approach could be a strict control which VM can send what changes (whitelist approach, not blacklist).Implementation of the above mechanism.\n\nDocumentation how to configure it securely.\n\n\n**Difficulty**: medium\n\n**Knowledge prerequisite**:\n\nshell and/or python scripting\n\nQubes OS qrexec services\n\n\n**Size of the project**: 175 hours\n\n**Mentor**: [Frédéric Pierret](https://www.qubes-os.org/team/)\n\n### Qubes Live USB[](https://doc.qubes-os.org#qubes-live-usb)\n\n**Project**: Revive Qubes Live USB, integrate it with installer\n\n**Brief explanation**: Qubes Live USB is based on Fedora tools to build live distributions. But for Qubes we need some adjustments: starting Xen instead of Linux kernel, smarter copy-on-write handling (we run there multiple VMs, so a lot more data to save) and few more. Additionally in Qubes 3.2 we have so many default VMs that default installation does not fit in 16GB image (default value) - some subset of those VMs should be chosen. Ideally we’d like to have just one image being both live system and installation image. More details: [#1552](https://github.com/QubesOS/qubes-issues/issues/1552), [#1965](https://github.com/QubesOS/qubes-issues/issues/1965).\n\n**Expected results**:\n\nAdjust set of VMs and templates included in live edition.\n\nUpdate and fix build scripts for recent Qubes OS version.\n\nUpdate startup script to mount appropriate directories as either copy-on-write (device-mapper snapshot), or tmpfs.\n\nOptimize memory usage: should be possible to run sys-net, sys-firewall, and at least two more VMs on 4GB machine. This include minimizing writes to copy-on-write layer and tmpfs (disable logging etc).\n\nResearch option to install the system from live image. If feasible add this option.\n\n\n**Difficulty**: hard\n\n**Knowledge prerequisite**:\n\nSystem startup sequence: bootloaders (isolinux, syslinux, grub, UEFI), initramfs, systemd.\n\nPython and Bash scripting\n\nFilesystems and block devices: loop devices, device-mapper, tmpfs, overlayfs, sparse files.\n\n\n**Size of the project**: 350 hours\n\n**Mentor**: [Frédéric Pierret](https://www.qubes-os.org/team/)\n\n### LogVM(s)[](https://doc.qubes-os.org#logvm-s)\n\n**Project**: LogVM(s)\n\n**Brief explanation**: Qubes AppVMs do not have persistent /var (on purpose). It would be useful to send logs generated by various VMs to a dedicated log-collecting VM. This way logs will not only survive VM shutdown, but also be immune to altering past entries. See [#830](https://github.com/QubesOS/qubes-issues/issues/830) for details.\n\n**Expected results**:\n\nDesign a\n\n*simple*protocol for transferring logs. The less metadata (parsed in log-collecting VM) the better.Implement log collecting service. Besides logs itself, should save information about logs origin (VM name) and timestamp. The service should\n\n*not*trust sending VM in any of those.Implement log forwarder compatible with systemd-journald and rsyslog. A mechanism (service/plugin) fetching logs in real time from those and sending to log-collecting VM over qrexec service.\n\nDocument the protocol.\n\nWrite unit tests and integration tests.\n\n\n**Difficulty**: easy\n\n**Knowledge prerequisite**:\n\nsyslog\n\nsystemd\n\nPython/Bash scripting\n\n\n**Size of the project**: 175 hours\n\n**Mentor**: [Frédéric Pierret](https://www.qubes-os.org/team/)\n\n### Whonix IPv6 and nftables support[](https://doc.qubes-os.org#whonix-ipv6-and-nftables-support)\n\n**Project**: Whonix IPv6 and nftables support\n\n**Brief explanation**: [T509](https://phabricator.whonix.org/T509)\n\n**Expected results**:\n\nWork at upstream Tor: An older version of\n\n[TransparentProxy](https://trac.torproject.org/projects/tor/wiki/doc/TransparentProxy)page was the origin of Whonix. Update that page for nftables / IPv6 support without mentioning Whonix. Then discuss that on the tor-talk mailing list for wider input.[here](https://trac.torproject.org/projects/tor/ticket/21397)implement corridor feature request add IPv6 support / port to nftables -\n\n[issue](https://github.com/rustybird/corridor/issues/39)port\n\n[whonix-firewall](https://github.com/Whonix/whonix-firewall)to nftablesmake connections to IPv6 Tor relays work\n\nmake connections to IPv6 destinations work\n\n\n**Difficulty**: medium\n\n**Knowledge prerequisite**:\n\nnftables\n\niptables\n\nIPv6\n\n\n**Size of the project**: 175 hours\n\n**Mentor**: [Patrick Schleizer](https://www.qubes-os.org/team/)\n\n### GUI agent for Windows 8/10[](https://doc.qubes-os.org#gui-agent-for-windows-8-10)\n\n**Project**: GUI agent for Windows 8/10\n\n**Brief explanation**: Add support for Windows 8+ to the Qubes GUI agent and video driver. Starting from Windows 8, Microsoft requires all video drivers to conform to the WDDM display driver model which is incompatible with the current Qubes video driver. Unfortunately the WDDM model is much more complex than the old XPDM one and officially *requires* a physical GPU device (which may be emulated). Some progress has been made to create a full WDDM driver that *doesn’t* require a GPU device, but the driver isn’t working correctly yet. Alternatively, WDDM model supports display-only drivers which are much simpler but don’t have access to system video memory and rendering surfaces (a key feature that would simplify seamless GUI mode). [#1861](https://github.com/QubesOS/qubes-issues/issues/1861)\n\n**Expected results**: Working display-only WDDM video driver or significant progress towards making the full WDDM driver work correctly.\n\n**Difficulty**: hard\n\n**Knowledge prerequisite**: C/C++ languages, familiarity with Windows API, familiarity with the core Windows WDM driver model. Ideally familiarity with the WDDM display driver model.\n\n**Size of the project**: 175 hours\n\n**Mentor**: [Rafał Wojdyła](https://www.qubes-os.org/team/)\n\n### Generalize the Qubes PDF Converter to other types of files[](https://doc.qubes-os.org#generalize-the-qubes-pdf-converter-to-other-types-of-files)\n\n**Project**: Qubes Converters\n\n**Brief explanation**: One of the pioneering ideas of Qubes is to use disposable virtual machines to convert untrustworthy files (such as documents given to journalists by unknown and potentially malicious whistleblowers) into trustworthy files. See [Joanna’s blog on the Qubes PDF Convert](https://theinvisiblethings.blogspot.co.uk/2013/02/converting-untrusted-pdfs-into-trusted.html) for details of the idea. Joanna has implemented a prototype for PDF documents. The goal of this project would be to generalize beyond the simple prototype to accommodate a wide variety of file formats, including Word documents, audio files, video files, spreadsheets, and so on. The converters should prioritise safety over faithful conversion. For example the Qubes PDF converter typically leads to lower quality PDFs (e.g. cut and paste is no longer possible), because this makes the conversion process safer.\n\n**Expected results**: We expect that in the timeframe, it will be possible to implement many converters for many file formats. However, if any unexpected difficulties arise, we would prioritise a small number of safe and high quality converters over a large number of unsafe or unuseful converters.\n\n**Difficulty**: easy\n\n**Knowledge prerequisite**: Most of the coding will probably be implemented as shell scripts to interface with pre-existing converters (such as ImageMagick in the Qubes PDF converter). However, shell scripts are not safe for processing untrusted data, so any extra processing will need to be implemented in another language – probably Python.\n\n**Size of the project**: 175 hours\n\n**Mentors**: Andrew Clausen and Jean-Philippe Ouellet\n\n### Progress towards reproducible builds[](https://doc.qubes-os.org#progress-towards-reproducible-builds)\n\n**Project**: Progress towards reproducible builds\n\n**Brief explanation**: A long-term goal is to be able to build the entire OS and installation media in a completely bit-wise deterministic manner, but there are many baby steps to be taken along that path. See:\n\nfor more information and qubes-specific background.\n\n**Expected results**: Significant progress towards making the Qubes build process deterministic. This would likely involve cooperation with and hacking on several upstream build tools to eliminate sources of variability.\n\n**Difficulty**: medium\n\n**Knowledge prerequisite**: qubes-builder [[1]](https://doc.qubes-os.org/building/qubes-builder-v2.html) [[2]](https://github.com/QubesOS/qubes-builderv2), and efficient at introspecting complex systems: comfortable with tracing and debugging tools, ability to quickly identify and locate issues within a large codebase (upstream build tools), etc.\n\n**Size of the project**: 350 hours\n\n**Mentor**: [Marek Marczykowski-Górecki](https://www.qubes-os.org/team/)\n\n### Porting Qubes to ARM/aarch64[](https://doc.qubes-os.org#porting-qubes-to-arm-aarch64)\n\n**Project**: Porting Qubes to ARM/aarch64\n\n**Brief explanation**:\n\nQubes currently only supports the x86_64 CPU architecture. Xen currently has additional support for ARM32/ARM64 processors, however work needs to be done to integrate this into the Qubes build process, as well as work in integrating this with the Qubes toolstack and security model. This may also be beneficial in simplifying the process of porting to other architectures.\n\nSome related discussion:\n\n**Expected results**:\n\nAdd cross-compilation support to qubes-builder and related components.\n\nMake aarch64 specific adjustments to Qubes toolstacks/manager (including passthrough of devices from device tree to guest domains).\n\nAarch64 specific integration and unit tests.\n\nProduction of generic u-boot or uefi capable image/iso for target hardware.\n\n\n**Difficulty**: hard\n\n**Knowledge prerequisite**:\n\nLibvirt and Qubes toolstacks (C and python languages).\n\nXen debugging.\n\nGeneral ARM architecture knowledge.\n\n\n**Size of the project**: 350 hours\n\n**Mentor**: [Marek Marczykowski-Górecki](https://www.qubes-os.org/team/)\n\n### Android development in Qubes[](https://doc.qubes-os.org#android-development-in-qubes)\n\n**Project**: Research running Android in Qubes VM (probably HVM) and connecting it to Android Studio\n\n**Brief explanation**: The goal is to enable Android development (and testing!) on Qubes OS. Currently it’s only possible using qemu-emulated Android for ARM. Since it’s software emulation it’s rather slow. Details, reference: [#2233](https://github.com/QubesOS/qubes-issues/issues/2233)\n\n**Expected results**:\n\na simple way of setting up Android qubes with hardware emulation (distributed as a template or as a salt, handling various modern Android versions)\n\nfiguring out and implementing an easy and secure way to connect an Android qube to a development qube with Android studio\n\ndocumentation and tests\n\n\n**Difficulty**: hard\n\n**Knowledge prerequisite**:\n\n**Size of the project**: 350 hours\n\n**Mentor**: Inquire on [qubes-devel](https://doc.qubes-os.org/introduction/support.html#qubes-devel).\n\n### Admin API Fuzzer[](https://doc.qubes-os.org#admin-api-fuzzer)\n\n**Project**: Develop a [Fuzzer](https://en.wikipedia.org/wiki/Fuzzing) for the [Qubes OS Admin API](https://doc.qubes-os.org/services/admin-api.html).\n\n**Brief explanation**: The [Qubes OS Admin API](https://doc.qubes-os.org/services/admin-api.html) enables VMs to execute privileged actions on other VMs or dom0 - if allowed by the Qubes OS RPC policy. Programming errors in the Admin API however may cause these access rights to be more permissive than anticipated by the programmer. If the there is a client error and the API response is too restrictive, it won’t reveal any information making it difficult to debug and handle errors, as it is a general error. More details:\n\n[QSB-087: Qrexec: Injection of unsanitized data into log output](https://www.qubes-os.org/news/2022/11/23/qsb-087/)(related to Qrexec rather than the Admin API, but helps understand dangers of unsanitized data in logs/output)[QSB-089: Qrexec: Memory corruption in service request handling](https://www.qubes-os.org/news/2023/05/11/qsb-089/)(related to Qrexec rather than the Admin API, but helps understand dangers of unsanitized data length that could be passed to other applications that may cause memory corruption on a faulty application)[QSB-099: Qrexec policy leak via policy.RegisterArgument service](https://www.qubes-os.org/news/2024/01/19/qsb-099/)[#5316: qvm-create error message unhelpful on missing template](https://github.com/QubesOS/qubes-issues/issues/5316)[#10345: Specific exception against PermissionDenied when API argument is invalid](https://github.com/QubesOS/qubes-issues/issues/10345)\n\nSince the Admin API is continuously growing and changing, continuous security assessments are required. A [Fuzzer](https://en.wikipedia.org/wiki/Fuzzing) would help to automate part of these assessments.\n\n**Expected results**:\n\nfully automated & extensible Fuzzer for parts of the Admin API\n\nuser & developer documentation\n\n\n**Difficulty**: medium\n\n**Prerequisites**:\n\nbasic Python understanding\n\nsome knowledge about fuzzing & existing fuzzing frameworks (e.g.\n\n[oss-fuzz](https://github.com/google/oss-fuzz/tree/master/projects/qubes-os))a hacker’s curiosity\n\n\n**Size of the project**: 175 hours\n\n**Mentor**: Inquire on [qubes-devel](https://doc.qubes-os.org/introduction/support.html#qubes-devel).\n\n### Secure Boot support[](https://doc.qubes-os.org#secure-boot-support)\n\n**Project**: Add support for protecting boot binaries with Secure Boot technology, using user-generated keys.\n\n**Brief explanation**: Since recently, Xen supports “unified EFI boot” which allows to sign not only Xen binary itself, but also dom0 kernel and their parameters. While the base technology is there, enabling it is a painful and complex process. The goal of this project is to integrate configuration of this feature into Qubes, automating as much as possible. See discussion in [issue #4371](https://github.com/QubesOS/qubes-issues/issues/4371)\n\n**Expected results**:\n\na tool to prepare relevant boot files for unified Xen EFI boot - this includes collecting Xen, dom0 kernel, initramfs, config file, and possibly few more (ucode update?); the tool should then sign the file with user provided key (preferably propose to generate it too)\n\nintegrate it with updates mechanism, so new Xen or dom0 kernel will be picked up automatically\n\ninclude a fallback configuration that can be used for troubleshooting (main unified Xen EFI intentionally does not allow to manipulate parameters at boot time)\n\n\n**Difficulty**: hard\n\n**Knowledge prerequisite**:\n\nbasic understanding of Secure Boot\n\nBash and Python scripting\n\n\n**Size of the project**: 175 hours\n\n**Mentor**: [Marek Marczykowski-Górecki](https://www.qubes-os.org/team/)\n\n### Reduce logging of Disposable VMs[](https://doc.qubes-os.org#reduce-logging-of-disposable-vms)\n\n**Project**: Reduce logging of Disposable VMs\n\n**Brief explanation**: Partial metadata of a DisposableVM is stored in the dom0 filesystem. This applies to various logs, GUI status files etc. There should be an option to hide as much of that as possible - including bypassing some logging, and removing various state files, or at the very least obfuscating any hints what is running inside DisposableVM. More details at [issue #4972](https://github.com/QubesOS/qubes-issues/issues/4972)\n\n**Expected results**: A DisposableVM should not leave logs hinting what was running inside.\n\n**Difficulty**: medium\n\n**Knowledge prerequisite**:\n\nPython scripting\n\nBasic knowledge of Linux system services management (systemd, syslog etc)\n\n\n**Size of the project**: 350 hours\n\n**Mentor**: [Marek Marczykowski-Górecki](https://www.qubes-os.org/team/)\n\n## Past Projects[](https://doc.qubes-os.org#past-projects)\n\nYou can view the projects we had in 2017 in the [GSoC 2017 archive](https://summerofcode.withgoogle.com/archive/2017/organizations/5074771758809088/). We also participated in GSoC 2020 and GSoC 2021, and you can see the project in the [GSoC 2020 archive](https://summerofcode.withgoogle.com/archive/2020/organizations/4924517870206976/) and [GSoC 2021 archive](https://summerofcode.withgoogle.com/archive/2021/organizations/5682513023860736).\n\nHere are some successful projects which have been implemented in the past by Google Summer of Code participants.\n\nWe adapted some of the language here about GSoC from the [KDE GSoC page](https://community.kde.org/GSoC)."
  },
  {
    "name": "omegaUp",
    "slug": "omegaup",
    "tagline": "Open CS Education as a catalyst for social change",
    "description": "omegaUp  is a non-profit organization (501c3) aimed to increase the number of talented Software Engineers in Latin America. Our open source platform omegaUp.com lets students immerse in a learning environment that fosters self paced learning of computer science skills with a democratic access to state-of-the-art learning tools.\n\nTeachers and tutors can create new coding challenges or use existing ones to start online programming competitions with local, national or even international reach, with automated grading of student's coding solutions. The omegaUp.com platform also enables teachers to leverage Competitive Programming tools and concepts inside the classroom to improve their educational experience.",
    "ideas_url": "https://github.com/omegaup/omegaup/blob/main/frontend/www/docs/Google-Summer-of-Code-2026.md",
    "website_url": "https://omegaup.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "mysql",
      "php",
      "typescript",
      "vue.js"
    ],
    "topic_tags": [
      "education",
      "web",
      "cloud",
      "edtech",
      "UX/UI"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/omegaup",
    "ideas_content": "# Table of Contents\n- [Ideas List](#ideas-list)\n- [How to Ramp Up](#how-to-ramp-up)\n- [Application Process](#application-process)\n- [Communications](#communications)\n- [Frequently Asked Questions](#frequently-asked-questions)\n\n# Ideas List\n\n> We encourage you to visit omegaup.org and omegaup.com to learn about our platform and features. And remember, this is an **Ideas List** we expect you complete most of the details in your proposal and you are also welcome to propose your own project idea. Don't hesitate to reach out for any questions or new ideas in our [Discord channel](https://discord.gg/gMEMX7Mrwe)!\n\n\n\n## Query Optimization and Performance Benchmarking\n\n**Brief Description**:\n\nThis project aims to improve the platform’s performance by optimizing SQL queries that currently have to do full table scans and implementing 2 integration tests: \n\n* One Integration test that analyzes the EXPLAIN of all queries to determine if it's efficient or not.\n* One integration test that analyzes the performance of all queries by running them on a synthetic dataset with dimensions comparable to those of production. \n\nThe goal is to ensure quick response times for frequent operations and ensure scalability under high-load scenarios. More details about the requirements can be found in [this doc](https://docs.google.com/document/d/1X_fAm97L6_v9P8_R0S_Lp7X6e7x7j7z-X5z5-x5z5z5).\n\n**Current status**:\n\n* Slow queries have been identified and documented in a [query tracker](https://docs.google.com/spreadsheets/d/1z5EZlGRY5MXUBYn5VoSX3c7Wqt14mI_iH-IY266bf_Y/edit?gid=0#gid=0).\n* Progress is tracked in the master issue [#8277](https://github.com/omegaup/omegaup/issues/8277), which lists created and merged PRs.\n* Key PRs: [#8450](https://github.com/omegaup/omegaup/pull/8450) (Script to populate database) and [#8423](https://github.com/omegaup/omegaup/pull/8423) (Inefficient query detection script).\n\n**Expected results**:\n\nSignificant reduction in execution time for queries that have already been identified to be inefficient. A reproducible benchmarking system to evaluate performance improvements. Integration tests prevent introduction of new inefficient queries in the future.\n\n**Preferred skills**:\n\n* SQL query optimization\n* MySQL\n* Python\n* PHP\n* YML\n\n**Possible mentor**:\n\n[Ankitsinghsisodya](https://github.com/Ankitsinghsisodya), [pabo99](https://github.com/pabo99), [carlosabcs](https://github.com/carlosabcs)\n\n**Estimated size of project:**\n\n350 hours\n\n**Skill level**:\n\nMedium\n\n## Performance Monitoring and Alerting Dashboard\n\n**Brief Description**:\n\nDefine and implement meaningful performance metrics for the services that omegaUp runs, including: front end server, grader, gitserver, MySQL server. On top of that monitoring, some thresholds should be defined to alert us to our email and/or slack. Some basic monitoring and alerting is already in place, this project calls for a big improvement on top of that.\n\n**Expected results**:\n\nThe monitoring and alerting allows us to catch and debug production issues before users start being significantly affected.\n\n**Preferred skills**:\n\n* New relic\n* SQL\n* PHP\n* Python\n\n**Possible mentor**:\n\n[heduenas](https://github.com/heduenas), [iqbalcodes6602](https://github.com/iqbalcodes6602)\n\n**Estimated size of project:**\n\n350 hours\n\n**Skill level**:\n\nMedium\n\n\n\n## Migrating from Vue 2 to Vue 3\n\n**Brief Description**:\n\nVue.js 2 has officially reached its EOF (End of Life) in favor of Vue.js 3. We need to migrate in order to avoid security risk and dependency deprecation and to take advantage of Vue 3's improved performance.\n\n**Expected results**:\n\nomegaup.com runs fully on Vue.js 3 and has no dependency on Vue.js 2.\n\n**Preferred skills**:\n\n* Vue.js\n* Typescript\n* PHP\n* REST APIs\n\n**Possible mentor**:\n\n[pabo99](https://github.com/pabo99), [iqbalcodes6602](https://github.com/iqbalcodes6602), [carlosabcs](https://github.com/carlosabcs)\n\n**Estimated size of project:**\n\n350 hours\n\n**Skill level**:\n\nMedium\n\n\n\n## Migrating Bootstrap 4 to 5\n\n**Brief Description**:\n\nMigrate the UI to Bootstrap 5 to modernize the UI by replacing jQuery with Vanilla JavaScript, resulting in a lighter and faster codebase. This upgrade will enable easier theming through CSS variables and drop legacy IE support to embrace modern web standards. Ultimately, it reduces technical debt while providing a more responsive grid system tailored for high-resolution displays.\n\n**Expected results**:\n\nThe omegaUp UI runs fully on bootstrap 5 and has no dependency on boostrap 4.\n\n**Preferred skills**:\n\n* Vue.js\n* Typescript\n* PHP\n* REST APIs\n\n**Possible mentor**:\n\n[pabo99](https://github.com/pabo99), [iqbalcodes6602](https://github.com/iqbalcodes6602), [carlosabcs](https://github.com/carlosabcs)\n\n**Estimated size of project:**\n\n350 hours\n\n**Skill level**:\n\nMedium\n\n\n\n## Cronjob Optimization\n\n**Brief Description**:\n\nWe have a number of cronjobs responsible for things such as updating student/school rankings, awarding badges to students, etc. Over the time they have become inefficient, error prone and hard to debug. We want to make them more efficient, increase their test coverage and improve their debug-ability.\n\n**Expected results**:\n\nCronjobs become much leaner, faster and easier to maintain.\n\n**Preferred skills**:\n\n* Python\n* SQL query optimization\n* PHP\n* REST APIs\n\n**Possible mentor**:\n\n[Ankitsinghsisodya](https://github.com/Ankitsinghsisodya), [iqbalcodes6602](https://github.com/iqbalcodes6602), [carlosabcs](https://github.com/carlosabcs)\n\n**Estimated size of project:**\n\n350 hours\n\n**Skill level**:\n\nHigh\n\n\n\n## Integrate Problem Creator\n\n**Brief Description**:\n\nA project from last year's GSoC introduced the Problem Creator, a visual editor that helps problem authors create and edit problems more easily. However, the Problem Creator isn't yet fully integrated with omegaUp. Currently, authors must write their problem in the Creator, download a .zip, and upload it manually. This project aims to streamline these workflows by fully integrating the Problem Creator with omegaUp's native create and edit features.\n\n**Current Status**:\n\n* A technical [pdesign doc](https://docs.google.com/document/d/1qpBwJQ6QIiIXgWpb_qa6OJ8KpJPcd11x3qKiefdgPAw/edit?tab=t.0) has been written for this project. \n* Completed backend changes:\n  * #8470 CDP classes and validations, added core CDP classes and validation logic.\n  * #8479 New method in ProblemDeployer to modify problem ZIPs, enables updating problem ZIP contents during deployment.\n  * #8554 CDPBuilder fixes and unit test coverage, fixed issues in CdpBuilder and added a unit test to ensure correctness.\n  * #8606 Language support in CDPBuilder, added multi-language support with priority based on languagePreference\n  * #8613 Backend logic for editing cases and CDP, added server-side logic to support case editing and CDP updates.\n  * Initial UI change completed: #8593 CasesForm and DeleteConfirmationForm components, introduced the base UI forms required for managing cases \n* Pending work (mostly UI-related)\n  * #8471 Integrate CDP into the problem form and handle external ZIPs\n  * #8492 UI implementation for the editing interface\n  * #8595 UI integration: Edit view, CaseEdit, and Sidebar\n\n**Expected results**:\n\nA seamless end-to-end user experience where authors can create or edit problems directly via the Problem Creator without manual file transfers.\n\n**Preferred skills**:\n\n* Vue.js\n* TypeScript\n* PHP\n* Integration Testing\n\n**Possible mentor**:\n\n[pabo99](https://github.com/pabo99), [heduenas](https://github.com/heduenas), [Ankitsinghsisodya](https://github.com/Ankitsinghsisodya)\n\n**Estimated size of project:**\n\n175 hours\n\n**Skill level**:\n\nHigh\n\n# How to Ramp Up\n\nIf you are interested spending this summer collaborating with us, first of all, we're honored that you are interested in our organization and we want to make the application process as smooth and enjoyable as possible for you. In order to familiarize yourself with [omegaUp.com](omegaup.com) and start collaborating with us please follow these steps:\n\n - Visit [omegaup.org](omegaup.org) to learn more about our work, our vision, and the people who are being benefited by our work.\n - Read [this article](http://www.ioinformatics.org/oi/pdf/v8_2014_169_178.pdf) published by our co-founders to learn about the architecture and overall design of our platform.\n - Read [this follow-up article](https://ioinformatics.org/journal/v18_2024_167_174_Duenas.pdf) to learn about the work done in more recent years in omegaUp.\n - Read our [technical documentation](https://github.com/omegaup/omegaup/tree/main/frontend/www/docs).\n\n# Application Process\n\n#### Our application process consists of three phases. If you want to participate with us this year, you must complete each of them in order.\n\n### Phase One: Complete our test \n\n - First, create an account at [omegaUp.com](https://omegaUp.com).\n - Join to our GSoC 2026 [omegaUp Test](https://omegaup.com/contest/gsoc2026). The test consists of 3 problems, you have to solve at least 2 of them in order to pass. **In the case of plagiarism, we will disqualify those applicants involved**, so please don't share your solutions with your fellow applicants.\n\n### Phase Two: Familiarize yourself with our codebase\n\nWe ask that you complete phase one before you start working with our codebase.\n\n - Follow these [instructions](https://github.com/omegaup/omegaup/blob/main/frontend/www/docs/Development-Environment-Setup-Process.md) to set up your development environment.\n - Find yourself an interesting bug to solve from our [issue tracker](https://github.com/omegaup/omegaup/issues) (specially from our list of [\"Good first issues\"](https://github.com/omegaup/omegaup/labels/Good%20first%20issue), or reach out to the [Discord channel](https://discord.gg/gMEMX7Mrwe) asking for one and we will be happy to find a good fit for you. Most of the conversations in the issue tracker are in Spanish but feel free to switch the conversation to English on any issue. Alternatively, you can go and find bugs on omegaup.com yourself, then report them in our issue tracker, and then fix them.\n - Implement your fix and submit it for review. Once it's merged you can move onto the third phase.\n\n### Phase Three: Writing your proposal\n\nAt this step we hope you are familiar with our development environment and code since that makes it easier to understand our project ideas. **We ask that you get at least three PR merged into one of the omegaUp repositories before working on a design for a specific project.**\n\n - Craft a design document for your project using [this template](https://docs.google.com/document/d/1_FKfpc2M3VLDVYqvT8ZgsgwIJ3zaZnyUVmSm-H3h6UQ/edit). If you want to work in more than one project, we ask that you mention that in your application but include only one design. This is to reduce the workload for reviewers. \n - We also encourage you to **send us your draft proposal to review and give feedback**. Send the link of your draft through this form `https://forms.gle/TbbscnWA5B2ZWfJq7`. Make sure that anyone with the link can see and comment.\n - We will try to provide you with as much feedback as we can and as soon as we can. However, we will not provide feedback to candidates who have not successfully completed phases 1 or 2.\n - When you consider that your application is ready, don't forget to **send it to [Google](https://summerofcode.withgoogle.com/age-verification/student/?next=%2Fstudent-signup%2F)** because if you don't do it, you will not be able to be considered in GSoC 2026.\n\n### Phase Four: Interview with the organization\nAfter design documents are submitted, we will select a short list of candidates based on the first 3 phases and schedule phone interviews with them. The interview will consist of both behavioral and technical questions.\n\nWe will only consider candidates that completed all 4 phases of the application.\n\n# Communications\n## If you have questions about the [development environment](https://github.com/omegaup/omegaup/blob/main/frontend/www/docs/Quiero-desarrollar-en-omegaUp.md) or the [codebase](https://github.com/omegaup/omegaup) or how the GSoC application process works at omegaUp, please follow our [Getting Help page](https://github.com/omegaup/omegaup/blob/main/frontend/www/docs/How-to-Get-Help.md) to effectively getting your question answered.\n\n**Our main communication medium with GSoC candidates is our [Discord channel](https://discord.gg/gMEMX7Mrwe). We invited you to join!**\n\n# Frequently Asked Questions #\n   * **The development environment installation script is throwing me an error.** Please follow our [Getting Help page](https://github.com/omegaup/omegaup/blob/main/frontend/www/docs/How-to-Get-Help.md) to effectively getting your issue resolved.\n   * **Am I expected to speak Spanish?** Of course not. We try our best to be as inclusive as possible to non-Spanish volunteers. Please feel free to use English throughout our communication channels and in your code. We have also found Google Translate to do a decent job in translating the Spanish contents of our GitHub page, we advise you to use it to navigate our issue tracker, wiki, etc.\n  * **How many spots will your organization have for GSoC 2026?** We will ask for 4 students this year, but there is no guarantee yet, we will know for sure until around mid-May 2026.\n  * **How do you choose your students?** We will review each application that we receive and will choose our candidates based on three things:\n    * Candidate's skill level. There are two good ways to show your skill level in your application: Through impactful pull requests sent to our repositories (this is the recommended way), or through previous experience. Make sure to include evidence of at least one of those in your application.\n    * Candidate's work plan. We ask you to write a high-level design of your project following our [proposal template](https://docs.google.com/document/d/1_FKfpc2M3VLDVYqvT8ZgsgwIJ3zaZnyUVmSm-H3h6UQ/edit)\n    * Cultural fit. We like people who promote inclusion in the organization and are proactively helping out peers. A good way to show help out other candidates when they ask questions on the [Discord channel](https://discord.gg/gMEMX7Mrwe).\n* **Are there any sample applications for I can look at?** Two good samples are:\n * Carlos Cordova's [proposal from 2018](https://docs.google.com/document/d/1ZEnC33hW4WjZ1WcsDjEtuIeNPuvW62q_hBFjhFosLOI/edit#heading=h.30j0zll)\n * Vincent Fango's [proposal from 2018](https://docs.google.com/document/d/1ei3AV1ByLpONbTgO3Grnl8aVOIL2hwz48IxLmDyuOWA/edit#heading=h.gjdgxs). You can also watch Vincent's final project presentation: <br>\n[![omegaUp dev environment installation on Windows](https://img.youtube.com/vi/cOnJ_5M1DFs/0.jpg)](https://www.youtube.com/watch?v=cOnJ_5M1DFs)\n* **Can I propose a solution to multiple problems from the ideas list?** We ask that you include the design for only one project in your application. When you are in the coding phase and if you finish that project early, you are more than welcome to work on an additional project.\n* **Are there more opportunities at omegaUp for me if I don't get selected for GSoC?** Of course, there are. We always welcome new volunteers who are interested in supporting our efforts. After results are released feel free to keep asking for work items."
  },
  {
    "name": "GeomScale",
    "slug": "geomscale",
    "tagline": "Scalable geometric and statistical software",
    "description": "GeomScale is a research and development project that delivers open source code for state-of-the-art algorithms for problems at the intersection of data science, optimization, geometric, and statistical computing. The current focus of GeomScale is on scalable algorithms for sampling from high-dimensional distributions, integration, convex optimization, and their applications. One of our ambitions is to fill the gap between theory and practice by turning state-of-the-art theoretical tools in geometry and optimization to state-of-the-art implementations. Towards this goal, we will deliver various innovative solutions in a variety of application fields, like finance, computational biology, and statistics that will extend the limits of contemporary computational tools. GeomScale aims in serving as a building block for an international, interdisciplinary, and open community in high dimensional geometrical and statistical computing. The main development is currently performed in volesti, a generic open source C++ library, with R and python interfaces (the latter is hosted in package dingo), for high-dimensional sampling, volume approximation, and copula estimation for financial modelling. In particular, the current implementation scales up to hundred or thousand dimensions, depending on the problem. To our knowledge it is the most efficient software package for sampling and volume computation to date. It is, in several cases, orders of magnitude faster compared to packages that solve the same problems. It can be used to compute challenging multivariate integrals and to approximate optimal solutions in optimization problems. It has already found important applications in systems biology by analyzing large metabolic networks (e.g., the latest human network) and in FinTech by detecting shock events and by evaluating portfolios performance in stock markets with thousands of assets. Other application areas include AI and in particular approximate weighted model integration. Recent studies has shown a potential application of volesti methods in trustworthy AI, static analysis of programs and differential privacy.",
    "ideas_url": "https://github.com/GeomScale/gsoc26/wiki/table-of-proposed-coding-projects",
    "website_url": "https://geomscale.github.io",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "c++",
      "r",
      "jupyter",
      "github-actions"
    ],
    "topic_tags": [
      "mathematics",
      "data science",
      "computational biology",
      "computational geometry",
      "statistics"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/geomscale",
    "ideas_content": "---\n:warning:   **NOTE** \n\nThis year contributors will have to choose between a ~90 hours small-sized project, ~175 hours medium-sized project or ~350 hours large project.\nFor more information please read the [official gsoc website](https://summerofcode.withgoogle.com/) as well as [GeomScale's introductory wiki for GSoC 2026](https://github.com/GeomScale/gsoc26/wiki).\n\n---\n\nGeomScale hosts a few projects in different github repositories. The most mature one is [volesti](https://github.com/GeomScale/volesti) written in C++. Then there are two repositories that act as interfaces of volesti (i) [Rvolesti](https://github.com/GeomScale/Rvolesti) in *R* that also contains utilities for financial applications and (ii) and [dingo](https://github.com/GeomScale/dingo) written in *Python* (uses C++ functions of volesti via Cython) and contains utilities for biological applications. Finally, there is [PorQua](https://github.com/GeomScale/PorQua) a Python package for index replication in finance.\n\nProposed projects are related to those repositories. There are **two** types of coding projects: research and development (marked as *R&D* in the table below) and pure development (marked as *Dev* in the table below). *R&D* projects needs a deep understanding of the mathematical background in addition to the implementation details that are needed by the *Dev* projects. Typically the former is more demanding than the later but this also depends on the background of the contributor.   \n\n---\n\nMentors, please edit this wiki page, and add your ideas to the table below.\n\nContributors, please look for a project that interests you in the table below. Before emailing project mentors, please do at least one project **test** and post a link to your solution on the proposal's wiki page.\n\n Proposal                        | Type                  | Languages | Size | Hours |\n---------------------------------|--------------------------|-----------|------|------|\n[Non-convex sampling in dingo](https://github.com/GeomScale/gsoc26/wiki/non-convex-sampling) | R&D | C++ /Python| Large | 350 | \n[Exclude Lpsolve from R and C++ interfaces of volesti](https://github.com/GeomScale/gsoc26/wiki/Exclude-Lpsolve) | Dev |  C++/R | Medium | 175 |  \n[Counting linear extensions with volume computation and applications in AI](https://github.com/GeomScale/gsoc26/wiki/Counting-linear-extensions-with-volume-computation-and-applications-in-AI) | R&D | C++ | Large | 350 |\n[Expose sampling and volume on spectrahedra to R interface of volesti](https://github.com/GeomScale/gsoc26/wiki/Spectrahedra-R-interface) | Dev | R/Rcpp | Medium | 175 |\n[Expose autodiff to R interface of volesti](https://github.com/GeomScale/gsoc26/wiki/Autodiff-R-interface) | Dev | R/Rcpp | Medium | 175 |\n[Geometric Inference of Convex Bodies from Random Sampling](https://github.com/GeomScale/gsoc26/wiki/Geometric-Inference-of-Convex-Bodies-from-Random-Sampling) | R&D | C++/Python | Large | 350|\n[Supporting Sparse Matrix Representation for H‐Polytopes in Rvolesti](https://github.com/GeomScale/gsoc26/wiki/Supporting-Sparse-Matrix-Representation-for-H%E2%80%90Polytopes-in-Rvolesti) | Dev | R/Rcpp | Small | 90 |\n[Enhancing Rvolesti: Integration of Advanced Rounding Routines](https://github.com/GeomScale/gsoc26/wiki/Enhancing-Rvolesti-%E2%80%93-Integration-of-Advanced-Rounding-Routines) | Dev | R/Rcpp | Small | 90 |\n[Benchmark Polytope Import Suite for volesti](https://github.com/GeomScale/gsoc26/wiki/Benchmark-Polytope-Import-Suite-for-volesti) | Dev | C++ | Medium | 175 |\n\nAll contributor applications will be discussed by the **GeomScale** mentor community, and proposals will be ranked considering factors such as quality, contributor's ability to successfully finish the project, and impact for the **GeomScale** project.  A finite number of slots will be granted to **GeomScale** by Google, thus, only the best proposals will get chosen. This implies that it is possible that some ideas will not become GSoC projects even if they are supported by a good contributor application. \n\nContributors, if you are interested in a coding project related to **GeomScale** that is not listed above, please\ntry to find mentors by posting a description of your project idea on the [gitter](https://gitter.im/GeomScale/community?utm_source=share-link&utm_medium=link&utm_campaign=share-link). If you find mentors, feel free to add your project idea to this wiki and write an application.  \n\n## Information Candidates Should Supply  \n\nThe application process has several steps. Before contacting anybody verifies that you are eligible.\nThe next step is to contact the mentor of the project you are interested in. You have to convince them that you are the right person to get the job done. The next step is to work out more details and to\ncontact the mentors or the GeomScale org by providing the following information by email or by\n[gitter](https://gitter.im/GeomScale/community?utm_source=share-link&utm_medium=link&utm_campaign=share-link).  \n\n* Project:\n  * Select a project in the list and provide your personal and detailed description. If you wish to work on another idea of your own, we are pretty open as long as this serves the goal of consolidating GeomScale as a whole.\n  * Provide a proposal of a technical solution with your envisioned methodology. The more detailed the better.\n  * Explain how the solution will be available to the user, in which form. Do not forget the documentation, unitary tests, and cross-platform aspects.\n  * Provide a realistic schedule with objectives (one every two weeks for example) and deadlines. Focus on mid-term objectives as well as on the final evaluation.\n\n\n* Personal data:\n  * First name, last name, affiliation, and geographical location.\n  * A brief list of the main studies and programming courses attended, with ranking.\n  * List of the most important software projects contributed and success.\n  * Which are your best skills in terms of programming and scientific computing?\n  * In general what is your taste in terms of programming? language, methodology, teamwork, etc.\n  * Is there anything that prevents you from working full time on the project during the program period?\n  * How do you see your involvement after the program ends? Do you see yourself pushing the project further, or do you see yourself contributing to other GeomScale projects?\n  * Are you more interested in the theory/scientific aspect of GeomScale, or do you feel more like a hacker?"
  },
  {
    "name": "GNOME Foundation",
    "slug": "gnome-foundation",
    "tagline": "A diverse and sustainable free software desktop.",
    "description": "The GNOME Foundation is a non-profit organization that believes in a world where everyone is empowered by technology they can trust. We do this by building a diverse and sustainable free software personal computing ecosystem.",
    "ideas_url": "https://gsoc.gnome.org/2026/",
    "website_url": "https://gnome.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "linux",
      "rust",
      "gtk",
      "Flatpak"
    ],
    "topic_tags": [
      "operating systems",
      "desktop",
      "graphics",
      "open source",
      "apps"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/gnome-foundation",
    "ideas_content": "# GNOME Project ideas for Google Summer of Code 2026\n\nFor general information on how to get involved with our project and participate in [Google Summer of Code](https://summerofcode.withgoogle.com/) with [GNOME](https://gnome.org) visit [gsoc.gnome.org](https://gsoc.gnome.org)\n\nThis is the list of project ideas that the GNOME community is interested in mentoring. GSoC interns can also propose their very own project ideas. If you are interested in proposing a project idea, please file an issue in our [Internship Project Ideas repository.](https://gitlab.gnome.org/Teams/Engagement/internship-project-ideas)\n\nGSoC contributors proposing something original must engage with the community strongly before or during the application period to get feedback and guidance to improve the proposal.\n\n## Project list\n\nThis project will introduce a right-click \"Uninstall\" option to the GNOME Shell App Grid. Currently, users must open GNOME Software or use the terminal to uninstall apps. This feature will make it simpler and quicker to uninstall apps from the app grid directly.\n\n### Features\n\n#### Right-Click Uninstall\n\n- Users can right-click on an app icon and choose \"Uninstall.\"\n- A confirm message will pop up before un-installing the app.\n- System apps which cannot be un-installed will provide a warning.\n\n#### Works with Various App Types\n\n- Handles Flatpak, Snap, APT, RPM, and DNF packages.\n- Detects automatically how the app was installed and un-installs it properly.\n\n#### Improved User Experience\n\n- No need to open GNOME Software or the terminal.\n- Simple and user-friendly with clear messages.\n\n#### Handles Errors Smoothly\n\n- Warns users if an app is important for the system.\n- Shows error messages if the uninstall fails.\n- Displays a progress notification while uninstalling.\n\n### How It Works\n\n#### Technologies Used\n\n- GNOME Shell & Mutter for UI changes.\n- JavaScript & C for coding.\n- D-Bus to communicate with system package managers.\n- Polkit to handle permissions when needed.\n\n#### Steps\n\n- Modify GNOME Shell to add the right-click uninstall option.\n- Connect to package managers to remove apps.\n- Handle errors like system app protection.\n- Test and improve for smooth performance.\n\n### Requirements\n\n- JavaScript & C (for GNOME Shell development).\n- Basic knowledge of package managers (Flatpak, Snap, APT, RPM, DNF).\n- Experience with D-Bus and Polkit (for permissions and system communication).\n\n### Communication\n\nGitLab: @AdrianVovk, Matrix Nickname: @adrianvovk:matrix.org\n\n### Project Length: Long (~350 hours)\n\n### Future Improvements\n\n- Drag & Drop Uninstall – Drag app icons to uninstall.\n- Remove Multiple Apps at Once – Choose and uninstall numerous apps at once.\n- App Usage Insights – Recommend apps to uninstall based on usage.\n\nThis project will simplify uninstalling apps in GNOME and make it quicker. Including this feature as part of GNOME Shell will enhance the user experience, making app management easy and effective.\n\nFind out more in [https://gitlab.gnome.org/Teams/internship/project-ideas/-/issues/65](https://gitlab.gnome.org/Teams/internship/project-ideas/-/issues/65)\n\nWhen a GPU unexpectedly resets, we currently effectively freeze rendering, as the EGL context used for compositing becomes practically defunct, with all allocated GPU memory lost. This can be improved by handling GPU resets by supporting GL_EXT_robustness (https://registry.khronos.org/OpenGL/extensions/EXT/EXT_robustness.txt) by resetting the compositor EGL context/display, re-uploading all GPU resources (Wayland shm client textures, background image, text rendering glyph caches, GNOME Shell chrome textures, ...).\n\n### Requirements\n\nComputer graphics, OpenGL and EGL knowledge, excellent C skills, relevant hardware (AMD)\n\n### Communication\n\nThe #gnome-shell IRC/Matrix channel.\n\n### Project Length: TBD\n\nFind out more in [https://gitlab.gnome.org/Teams/internship/project-ideas/-/issues/68](https://gitlab.gnome.org/Teams/internship/project-ideas/-/issues/68)\n\nImplement support in mutter (and its scene graph and compositing library Clutter) for unredirecting client buffers into DRM overlay planes. This involves calculating what elements of the scene graph are candidates for unredirection, without relying on anything other than the scene graph state itself, as well as plumbing the act of unredirecting via the relevant kernel mode setting API, as well as evaluating eventually using libraries such as libliftoffi.\n\nRelated GitLab issues: [https://gitlab.gnome.org/GNOME/mutter/-/issues/61](https://gitlab.gnome.org/GNOME/mutter/-/issues/61)\n\n### Requirements\n\nComputer graphics and scene graph knowledge, excellent C skills, KMS/DRM experience\n\n### Communication\n\nThe #gnome-shell Matrix channel.\n\n### Project Length: TBD\n\nFind out more in [https://gitlab.gnome.org/Teams/internship/project-ideas/-/issues/10](https://gitlab.gnome.org/Teams/internship/project-ideas/-/issues/10)\n\nThis project is about adding support for playing and building vocab-style crossword puzzles to libipuz and GNOME Crosswords. These puzzles are solved similarly to crosswords, but are constructed/built differently. Instead of fitting words to a grid shape, a specific set of words are used and fit together as best as possible. These puzzles are commonly used in schools to teach students vocabulary for a unit or lesson.\n\n[Here's an example (first hit on google)](https://gitlab.gnome.org/-/project/19387/uploads/6601d25ca1bfe86e1c2cf8136e4edd53/image.png) of what these puzzle-types look like.\n\nThe project involves adding support to the puzzle kind in libipuz, making sure the player can play it correctly, and then extending the editor to automatically create such puzzles.\n\nThe bulk of the internship will be spent writing code to generate compact grids that fit the constraints, adjusting the GTK UI to support it, and making sure it prints correctly.\n\n### Components\n\n### Requirements\n\nExperience with C / GLib-style programming is required for this project.\n\n### Mentors\n\njblandford, federico\n\n### Project length\n\nShort Project\n\n### Communication\n\n[Matrix (#crosswords:gnome.org)](https://matrix.to/#/#crosswords:gnome.org) and GitLab are best.\n\nFind out more in [https://gitlab.gnome.org/Teams/internship/project-ideas/-/issues/69](https://gitlab.gnome.org/Teams/internship/project-ideas/-/issues/69)"
  },
  {
    "name": "AnkiDroid",
    "slug": "ankidroid",
    "tagline": "AnkiDroid makes remembering things easy",
    "description": "Memorize anything with AnkiDroid!<br/><br/>\n\nAnkiDroid lets you learn flashcards very efficiently by showing them just before you would forget. It is fully compatible with the spaced repetition software Anki (including synchronization), which is available for Windows/Mac/Linux/ChromeOS.<br/><br/>\n\nStudy all sorts of things wherever and whenever you want. Make good use of idle times on bus trips, in supermarket queues or any other waiting situation!<br/><br/>\n\nCreate your own flashcard decks or download free decks compiled for many languages and topics (more than 6000 available).<br/><br/>\n\nAdd material through the desktop application Anki or directly through AnkiDroid. The application even supports adding material automatically from a dictionary!<br/><br/>\n\n★ Key features:<br/>\n• supported flashcard contents: text, images, sounds, LaTeX & MathJax<br/>\n• spaced repetition (supermemo 2 algorithm)<br/>\n• text-to-speech integration<br/>\n• check your pronunciation<br/>\n• more than 6000 premade decks<br/>\n• progress widget<br/>\n• detailed statistics<br/>\n• syncing with AnkiWeb<br/>\n• open source",
    "ideas_url": "https://docs.google.com/document/d/1ygIJl-Tp5_wJDKkSXrCC8h5K3WUG8D4BcJa_j70F0Zo",
    "website_url": "https://github.com/ankidroid/Anki-Android",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "android",
      "rust",
      "kotlin",
      "mobile"
    ],
    "topic_tags": [
      "education",
      "mobile",
      "android",
      "user generated content",
      "Flashcards"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/ankidroid",
    "ideas_content": "Die Datei kann in Ihrem Browser nicht geöffnet werden, weil JavaScript nicht aktiviert ist. Aktivieren Sie JavaScript und laden Sie die Seite noch einmal.\nAnkiDroid 2026 GSoC Ideas List\nTab\nExtern\nFreigeben\nAnmelden\nDatei\nBearbeiten\nAnsicht\nTools\nHilfe\nBedienungshilfen\nFehlerbehebung"
  },
  {
    "name": "CNCF",
    "slug": "cncf",
    "tagline": "Building sustainable ecosystems for cloud native",
    "description": "Cloud Native Computing Foundation (CNCF) serves as the vendor-neutral home for many of the fastest-growing open source projects, including Kubernetes, Prometheus, and Envoy.",
    "ideas_url": "https://github.com/cncf/mentoring/blob/main/programs/summerofcode/2026.md",
    "website_url": "https://cncf.io",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "prometheus",
      "kubernetes",
      "OpenTelemetry",
      "envoy"
    ],
    "topic_tags": [
      "cloud",
      "cloud native",
      "observability"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/cncf",
    "ideas_content": "## Project Ideas\n\nIf you are a project maintainer and are considering mentoring during the GSoC 2026 cycle, please, submit your ideas below using the template.\n\n[Google Summer of Code 2026 Announcement](https://groups.google.com/g/google-summer-of-code-discuss/c/D-aU3nHnGBQ/m/VU7lwF_MBQAJ)  \n[Google Summer of Code Timeline](https://developers.google.com/open-source/gsoc/timeline)\n\nKey GSoC 2026 dates:\n* Organizations application period: Monday, Jan 19, to Tuesday, Feb 3, 2026\n* CNCF Project proposals submissions recommendation: Wednesday Jan 14, 2026\n  **Note**, proposals can still be submitted after this recommended date, but the Mentorship team needs time to evaluate the proposals and package our application. The more proposals we have, the stronger our org application will be.\n\nYou can find the project ideas from previous year [here](./2025.md).\n\n> **NOTE:** Please note that GSoC is a program known for its strict deadlines. In addition to responding to your mentee on time, you will be required to submit evaluations on time. Failures to meet the deadlines might affect CNCF's future participation in GSoC.\n\nLinux Foundation [Guidance Regarding Use of Generative AI Tools for Open Source Software Development](https://www.linuxfoundation.org/legal/generative-ai)\n\n---\n\n### Template\n\n```\n#### CNCF Project Name\n\n##### Project Title\n\n- Description:\n- Expected Outcome:\n- Recommended Skills:\n- Expected project size: # one of small (~90 hour projects), medium (~175 hour projects) and large (~350 hour projects)\n- Mentor(s): #For GSoC, it is **required** to have at least 2 mentors with 1 being a primary mentor.\n  - Jane Doe (@jane-github, jane@email.address) - primary\n  - John Doe (@john-github, john@email.address)\n- Upstream Issue (URL):\n```\n\n---\n\n## Ideas\n\n\n<!-- TOC -->\n* [Drasi](#drasi)\n  * [Reactive Agents with Drasi & Dapr](#reactive-agents-with-drasi-dapr)\n* [Inspektor Gadget](#inspektor-gadget)\n  * [Security-focused UX Improvements for the Inspektor Gadget kubernetes-sigs/headlamp Plugin](#security-focused-ux-improvements-for-the-inspektor-gadget-kubernetes-sigsheadlamp-plugin)\n* [Jaeger](#jaeger)\n  * [AI-Powered Trace Analysis: Phase 2 - Self-Service \"Skills\" Framework](#ai-powered-trace-analysis-phase-2---self-service-skills-framework)\n* [kgateway](#kgateway)\n  * [Benchmarking and Performance Evaluation of Inference Routing Extensions in kgateway](#benchmarking-and-performance-evaluation-of-inference-routing-extensions-in-kgateway)\n* [KitOps](#kitops)\n  * [Enrich KitOps Integration Guides with Kubeflow Model Registry, Argo Workflows, Kyverno](#enrich-kitops-integration-guides-with-kubeflow-model-registry-argo-workflows-kyverno)\n* [Kmesh](#kmesh)\n  * [Kmesh Dashboard for Simplified Service Mesh Management](#kmesh-dashboard-for-simplified-service-mesh-management)\n* [[kpt](https://kpt.dev/)](#kpt)\n  * [Build e-commerce example kpt package](#build-e-commerce-example-kpt-package)\n* [ModelPack](#modelpack)\n  * [Unified transformer specification and its auto-generation method for the existing models](#unified-transformer-specification-and-its-auto-generation-method-for-the-existing-models)\n* [OpenKruise](#openkruise)\n  * [Alternative progressive delivery of deployment without changing strategy to Recreate](#alternative-progressive-delivery-of-deployment-without-changing-strategy-to-recreate)\n* [OpenTelemetry](#opentelemetry)\n  * [OTTL stabilization and 1.0 offering](#ottl-stabilization-and-10-offering)\n* [OSCAL Compass](#oscal-compass)\n  * [OSCAL documents signing](#oscal-documents-signing)\n* [PipeCD](#pipecd)\n  * [GCP Cloud Run plugin for pipedv1](#gcp-cloud-run-plugin-for-pipedv1)\n* [WasmEdge](#wasmedge)\n  * [Implement Custom Section Parsing and Branch Hinting proposal](#implement-custom-section-parsing-and-branch-hinting-proposal)\n  * [Refine the WASM instruction structure in WasmEdge](#refine-the-wasm-instruction-structure-in-wasmedge)\n  * [WASM Exception-Handling proposal for AOT/JIT in WasmEdge](#wasm-exception-handling-proposal-for-aotjit-in-wasmedge)\n<!-- TOC -->\n\n#### Drasi\n\n##### Reactive Agents with Drasi & Dapr\n\n- Description: Current AI Agents are mostly \"passive\"—they wait for a user to chat with them. To build \"Ambient Agents\" that can autonomously monitor and react to the world (e.g., \"Wake up when a high-value order is stuck\"), developers need to bridge Real-Time Change Detection with Resilient Agent Runtimes.\n\n- This project connects two CNCF ecosystem projects: **Drasi** (Change Detection) and **Dapr Agents** (Agent Framework). The goal is to build a unified Python-based integration layer that allows Dapr Agents to dynamically \"sense\" their environment. The student will build a \"Smart Router\" reaction that will allow Drasi to send events to Dapr Pub/Sub as standard CloudEvents, and update the Dapr Agents SDK to make subscribing to these events a one-line code experience. This enables \"Scale-to-Zero\" architectures where agents only wake up when specific data conditions are met, eliminating inefficient polling or fragile persistent socket connections.\n\n- Expected Outcome:\n  - **Drasi Router Reaction (Python):** A configurable microservice that routes Drasi events to Dapr Pub/Sub topics based on dynamic rules and hosts an embedded MCP (Model Context Protocol) Server for agents to discover queries at runtime.\n  - **Dapr Agents SDK Extensions:** A Python module (`dapr_agents.extensions.drasi`) containing Pydantic models for Drasi events and a `@drasi_trigger` decorator that handles CloudEvent validation and subscription automatically.\n  - **Ambient Agent Demo:** A complete end-to-end reference architecture (e.g., a \"Proactive Support Agent\") that detects critical database changes and trigger a Dapr Agent workflow to resolve them.\n\n- Recommended Skills:\n  - Python (Intermediate/Advanced)\n  - Kubernetes & Docker (Intermediate)\n  - Understanding of Microservices and Pub/Sub\n\n- Expected project size: Large\n\n- Mentor(s):\n  - Aman Singh (@amansinghoriginal, singh.amandeep@microsoft.com) from Drasi - primary\n  - Casper Nielsen (@CasperGN, casper@diagrid.io) from Dapr Agents\n\n- Upstream Issue (URL): https://github.com/drasi-project/drasi-platform/issues/383\n\n\n#### Inspektor Gadget\n\n##### Security-focused UX Improvements for the Inspektor Gadget kubernetes-sigs/headlamp Plugin\n\n- Description:\n This project improves the user experience of the Inspektor Gadget plugin for Headlamp with a security-first perspective. The work focuses on four areas: (1) improving interactive traffic visualization so operators can understand and investigate cluster communication patterns, (2) adding an ebpftop-style view to monitor resource usage and runtime status of eBPF gadgets (to make observability overhead transparent), (3) improving DNS debugging workflows with security-relevant signals (failed lookups, retry storms, unexpected domains/resolutions), and (4) streamlining installation/onboarding with guided setup, prerequisite checks, and clearer error handling to reduce misconfiguration and unsafe permissioning. \n\n- Expected Outcome:\n  - Improvements to an interactive traffic capture and visualization experience in Headlamp that helps operators understand and investigate cluster communication patterns.\n  - Improvements to a resource monitoring dashboard for eBPF programs/gadgets showing real-time and (where feasible) historical CPU/memory metrics to understand observability overhead.\n  - Improvements to DNS debugging UX that helps diagnose DNS failures and highlights security-relevant DNS behaviors (failed lookups, retry storms, unexpected domains/resolutions) scoped to relevant workloads/namespaces.\n  - Improvements to the Inspektor Gadget installation/onboarding experience with step-by-step guidance, prerequisite checks, actionable error messages, and troubleshooting assistance.\n  \n- Recommended Skills: \n  TypeScript, React, UX design principles \n  Optional Kubernetes fundamentals, networking concepts, eBPF fundamentals \n\n- Expected project size: \n  large (~350 hour projects) \n- Mentor(s): \n  - Ashu Ghildiyal (@ashu8912, ashughildiyal5@gmail.com) - primary\n  - Dor Serero (@dorser, dor.serero@gmail.com)\n  - Rene Dudfield (@illume, renesd@gmail.com) \n\n- Upstream Issue (URL): \n  - https://github.com/inspektor-gadget/headlamp-plugin/issues/17 \n\n\n#### Jaeger\n\n##### AI-Powered Trace Analysis: Phase 2 - Self-Service \"Skills\" Framework\n\n- **Description:** Jaeger is the industry-standard platform for distributed tracing. As microservice architectures grow complex, finding root causes in massive trace data becomes increasingly difficult. While Phase 1 of this initiative established a baseline AI assistant for natural language search, the system currently relies on hard-coded capabilities. This project (Phase 2\\) aims to transform the Jaeger AI agent from a static chatbot into an extensible, user-programmable platform. The primary objective is to implement a \"Self-Service Skills\" framework, architecturally similar to \"Claude Code Skills.\" This will allow end-users to teach the Jaeger AI new debugging workflows (e.g., \"Analyze Critical Path\" or \"Detect N+1 Queries\") by simply adding configuration files containing system prompts and logic rules, without needing to recompile the Jaeger binary. The applicant will build this extension within the Jaeger v2 (OpenTelemetry-based) architecture, utilizing **LangChainGo** to orchestrate interactions with Language Models (SLMs/LLMs). This project bridges the gap between generic AI reasoning and domain-specific observability expertise.\n- **Expected Outcome:**\n  - **Skills Engine Implementation:** A robust backend framework in Go that dynamically discovers, validates, and loads user-defined \"Skills\" (prompts and tool definitions) from configuration.\n  - **Smart Analysis Features:** A polished implementation of Natural Language Search and Contextual Trace Explanation that intelligently leverages these loaded skills.\n  - **Local-First Support:** Verified compatibility with local model runners (e.g., Ollama, Llama.cpp) to ensure deterministic performance without sending data to public clouds.\n  - **UI Integration:** Enhancements to the Jaeger React UI to expose these AI capabilities and visualize the \"reasoning steps\" taken by the agent.\n  - **Documentation:** A complete guide for users on \"How to Author Custom AI Skills for Jaeger.\"\n- **Learning Opportunities:**\n  - **Agentic AI Architecture:** Learn to design stateful AI agents in Go that utilize \"Tool Calling\" and \"Reasoning Loops\" rather than simple text generation.\n  - **OpenTelemetry Internals:** Gain deep familiarity with the OpenTelemetry Collector architecture, as Jaeger v2 is built directly on top of it.\n  - **Cloud-Native Engineering:** Experience contributing to a graduated CNCF project, including navigating code reviews, writing design docs (RFDs), and adhering to open-source best practices.\n  - **Full-Stack Development:** Practical experience bridging a complex Go backend with a modern React frontend.\n- **Recommended Skills:**\n  - **Languages:** Strong proficiency in **Go (Golang)** is required. Experience with **TypeScript/React** is highly recommended.\n  - **AI/LLM:** Familiarity with LLM concepts (Prompt Engineering, RAG, Function Calling) and frameworks like LangChain.\n  - **Domain Knowledge:** Basic understanding of distributed systems, observability, or debugging workflows is beneficial.\n- **Expected project size:** Large (~350 hour projects)\n- **Mentors:**\n  - Jonah Kowall (@jkowall, jkowall@kowall.net)\n  - Yuri Shkuro (@yurishkuro, github@ysh.us)\n- Upstream Issue: https://github.com/jaegertracing/jaeger/issues/7827\n\n\n#### kgateway\n\n##### Benchmarking and Performance Evaluation of Inference Routing Extensions in kgateway\n\n- Description: kgateway provides inference routing capabilities based on the Kubernetes Gateway API Inference Extension project. This integration enables advanced behaviors such as model-aware routing, serving priority, and customizable load-balancing of self-hosted Generative AI models.\n\n  However, there is currently no standardized or reproducible way to evaluate the performance impact of these inference routing extensions.\n\n  This project aims to design and implement a comprehensive benchmarking framework to measure the latency, throughput, and resource overhead introduced by inference routing extensions in kgateway. The benchmarks will help maintainers and users understand performance tradeoffs, validate optimizations, and guide future architectural decisions.\n\n- Expected Outcome:\n  - A reproducible benchmarking framework for inference routing extensions in kgateway\n  - Benchmark scenarios covering:\n    - Baseline gateway routing vs inference-enabled routing\n    - Different inference extensions and EPP configurations\n    - Request/response and streaming inference workloads\n  - Collected metrics including:\n    - End-to-end latency (p50 / p95 / p99)\n    - Throughput\n    - CPU and memory overhead\n  - Automated benchmark execution (e.g., via CI or documented scripts)\n  - Documentation describing benchmark methodology, results interpretation, and best practices\n\n- Recommended Skills:\n  - Go\n  - Kubernetes\n  - Familiarity with gateways or networking concepts\n  - Basic understanding of AI inference workloads is a plus\n\n- Expected project size:\n  Medium (~175 hour projects)\n\n- Mentor(s):\n  - Primary Mentor: Nina Polshakova (@npolshakova, nina.polshakova@solo.io)\n  - Secondary Mentor: Daneyon Hansen (@danehans, daneyon.hansen@solo.io)\n\n- Upstream Issue (URL):\n  https://github.com/kgateway-dev/kgateway/issues/12289\n\n\n#### KitOps\n\n##### Enrich KitOps Integration Guides with Kubeflow Model Registry, Argo Workflows, Kyverno\n\n- Description: KitOps enables OCI-based packaging and distribution of ML artifacts such as models, datasets, and configurations. Kubeflow’s Model Registry supports OCI-based storage, which aligns well with KitOps’ design. However, there is currently no standardized guidance on how to use KitOps with the Kubeflow Model Registry. This project will define documentation explaining how to set up and use KitOps for model registration, retrieval, and lifecycle management within a Kubeflow environment. The work will cover setup, usage patterns, and best practices, with optional references to extending these workflows to related tools such as Argo Workflows. There is also potential for a guide on how to extend policy engines for ML workflows with Kyverno. \n\n- Expected Outcome:\n  - Documentation describing how to use KitOps with Kubeflow Model Registry\n  - Step-by-step guides for model registration, retrieval, and management\n  - tutorial\n- Recommended Skills:\n  - Python\n  - Golang\n  - Technical Writing\n- Expected project size: small\n- Mentor(s): #For GSoC, it is **required** to have at least 2 mentors with 1 being a primary mentor.\n  - Gorkem Ercan (@gorkem, gorkem.ercan@gmail.com) - primary\n  - Angel Misevski (@amisevsk, amisevsk@gmail.com)\n- Upstream Issue (URL): https://github.com/kitops-ml/kitops/issues/858\n\n\n#### Kmesh\n\n##### Kmesh Dashboard for Simplified Service Mesh Management\n\n- Description: In discussions with developers and end-users, we have received numerous comments indicating that Kmesh presents an excessively high barrier to use. For example, the use of waypoints encompasses three levels of granularity: Namespace, Service, and Workload. Furthermore, certain traffic management policies necessitate editing the Envoy filter. Following discussions on this matter during the community meeting, it was decided to incorporate a Kmesh dashboard into the Kmesh project. This will lower the barrier to using Kmesh through an interactive interface.\n- Expected Outcome:\n  - A user-friendly dashboard that simplifies Kmesh operations through intuitive UI workflows\n  - One-click or guided waypoint installation across Namespace, Service, and Workload levels with clear visual feedback\n  - Interactive service topology map (similar to Kiali) showing service dependencies, traffic flow, and health status\n  - Simplified circuit breaker configuration interface with preset templates and real-time validation\n  - Rate limiting configuration with visual policy builder and immediate feedback on applied rules\n  - Integrated metrics dashboard showing key service mesh performance indicators (latency, error rates, throughput)\n  - Built-in authentication support with role-based access control (RBAC) for secure dashboard access\n  - Comprehensive documentation and user guides for all dashboard features\n- Recommended Skills: TypeScript, React, Kubernetes, Service Mesh concepts, UX/UI design principles\n  TypeScript, React, Kubernetes, Service Mesh concepts, UX/UI design principles\n- Expected project size: medium\n  - ZhenCheng Li(@LiZhenCheng9527, leezhencheng6@gmail.com) - primary,\n  - Zhonghu Xu (@hzxuzhonghu, zhhxu2011@gmail.com),\n  - Zengzeng Yao(@yaozengzeng, yaozengzeng@huawei.com)\n- Upstream Issue (URL): https://github.com/kmesh-net/kmesh/issues/1552\n\n\n#### [kpt](https://kpt.dev/)\n\n[kpt](https://kpt.dev/) is a toolchain that allows users to cutomize kubernets packages declaratively. kpt uses a\n[configuration as data](https://cloud.google.com/blog/products/containers-kubernetes/understanding-configuration-as-data-in-kubernetes)\napproach for customization. The user specifies their customization changes as data in yaml files and kpt updates\nthe source package by applying the customization to the kubernetes package. Unlike templating tools such as helm,\nthere are no costomization directives in the source package itself.\n\nCurrently, complete examples for using kpt are in specialized domains such as telecommunication management, which \nare difficult to understand without familiarity with that domain. Other examples such as those int eh documentation \nare rather piecemeal and don't give a complete picture of the power of kpt. The purpose of this project is to \nprovide a complete example that demonstrates the power of kpt in a domain that is more widely understood.\n\n##### Build e-commerce example kpt package\n\nIn this project, the contributor will take a complete e-commerce application such as [Online Boutique](https://github.com/GoogleCloudPlatform/microservices-demo)\nand package it as a kpt package. The contributor will then show how the example can be customized using the kpt \ntoolchain in a number of ways such as:\n\n1. Change from online boutique to online florist or online car accessory site\n1. Language and currency localization\n1. Sales Tax/VAT localization\n1. Deployment configuration (Small/medium/large)\n\n\n- Description: Use an example e-commerce application and create the related kpt package with the description how to deploy the application.\n- Expected Outcome: The kpt file and related documentation of an e-commerce example application are contributed to kpt\n- Recommended Skills: Capability to learn, basic cloud native skills\n- Expected project size: small (~90 hours)\n- Mentor(s): #For GSoC, it is **required** to have at least 2 mentors with 1 being a primary mentor.\n  - Liam Fallon (@liamfallon) - primary\n  - Ciaran Johnston (@ciaranjohnston)\n  - Gergely Csatari (@CcsatariGergely)\n- Upstream Issue (URL): https://github.com/kptdev/kpt/issues/4326\n\n\n#### ModelPack\n\n##### Unified transformer specification and its auto-generation method for the existing models\n\n- Description: Transformer is the dominant architecture for modern LLMs, and its design has largely converged. For example, most state-of-the-art open-source models adopt GQA/MLA for the Attention layer and MoE for the MLP layer. As a result, a Transformer can be viewed as a composition of standardized building blocks. This enables further abstraction of a unified architectural specification across different open-source models, which can serve as the Transformer specification in ModelPack. Based on this specification, many valuable capabilities become possible. For inference engines, it enables automatic support for multiple Transformer models, so newly trained Transformer models can be supported without per-model adaptation.\n- Expected Outcome:\n  - Jointly complete a unified Transformer specification (an in-progress PR already exists)\n  - Using vLLM and SGLang, conduct POCs on three or more mainstream open-source Transformer models based on this specification\n  - Design a workflow or Claude skills that can automatically generate Transformer specification definitions from models in the Hugging Face transformers repository\n- Recommended Skills:\n  - Python\n  - Familiar with LLM Prompts and LLM Inference Engine\n- Expected project size: medium\n- Mentor(s):\n  - Zhao Chen (@aftersnow, zhaochen.zju@gmail.com) - primary\n  - Peng Tao (@bergwolf, bergwolf@hyper.sh)\n- Upstream Issue (URL): https://github.com/modelpack/model-spec/issues/164\n\n\n\n#### OpenKruise\n\n##### Alternative progressive delivery of deployment without changing strategy to Recreate\n\n- Description: Currently **OpenKruise Rollout** change the updateStrategy of kubernetes Deployment to Recreate during the progressive delivery. However such hack cause concerns about the risk of recreate all pods if deployment is not paused properly. This program will explore an alternative strategy that utilize the minReadySeconds and maxUnvailable knobs to control the progressive delivery of Deployment. It is hopefully a more robust way of enabling progressive delivery for native Deployment workload.\n- Expected Outcome:\n  - add an alternative implementation for progressive delivery of Deployment in OpenKruise Rollout\n  - end-to-end test cases that cover related normal rollout, rollback cases\n- Recommended Skills:\n  - Kubernetes (Intermediate)\n  - Operator Development\n  - Golang\n- Expected project size: medium\n- Mentor(s): #For GSoC, it is **required** to have at least 2 mentors with 1 being a primary mentor.\n  - Zhang Zhen (@furykerry, furykerry@gmail.com) - primary\n  - Zhong Tianyun (@AiRanthem, airanthem666@gmail.com)\n- Upstream Issue (URL): https://github.com/openkruise/rollouts/issues/323\n\n\n\n#### OpenTelemetry\n\n##### OTTL stabilization and 1.0 offering\n\n- Description: This project focuses on the stabilization and creation of a 1.0 offering for the OpenTelemetry Transformation Language (OTTL) within the OpenTelemetry Collector. OTTL is a domain-specific language used to transform telemetry data as it passes through the collector. The goal is to bring OTTL to a stable 1.0 state by addressing a series of identified improvements and feature gaps. This includes enhancing the language's expressiveness with features like looping support (e.g., iterating over maps and slices) and refining the type system to ensure robustness and ease of use. The mentee will work on language implementation in Go, participate in design discussions, and contribute to the stabilization of the language. This is a great opportunity to learn about language design, compilers, and the internals of a high-performance observability tool.\n- Expected Outcome:\n  - Implementation of key features such as looping support and type system enhancements.\n  - Resolution of stabilization issues identified in the path to 1.0.\n  - Improved test coverage and documentation for new and existing OTTL features.\n  - Contribution to the OTTL specification and design proposals.\n- Recommended Skills: Go, understanding of data structures, interest in language design and parsing.\n- Expected project size: large (~350 hour projects)\n- Mentor(s):\n  - Ridwan Sharif (@ridwanmsharif, ridwanmsharif@google.com) - primary\n  - Braydon Kains (@braydonk, braydonk@google.com)\n- Upstream Issue (URL): \n  - https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/30800\n  - https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/45365\n\n\n\n#### OSCAL Compass\n\n##### OSCAL documents signing\n\n- Description: CNCF OSCAL Compass trestle provides means to author and validate OSCAL documents including catalogs, profiles, component definitions and such. There is currently no standardized way to sign same. Needed is to define the signing goals and trust model, choosing the signing and envelope standards, and the implementation of signing during artifact generation. Also needed are key management and identity, verification support, and provenance metadata support. See upstream issue for more details.\n\n- Expected Outcome:\n  - trestle code to sign and verify signing of OSCAL documents\n  - clear error messages for failures\n  - sufficient test case coverage\n  - documentation\n  - tutorial\n- Recommended Skills:\n  - Python\n- Expected project size: large\n- Mentor(s): #For GSoC, it is **required** to have at least 2 mentors with 1 being a primary mentor.\n  - Lou DeGenaro (@degenaro, lou.degenaro@gmail.com) - primary\n  - Chris Butler (@butler54, chris.butler@redhat.com)\n  - Vikas Agarwal (@vikas-agarwal76, avikas@in.ibm.com)\n- Upstream Issue (URL): https://github.com/oscal-compass/compliance-trestle/issues/2037\n\n\n#### PipeCD\n\n##### GCP Cloud Run plugin for pipedv1\n\n- Description: PipeCD v1 - the new version based on a plugin architecture (ref: [PipeCD plugin-arch overview blog](https://pipecd.dev/blog/2024/11/28/overview-of-the-plan-for-pluginnable-pipecd/)), has released an alpha version, and we are rapidly adding features supported in v0. We need to develop a plugin for PipeCD v1 to support [GCP Cloud Run](https://cloud.google.com/run) deployment. In PipeCD v0, the support for GCP Cloud Run deployment is built in piped source directly (ref [PipeCD Cloud Run deployment](https://pipecd.dev/docs-v0.55.x/user-guide/managing-application/defining-app-configuration/cloudrun/)), the idea is to move the Cloud Run deployment support to the plugin to make it easier to maintain and extend.\n- Expected Outcome:\n  - CloudRun plugin for PipeCD\n  - Possible update plugin SDK while develop the plugin\n  - Possible update docs how to develop PipeCD plugin\n  - Blog about how to develop a PipeCD plugin on [https://pipecd.dev/blog/](https://pipecd.dev/blog/)\n- Recommended Skills:\n  - Golang\n  - GCP Cloud Run\n  - GitOps\n  - Continuous Delivery (CD)\n- Expected project size: Medium\n- Mentor(s):\n  - Khanh Tran (@khanhtc1202, khanhtc1202@gmail.com)\n  - Shinnosuke Sawada-Dazai (@Warashi, shin@warashi.dev)\n- Upstream Issue:\n  - https://github.com/pipe-cd/pipecd/issues/6114\n\n#### WasmEdge\n\n##### Implement Custom Section Parsing and Branch Hinting proposal\n\n- Description: As discussed in the [WasmEdge January 2026 community meeting](https://youtu.be/MKOHVU1VBzg), some toolchains may want to apply the branch hinting proposal. However, WasmEdge is currently unable to implement it due to the lack of custom section parsing. In this program, we aim to incorporate custom section parsing and branch hinting into the WasmEdge toolchain.\n- Expected Outcome:\n  - A series of test cases that verify the behavior of the custom section parsing and branch hinting proposal\n  - An implementation of these defined features\n  - A document discussing the design decisions and how to use them\n- Recommended Skills:\n  - C++\n  - WebAssembly\n- Expected project size: large\n- Mentor(s): #For GSoC, it is **required** to have at least 2 mentors with 1 being a primary mentor.\n  - YiYing He (@q82419, yiying@secondstate.io) - primary\n  - Hung-Ying, Tai (@hydai, hydai@secondstate.io)\n- Upstream Issue (URL): https://github.com/WasmEdge/WasmEdge/issues/4517\n\n\n##### Refine the WASM instruction structure in WasmEdge\n\n- Description: According to the definition of WASM instructions, there are variety of immediates in every instructions. And in WasmEdge data structures currently, the immediates data of each instructions is packaged in the instruction class. This causes the situation that the instruction class should have the enough size to fit both the instructions with large and small size of immediates, and the runtime memory usage is wasted. In this program, we expect the mentee to refactor the data structures to split the instruction OpCode vector and the immediates data buffer vector to refine the memory usage of WasmEdge.\n- Expected Outcome:\n  - Refactor the instruction class to split the OpCode vector and immediates data\n  - Update all tests which contain the instruction class and pass all tests\n  - Perf the memory usage to prove the implementation\n- Recommended Skills:\n  - C/C++\n  - WebAssembly\n- Expected project size: large\n- Mentor(s): #For GSoC, it is **required** to have at least 2 mentors with 1 being a primary mentor.\n  - YiYing He (@q82419, yiying@secondstate.io) - primary\n  - Hung-Ying, Tai (@hydai, hydai@secondstate.io)\n- Upstream Issue (URL): https://github.com/WasmEdge/WasmEdge/issues/4558\n\n\n##### WASM Exception-Handling proposal for AOT/JIT in WasmEdge\n\n- Description: The exception-handling proposal is merged into the WASM spec version 3.0. In WasmEdge, we supported the interpreter mode. Since the WASM 3.0 become the default WASM standard currently, we should implement the AOT/JIT mode of this proposal for the completion of the WASM 3.0. In this program, we expect the mentee to implement the exception-handling proposal in AOT/JIT and pass the spec tests.\n- Expected Outcome:\n  - Implement the AOT/JIT of exception-handling proposal according to the WASM spec\n  - Pass the spec tests\n- Recommended Skills:\n  - C/C++\n  - WebAssembly\n  - LLVM\n- Expected project size: large\n- Mentor(s): #For GSoC, it is **required** to have at least 2 mentors with 1 being a primary mentor.\n  - YiYing He (@q82419, yiying@secondstate.io) - primary\n  - Hung-Ying, Tai (@hydai, hydai@secondstate.io)\n- Upstream Issue (URL): https://github.com/WasmEdge/WasmEdge/issues/4557"
  },
  {
    "name": "rocket.chat",
    "slug": "rocketchat",
    "tagline": "Open source communications platform for the AI age",
    "description": "Open source team chat and communications platform \n\nRocket.Chat is one of the largest active open source (permissive MIT license) nodeJS communications platform communities on GitHub, connecting 2,500+ global community contributors (across projects) from 30+ countries, with 41,700+ GitHub stars, 11,100 forks, 1,005+ total releases and 15,100+ issues since inception in 2015.\n\nRocket.Chat is a team chat platform written in full-stack Typescript. It offers a fully featured team chat experience on modern browsers, comparable to Slack and Microsoft Teams. Mobile and desktop clients run on iOS, Android, Mac, Windows, and Linux. The server can scale from a small family messaging server for 5 users on a Raspberry Pi 5, to clustered micro-services configuration that can support hundred thousands of users. On-premises Rocket.Chat can ensure 100% complete security and privacy of your valuable communications/data.\n\nRocket.Chat is now installed on over 500k servers and counts over 12m users worldwide.  Federated communication support extends our reach exponentially. \n\nUsers can set up Rocket.Chat on cloud or by hosting their own servers on-premises. Thanks to its extension support via Rocket.Chat Apps, and rich APIs, startups and innovators have customized Rocket.Chat into new products and services. Omnichannel extends reach to wherever user may be including WhatsApp, Instagram, Facebook Messenger and more.  Increasingly, innovators in Generative AI  and LLM app developers are launching their concepts on the Rocket.Chat platform to keep all data flows and communications 100% private and secure. \n\nRocket.Chat has won multiple prizes such as a 2016 Bossie Award for Best Open Source Application and first prize in the 2017 edition of All Things Open’s Startup Competition.\n\nRocket.Chat's community interacts 24 x 7 at the community Rocket.Chat server  https://open.rocket.chat  since  2015.",
    "ideas_url": "https://github.com/RocketChat/google-summer-of-code/blob/main/google-summer-of-code-2026.md#-project-ideas",
    "website_url": "https://github.com/RocketChat",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "javascript",
      "typescript",
      "node",
      "LLM",
      "generative ai"
    ],
    "topic_tags": [
      "communications",
      "messaging",
      "group chat",
      "Team Collaboration",
      "Chat platform"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/rocketchat",
    "ideas_content": "# Google Summer of Code 2026\n\n## [![Google Summer of Code 2026](https://github.com/Sing-Li/bbug/raw/master/images/gsoclogo.jpg)](https://summerofcode.withgoogle.com)\n\n## How to apply\n\nRocket.Chat is proud to be a participating mentoring open source organization for [Google Summer of Code 2026](https://summerofcode.withgoogle.com/). helping to usher in a new generation of global open source contributors and enthusiasts.\n\nJoin our [Google Summer of Code 2026 Team ](https://open.rocket.chat/channel/opensource2026) and introduce yourself to the rapidly growing community of 800+ right now! \n\nFor timeline, see [Official Google Summer of Code 2026](https://developers.google.com/open-source/gsoc/timeline) Timeline for more details.\n\nAlmost anyone in the world [over 18 years of age](https://opensource.googleblog.com/2021/11/expanding-google-summer-of-code-in-2022.html) who loves coding and wants to explore the incredible world of open source can join us as a GSoC 2026 contributor.\n\nMost exciting news for the 2026 season is continued focus on ML/AI projects, and the continued support for a small project size with a 90 hours duration; allowing participation from those who can only devote part of their summer to exploring open source.\n\nFor details and rules of Google Summer of Code 2026, please see the [GSoC 2026 Official Website](https://summerofcode.withgoogle.com/). For timeline, see [Official Google Summer of Code 2026 Timeline](https://developers.google.com/open-source/gsoc/timeline) for more details.\n\nIf you intend to use AI to assist you in the creation of your project proposal, please be aware that we will not be accepting any proposals that is directly created by an LLM or Agentic AI tooling.   The proposal must be crafted by you personally (OK to use AI for research, translation, and so on) and you must be ready to defend every line of its content when/if we contact you for a meeting.  You should also be engaged within our community (active on our [Google Summer of Code 2026 Team ](https://open.rocket.chat/channel/opensource2026), attend our weekly tea time, take our live workshops, and so on) and have auditable Github activity to increase the probability of your proposal being considered for GSoC 2026.   See [Google's Contributors Guide on using AI tooling in GSoC 2026](https://docs.google.com/document/d/1t9GcIBnNXPNO6klRQvU8pL8-uV6afzLo6JUAM299suA/edit?tab=t.0#heading=h.tgbr0z4x9eg5) for some suggestions.\n\n### **Contacting Rocket.Chat**\n\nFor general information, please visit our 24 x 7 community channel for Google Summer of Code 2026 : [https://open.rocket.chat/channel/opensource2026](https://open.rocket.chat/channel/opensource2026)\n\nJoin our [Google Summer of Code 2026 Team ](https://open.rocket.chat/channel/opensource2026) today, introduce yourself to the friendly community, and interact with over **800 like-minded** contributors/mentors (as of February 17, 2026) and meet the team in the [12+ team channels](https://open.rocket.chat/channel/opensource2026/team-channels).\n\nInterested contributors are also encouraged to interact directly with our team and community on the team channels:\n\n[https://open.rocket.chat/channel/opensource2026/team-channels](https://open.rocket.chat/channel/opensource2026/team-channels)\n\nAs well as on GitHub:\n\n[https://github.com/RocketChat/Rocket.Chat](https://github.com/RocketChat/Rocket.Chat)\n\nThose who prefers forums can post messages on our GSoC forum channel (although as the leading open source team chat project we prefer you use Rocket.Chat channels above to reach us instantly).\n\n---\n\n### **Latest update**\n\nAs of **February 17, 2026**  we have welcomed *800* open source contributors from all over the world, new to Rocket.Chat, to join us for preparation of GSoC 2026 in our [community channel](https://open.rocket.chat/channel/opensource2026).  Over *68* contributors have already signed up for our [open source contribution leaderboard](https://gsoc.rocket.chat) and contributed 14 Merged PRs, 155 Open PRs, and 113 Issues!  Our [2026 ideas list](https://github.com/RocketChat/google-summer-of-code/blob/main/google-summer-of-code-2026.md#-project-ideas) is now live and mentors (many returning former GSoC participants) are finalizing details of the projects.  We are meeting everyone at a live tea time every Friday and just announced a live workshop on App creation that community members can participate in.    Thanks to everyone for their interest and ethusiasm on open source.\n\nAs of **January 27, 2026**  we have welcomed *638* open source contributors from all over the world, new to Rocket.Chat, to join us for preparation of GSoC 2026 in our [community channel](https://open.rocket.chat/channel/opensource2026).  We have released an initial [2026 ideas list](https://github.com/RocketChat/google-summer-of-code/blob/main/google-summer-of-code-2026.md#-project-ideas) and are now talking with mentors (many returning former GSoC participants) on expanding the list with interesting projects   Thanks to everyone for their interest and ethusiasm on open source, and looking forward to meet everyone at our tea time on Fridays.\n\nAs of **January 8, 2026**  we have welcomed *470* open source contributors from all over the world, new to Rocket.Chat, to join us for preparation of GSoC 2026 in our [community channel](https://open.rocket.chat/channel/opensource2026).  We want to thank everyone for their interest and ethusiasm on open source, and looking forward to meet everyone at our tea time on Fridays.\n\n\nAs of **December 7, 2025**  we started to welcome open source contributors from all over the world, new to Rocket.Chat, to join us for preparation of GSoC 2026 in our [community channel](https://open.rocket.chat/channel/opensource2026).\n\n## 📂 Project Ideas   \n\n(This list is going through some rapid changes as we work with mentors to fully flesh out the project ideas.)\n\n\n### 💡 High-Performance Message Parser Rewrite\n\n👥 **Mentor(s):** Matheus Cardoso  \n📢 **Communication Channel:** [team channel](https://open.rocket.chat/channel/idea-High-Performance-Message-Parser-Rewrite)\n\n💬 **Description:**\nThe current Rocket.Chat [message parser](https://github.com/RocketChat/Rocket.Chat/tree/develop/packages/message-parser) relies on [PeggyJS](https://github.com/peggyjs/peggy) (formerly [PEG.js](https://github.com/pegjs/pegjs)). While effective, the generated parser creates performance bottlenecks and adds significant bundle size overhead.\nThe goal of this project is to replace the PeggyJS-generated parser with a highly optimized, hand-written TypeScript implementation (or using a toolkit like [Chevrotain](https://github.com/Chevrotain/chevrotain). The new implementation must produce the exact same Abstract Syntax Tree (AST) structure as the current one but with a focus on **speed**, **type safety**, and **modularity**.\n\n💪 **Desired Skills:**\n\n* TypeScript\n* Algorithms & Data Structures (Context-Free Grammars, Recursive Descent)\n* Performance Profiling & Benchmarking\n* Property-based Testing (e.g., fast-check)\n\n🎯 **Goals/Deliverables:**\n\n* **Core Implementation:** A functional, drop-in replacement parser in pure TypeScript.\n* **100% Parity:** Pass all existing unit tests (`message-parser/tests/*.test.ts`) to guarantee backward compatibility.\n* **Robustness:** Implement **Fuzz Testing** (property-based testing) to ensure the parser handles edge cases and malformed inputs without crashing.\n* **Performance:** Create a benchmark suite demonstrating significant improvements in **ops/sec** and a reduction in **bundle size**.\n\n⏳ **Project Duration:**\n175 hours\n\n📈 **Difficulty:**\nMedium\n\n---\n\n### 💡 AI Rocket.Chat Apps Generator \n\n👥 **Mentor(s):**   Dnouv    \n📢 **Communication Channel:**   [team channel](https://open.rocket.chat/channel/idea-AI-Rocket-Chat-Apps-Generator)\n\n💬 **Description:**  \nThis is a set of extension (or a fork) of open source `gemini-cli` that will facilitate anyone to create/generate their own  Rocket.Chat app with ease. \n\nThe tool must have built-in internal knowledge of the architecture of a Rocket.Chat App, how to build and test an App,  and how to generate ALL the elements that an App can use to interface with the Apps Engine/server (bridged APIs, web hooks, persistence, per-user state management and so on).     \n\nThe tool should also be able to generate and maintain tests for the created App.\n\n💪 **Desired Skills:**  \n* Experience with modern code generation cli (Claude Code, OpenCode, OpenAI Codex, `gemini-cli` and so on ) \n* A passion for creating tooling for AI coding  \n* Familiarity with Rocket.Chat App creation and Apps Engine operation\n* TypeScript development \n* `gemini-cli` architecture and extension mechanisms \n* Prompt engineering\n\n🎯 **Goals/Deliverables:**  \nA very easy to use and understand CLI tool that anyone can use to create, test, and deploy their own custom Rocket.Chat apps. \n\n⏳ **Project Duration:**  \n175 hours  \n\n📈 **Difficulty:**  \nMedium  \n\n---\n\n\n### 💡 Refactor Virtualized Lists to Use TanStack Virtual\n\n👥 **Mentor(s):** Martin Schoeler, Douglas Fabris  \n📢 **Communication Channel:** [team channel](https://open.rocket.chat/channel/idea-Refactor-Virtualized-Lists-to-Use-TanStack-Virtual)  \n\n💬 **Description:**  \nReplace existing Virtuoso based virtual lists with a standardized implementation using TanStack Virtual, ensuring consistent behavior and performance.\n\n💪 **Desired Skills:**  \n- React  \n- TypeScript  \n- Jest or Playwright  \n\n🎯 **Goals/Deliverables:**  \n- Refactor all virtual list implementations  \n- Maintain feature parity with tests  \n\n⏳ **Project Duration:**  \n175 hours  \n\n📈 **Difficulty:**  \nMedium  \n\n---\n\n### 💡 Rocket.Chat Code Analyzer: agentic inference context reduction mechanics \n👥 **Mentor(s):**   William Liu  \n📢 **Communication Channel:**  [team channel](https://open.rocket.chat/channel/idea-Rocket-Chat-Code-Analyzer)   \n\n💬 **Description:**  \nMost production codebases are stored in huge revision control repositories (similar to Rocket.Chat) and  are often monorepos that combines the source code of a large number of related subprojects.  \n\nWhen AI agentic tooling is unleashed on these huge code repositories, it quickly reveals the primitive and wasteful (unoptimized) nature of early tools.    Because LLM inferences are being performed inside a loop where the context of the queries are being built; and the context is constantly increasing in size, query after query.    \n\nThis means that repositories as large as Rocket.Chat is often out of reach (of the token/AI-inference budget) for many open source developers.  Even though some AI service providers offer per-session caching and compression (llmlinqua and so on), these are O(n) optimizations that have only nominal impact on the overall project/session cost when large repositories are involved.  \n\nThis project explores and implements a class of “domain specific context reduction mechanisms” that can  have exponential impact when working with large code repositories.  These scoping mechanisms are specific to (works only with)  the domain of “code analysis/generation”.  \n\nThe project’s code will be an extension or fork of `gemini-cli`,  with the context reduction mechanism added.   It will enable users of `gemini-cli`  to work with (analyze, or generate code based on ) the (known to be huge) Rocket.Chat’s monorepo, all within the budget of the “free tier” inference currently offered by Google.       \nIdeally, the mechanics should be implemented in a re-usable manner, extending its utility to other large codebases and the contributor can contribute it back upstream to `gemini-cli`. \n\n💪 **Desired Skills:**   \n* A passion for innovations on open source tooling for the age of open source AI  (vibe) coding \n* Experience with modern code generation cli - Claude Code, OpenCode, OpenAI Codex, gemini-cli and so on\n* Intimate understanding of how  gemini-cli works  — Familiarity with Rocket.Chat’s codebase in our monorepo\n* TypeScript development \n* Coding with `gemini-cli` extension mechanisms \n* Prompt engineering \n* Theoretical understanding of agentic systems and LLM inference \n\n🎯 **Goals/Deliverables:**   \nTooling that enables open source AI developers to work with huge production code repositories, within industry provider’s free-tier limits; opening access of these great tools to an exponentially larger population of users.    \n\n⏳ **Project Duration:**  \n175 hours  \n\n📈 **Difficulty:**  \nMedium  \n\n---\n\n### 💡 Embedded Chat 2026\n\n👥 **Mentor(s):** Zishan Ahmad\n\n📢 **Communication Channel:** [team channel](https://open.rocket.chat/channel/idea-Embedded-Chat-2026)\n\n💬 **Description:**\nThis project improves EmbeddedChat by keeping it compatible with the latest Rocket.Chat releases, adding support for homeserver and federation features, and introducing a pluggable AI adapter layer. It also focuses on better mobile usability, improved accessibility, and welcoming practical improvements to the overall experience.\n\n💪 **Desired Skills:**\n\n- Strong understanding of Rocket.Chat APIs and SDKs\n- Experience with React.js and Node.js\n- Familiarity with UI design and responsive layouts\n- Interest in accessibility standards and best practices\n- Understanding of AI integrations is a plus\n\n🎯 **Goals/Deliverables:**\n\n\n- Update Rocket.Chat APIs and SDKs, then update React, Node, and related packages to the latest versions so EmbeddedChat works with current Rocket.Chat releases.\n- Upgrade EmbeddedChat for compatibility with Rocket.Chat homeserver capabilities, including Matrix federation and bridged rooms.\n- Add a pluggable adapter to connect EmbeddedChat with local or external AI through an integrator-controlled layer, enabling smart widget features beyond core.\n- Improve EmbeddedChat UI and the native app to achieve better mobile responsiveness.\n- Add WCAG compliance, keyboard navigation, and automated accessibility testing across all components.\n- Welcoming any other creative ideas that improve the project.\n\n⏳ **Project Duration:** 175 hours\n\n📈 **Difficulty:** Medium\n\n---\n\n### 💡 Replace old Rest Api definitions over the new API\n\n👥 **Mentor(s):**  @diego.sampaio @guilherme.gazzo  \n📢 **Communication Channel:** [team channel](https://open.rocket.chat/channel/idea-Replace-old-REST-API-definitions-over-the-new-API) \n\n\n💬 **Description:**  \nThe goal of this project is to continue the migration of our REST typings to the new API format.\nThis new format not only standardizes API definitions, but also enables automatic generation of OpenAPI documentation directly from the type definitions.\n\nIn addition to the typings migration, the project also includes architectural adaptations to support like: A clear separation between route definitions and their corresponding actions/handlers\n\n💪 **Desired Skills:**  \n* Typescript\n\n⏳ **Project Duration:**  350 hours  \n\n📈 **Difficulty:**  Medium  \n\n---\n\n### 💡 OpenClaw Integration for Rocket.Chat\n\n👥 Mentor(s): Jeffrey Yu\n\n📢 Communication Channel: ** [team channel](https://open.rocket.chat/channel/idea-OpenClaw-Integration-for-Rocket-Chat)\n\n💬 Description:  \n[OpenClaw](https://openclaw.ai/) (previously named **Clawdbot**) is a fast-growing open-source autonomous AI agent. Unlike traditional prompt-response chatbots, OpenClaw focuses on proactive, autonomous task execution — such as managing workflows, triaging inboxes, orchestrating tools, or generating code — by combining LLM reasoning with real tool integrations. This agent-driven paradigm has led to strong adoption in the open-source community.\n\nThe essential interaction layer of OpenClaw allows users to control and supervise the agent conversationally through messaging apps. Currently, OpenClaw [supports](https://docs.openclaw.ai/channels/telegram) messaging platforms like Telegram and WhatsApp, while there is a surging [community demand](https://github.com/openclaw/openclaw/issues/7520) for Rocket.Chat integration.\n\nThis project aims to implement Rocket.Chat integration for OpenClaw. This tool will enable users to interact with autonomous AI agents directly from Rocket.Chat DMs and channels.\n\n🛠️ Desired Skills:\n\n- TypeScript / Node.js\n- Experience building webhook-based integrations and handling realtime messaging events\n- Familiarity with OpenClaw and Rocket.Chat Apps / APIs\n- Understanding of authentication and secure token handling\n\n🎯 Goals:\n\n- Support direct messages and slash-command channel conversations for OpenClaw\n- Enable secure configuration and authentication flow with role-based access control\n\n⏳ Project Duration: 175 hours\n\n📊 Difficulty: Medium\n\n---\n\n### 💡 Minimal MCP Server Generator for Rocket.Chat\n\n👥 **Mentor(s):**  Hardik Bhatia  \n📢 **Communication Channel:** [team channel](https://open.rocket.chat/channel/idea-Minimal-MCP-Server-Generator-for-Rocket-Chat)   \n\n💬 **Description:**\nThis is an extension/customization of open source `gemini-cli` that will generate a production-ready MCP server, together with tests,  for any subset of Rocket.Chat APIs specified. \n\nMCP is high level alternative protocol used for LLM function calling (tools calling) that Anthropic had trained their LLM to excel in.  MCP has been adopted on a viral scale by many developers transitioning to AI Code generation.  Most recently, all major frontier models providers/platformers have caught up and supported MCP;  and Anthropic has donated the protocol to the Linux Foundation.    \n\nToday, one major problem when adopting MCP is that it is originally designed to reward the inference platform provider.  Almost all MCP servers are written to support a large set of services APIs that covers the functionality of the specific service provider (usually tightly coupled with an associated platform provider).  And anyone adopting multiple MCP servers will experience “context bloat”  where most of their token budget and context-content is consumed by static MCP requirements; associated with API calls that they will never need or use within their project.  This situation is exacerbated  in agentic code generator workflows where every agent is burning token in loops unnecessarily while supporting API/tools that the project will never need.\n\nRocket.Chat will solve this problem with this Minimal MCP Server Generator project.  With this tool, Rocket.Chat developers can generate production grade minimal MCP server for their project, covering only the subset of API required by the project.   This will significantly reduce the cost of all Rocket.Chat code generation projects involving MCP.  Since Rocket.Chat is open source, this tool can make many projects possible by fitting into the “free tier” of the platform providers.  \n\nCandidate is encouraged to solve this problem more generically while fulfilling all Rocket.Chat’s requirements.  Ideally, the tool can benefit all similar upstream projects/platforms, open source or otherwise. \n\n💪 **Desired Skills:**  \n* A passion for creating innovative tooling for AI (Vibe 2.0) coding \n* Experience with modern code generation cli : Claude Code, OpenCode, OpenAI Codex, gemini-cli and so on\n* Experience with creation  of (or working with) MCP servers\n* TypeScript development \n* gemini-cli architecture and extension mechanisms \n* Prompt engineering\n\n🎯 **Goals/Deliverables:**   \nA tool to generate a minimal-cover MCP server for anyone developing with Rocket.Chat who also needed MCP support.  This can greatly reduce the cost, while increasing the stability and reliability of agentic code generation process.\n\n⏳ **Project Duration:**  \n175 hours  \n\n📈 **Difficulty:**  \nMedium  \n\n---\n\n### 💡 AI Generated Regression Test Suite for Desktop (Electron) App\n\n👥 **Mentor(s):**  Harmeet Kour, Jessica Souza  \n📢 **Communication Channel:** [team channel](https://open.rocket.chat/channel/idea-AI-Generated-Regression-Test-Suite-for-Desktop-Electron-App)  \n\n💬 **Description:**   \nIn this project, the contributor will build a full coverage test suite for our Desktop (Electron) App with the help of the latest available open source mainstream AI code generation tooling (Gemini cli or OpenCode). Mentors will help in scoping the coverage and enumeration of the essential cases, as well as guiding for best practices in test suite creation, CI integration, and QA in general. \n\n🎯 **Goals/Deliverables:** \nOur Desktop App (Electron) project is currently in need of a full coverage test suite.  This will add the essential test suite to ensure the project's maintainability and long term stability. \n\n💪 **Desired Skills:**  \n- Electron and JavaScript\n- Familiarity with our Desktop App and TypeScript development\n- Must already be experienced with mainstream open source (AI) code generation technology\n\n⏳ **Project Duration:**  \n90 hours\n\n📈 **Difficulty:** \nMedium\n\n-----\n\n### 💡 Mobile Apps: Notifications Improvements\n\n👥 **Mentor(s):** Rohit Bansal    \n📢 **Communication Channel:** [team channel](https://open.rocket.chat/channel/idea-Mobile-Apps-Notifications-Improvements) \n\n💬 **Description:**  \nImprove the overall push notification experience on mobile by enhancing notification content, reducing noise, and ensuring outdated notifications are automatically removed from the system Notification Center.\n\nThe project focuses on improving clarity, usability, and correctness of notifications across iOS and Android platforms.\n\n💪 **Desired Skills:**  \n- React Native\n- TypeScript\n- Native iOS & Android notification handling\n- Backend API design\n\n🎯 **Goals/Deliverables:**  \n- Display attachments in push notifications where supported\n- Trim reply and quote content in notifications to improve readability\n- Support replying in threads directly from notifications\n- Display thread context in push notification content\n- Reduce notification clutter in the system Notification Center\n- Implement a backend endpoint that receives message IDs, determines their read/unread state and integrates this logic to automatically clear read notifications from the Notification Center\n\n⏳ **Project Duration:**\n175 hours\n\n📈 **Difficulty:**  \nMedium\n\n-----\n\n### 💡 Mobile Apps: Use bottom tabs navigation\n\n👥 **Mentor(s):** Diego Mello  \n📢 **Communication Channel:** [team channel](https://open.rocket.chat/channel/idea-Mobile-Apps-Use-bottom-tabs-navigation)\n\n💬 **Description:**  \nWe're currently using sidebar navigation on the app, but we have plans to apply bottom tabs navigation to improve UX.\n\n💪 **Desired Skills:**  \n- React Native\n- TypeScript\n\n🎯 **Goals/Deliverables:**  \nWe'll have to iterate around which tabs works best, a first execution of this would consider:\n- Home tab: List of all channels except discussions and DMs\n- Discussions tab: Only discussions\n- DMs: Only DMs\n- More: Display everything that's on Settings currently\n- Search: We would move search to the tabs, so it follows new pattern of iOS 26\n\nCurrently the workspace selection is done by tapping the workspace name on the main screen.\nWe should move it to the sidebar.\n\n⏳ **Project Duration:**\n175 hours\n\n📈 **Difficulty:**  \nMedium\n\n-----\n\n### 💡 Custom mentions\n\n👥 **Mentor(s):** Diego Mello  \n📢 **Communication Channel:** [team channel](https://open.rocket.chat/channel/idea-Custom-mentions)  \n\n💬 **Description:**  \nAllow the creation of new mentions targetting a specific set of users.\nThis is very useful when you need to notify a group of people, but don't want to use `@all` or `@here`.\nWhile this can be technically achieved using teams feature, it's a little bit too much work for a simple communication win.\n\nA room with engineers could have custom mentions for `@backend`, `@frontend`, `@sre`, `@mobile`, `@em`, etc.\nA group of people that was involved on a project could have `@project-abc`.\n\n💪 **Desired Skills:**  \n- React\n- React Native\n- TypeScript\n\n🎯 **Goals/Deliverables:**  \n- Allow custom mentions on web\n- Allow custom mentions on mobile\n- Display a list of people that belonged to the team when the message was sent\n- Add `Custom mentions` to admin panel\n\n⏳ **Project Duration:**\n175 hours\n\n📈 **Difficulty:**  \nMedium\n\n-----\n\n### 💡 Activity Hub\n\n👥 **Mentor(s):** Pierre Lehnen, Milton Rucks  \n📢 **Communication Channel:** [team channel](https://open.rocket.chat/channel/idea-Activity-Hub)  \n\n💬 **Description:**  \nBuild a new screen on the rocket.chat client  where users can see a history of their recent notifications and mentions, with options to manually remove items from this history or to clear the whole history at any time. Additionally, show a list of all of the user’s starred messages from every channel.\n\n💪 **Desired Skills:**  \n- React\n- Typescript (Backend and Frontend)\n\n🎯 **Goals/Deliverables:**  \nMake it easier for users to keep track of recent messages or messages that they have already read but still want to keep a reference to for quick access in the near future.\n\n⏳ **Project Duration:**  \n175 hours\n\n📈 **Difficulty:** \nMedium\n\n---\n\n### 💡 Desktop App: Multiple Conversation Tabs\n\n👥 **Mentor(s):** Jean Brito, Felipe Scuciatto  \n📢 **Communication Channel:** [team channel](https://open.rocket.chat/channel/idea-Desktop-App-Multiple-Conversation-Tabs) \n\n💬 **Description:**  \nEnhance the Rocket.Chat Electron desktop app by introducing multi conversation tab support, allowing users to open and manage multiple channels, DMs, or threads simultaneously.\n\n💪 **Desired Skills:**  \n- React  \n- TypeScript  \n- Electron  \n\n🎯 **Goals/Deliverables:**  \n- Tabbed conversation interface  \n- Improved productivity for power users  \n- Reduced friction when switching contexts  \n\n⏳ **Project Duration:**  \n90 hours  \n\n📈 **Difficulty:**  \nMedium  \n\n---\n\n### 💡 Agenda Jobs Admin Page\n\n👥 **Mentor(s):**  Kevin Aleman, Douglas Gubert  \n📢 **Communication Channel:** [team channel](https://open.rocket.chat/channel/idea-Agenda-Jobs-Admin-Page)  \n\n💬 **Description:**  \nCreate an admin interface to visualize and manage all Agenda scheduled jobs, including execution history, failures, and administrative actions.\n\n💪 **Desired Skills:**  \n- React  \n- TypeScript  \n- Node.js  \n- MongoDB  \n\n🎯 **Goals/Deliverables:**  \n- Admin UI for scheduled jobs  \n- Failure visibility and execution history  \n- Quick administrative actions  \n\n⏳ **Project Duration:**  \n175 hours  \n\n📈 **Difficulty:**  \nMedium  \n\n---\n\n### 💡 Required Role per Channel for Membership Control\n\n👥 **Mentor(s):** Gabriel Casals  \n📢 **Communication Channel:** [team channel](https://open.rocket.chat/channel/idea-Required-Role-per-Channel-for-Membership-Control) \n\n💬 **Description:**  \nIntroduce channel level RBAC by allowing admins or channel leads to define a required role for channel membership. Users without the role cannot be added and receive a clear error message.\n\n💪 **Desired Skills:**  \n- Node.js  \n- MongoDB  \n- Authorization and RBAC concepts  \n\n🎯 **Goals/Deliverables:**  \n- Channel level required role configuration  \n- Enforcement on membership flows  \n- Audit logs and admin UI  \n\n⏳ **Project Duration:**  \n90 hours  \n\n📈 **Difficulty:**  \nMedium  \n\n---\n\n### 💡 Personal Calendar\n\n👥 **Mentor(s):** Pierre Lehnen  \n📢 **Communication Channel:** [team channel](https://open.rocket.chat/channel/idea-Personal-Calendar)\n\n💬 **Description:**  \nCreate a new interface that allows users to view and manage their personal Rocket.Chat calendar directly within the product, expanding and integrating the existing backend calendar system.\n\n💪 **Desired Skills:**  \n- React  \n- TypeScript  \n- Frontend focused development  \n\n🎯 **Goals/Deliverables:**  \n- Manage calendar events inside Rocket.Chat  \n- Support internal and optional external calendars  \n\n⏳ **Project Duration:**  \n175 hours  \n\n📈 **Difficulty:**  \nMedium  \n\n---\n\n### 💡 Rebuilding the Jira Integration App for Rocket.Chat\n\n👥 **Mentor(s):** Felipe Scuciatto  \n📢 **Communication Channel:** [team channel](https://open.rocket.chat/channel/idea-Rebuilding-the-Jira-Integration-App-for-Rocket-Chat) \n\n💬 **Description:**  \nRebuild and modernize the Jira integration app for Rocket.Chat, restoring a critical productivity feature that enables users to work with Jira issues directly from chat.\n\n💪 **Desired Skills:**  \n- Rocket.Chat Apps Engine  \n- TypeScript  \n\n🎯 **Goals/Deliverables:**  \n- Fully functional Jira Marketplace app  \n- Issue interaction inside Rocket.Chat  \n\n⏳ **Project Duration:**  \n90 hours  \n\n📈 **Difficulty:**  \nMedium  \n\n---\n\n\n### 💡 Apps Engine Test Framework for Apps\n\n👥 **Mentor(s):** Douglas Gubert    \n📢 **Communication Channel:** [team channel](https://open.rocket.chat/channel/idea-App-Engine-Test-Framework-for-Apps)\n\n💬 **Description:**  \nIntroduce a test framework for Rocket.Chat Apps Engine to simplify unit and integration testing by providing standardized mocks and scaffolding.\n\n💪 **Desired Skills:**  \n- TypeScript  \n- Node.js  \n\n🎯 **Goals/Deliverables:**  \n- Improved testing experience for app developers  \n- Standardized testing utilities  \n- Support for integration tests  \n\n⏳ **Project Duration:**  \n175 hours  \n\n📈 **Difficulty:**  \nMedium  \n\n---\n\n### 💡 Room Header Buttons Ordering\n\n👥 **Mentor(s):** Milton Rucks, Martin Schoeler  \n📢 **Communication Channel:** [team channel](https://open.rocket.chat/channel/idea-Room-Header-Buttons-Ordering)  \n\n💬 **Description:**  \nImplement a configurable layout engine for the room header that allows administrators to explicitly define the display order of action buttons. This enables pinning high priority actions directly in the main toolbar while organizing secondary actions in the overflow (ellipsis) menu based on organizational needs.\n\n💪 **Desired Skills:**  \n- React  \n- TypeScript  \n- UI layout systems  \n\n🎯 **Goals/Deliverables:**  \n- Reduce UI clutter in room headers  \n- Surface high priority actions more effectively  \n- Improve user efficiency  \n\n⏳ **Project Duration:**  \n90 hours  \n\n📈 **Difficulty:**  \nMedium  \n\n---\n\n### 💡 Ephemeral Messages\n\n👥 **Mentor(s):** TBD    \n📢 **Communication Channel:** Rocket.Chat Contributors Workspace  \n\n💬 **Description:**  \nA feature enabling users to send self destructing messages that automatically and permanently delete themselves from chat history and the server after a specified duration or once viewed by the recipient.\n\n💪 **Desired Skills:**  \n- Node.js  \n- Message lifecycle management  \n- Security and privacy concepts  \n\n🎯 **Goals/Deliverables:**  \n- Time based and view based message expiration  \n- Improved privacy for sensitive data sharing  \n- Reduced long term chat clutter  \n\n⏳ **Project Duration:**  \n350 hours  \n\n📈 **Difficulty:**  \nMedium  \n\n---\n\n### 💡 Sidebar Custom Grouping\n\n👥 **Mentor(s):** TBD  \n📢 **Communication Channel:** Rocket.Chat Contributors Workspace  \n\n💬 **Description:**  \nAllow users to create custom, collapsible folders or sections in the sidebar to manually organize channels, direct messages, and other conversations.\n\n💪 **Desired Skills:**  \n- React  \n- TypeScript  \n- UX focused feature design  \n\n🎯 **Goals/Deliverables:**  \n- Better workspace navigation  \n- Reduced information overload  \n- User controlled prioritization  \n\n⏳ **Project Duration:**  \n175 hours  \n\n📈 **Difficulty:**  \nMedium  \n\n---\n\n### 💡 Warning and Reporting for Login Attempts from Inactive or Deactivated Users\n\n👥 **Mentor(s):** TBD  \n📢 **Communication Channel:** Rocket.Chat Contributors Workspace  \n\n💬 **Description:**  \nDetect and report authentication attempts from inactive (180+ days) or deactivated user accounts, generating real time alerts and periodic risk reports for administrators.\n\n💪 **Desired Skills:**  \n- Node.js  \n- Authentication and authorization systems  \n- Security and audit logging  \n\n🎯 **Goals/Deliverables:**  \n- Detection of suspicious login attempts  \n- Admin alerts and risk reports  \n- Audit and compliance support  \n\n⏳ **Project Duration:**  \n175 hours  \n\n📈 **Difficulty:**  \nMedium  \n\n---\n\n### 💡 New Users Anti Spammer System\n\n👥 **Mentor(s):**  TBD  \n📢 **Communication Channel:** Rocket.Chat Contributors Workspace  \n\n💬 **Description:**  \nBuild an AI assisted system that monitors new users during their first 6 to 10 weeks, detecting spam patterns and suspicious behavior to protect communities and reduce manual moderation.\n\n💪 **Desired Skills:**  \n- Node.js  \n- Rule based or ML detection systems  \n- Trust and safety concepts  \n\n🎯 **Goals/Deliverables:**  \n- Behavioral analysis of new users  \n- Automated moderation actions  \n- Daily risk scoring and reporting  \n\n⏳ **Project Duration:**  \n175 hours  \n\n📈 **Difficulty:**  \nMedium  \n\n---\n\n### 💡 Tamagui-Based Refactor of Fuselage Components: Bundle Size and Performance Analysis\n\n👥 **Mentor(s):** TBD\n\n📢 **Communication Channel:** Rocket.Chat Contributors Workspace  \n\n💬 **Description:**  \n\nThis project focuses on refactoring the core Fuselage components to be built on top of the Tamagui library.\nOnce the Tamagui-based components are implemented, a comparative evaluation will be conducted against the current implementation, taking into account:\n\n- Generated bundle size\n- Runtime performance\n\nFrom a visual standpoint, the components should not present any discrepancies, preserving the same appearance and behavior as the existing components.\nAdditionally, the Tamagui implementation must continue to use the existing design tokens, ensuring visual consistency and alignment with the current design system.\n\n💪 **Desired Skills:**  \n- Typescript\n\n⏳ **Project Duration:**  \n350 hours  \n\n📈 **Difficulty:**  \nMedium"
  },
  {
    "name": "Pharo Consortium",
    "slug": "pharo-consortium",
    "tagline": "Modern and immersive programming language",
    "description": "Pharo is a dynamic, purely object-oriented programming language (where everything is an object) that is inspired by Smalltalk. It also includes a powerful IDE that focuses on simplicity and quick feedback. Its entire syntax can fit on a postcard, and you can code directly in the debugger. Pharo has useful tools that help you work efficiently.\n\nThe goal of Pharo is to provide a clean, innovative, free, and open-source environment. With a stable and small core system, great development tools, and regular updates, Pharo is a good choice for building and running important applications.\n\nPharo supports a healthy community made up of both private and commercial contributors who help improve and maintain the core system and its external packages.",
    "ideas_url": "https://gsoc.pharo.org/ideas",
    "website_url": "https://pharo.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "git",
      "smalltalk",
      "pharo",
      "spec",
      "SUnit"
    ],
    "topic_tags": [
      "machine learning",
      "programming languages",
      "virtual machines",
      "Modelling",
      "Live music"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/pharo-consortium",
    "ideas_content": "Below is the list of project ideas that were proposed by the Pharo community. You can apply to any of those projects by sending an email to one of its mentors. Do not hesitate to propose your own idea but make sure that there is at least one mentor in the community who would agree to supervise you.\n\nA generic AST for Moose\n\nThe idea is to define a generic meta-model for ASTs\n\nAlgorithms, data structures and graphs\n\nPharo has a vast implementationg of data structures such as various kinds of lists, trees and graphs (...)\n\nCompiler Optimizations in SSA form\n\nDruid is a metacompiler to generate a Just-In-Time Compiler in the Pharo VM. With Druid, language im (...)\n\nOptimizing the Pharo Compiler at Bytecode-Level\n\nThis project explores the implementation of an optimizing compiler for Pharo bytecode. It uses the D (...)\n\nFault Location DrTest Plugin\n\nIn this project, the student will implement two or three different fault location algorithms, for th (...)\n\nChatPharo: Bringing LLMs to Live Programming\n\nThis project focuses on improving and extending an existing interface between Pharo and large langua (...)\n\nEnhancing Pharo’s Refactoring Engine for a Smarter Development Experience\n\nOne of its key strengths is its powerful development environment, which includes an advanced refacto (...)\n\nAdding Game Tiles and Sprites to Cormas\n\nThe current version of Cormas allows us to visualize the space and agents in the simulation using co (...)\n\nImprove the Green threads / Fiber\n\nPharo currently implements Green Threads / Fiber through the Process class. However, certain edge ca (...)\n\nEnhance Register Allocation at Control Flow Merge Points During JIT Compilation\n\nThe JIT compiler in the Pharo VM uses an Abstract Interpreter to translate Pharo methods into machin (...)\n\nA DJ Application with Phausto and Bloc\n\nDevelop a DJ application in Pharo using Phausto for audio playback, filters, and effects, and Bloc f (...)\n\nChucK inside Pharo\n\nImplement an API to run the ChucK virtual machine directly from Pharo, allowing users to write and e (...)\n\nEnhance Slang with Separate Compilation\n\nSlang is a framework for writing Virtual Machines in Smalltalk and compiling them to C for performan (...)\n\nEliminate Object Pointers in JIT-Compiled Code for Better GC Performance\n\nIn the Pharo VM, JIT compilation embeds object pointers directly into compiled machine code. These p (...)\n\nBetter support for web elements in Foliage/Microdown\n\nImprove the web support of Foliage and Microdown [Foliage](https://github.com/Ducasse/Foliage) / [M (...)"
  },
  {
    "name": "Konflux",
    "slug": "konflux",
    "tagline": "Secure software pipelines, the K8s way",
    "description": "Konflux is an open source, opinionated Kubernetes-native software factory built on Tekton, focused on software supply chain security. It provides an end-to-end pipeline: hermetic builds from source, cryptographic signing, provenance attestation, vulnerability scanning, policy verification, and release automation. Konflux integrates with the broader supply chain security ecosystem (Sigstore, SLSA, Conforma) and is built by a welcoming community that values collaboration, transparency, and mentorship.\nContributors work with cutting-edge cloud-native technologies and help shape how we solve one of the most critical challenges in modern software delivery.",
    "ideas_url": "https://github.com/konflux-ci/community/wiki/Google-Summer-of-Code-&-Outreachy-Project-Ideas-%E2%80%90-2026",
    "website_url": "https://konflux-ci.dev/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "go",
      "docker",
      "kubernetes",
      "tekton"
    ],
    "topic_tags": [
      "cloud-native",
      "CI/CD",
      "Tekton",
      "SLSA",
      "supplychain"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/konflux",
    "ideas_content": "# Google Summer of Code & Outreachy Project Ideas - 2026\n\nBelow you will find a list of proposed projects. Each idea includes essential information to help you understand the scope, required skills, and who to contact for more details.\n\n## Important Notes for Applicants\n\n* **Project Scope:** Some projects might be adaptable in scope to fit _GSoC_'s 175-hour or 350-hour options, or _Outreachy_'s 40-hour/week commitment. Discuss this with your mentor.\n* **Skill Requirements:** While specific programming languages and technologies are listed, enthusiasm and a willingness to learn are often just as important. Don't be discouraged if you don't know every single technology listed.\n* **Community Engagement:** We highly recommend engaging with our community before applying. This could involve contributing to our repositories, participating in discussions, or attending our meetings (if any).\n\n---\n\n## Project ideas table\n\n* [Reproducible Builds](#reproducible-builds)\n* [zstd:chunked compression](#zstd-chunked-compression)\n* [prefetch: Adding support for the `uv` Python package manager to the Hermeto project](#prefetch-adding-support-for-the-uv-python-package-manager-to-the-hermeto-project)\n* [prefetch: Adding support for the Debian/Ubuntu package ecosystem [DEB] to the Hermeto project](#prefetch-adding-support-for-the-debianubuntu-package-ecosystem-deb-to-the-hermeto-project)\n---\n\n## Reproducible Builds\n* **Assessment level**: intermediate\n* **Programming Languages:** Go, Bash\n* **Technologies:** Docker, Tekton, Buildah\n* **Mentors:**\n    * Ralph Bean <ralph.bean@gmail.com>\n\n### Description\n\nThe goal of this project is to demonstrate bit-wise reproducible builds in Konflux.\n\nKonflux is all about supply chain security, and [reproducible builds](https://reproducible-builds.org/) are a great property to have if you want to be able to verify that the build system hasn't been tampered with. For the purposes of this project, a build is \"bit-wise reproducible\" if you can build it twice and get a binary output with the same sha256 digest.\n\n**Expectations:**\n* Familiarize yourself with the [buildah task](https://github.com/konflux-ci/build-definitions/tree/main/task/buildah-oci-ta) used in the konflux container build pipeline, and what other tasks are used to populate its parameters. Notice how if you build a container from the same commit twice, you get a container image with a different digest each time. Not reproducible!\n* Research methods used by other systems and other communities to improve the degree of their support for reproducible builds. Example: [fixing the timestamp of the build to the timestamp of the commit](https://github.com/konflux-ci/build-definitions/issues/1268).\n* Propose a series of example experiments to demonstrate that different kinds of containerfiles are or are not reproducible.\n* Propose a series of patches or improvements to the konflux build pipeline tasks to increase the number of your example experiments that successfully produce reproducible builds.\n---\n\n## zstd:chunked compression\n* **Assessment level**: intermediate\n* **Programming Languages:** Go, Bash\n* **Technologies:** Docker, Tekton, Buildah\n* **Mentors:**\n    * Ralph Bean <ralph.bean@gmail.com>\n\n### Description\n\nThe goal of this project is to demonstrate building and releasing containers through Konflux with zstd:chunked compression.\n\nContainer images are normally stored and distributed with gzip compression. zstd:chunked is a more modern alternative that offers a number of performance improvements.\n\n**Expectations:**\n* Research other communities and tools that offer zstd:chunked compression.\n* Research prior discussions about adopting zstd:chunked compression [in Konflux](https://github.com/konflux-ci/build-definitions/issues/1264) and [in Fedora](https://fedoraproject.org/wiki/Changes/zstd:chunked).\n* Modify the build tasks in Konflux ecosystem to support producing images with zstd:chunked compression.\n* Build out integration and e2e test cases that prove that images distributed with zstd:chunked compression can be successfully handled by the konflux release pipelines.\n* Find and fix scenarios in the release pipelines where zstd:chunked compression is problematic.\n\n## prefetch: Adding support for the `uv` Python package manager to the Hermeto project\n* **Assessment level**: intermediate\n* **Programming Languages:** Python\n* **Technologies:** Docker\n* **Project scope**: 12 weeks\n* **Mentors:**\n    * Erik Skultety <skultety.erik@gmail.com>\n    * Alexey Ovchinnikov <alexaovchinn@gmail.com>\n\n### Project background\nhttps://github.com/hermetoproject/hermeto is a dependency fetching tool that enables CI platforms (like Konflux CI) to\n* utilize fully offline, network-isolated container builds by pre-fetching all required dependencies and\n* achieve high levels of SLSA compliance by providing a Software Bill of Materials (SBOM) of the fetched artifacts\nIt implements backend support for various package ecosystems including pip, npm, Go, Cargo, etc.\n\n### Description\n\nThe goal of this project is to introduce a new Python package ecosystem prefetch backend to the [Hermeto](https://github.com/hermetoproject/hermeto) project able to process the `uv` Package manager ecosystem natively.\n\nHermeto currently only supports prefetching packages for Python projects for the Pip ecosystem which revolves around the notion of `requirements` files. While `uv` is backwards compatible with pip (at least as far as the Hermeto project is concerned) and can work with `requirements` files via the its pip module invocation that is NOT the native way. `uv` has its own workflow based on `uv lock` and `uv sync` that will have to be supported natively in this new backend.\n\n**Expectations:**\n* research the whole `uv` ecosystem:\n  - how dependencies are recorded in the `uv.lock` lockfile, what format does the file follow\n  - what it takes to update the dependencies in the lockfile\n  - inspecting `uv`'s internals to verify whether there's a potential arbitrary code execution path possible\n* record the problem domain research in form of a thorough design document proposal against the Hermeto project\n* implement support for dependency fetching for the `uv` ecosystem based on the design document\n* integrate the new backend's functionality with Hermeto's SBOM artifact generating machinery to record all fetched dependencies for the `uv` ecosystem\n* address quality aspects of the solution via unit & integration tests\n* document the functionality in form of a user facing docs page\n\n## prefetch: Adding support for the Debian/Ubuntu package ecosystem [DEB] to the Hermeto project\n\n * **Assessment level:** advanced\n * **Programming Languages:** Python\n * **Technologies:** Debian packaging format and tools (dpkg, apt), Docker\n * **Project scope:** 12 weeks\n * **Mentors:**\n    - Erik Skultety <skultety.erik@gmail.com>\n\n### Project background\nhttps://github.com/hermetoproject/hermeto is a dependency fetching tool that enables CI platforms (like Konflux CI) to\n* utilize fully offline, network-isolated container builds by pre-fetching all required dependencies and\n* achieve high levels of SLSA compliance by providing a Software Bill of Materials (SBOM) of the fetched artifacts\nIt implements backend support for various package ecosystems including pip, npm, Go, Cargo, etc.\n\n### Description\n\nThis project aims to extend [Hermeto](https://github.com/hermetoproject/hermeto) with support for the Debian/Ubuntu package ecosystem (.deb packages), enabling offline builds for Debian-based container images. Unlike ecosystems such as NPM or Cargo, the Debian world lacks a standardized lockfile format for pinning exact package versions with checksums. This gap presents both a challenge and an opportunity for original research and tooling development.\n\nThere are two major components to successfully completing this project:\n\n1. Ecosystem research & lockfile/manifest schema design: A comprehensive study of the Debian packaging ecosystem, including:\n  - dependency resolution mechanisms\n  - repository metadata formats\n  - existing tooling\nThis research will inform the design of a manifest (a \"lockfile\") schema specification that captures all information needed for reproducible package fetching.\n\n2. Hermeto DEB backend implementation: A new package manager backend for Hermeto that consumes the manifest, downloads '.deb' packages from\nspecified mirrors, verifies checksums, generates SBOM (Software Bill of Materials) components, and produces repository metadata for offline `apt` installation.\n\nAdditionally to the above, a prototype manifest generator tool will need to be developed to demonstrate end-to-end functionality. This generator will resolve dependencies for a given set of packages and produce a valid manifest file. The https://github.com/konflux-ci/rpm-lockfile-prototype in the Konflux organization dealing with the RPM ecosystem serves as an excellent reference implementation for this particular use case.\n\n**Expectations:**\n  - Research and document the Debian package ecosystem\n  - Evaluate existing DEB manifest approaches (if any) and reproducible builds tooling\n  - Design a DEB manifest schema suitable for Hermeto consumption, drawing parallels to the existing `rpms.lock.yaml` format\n  - Implement a Hermeto backend that fetches '.deb' packages based on the manifest\n  - Implement a post-processing step to generate local repository metadata for offline `apt` usage\n  - Develop a prototype manifest generator tool that resolves dependencies and outputs valid manifest files based on the schema\n  - Provide user documentation following the style of existing Hermeto package manager guides\n  - Create integration tests validating the complete fetch → inject → offline-install workflow\n\n**Return to [Home Page](Home)**"
  },
  {
    "name": "AFLplusplus",
    "slug": "aflplusplus",
    "tagline": "State of the art fuzzing for better security",
    "description": "We are dedicated to provide the most effective fuzzing frameworks. Our work includes AFL++, the most effective and flexible fuzzer, and libafl, a library to build your own fuzzer with the most modern techniques and technologies.",
    "ideas_url": "https://github.com/AFLplusplus/LibAFL/issues/3706",
    "website_url": "https://aflplus.plus",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "llvm",
      "rust",
      "fuzzing",
      "qemu"
    ],
    "topic_tags": [
      "fuzzing",
      "ci"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/aflplusplus",
    "ideas_content": "-\n-\n[Notifications](https://github.com/login?return_to=%2FAFLplusplus%2FLibAFL)You must be signed in to change notification settings -\n[Fork 446](https://github.com/login?return_to=%2FAFLplusplus%2FLibAFL)\n\n[GSoCGoogle Summer of Code](https://github.com/AFLplusplus/LibAFL/issues?q=state%3Aopen%20label%3A%22GSoC%22)Google Summer of Code\n\n## Description\n\nWelcome to our Google Summer of Code idea list for 2026!\n\nOur projects are technical, demanding, and meant for students who genuinely want to learn by doing. We value careful thinking, solid fundamentals, and the ability to work independently more than flashy output. Quality matters here. If we’re not confident a collaboration will work well, we prefer not to take a student at all.\n\nBefore applying, take time to understand the project space. Read existing documentation and code, experiment locally, and ask precise, well-researched questions. Early pull requests, small but thoughtful, are strongly encouraged and are the best way to demonstrate seriousness and technical fit.\n\nWe do not accept AI-generated, low-effort proposals or submissions. If you use tools, you are still fully responsible for understanding and defending every line of what you submit.\n\nIf this sounds like the kind of environment you want to grow in, join the fuzzing Discord, introduce yourself, and start engaging early. The strongest applications usually come from students who do exactly that.\n\nBelow you find a list of potential projects, but you can come up with your own!\n\n## Metadata\n\n## Metadata\n\n### Assignees\n\n### Labels\n\n[GSoCGoogle Summer of Code](https://github.com/AFLplusplus/LibAFL/issues?q=state%3Aopen%20label%3A%22GSoC%22)Google Summer of Code"
  },
  {
    "name": "MalariaGEN",
    "slug": "malariagen",
    "tagline": "The Malaria Genomic Epidemiology Network",
    "description": "MalariaGEN is a global network of global partners who share and integrate data relevant to inform malaria surveillance, our mission is to generate insights and tools that bridge the gaps for analysts in malaria endemic settings to use their data meaningfully to inform public health efforts. We build and optimise data resources and analytical tools to run directly in the cloud. Our flagship project is the Vector Observatory, which includes whole-genome sequence data for over 30,000 mosquitoes, integrating data from 70 partners across the globe from over 17 different mosquito species -- this is the largest resource on genetic variation data for any multicellular organism (other than humans!). Our goal is to enable analysts, scientists, students and public health practitioners to access these data without the need for any dedicated compute infrastructure, by optimising our resources to run within free compute environments (a big shout to Google Colab!) and by developing training resources that support partners to get confident with using cloud-native data and resources for their analysis.",
    "ideas_url": "https://docs.google.com/document/d/178LEZEsC0xbknHDId83k5XzIDRtnyVw243Ta0fhlvPM/edit?tab=t.0",
    "website_url": "https://www.malariagen.net/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "GCS"
    ],
    "topic_tags": [
      "machine learning",
      "genomics",
      "big data",
      "cloud",
      "analytics"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/malariagen",
    "ideas_content": "Die Datei kann in Ihrem Browser nicht geöffnet werden, weil JavaScript nicht aktiviert ist. Aktivieren Sie JavaScript und laden Sie die Seite noch einmal.\nMalariaGEN - GSoC 2026\nTab\nExtern\nFreigeben\nAnmelden\nDatei\nBearbeiten\nAnsicht\nTools\nHilfe\nBedienungshilfen\nFehlerbehebung"
  },
  {
    "name": "Kubeflow",
    "slug": "kubeflow",
    "tagline": "The Machine Learning Toolkit for Kubernetes (AI)",
    "description": "Our goal is to streamline the process of scaling and deploying machine learning (ML) models to production by leveraging Kubernetes' strengths: \n<br /><br />\n-   Seamless deployments: Effortless, repeatable, and portable deployments across diverse infrastructure, allowing you to experiment on local machines and then seamlessly transition to on-premises clusters or the cloud.\n<br /><br />\n-   Microservice management: Efficient deployment and management of loosely-coupled microservices for building modular and scalable ML pipelines.\n<br /><br />\n-   Dynamic scaling: Automated scaling based on demand, ensuring optimal resource utilization.\n<br /><br />\nUser-centric design: Recognizing the diverse tool preferences within the ML community, we prioritize user customization (within reasonable boundaries). Our system takes care of the repetitive tasks, freeing users to focus on the core ML challenges.\n<br /><br />\nStarting focused, expanding rapidly: While we initially focused on specific technologies, we actively collaborate with various projects to integrate additional tools and broaden our reach.\n<br /><br />\nOur vision: A future where simple manifests empower you to utilize a user-friendly ML stack anywhere Kubernetes runs, with self-configuration capabilities based on the deployment environment.",
    "ideas_url": "https://www.kubeflow.org/events/upcoming-events/gsoc-2026/",
    "website_url": "https://kubeflow.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "go",
      "kubernetes",
      "typescript",
      "YAML"
    ],
    "topic_tags": [
      "machine learning",
      "kubernetes",
      "AI/ML",
      "generative AI"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/kubeflow",
    "ideas_content": "# Google Summer of Code 2026\n\nThe Kubeflow Community plans to participate in [ Google Summer of Code 2026](https://summerofcode.withgoogle.com/).\nThis page aims to help you participate in GSoC 2026 with Kubeflow.\n\n#### Note\n\nwe are currently awaiting final confirmation of our participation in GSoC 2026. Google will announce the final list of accepted organizations on**February 18, 2026**.\n\n## What is GSoC?\n\nGoogle Summer of Code (GSoC) is a global program that offers students [stipends](https://developers.google.com/open-source/gsoc/help/student-stipends) for working on open-source projects during the summer.\n\nFor more information, see the [GSoC FAQ](https://developers.google.com/open-source/gsoc/faq) and watch the video below:\n\n## How can I participate?\n\nThank you for your interest in participating in GSoC with Kubeflow!\n\nPlease carefully read the following information to learn how to participate in GSoC with Kubeflow.\n\n### Key Dates\n\nHere are the key dates for GSoC 2025, the [full timeline](https://developers.google.com/open-source/gsoc/timeline) is available on the GSoC website:\n\n| Event | Date |\n|---|---|\nMentor Proposals | February 3rd |\nOrg Acceptance | February 19th |\nApplications Open | March 16 @ 18:00 UTC |\nApplications Deadline | March 31 @ 18:00 UTC |\nAccepted Proposals Announced | April 30 |\n\n### Eligibility\n\nTo participate in GSoC with Kubeflow, you **must** meet the GSoC [eligibility requirements](https://developers.google.com/open-source/gsoc/faq#what_are_the_eligibility_requirements_for_participation):\n\n- Be at least 18 years old at time of registration.\n- Be a student or an\n[open source beginner](https://developers.google.com/open-source/gsoc/faq#how_do_i_know_if_i_am_considered_a_beginner_in_open_source_development). - Be eligible to work in their country of residence during duration of program.\n- Be a resident of a country not currently embargoed by the United States.\n\n### Steps\n\n- Sign up as a student on the\n[GSoC website](https://summerofcode.withgoogle.com/). - Join the\n[Kubeflow Slack](https://www.kubeflow.org/docs/about/community/#kubeflow-slack-channels):**NOTE:**please**do not**reach out privately to mentors, instead, start a thread in thechannel so others can see the response.`#kubeflow-contributors`\n\n\n- Learn about Kubeflow:\n- Read the\n[Introduction to Kubeflow](https://www.kubeflow.org/docs/started/introduction/) - Review the\n[Architecture Overview](https://www.kubeflow.org/docs/started/architecture/) - Consider\n[trying out Kubeflow](https://www.kubeflow.org/docs/started/installing-kubeflow/)(not required, can be challenging)\n\n- Read the\n- Review the\n[project ideas](https://www.kubeflow.org/events/upcoming-events/gsoc-2026/#project-ideas)to decide which ones you are interested in:- You may wish to attend the next\n[community meeting](https://www.kubeflow.org/docs/about/community/#kubeflow-community-calendar)for the group that is leading your chosen project. **NOTE:**while we recommend you submit a proposal based on the project ideas, you can also submit a proposal with your own idea.\n\n- You may wish to attend the next\n- Submit a proposal through the\n[GSoC website](https://summerofcode.withgoogle.com/)between**March 16th**and**March 31st**:- Please see\n[these guidelines](https://google.github.io/gsocguides/student/writing-a-proposal)on how to write a good proposal. - Kubeflow requests that you use\n[this template](https://github.com/kubeflow/community/tree/master/proposals/gsoc)for your proposal. - You will need to submit PDF version of your proposal on GSoC website before March 30th, 2026.\n\n- Please see\n- Wait for the results to be announced on\n**May 8th**.\n\n## Project Ideas\n\n### Project 1: Agentic RAG on Kubeflow (Expansion of kubeflow/docs-agent)\n\n**Components:** Kubeflow Pipelines (KFP), KServe, Manifests (Deployment/Infra), LLM Agents\n\n**Mentors:** @chasecadet, @tarekabouzeid (Tarek Abouzeid - Kubeflow Platform)\n\n**Contributor:** Details:\n\n**Project Overview & Scope:** This project aims to evolve the existing kubeflow/docs-agent from a simple retrieval tool into a robust Reference Architecture for Agentic RAG on Kubeflow. Currently, the tool performs basic lookups. The GSoC contributor will upgrade this to an agentic workflow that can intelligently parse user questions, access the Kubeflow Git repository and Reference Platform Architecture as tools, and provide cited, technical answers. The core goal is “Dogfooding”: We want to use Kubeflow to build the AI that helps users learn Kubeflow.\n\n**Key Deliverables (GSoC Scope):**\n\n**Agentic Architecture:**Implement an agent (using frameworks like LangGraph or Kagent) running on Kubeflow that can query specialized indices (Documentation, GitHub Issues, Platform Architecture).**Ingestion Pipelines:**Build reusable Kubeflow Pipelines (KFP) to scrape, chunk, and index “Golden Data” from our reference architectures, establishing a best-practice pattern for data handling.**Local Serving via KServe:**Demonstrate how to serve the agent’s LLM (e.g., Llama 3) using KServe on the cluster, utilizing Scale-to-Zero to handle bursty workloads efficiently.**Deployment Reference:**Create the Terraform/Manifests required to deploy this entire stack on Oracle Cloud Infrastructure (OCI), serving as a reproducible reference for the community.\n\n**Future Vision (Context for the Contributor):** While beyond the immediate GSoC scope, this project lays the foundation for advanced capabilities:\n\n**Fine-Tuning & Routing:**Future iterations will use KFP to fine-tune specialized “Router” models that direct queries to specific agents.**Security (MCP & Istio):**We envision integrating the Model Context Protocol (MCP) and using Istio sidecars to secure agent-to-tool communication.\n\nThe GSoC contributor is building the bedrock layer that these future innovations will stand upon.\n\n**Community Value:**\n\n**“Golden Data” Standard:**By curating the data for this agent, we will identify gaps in our documentation and create a trusted dataset of “verified” configurations that the community can use to benchmark their own internal platforms.**Helm Alignment:**This project will validate the new community Helm charts by acting as a “consumer,” providing feedback on their ease of deployment in a complex GenAI stack.**Platform Alignment:**We will work closely with Tarek Abouzeid to align with the Kubeflow Platform Documentation. The project must clearly separate Core Kubeflow Services (portable) from Cloud-Specific Adapters (OCI), ensuring the agentic architecture remains portable for any user.\n\n**Ideas and references:**\n\n- Current Repo:\n[kubeflow/docs-agent](https://github.com/kubeflow/docs-agent) - Platform Standards:\n[Kubeflow Platform Docs](https://www.kubeflow.org/docs/kubeflow-platform/) - Infrastructure:\n[Terraform OCI Provider Docs](https://registry.terraform.io/providers/oracle/oci/latest/docs)\n\n**Difficulty:** Hard\n\n**Size:** 350 hours\n\n**Skills Required/Preferred:**\n\n- Python (Backend, Agent logic)\n- Kubeflow (Pipelines, KServe)\n- GenAI/LLM Ops (RAG, Vector Databases)\n- Infrastructure (Terraform, Docker, Kubernetes)\n- Communication (Ability to document architectural decisions clearly)\n\n### Project 2: OptimizationJob CRD for Hyperparameter Optimization\n\n**Components:** [kubeflow/katib](https://www.github.com/kubeflow/katib), [kubeflow/sdk](https://www.github.com/kubeflow/sdk), [kubeflow/trainer](https://www.github.com/kubeflow/trainer)\n\n**Mentors:** [@akshaychitneni](https://github.com/akshaychitneni), [@andreyvelich](https://github.com/andreyvelich)\n\n**Contributor:**\n\n**Details:**\n\nHyperparameter optimization (HPO) is critical for maximizing model performance in machine learning workflows. While Katib currently provides HPO capabilities through the `Experiment`\n\nCRD, it was designed for broad use cases including Neural Architecture Search (NAS) and arbitrary workloads.\n\nThis project aims to design and implement a new **OptimizationJob CRD** (`optimizer.kubeflow.org/v1alpha1`\n\n) specifically focused on hyperparameter optimization for TrainJobs. The new CRD will provide:\n\n**Tighter TrainJob Integration**: Replace unstructured trial specifications with typed TrainJob templates, enabling strong validation**Shared Initialization**: Implement a common initializer pattern that runs once and shares model/dataset artifacts across all trials reducing trial startup time and storage costs**Simplified API**: Focus exclusively on HPO use cases**Modern Metrics Collection**: Support push-based metrics reporting via the Kubeflow SDK**SDK Alignment**: Integrate with`OptimizerClient`\n\nAPI from[KEP-46: Hyperparameter Optimization in Kubeflow SDK](https://github.com/kubeflow/sdk/blob/main/docs/proposals/46-hyperparameter-optimization/README.md)\n\nTracking issue: [kubeflow/katib#2605](https://github.com/kubeflow/katib/issues/2605)\n\n**Difficulty:** Hard\n\n**Size:** 350 hours (Large)\n\n**Skills Required/Preferred:**\n\n- Go\n- Python\n- Familiarity with Kubernetes controllers, CRDs\n- Basic understanding of machine learning training workflows\n- Experience with HPO frameworks\n\n## Project #: End-to-End ARM64 Support & Validation on Kubeflow\n\n**Components:** Manifests (Platform), Kubeflow Pipelines (KFP), Katib, Notebooks, Trainer\n\n**Mentors:** @chasecadet, @jtu-ampere (Mentor)\n\n**Owning Team:** ARM Contributions Team\n\n**Contributor:**\n\n**Details:**\n\n**Context & Vision:**\nAs development teams increasingly move to Apple Silicon ([M-series chips](https://en.wikipedia.org/wiki/Apple_silicon#M-series_SoCs)) and production workloads shift to cost-efficient ARM-based cloud instances (like [OCI Ampere](https://www.oracle.com/cloud/compute/arm/), [Google Axion](https://cloud.google.com/products/axion), and [AWS Graviton](https://aws.amazon.com/ec2/graviton/) ), ARM64 support is a critical requirement for the future of Kubeflow.\n\nCurrently, support is fragmented. The ARM Contributions Team aims to close this gap by establishing First-Class Citizen support for ARM64 across the entire Kubeflow Reference Platform. This initiative is not just about compiling binaries; it is about validating the “Kubeflow Platform” experience to ensure it is robust, reproducible, and ready for diverse environments.\n\n**Strategic Alignment:**\nThis work directly supports the Kubeflow Platform Definition. By validating the end-to-end platform on non-x86 architectures, the team serves as a critical quality gate, ensuring that “Kubeflow” remains a consistent standard regardless of the underlying hardware.\n\n**Collaboration & History:**\n\nThis project builds upon the extensive groundwork laid by the ARM Support Team, who have previously validated and built many of these images. The goal is to upstream this foundational work—porting validated Dockerfiles, build flags, and image tags into the official Kubeflow repositories—effectively making the community’s “best effort” success the official standard. Scope & Deliverables\n\n**Scope & Deliverables:**\n\nMulti-Arch Build System (CI/CD)\n\n**Audit & Standardization:**The team will identify every container image in the official kubeflow/manifests release that lacks an ARM64 variant.**Pipeline Implementation:**Update build systems (GitHub Actions/Prow) to generate multi-arch manifests (AMD64/ARM64) automatically on release. The goal is a single tag (e.g., :v2.0.0) that pulls the correct image for the host architecture.Platform Manifest Validation\n\n**Architecture Agnosticism:**Ensure official Kustomize manifests do not hardcode architecture-specific SHA hashes or incompatible image tags, ensuring the manifests apply cleanly regardless of the node architecture.Infrastructure: Cloud & Edge\n\n**Cloud Validation (OCI):**Leverage Oracle Cloud Infrastructure (OCI) Ampere A1 instances to maintain a persistent “Golden” test environment.**Stretch Goal:**On-Premise & Edge Demonstration: A key stretch goal for this team is to demonstrate Kubeflow running on on-premise ARM hardware.**The “Why”:**This serves as the ultimate proof of Kubeflow’s portability. By successfully deploying to an edge environment (outside of managed cloud services), we demonstrate that Kubeflow is truly infrastructure-agnostic and ready for Edge AI use cases.End-to-End (E2E) Platform QA\n\n**Full Suite Testing:**Run the full Kubeflow End-to-End test suite on ARM infrastructure to catch architecture-specific bugs (e.g., generic libc dependencies, JIT compiler issues in TensorFlow/PyTorch).**Documentation & “Golden Data”:**Generate a “Golden Data” set of known-good configurations for running Kubeflow on ARM. This includes documentation on “gotchas” for users running local development clusters on Apple Silicon (Kind/Minikube).\n\n**Difficulty:** Medium/Hard (Depends on CI/CD complexity)\n\n**Size:** 350 hours\n\n**Tracking & References:**\n\n- KFP Issue:\n[Build and publish ARM images for KFP #10309](https://github.com/kubeflow/pipelines/issues/10309) - Manifests Issue:\n[Support for the aarch64 architecture #2745](https://github.com/kubeflow/manifests/issues/2745)\n\n**Team Capabilities & Stack:**\n\n- Docker/Containerization: Deep understanding of multi-arch builds (docker buildx, manifests).\n- CI/CD: GitHub Actions (primary), Prow (secondary).\n- Kubernetes: Kustomize, Manifest management.\n- Go/Python: Ability to debug build scripts and genericize code that assumes x86 architecture.\n- Infrastructure: Familiarity with cloud instances and bare-metal/edge hardware configuration.\n\n### Project 3: KServe Models Web Application\n\n**Components:** Kserve, Kubeflow Common Library, Kubeflow Dashboard\n\n**Mentors:** [Griffin Sullivan](https://github.com/Griffin-Sullivan), [Harshit Nayan](https://github.com/LogicalGuy77), [Dhanisha Phadate](https://github.com/dhanishaphadate)\n\n**Contributor:**\n\n**Details:** The project includes improving test coverage and cleanup, adding end-to-end and deployment-level testing, and validating the application through full deployment workflows. It also migrates the repository from KServe to Kubeflow and extends the UI to support KServe v0.16/0.17 features, including [LLMInferenceService](https://kserve.github.io/website/docs/model-serving/generative-inference/llmisvc/llmisvc-overview) and [InferenceGraph](https://kserve.github.io/website/docs/model-serving/inferencegraph/overview).\n\nThis project modernizes the KServe Models Web Application by upgrading Angular from v14 to v16+. The Kubeflow common library will be upgraded first, followed by updates to Dockerfiles, Makefiles, workflows and documentation.\n\n**Difficulty:** Hard\n\n**Size:** 350 hours\n\n**Skills Required/Preferred:**\n\n- Angular & TypeScript\n- Kubernetes and CRDs\n- Docker and CI/CD\n- Kubeflow / KServe (preferred)\n\n### Project 4: Platform Scalability and Security\n\n**Components:** Kubeflow Manifests, Kubeflow Pipelines, Kubeflow Training Operator\n\n**Mentors:** [Julius von Kohout](https://github.com/juliusvonkohout)\n\n**Contributor:**\n\n**Details:** As Kubeflow scales to environments with 1,000+ namespaces, core bottlenecks emerge. This project focuses on optimizing CRD controllers, improving multi-tenancy security, and hardening the platform. Key work areas include: refactoring the Profile Controller to use Metacontroller for a cleaner plugin system, migrating from Istio Gateway to the Kubernetes Gateway API and enabling Model Registry by default. Many CRD controllers are written inefficiently and struggle with the reconciliation load or block the Kubernetes API server with too many requests.\nUsing “Kubernetes user namespaces” for PSS baseline in the level in PSS restricted will also be an explorative task.\n\n**Difficulty:** Hard\n\n**Size:** 350 hours\n\n**Related Issues/PR:**\n\n[Rootless Kubeflow](https://github.com/kubeflow/manifests/issues/2528)[Enable model-registry with UI by default](https://github.com/kubeflow/manifests/pull/3318)[Update kserve/kserve manifests from v0.16.0](https://github.com/kubeflow/manifests/pull/3290)[Fix kustomize warnings](https://github.com/kubeflow/manifests/pull/3268)[Migrate to gateway API](https://github.com/kubeflow/manifests/pull/3094)[“zero-trust” security / networking for training jobs](https://github.com/kubeflow/trainer/issues/2341)[fix: variable namespaces for networkpolicies](https://github.com/kubeflow/manifests/pull/3319)[Recurring Runs Queue Throughput Optimization](https://github.com/kubeflow/pipelines/pull/12610)[Add securityContext support for container components](https://github.com/kubeflow/pipelines/pull/12577)[add gRPC metrics to api-server (RPS/latency), optimize execution spec reporting](https://github.com/kubeflow/pipelines/pull/12010)[ConfigMap-based plugin system for profile controller](https://github.com/kubeflow/dashboard/pull/177)[fix(frontend): Prevent Unauthorized Cross-Namespace Artifact Access](https://github.com/kubeflow/pipelines/pull/12550)[Kubeflow platform pull requests](https://github.com/kubeflow/manifests/pulls)\n\n**Skills Required/Preferred:**\n\n- Go\n- Kubernetes\n- Python\n- Istio\n- Networking\n- Linux Security\n\n### Project 5: Helm Charts\n\n**Components:** Kubeflow Manifests, Kubeflow Pipelines, Kubeflow Katib\n\n**Mentors:** [Julius von Kohout](https://github.com/juliusvonkohout), [Humair Khan](https://github.com/HumairAK), [Dhanisha Phadate](https://github.com/dhanishaphadate)\n\n**Contributor:**\n\n**Details:** This project continues the KSC-approved initiative to provide Kubeflow platform and standalone components via Helm. The goal is to move beyond Kustomize-only deployments to offer minimalistic, maintainable Helm charts that reflect Kustomize defaults 1:1. Key tasks include: developing and testing Helm charts for KFP and Katib, implementing CI/CD testing infrastructure for Helm-based deployments and coordinating with component maintainers to ensure cross-project consistency.\n\nThis project will touch most components and continue the helm chart initiative started by Kunal Dugar who also helped a lot with the testing infrastructure. This will therefore also include working with maintainers of other components such as KFP maintainersfor the KFP helm charts, security and scalability topic or Katib maintainers for Katib helm charts. Some have already open PRs and there was a formal vote by the KSC (Kubeflow steering Committee) that we are moving forward with offering Kubeflow platform and standalone components as helm charts. Therefore it is not just the technical part, but also the coordination effort. The goal is to make minimalistic helm charts that are easy to maintain next to kustomize and only expose sensible settings relevant to most users. For the time being the rendered chart default values must replicate kustomize 1:1. The testing infrastructure has already been set up in the GSOC 2025 efforts in kubeflow/manifests where we already have a few helm charts.\n\n**Difficulty:** Hard\n\n**Size:** 350 hours\n\n**Related Issues/PR:**\n\n[Pipeline Helm Charts](https://github.com/kubeflow/manifests/pull/3237)[Helm Chart Templates For Katib](https://github.com/kubeflow/katib/pull/2553)[Helm charts (KEP 831)](https://github.com/kubeflow/manifests/issues/2730)[Fix the remaining Kustomize 5 warnings](https://github.com/kubeflow/manifests/issues/2991)\n\n**Skills Required/Preferred:**\n\n- Helm\n- Kustomize\n- Kubernetes\n- GitHub Actions\n- Bash\n- Community Coordination\n\n### Project 6: MCP Server for Kubeflow SDK\n\n**Components:** [kubeflow/sdk](https://github.com/kubeflow/sdk), [kubeflow/trainer](https://github.com/kubeflow/trainer)\n\n**Mentors:** [@jaiakash](https://github.com/jaiakash), [@dhanishaphadate](https://github.com/dhanishaphadate), [@abhijeet-dhumal](https://github.com/abhijeet-dhumal)\n\n**Contributor:** [TBD]\n\n**Details:**\nThe Kubeflow SDK allows users with limited Kubernetes knowledge to use standard Python APIs to interact with the Kubeflow ecosystem. Documentation: [https://sdk.kubeflow.org/en/latest/index.html](https://sdk.kubeflow.org/en/latest/index.html)\n\nMost of us use LLMs to create/debug code for jobs, models, etc., but currently there is no mechanism for the LLM to see TrainJob status, debug a crash loop, or provide consolidated metrics about previous tasks. We want to extend and improve the Developer Experience (DX) with a Model Context Protocol (MCP) server for the Kubeflow ecosystem.\n\nWe have a [kubeflow/community#936](https://github.com/kubeflow/community/issues/936) and an existing MVP for this project. The contributor will extend the MCP server to cover additional use cases, improve error handling, add comprehensive documentation, and potentially integrate with other Kubeflow components like Model Registry.\n\n**Core Deliverables:**\n\n- MCP tools for TrainJob lifecycle (\n`fine_tune`\n\n,`get_training_job`\n\n,`list_training_jobs`\n\n,`delete_training_job`\n\n) - Pre-flight validation (\n`get_cluster_resources`\n\n,`estimate_resources`\n\n,`check_training_prerequisites`\n\n) - Job observability (\n`get_training_logs`\n\n,`get_job_events`\n\n) - Storage setup (\n`setup_training_storage`\n\n)\n\n**Stretch Goals:**\n\n- Policy-based access control (persona-based RBAC)\n- Custom trainer support (\n`run_custom_training`\n\n,`run_container_job`\n\n) - Integration with Model Registry MCP catalog\n- Progress tracking (pending\n[KEP-937](https://github.com/kubeflow/community/pull/937))\n\nTracking issue: [https://github.com/kubeflow/sdk/issues/238](https://github.com/kubeflow/sdk/issues/238)\n\n**Difficulty:** Medium\n\n**Size:** 175 hours (Medium)\n\n**Skills Required/Preferred:**\n\n- Experience with LLM / MCP development.\n- Familiarity with the Kubeflow SDK and Trainer codebase.\n- Understanding of the Kubeflow Ecosystem and basic Kubernetes concepts.\n- Engage and contribute to Kubeflow community on Slack and GitHub.\n\n### Project 7 : Integrate Kubeflow SDK with OpenTelemetry\n\n**Components:** [kubeflow/sdk](https://www.github.com/kubeflow/sdk)\n\n**Mentors:** [@kramaranya](https://github.com/kramaranya), [@dhanishaphadate](https://github.com/dhanishaphadate), [@jaiakash](https://www.github.com/jaiakash)\n\n**Contributor:**\n\n**Details:**\n\nThe Kubeflow SDK enables users with limited Kubernetes knowledge to interact with the Kubeflow ecosystem using standard Python APIs. As AI/ML workloads become more complex and distributed, observability into pipeline execution, model training, and inference workflows becomes critical.\n\nThis project aims to integrate the Kubeflow SDK with OpenTelemetry (OTel) to provide standardized, vendor-neutral telemetry for Kubeflow-based workloads. The integration will enable end-to-end visibility into SDK operations by capturing distributed traces, metrics, and logs across pipeline compilation, submission, execution, and training lifecycles.\n\nThe project will also explore leveraging existing OpenTelemetry and Generative AI instrumentation patterns—such as span conventions for model execution, prompt handling, and inference steps—where applicable.\n\n**Features Expected:**\n\n- Add OpenTelemetry instrumentation to key Kubeflow SDK components\n- Enable distributed tracing for pipeline execution and SDK operations\n- Collect and export metrics related to AI/ML workloads\n- Provide configurable OTel exporters and sampling options\n- Documentation and examples demonstrating observability setup and usage\n- cover below SDK clients\n\n| SDK Client | Component |\n|---|---|\n`TrainerClient` | Kubeflow Trainer |\n`PipelinesClient` | Kubeflow Pipelines |\n\n```\nkubeflow/\n├── trainer/ # TrainerClient - distributed training & fine-tuning\n├── optimizer/ # OptimizerClient - Katib AutoML & hyperparameter tuning\n├── hub/ # ModelRegistryClient - model artifact management\n└── common/ # Shared utilities across clients\n```\n\n\nBonus requirement to complete\n\n| SDK Client | Component |\n|---|---|\n`OptimizerClient` | Kubeflow Katib |\n`ModelRegistryClient` | Model Registry |\n`SparkClient` | Spark Operator |\n\n**Difficulty:** [intermediate|hard]\n\n**Size:** [350 hours]\n\n**Skills Required/Preferred:**\n\n- Python\n- Understanding of the Kubeflow Ecosystem (preferred)\n- OpenTelemetry (tracing, metrics, logging)\n- Distributed systems and observability concepts\n- Kubernetes and CRDs\n\n### Project 10: Dynamic LLM Trainer Framework for Kubeflow\n\n**Components:**\n[kubeflow/trainer](https://www.github.com/kubeflow/trainer),\n[kubeflow/sdk](https://www.github.com/kubeflow/sdk)\n\n**Mentors:**\n[@tariq-hasan](https://github.com/tariq-hasan),\n[@andreyvelich](https://github.com/andreyvelich)\n\n**Contributor:**\n\n**Details:**\n\nKubeflow Trainer provides Kubernetes-native distributed ML training with a Python-first experience. It currently supports LLM fine-tuning through TorchTune as a built-in backend, but TorchTune is no longer actively adding new features, limiting support for emerging models and post-training methods (DPO, PPO, ORPO).\n\nThis project proposes a **Dynamic LLM Trainer Framework** that decouples Kubeflow Trainer from any single fine-tuning backend. The goal is to introduce a pluggable architecture enabling multiple frameworks to integrate seamlessly while preserving backward compatibility and a simple Python SDK. This builds on the existing plugin architecture in `pkg/runtime/framework/plugins/torch/`\n\nand extends the `BuiltinTrainer`\n\npattern in the SDK.\n\n**The framework will provide:**\n\n- A backend-agnostic LLM Trainer interface, symmetric to TrainingRuntime on the control plane\n- Dynamic backend registration for in-tree and external frameworks\n- TorchTune refactored as a first-class pluggable backend\n- Faster day-0/day-1 support for new models and fine-tuning strategies\n- Backward compatibility for existing TorchTune-based workflows\n\n**Initial backends to explore:**\n\n| Backend | Rationale |\n|---|---|\n| TorchTune | Preserve existing functionality |\n| TRL | Industry standard for SFT/DPO/PPO |\n| Unsloth | ~2× faster, ~70% lower memory |\n| LlamaFactory | 100+ model support |\n\nBeyond in-tree backends, the SDK should support external framework registration, mirroring how TrainingRuntime enables custom runtimes.\n\nThis project is well-suited for contributors interested in ML systems, API design, and bridging modern LLM tooling with production Kubernetes platforms.\n\nTracking issue: [kubeflow/trainer#2839](https://github.com/kubeflow/trainer/issues/2839)\n\n**Difficulty:** Hard\n\n**Size:** 350 hours (Large)\n\n**Skills Required/Preferred:**\n\n- Python, Go\n- Familiarity with Kubernetes and Kubeflow Trainer architecture\n- Experience with LLM fine-tuning frameworks (TRL, TorchTune, Unsloth)\n- Understanding of distributed training concepts\n- Interest in API and framework design\n\n### Project 11: Composable Kale Notebooks with Visual Pipeline Editor\n\n**Components:** Kubeflow Kale\n\n**Mentors:** [Eder Ignatowicz](https://github.com/ederign), [Stefano Fioravanzo](https://github.com/StefanoFioravanzo)\n\n**Contributor:**\n\n**Details:**\nThis project extends Kale to support composition of multiple Kale notebooks into a single Kubeflow Pipeline. Each notebook becomes a first-class pipeline unit, with explicit inputs and outputs, allowing users to orchestrate multi-notebook workflows directly from the notebook environment.\n\nA core requirement of the project is a visual editor that enables users to compose, configure, and reason about notebook-based pipelines graphically. The editor will align with existing JupyterLab UI patterns and extension APIs to minimize risk and ensure consistency with the Jupyter ecosystem.\n\n**Goals:**\n\n- Treat Kale notebooks as first-class pipeline components\n- Define notebook-based workflows into a re-usable and shareable format\n- Compose multiple Kale notebooks into a single pipeline\n- Define explicit inputs and outputs between notebooks (parameters, artifacts)\n- Integrate with Kubeflow Pipelines via @dsl.notebook_component\n- Provide a visual editor aligned with existing JupyterLab UI patterns\n- Support runtime configuration for pipeline execution\n- Keep authoring and composition inside JupyterLab\n\n**Expected Outcomes:**\n\n- A visual pipeline editor integrated into JupyterLab\n- A concrete model for Kale notebook composition and execution\n- A reference implementation aligned with Kubeflow Pipelines\n- Documentation and examples for multi-notebook workflows\n\n**Why This Project**\n\nNotebook workflows are commonly split across multiple files. Without visual composition, understanding and maintaining these workflows becomes difficult. Aligning the editor with existing JupyterLab UI patterns reduces implementation risk while improving clarity, usability, and maintainability.\n\n**Difficulty:** Hard\n\n**Size:** 350 hours\n\n**Related Issues/PR:**\n\n**Skills Required/Preferred:**\n\n- Python (Kale internals, Kubeflow Pipelines DSL)\n- JavaScript / TypeScript (visual editor, JupyterLab extensions)\n- Familiarity with Jupyter notebooks and pipeline concepts\n- Experience or interest in working within established UI frameworks\n\n### Project 12: Kubeflow SDK/SparkClient - Batch Jobs, Observability & Production Readiness\n\n**Components:** [kubeflow/sdk](https://www.github.com/kubeflow/sdk) (SparkClient), [kubeflow/spark-operator](https://www.github.com/kubeflow/spark-operator)\n\n**Mentors:** [@shekharrajak](https://github.com/shekharrajak), [@tariq-hasan](https://github.com/tariq-hasan)\n\n**Contributor:**\n\n**Details:**\n\nThe Kubeflow SparkClient provides a unified Python API for running Apache Spark workloads on Kubernetes. The current MVP supports interactive Spark Connect sessions (KEP-107), but lacks batch job submission, usage with other kubeflow SDK Client, kubeflow components and production observability features.\n\nThis project extends SparkClient to support the complete Spark workflow on Kubernetes:\n\n**1. Batch Job Submission (Core Feature)**\n\nImplement `submit_job()`\n\nAPI for submitting batch Spark jobs via SparkApplication CRD:\n\n- Python function mode: Serialize and execute user-defined functions\n- Script mode: Submit existing PySpark/Scala scripts\n- Job lifecycle:\n`list_jobs()`\n\n,`get_job()`\n\n,`get_job_logs()`\n\n,`wait_for_job()`\n\n,`delete_job()`\n\n, and more - Integration with existing SparkClient patterns (options, validation, error handling)\n\n**2. Observability & Monitoring**\n\nBuild monitoring capabilities for production Spark workloads:\n\n- Metrics collection from Spark REST API (task stats, executor metrics, stage progress)\n- Structured event streaming (task completion, failures, stage boundaries)\n- Health checking and readiness probes\n- Optional Prometheus metrics exporter\n\n**3. Data Transfer & Transform reading from Data LakeHouse**\n\nTryout reading and connecting to data warehouse and data lakehouse:\n\n- Real world usecases of ETL jobs\n- Transform and enrich the data\n- Use Kubeflow components along with SDK SparkClient\n\n**4. Documentation & Examples**\n\n- API reference documentation (auto-generated)\n- Deployment, debug guide\n- Troubleshooting guide\n- Example notebooks (Jupyter/Colab)\n- Examples for connecting to Spark Cluster - EMR/Apache Spark k8s\n\n**Technical Architecture:**\n\n- CRD builder for SparkApplication (similar to SparkConnect)\n- Reuses existing validation, options, and error handling infrastructure\n- Use different SDK clients and kubeflow components like Notebook.\n\n**Community Value:**\n\n- Completes the SparkClient vision from KEP-107\n- Enables end-to-end Spark workflows (interactive development, batch & all different usecases)\n- Aligns with Kubeflow’s mission of simplifying ML infrastructure\n- Provides foundation for future Kubeflow Pipelines integration\n- Showcase different ways of using SparkClient with Kubeflow Components\n\n**Related Issues/KEPs:**\n\n**Difficulty:** Hard\n\n**Size:** 350 hours (Large)\n\n**Skills Required/Preferred:**\n\n- Python (Core development)\n- Kubernetes (CRDs, API, RBAC)\n- Apache Spark (Architecture, Configuration)\n- Testing (Unit, Integration, E2E)\n- Technical Writing (Documentation)\n\n### Feedback\n\nWas this page helpful?\n\nThank you for your feedback!\n\nWe're sorry this page wasn't helpful.\nIf you have a moment, please [share your feedback](https://github.com/kubeflow/website/issues/new?title=[Feedback]+events/upcoming-events/gsoc-2026.md) so we can improve.\n\n[gsoc: Add End-to-End ARM64 Support & Validation on Kubeflow for GSoC 2026 proposal (#4299) (719404fc)](https://github.com/kubeflow/website/commit/719404fc2b12e72fa04a4d35f39a3ff2bf46a103)"
  },
  {
    "name": "FLARE",
    "slug": "flare",
    "tagline": "Industry leading malware analysis",
    "description": "The Mandiant FLARE team is a collection of about 40 reverse engineers that analyze malware in support of threat intel, incident response, and computer forensic investigations. We spend our days using disassemblers, debuggers, decompilers, and emulators to figure out what malware does and how we can contain it. We’re known for delivering training sessions that share our experience and releasing open source software that automates the boring things. If you have even a passing interest in reverse engineering or malware analysis, reach out so that we can chat!",
    "ideas_url": "https://github.com/mandiant/flare-gsoc/blob/2026/doc/project-ideas.md",
    "website_url": "https://cloud.google.com/security/flare",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "Sandbox",
      "ida-pro"
    ],
    "topic_tags": [
      "emulation",
      "disassembly",
      "decompilation",
      "malware-analysis",
      "reverse-engineering"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/flare",
    "ideas_content": "# Project Ideas\n*FLARE @ Google Summer of Code 2026*\n\nThis document lists examples of projects that would be great for GSoC 2026 contributors.\nThe list doesn't include everything - feel free to identify your own idea and propose it!\n\nAll of our project ideas revolve around reverse engineering tools.\nThat is, we want to improve the lives of malware analysts through novel techniques and automation.\nTo succeed with any of these examples, you should have a basic familiarity with reverse engineering or a strong desire to learn.\n\nOur tools are used by thousands of analysts to identify, describe, and stop malware.\n\nBriefly:\n- [capa](https://github.com/mandiant/capa) identifies the capabilities in executable files, such as \"installs a service\" or \"downloads data via HTTP\".\n  - enhance static analysis\n  - enhance dynamic analysis\n- [FLOSS](https://github.com/mandiant/flare-floss) automatically deobfuscated protected strings in malware.\n  - extract language specific strings (.NET, Swift, Zig, ...)\n  - QUANTUMSTRAND\n- [GoReSym](https://github.com/mandiant/GoReSym) is a Go symbol parser that extracts program metadata (such as CPU architecture, OS, endianness, compiler version, etc), function metadata, filename and line number metadata, and embedded structures and types.\n- [XRefer](https://github.com/mandiant/xrefer) is an IDA plugin offering a custom navigation interface to examine execution paths, highlight downstream behaviors, cluster related functions, and generate Gemini-based insights into the malware's anatomy.\n  - [Backend Expansion (Radare2 or Vivisect))](https://github.com/mandiant/flare-gsoc/blob/2026/doc/project-ideas.md#xrefer-backend-expansion-radare2-or-vivisect)\n  - [Native Frontend Development (Binary Ninja or Ghidra)](https://github.com/mandiant/flare-gsoc/blob/2026/doc/project-ideas.md#xrefer-native-frontend-development-binary-ninja-or-ghidra)\n\n## capa: Native Script Analysis Support\n\n*size*: large, estimated 350 hours\n\n*difficulty*: hard\n\n*mentors*: [@mike-hunhoff](https://github.com/mike-hunhoff), [@Maijin](https://github.com/Maijin), [@larchchen](https://github.com/larchchen)\n\nCurrent static analysis tools often struggle with scripting languages, relying on fragile regular expressions that are easily evaded. As adversaries increasingly \"Live off the Land\" using scripts, the need for robust, structural analysis is critical.\n\nThis project aims to extend the **capa** engine to natively support static analysis of scripting languages by integrating **Tree-sitter**. By moving beyond byte-sequence matching to Abstract Syntax Tree (AST) analysis, we can detect capabilities in interpreted languages with the same fidelity capa currently provides for PE, ELF, and .NET binaries.\n\n**Deliverables**\n\n* **Core Integration**: Integrate the `tree-sitter` parser library into capa's Python architecture.\n* **Backend Development**: Develop a new analysis backend that traverses the AST to extract features (function calls, variable usage, structure) rather than using regex.\n* **Language Support**: Implement initial support for \\*Nix/Cloud languages (focusing on Bash and Python) or Windows (PowerShell).\n* **Rule Verification**: Create a set of capa rules to demonstrate and test the new capability against real-world samples.\n\n**Required Skills**\n\n* Strong proficiency in Python3.\n* Understanding of compilers, parsers, or Abstract Syntax Trees (AST).\n* Familiarity with `tree-sitter` is a major plus.\n* Knowledge of scripting languages (Bash, Python, or PowerShell).\n* Basic understanding of Git and malware analysis concepts.\n\n## capa: Automated Rule Generation Agent\n\n*size*: large, estimated 350 hours\n\n*difficulty*: medium to hard\n\n*mentors*: [@mike-hunhoff](https://github.com/mike-hunhoff), [@Maijin](https://github.com/Maijin)\n\nMandiant’s [capa](https://github.com/mandiant/capa) is the industry standard for identifying capabilities in executable files. However, the volume of new malware variants and requested rules in our issue tracker often exceeds the capacity of human analysts. Keeping the ruleset up-to-date manually is challenging against the velocity of new threat techniques.\n\nThis project aims to develop an autonomous **capa agent** that functions as a \"virtual contributor.\" The agent will automate the heavy lifting of rule creation by parsing GitHub Issues or analyzing raw samples, generating valid YAML rules using Large Language Models (LLMs), and crucially verifying them against the official capa linter and test runner before submission. The system adheres to a Human-in-the-Loop (HITL) philosophy: the agent does the engineering and testing, but human maintainers retain control over the final merge via Pull Requests.\n\n**Deliverables**\n\n* **Agent Core & Triggers**: Develop the agent logic using Google ADK to handle \"Reactive\" triggers (parsing GitHub Issues for context/samples) and \"Proactive\" triggers (scanning daily feeds).\n* **Generation & Grounding**: Implement the LLM integration (e.g., Gemini) to write rules, using RAG or tool use (Google Search) to verify API definitions and shell commands.\n* **Validation Loop**: Build a robust self-correction loop where the agent runs the `capa` linter and test runner, parsing error logs to fix syntax errors automatically *before* a human sees the code.\n* **Automated PR Workflow**: Create the logic to package verified rules and submit them as formatted Pull Requests to `mandiant/capa-rules`, including test results in the PR description.\n\n**Required Skills**\n\n* Strong proficiency in Python.\n* Experience with LLMs, Agents, or Prompt Engineering.\n* Basic understanding of malware analysis and the capa rule format (YAML).\n* Familiarity with Git, GitHub Actions, or CI/CD pipelines.\n\n## capa: Enhance Static Analysis\n\n_size_: medium to large\n\n_difficulty_: medium\n\n_mentors_: [@mike-hunhoff](https://github.com/mike-hunhoff)\n\nThis initiative focuses on advancing the static analysis capabilities of capa. Key research areas include improving program analysis to effectively distinguish between library/runtime code and programmer-written logic, allowing capa and similar tools to prioritize the program's most significant components. Furthermore, integrating AI at various stages of the analysis could provide significant enhancements.\n\n**Deliverables**:\n\n* Assess the current performance and functionality of capa\n* Brainstorm and pinpoint specific areas for potential improvement\n* Develop, validate, and provide documentation for all implemented enhancements\n* Stretch Goal: Explore and build AI-driven analysis to bolster results\n\n**Skill Requirements**:\n\n* Strong proficiency in Python programming\n* Fundamental knowledge of malware analysis\n* Competency with tools like IDA Pro, Ghidra, Binary Ninja, or vivisect\n* Practical experience using Git and GitHub\n\n\n## capa: Enhance Dynamic Analysis\n\n_size_: medium to large\n\n_difficulty_: medium\n\n_mentors_: [@mike-hunhoff](https://github.com/mike-hunhoff)\n\nThis project's goal is to improve capa's dynamic analysis functionality (i.e. VMRay sandbox runs). Potential improvements include filtering out sandbox noise, improving capa's extraction and matching algorithms, enhancing existing rules, etc. Applying AI analysis could also be part of this project.\n\n**Deliverables**:\n\n- Review and evaluate current capa functionality and performance\n- Identify and brainstorm areas of improvement\n- Implement, test, and document improvements\n- Stretch goal: research and develop AI analysis to enhance capa results\n\n**Required Skills**:\n\n- Solid Python programming skills.\n- Familiarity with dynamic (and static) analysis of malware.\n- (Optional: Familiarity with VMRay sandbox analysis results).\n- Experience with Git and GitHub.\n\n\n## FLOSS: Extract Language Specific Strings (.NET, Swift, Zig, ...)\n\n_size_: large, estimated 350 hours\n\n_difficulty_: medium\n\n_mentors_: [@mr-tz](https://github.com/mr-tz)\n\n_link_: [https://github.com/mandiant/flare-floss/issues/718](https://github.com/mandiant/flare-floss/issues/718)\n\nVarious programming languages embed the constant data, like strings, used within executables in different ways. Most tools, like strings.exe, just look for printable character sequences. This doesn't work well for files compiled from Go or Rust.\n\nHere we propose to extend FLOSS to include a framework to extract language specific strings from executables. After identifying the language, a specific extractor can use specialized logic to pull out the strings embedded into a program by the author. When possible, the extractor should indicate library and runtime-related strings. For example, the extractor may parse debug information to recognize popular third party libraries and annotate the related strings appropriately.\n\nToday, FLOSS automatically deobfuscates protected strings found in malware. Better categorization of its output would make its users more efficient. Extracting language-specific strings would make FLOSS more useful and manifest success as the default tool used by security analysts.\n\n**Deliverables**\n\n- Enhance existing Go and Rust string extraction\n- Develop language identification module\n  - Initial focus on .NET\n  - Consider also Swift, Zig, …\n- Research language string embeddings and create extractor code\n  - We can share existing knowledge and code to bootstrap this\n- Identify strings related to runtime and library code for targeted programming languages\n- Extend standard output format and render results\n\n**Required Skills**\n\n- Medium knowledge of Python 3\n- Basic understanding of reverse engineering (focus: Windows PE files)\n- Experience with .NET or Swift (internals) is a plus, but not required\n- Interest in malware analysis with focus on static analysis\n- Basic understanding of Git\n\n\n## FLOSS: QUANTUMSTRAND\n\n_size_: large, estimated 350 hours\n\n_difficulty_: medium\n\n_mentors_: [@mr-tz](https://github.com/mr-tz)\n\n_link_: [https://github.com/mandiant/flare-floss/issues/943](https://github.com/mandiant/flare-floss/issues/943)\n\nExtend FLOSS to use the rendering techniques pioneered by QUANTUMSTRAND.\n\nQUANTUMSTRAND is an experiment that augments traditional strings.exe output with context to aid in malware analysis and reverse engineering. For example, we show the structure of a file alongside its strings and mute/highlight entries based on their global prevalence, library association, expert rules, and more.\n\nFLOSS is a tool that automatically extracts obfuscated strings from malware, rendering the human-readable data in a way that enables rapid reverse engineering.\n\nWe propose to extend FLOSS to use the techniques pioneered by QUANTUMSTRAND to highlight important information while muting common and/or analytically irrelevant noise. The project will provide an opportunity to dig into the PE, ELF, and/or Mach-O file formats, finding ways to make technical details digestible. If successful, FLOSS will continue to be the tool that malware analysts turn to when triaging unknown files.\n\n**Deliverables**\n\n- Research\n  - Review Quantumstrand functionality\n  - Evaluate most useful features for integration into FLOSS\n- Identify and Propose Improvements\n  - Suggest improvements for the user interface and experience\n  - Review and enhance string tagging databases\n  - Discuss ideas with mentors and FLOSS user community\n- Implementation\n  - Implement improved functionality\n  - Work on a GUI to interactively display FLOSS results\n- Evaluation and Knowledge Sharing\n  - Test improvements and gather feedback from users\n  - Write blog post about experience and project achievements\n\n**Required Skills**\n\n- Solid knowledge of Python 3\n- Basic understanding of reverse engineering / malware analysis\n- Basic understanding of Git\n- Experience or interest with file formats such as PE, ELF, and/or Mach-O\n- Experience or interest in user interface and/or user experience design\n\n\n## GoReSym: Recover Golang Structure Tags and Interface Methods in GoReSym\n\n**Mentors:** @stevemk14ebr, @jaeyoungkimG  \n**Difficulty:** Easy to Medium  \n**Project Repo:** [https://github.com/mandiant/GoReSym](https://github.com/mandiant/GoReSym)  \n\n### Description\nGoReSym is a Go symbol parser that extracts program metadata, function information, and embedded structures/types from Go binaries. It is widely used by reverse engineers to analyze stripped Go binaries and reconstruct type definitions.\n\nCurrently, GoReSym recovers structure fields but fails to extract **structure tags** (e.g., `` `json:\"name\"` ``) and **interface method names**. These tags are critical for understanding how data is serialized (JSON, XML) and how the application interacts with databases or external APIs. The goal of this project is to implement the parsing logic required to recover these missing metadata fields and include them in GoReSym's JSON output.\n\n### Task Details\nThe contributor will need to:\n1.  **Analyze Existing Parsers:** Study how GoReSym currently extracts `StructField` information by looking at the code adapted from the Go runtime (specifically `objfile` and type parsing logic).\n2.  **Implement Tag Extraction:** Add logic to read the tag string associated with struct fields. This involves understanding the internal memory layout of Go types.\n3.  **Implement Method Name Extraction:** Add logic to recover method names for Interface types.\n4.  **Update Output:** Modify the JSON serialization to include these new fields.\n5.  **Testing:** specific test cases involving structs with various tags and interfaces to ensure accurate recovery across different Go versions.\n\n### Recommended Skills\n*   **Go (Golang):** Intermediate knowledge.\n*   **Reverse Engineering:** Basic understanding of binary formats (PE, ELF, Mach-O) and memory layouts.\n*   **Go Internals:** Familiarity with how Go stores type metadata (`moduledata`, `pclntab`) is helpful but can be learned during the project.\n\n### Resources\n*   **Issue Discussion:** [GoReSym Issue #37](https://github.com/mandiant/GoReSym/issues/37) (contains references to similar implementations).\n*   **Reference Implementation:** [goretk/gore type parsing](https://github.com/goretk/gore/blob/3009b3909f08fa910e5a93d893bb66117f3628f9/type2.go#L149)\n\n## XRefer: Backend Expansion (Radare2 or Vivisect)\n\n_size_: large, estimated 360 hours\n\n_difficulty_: medium\n\n_mentors_: @m-umairx, @binjo\n\n### Description\n**XRefer** is a binary analysis tool that correlates cross-references, API traces, and LLM-generated insights to cluster functions by behavior. Currently, XRefer utilizes a robust backend abstraction layer (`xrefer_new/backend/base.py`) with implementations for IDA Pro, Ghidra, and Binary Ninja.\n\nThis project aims to democratize access to XRefer by implementing a backend for a fully open-source/free disassembly framework: **Radare2** (via r2pipe) or **Vivisect**. While Ghidra is free, it is heavy and complex to set up in automated environments. By supporting lightweight frameworks like Vivisect or Radare2, we can create a truly **standalone CLI release** of XRefer. This would allow users to install and run XRefer (e.g. via `pip`) without requiring complex setups or commercial licenses, significantly lowering the barrier to entry for students and researchers.\n\nThe core task involves mapping the target framework's API to XRefer's standardized `BackEnd` interface. This includes implementing memory reading, function enumeration, disassembly lifting (to XRefer's `Instruction` format), and cross-reference analysis.\n\n### Deliverables\n* **Functional Backend Module:** A fully implemented backend package (e.g., `xrefer_new/backend/vivisect/`) that adheres to the `BackEnd` abstract base class.\n* **Core Abstraction Refinement:** As the backend abstraction layer is relatively new, the student is expected to identify and implement necessary fixes, tweaks, or extensions to the base interface (`xrefer_new/backend/base.py`) to ensure the new backend functions correctly and the abstraction remains robust.\n* **CLI Integration:** A working standalone CLI version of XRefer that uses this new backend by default when no commercial tool is detected.\n* **Unit Tests:** A comprehensive test suite verifying that the new backend returns data (functions, strings, xrefs) consistent with the existing IDA/Ghidra backends.\n* **Documentation:** Setup guides for the standalone CLI version and dependency management.\n\n### Required Skills\n* **Python:** Advanced proficiency.\n* **Reverse Engineering:** Understanding of binary file formats (PE/ELF), memory sections, and assembly (x86/x64).\n* **Target Framework API:** Familiarity with **Radare2 (r2pipe)** or **Vivisect** internals is highly preferred.\n\n## XRefer: Native Frontend Development (Binary Ninja or Ghidra)\n\n_size_: large, estimated 360 hours\n\n_difficulty_: medium\n\n_mentors_: @m-umairx, @binjo\n\n### Description\nXRefer's architecture separates the analysis logic (`core/analyzer.py`) from the underlying disassembler via a backend abstraction layer. However, the current Graphical User Interface (GUI) is implemented exclusively for IDA Pro.\n\nThis project aims to build a **native frontend module** for another major platform. The candidate may choose to target either **Binary Ninja** OR **Ghidra**.\n\nRather than creating a generic GUI abstraction, the goal is to write a dedicated GUI module tailored specifically to the chosen platform's capabilities. This ensures the plugin feels \"native\" to the environment, utilizing the specific Docking API and UI toolkit of the host (Qt for Binary Ninja, Swing for Ghidra).\n\nThe student will implement a new GUI module (e.g., `xrefer_new/gui/binaryninja/` or `xrefer_new/gui/ghidra/`) that consumes the platform-agnostic analysis data produced by the XRefer core and renders it using the host's native UI widgets. This will replicate the rich experience of the IDA plugin—including cluster visualization, colored tables, and interactive navigation—directly within the chosen client.\n\n### Deliverables\n* **Native Frontend Module:** A platform-specific Python module implementing the XRefer UI, utilizing the native docking and widget APIs of the chosen tool.\n* **Visual Parity:** Replication of key XRefer visual features using the host's UI primitives:\n    * **Cluster Graphs:** Rendering ASCII-art or graph-based visualizations of function clusters.\n    * **Context Tables:** Interactive lists of cross-references, strings, and capabilities.\n    * **Status Ribbons:** Information bars displaying analysis state.\n* **Interactive Navigation:** Implementation of double-click navigation and synchronization between the XRefer view and the host disassembly listing.\n* **Integration:** Seamless loading of the GUI module when XRefer is started within the client.\n\n### Required Skills\n* **Python:** Strong proficiency (required for XRefer core integration).\n* **Platform Specifics (Candidate must possess skills for their chosen path):**\n    * **Binary Ninja Path:** Experience with **Qt (PyQt5/PySide)** and the `binaryninjaui` API.\n    * **Ghidra Path:** Experience with **Java/Swing** (Ghidra's GUI toolkit) and the PyGhidra API is highly preferred.\n* Experience with and access to IDA Pro are preferred, as the candidate should ideally be able to explore the IDA plugin frontend independently to replicate it on the target platform."
  },
  {
    "name": "NixOS Foundation",
    "slug": "nixos-foundation",
    "tagline": "Declarative builds and deployments",
    "description": "Our role is to support the infrastructure and development of the NixOS project as a whole.\n\nMost of the development is happening here:\nhttps://github.com/nixos/nix - the Nix cli and language reference implementation\n\nhttps://github.com/nixos/nixpkgs - package definitions for the Nix package manager and NixOS source code\n\nA few key points are:\n- keeping our ci up and running\n- hosting a trustworthy binary cache for the public\n- providing documentation for everything Nix\n- unblocking contributors and keeping things civil",
    "ideas_url": "https://github.com/NixOS/GSoC/blob/main/ideas/2026.md",
    "website_url": "https://nixos.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "git",
      "nix"
    ],
    "topic_tags": [
      "declarative",
      "reproducible",
      "InfrastrucutreAsCode"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/nixos-foundation",
    "ideas_content": "# Ideas\n\nWelcome to our Google Summer of Code ideas list!\n\n## Review Nixpkgs PRs\n\nEffort: Small (90 hours) - Large (350 hours)\n\nNixpkgs is the largest package repository with over 120k packages. It is maintained in the [Nixpkgs](https://github.com/nixos/nixpkgs/) repository, where hundreds of active committer-maintainers are ensuring that tens of thousands of people get the latest and greatest up-to-date packages.\n\nAs such, many people including thousands of listed non-committer maintainers are [submitting PRs](https://github.com/nixos/nixpkgs/) all the time to propose changes. While there is a big number of reviewers of these PRs, we can always use more help to make sure all are tended to.\n\nTherefore this project is about helping out with PR reviews, allowing you to get an in-depth view of various parts of Nixpkgs.\n\nPossible mentors:\n- Almost any [Nixpkgs committer](https://github.com/NixOS/nixpkgs-committers/tree/main/members)\n\nDifficulty: Easy to medium depending on choice\n\nActivities:\n- Review updates\n- Review code changes\n- Improve smoke tests (`passthru`), facilitating future review / automation\n- User testing if needed, updating user documentation\n- Document merge criteria\n\n## Improved release notes for Nixpkgs\n\nEffort: Small (90 hours) (or Medium (175 hours) with nice-to-have)\n\nNixpkgs and NixOS release notes are currently an unordered messy list that is barely readable: [Nixpkgs](https://github.com/NixOS/nixpkgs/blob/master/doc/release-notes/rl-2511.section.md), [NixOS](https://github.com/NixOS/nixpkgs/blob/master/nixos/doc/manual/release-notes/rl-2511.section.md).\n\nThese release notes are often not very relevant, hard to read and cause frequent merge conflicts. This project is to add infrastructure to make each release note entry be declared in its own file, with optional extra structure and attributes, and then use this to generate better release notes.\nNice to have: Generate them dynamically for the user, like the Home Manager news feature.\n\nPossible mentors:\n- Previous release managers \n\nDifficulty: Easy\n\nPrior art:\n- https://nix.dev/manual/nix/2.33/development/contributing.html#add-a-release-note\n- https://github.com/nix-community/home-manager/tree/master/modules/misc/news\n\n## Migrate some NixOS modules to modular services\n\nEffort: Small (90 hours) to Large (350 hours)\n\n[Modular services](https://nixos.org/manual/nixos/unstable/#modular-services) are a new NixOS feature to reduce evaluation time as more service modules are written, contrasting the historic evaluation time increases as the [central module list](https://github.com/NixOS/nixpkgs/blob/master/nixos/modules/module-list.nix) increased, while also supporting more flexible usage patterns like multiple instances of a service type on the same host.\nThis project is to migrate some standard service modules to modular services. Pick a module from the module list, see if it makes sense to migrate it, and make a PR for it. Can be extended to arbitarily many modules.\n\nSkills required:\n- NixOS configurations\n- Systemd services\n\nPossible mentors:\n- Robert Hensing\n- Silvan Mosberger\n\nDifficulty: Medium\n\nReferences:\n- https://github.com/NixOS/nixpkgs/issues/428084\n- https://github.com/NixOS/nixpkgs/pull/475372\n- https://github.com/NixOS/nixpkgs/pull/476861\n\n## Security Tracker Improvements\n\nEffort: Small (90 hours) - Large (350 hours)\n\nImprove the Nixpkgs Security Tracker with the following enhancements:\n- Improve matching quality with more structured data and heuristics\n- Implement workflow for change proposals by maintainers\n- Enable sharing evaluation data across multiple services\n- Increase data storage efficiency\n- Fix UI problems\n- Dig into data to increase transparency or observability\n- Introduce new tools or paradigms into the development process\n\nSkills required:\n- Web development\n- Data analysis\n- User interface design\n- Backend development\n\nPossible mentors:\n- (Add yourself here!)\n\nDifficulty: Easy to Medium, depending on choice\n\nReferences:\n- https://tracker.security.nixos.org/\n- https://github.com/NixOS/nix-security-tracker/issues\n\nPrior efforts:\n- Existing security tracker infrastructure\n\n## Testing Dynamic Derivations\n\nEffort: Medium (175 hours)\n\nExisting work on an experimental feature known as \"dynamic derivations\", which refers to derivation outputs that can themselves be derivations, lacks the adequate testing to be upstreamed. Moreover, functionality can be added to enable \"lang2nix\" tools to work more seamlessly. The goal is to thoroughly test this feature and add new functionalities such as methods for converting foreign packages to Nix using graphs for various package managers, creating conversion tools for Ninja and Make graphs (benefiting large builds like Chromium and LLVM), determining paths for upstream tools like CMake and Meson to integrate with Nix, and exploring modifications to language-specific package managers to utilize Nix for the actual building process.\n\nSkills required:\n- Nix derivation understanding\n- Build systems (Ninja, Make, CMake, Meson)\n- Graph algorithms\n- Nice to have: C++ for Nix internals if you want to fix a problem with dynamic derivations\n\nPossible mentors:\n- (Add yourself here!)\n\nDifficulty: Hard\n\nReferences:\n- https://github.com/NixOS/rfcs/blob/master/rfcs/0092-plan-dynamism.md\n- https://github.com/NixOS/rfcs/pull/92\n- https://github.com/NixOS/nix/issues/6316\n\nPrior efforts:\n- Existing dynamic derivations implementation in Nix\n\n\n## Declarative user profile pictures\n\nEffort: Small (90 hours)\n\nCurrently, user profile pictures as they are used in Gnome cannot be reasonably changed. The interface used for changing user icons in the Gnome system settings is unreliable (seems to only work for the preset icons). The only way to change them at all is to manually put them into /var/lib/AccountsService/icons.\n\nThe project is to make declarative user icons possible by e.g. patching accountsservice to point the user icon directory to an immutable location in /etc or systemd service to place user icons in /var/lib/AccountsService/icons. This is followed up by writing NixOS VM tests to make sure it works.\n\nPossible mentors:\n- (Add yourself here!)\n\nDifficulty: Easy\n\nReferences:\n- https://github.com/NixOS/nixpkgs/issues/163080\n\n## Enhanced Patch Information Extraction\n\nEffort: Medium (175 hours)\n\nImprove the mechanisms for extracting and exposing information from patches in nixpkgs. This includes better metadata extraction, structured data output, and potentially machine-readable formats for downstream tooling integration.\n\nSkills required:\n- Nix expression evaluation\n- JSON handling\n- Metadata extraction patterns\n\nPossible mentors:\n- (Add yourself here!)\n\nDifficulty: Hard, because it's open ended and requires some research to find a good solution\n\nReferences\n- https://github.com/NixOS/nixpkgs/issues/39392\n\n## Cross-Ecosystem Vendored Dependencies\n\nEffort: Medium (175 hours)\n\nCurrently, retrieving vendored dependencies is ecosystem-specific. This project aims to create a unified mechanism for fetching vendored dependencies from any package, regardless of the ecosystem (Rust, Dart, Go, etc.). This would provide a consistent interface for handling vendored code across different language ecosystems.\nFor instance the Nixpkgs function for building a Go package could be extended with a \"pass-through\" derivation that reports what the vendored dependencies are, so that this information can be integrated into the security tracker later.\n\nSkills required:\n- Advanced Nix internals knowledge\n- Understanding of multiple ecosystems (Cargo, pub, Go modules, etc.)\n- Fetcher implementation experience\n\nPossible mentors:\n- (Add yourself here!)\n\nDifficulty: Medium\n\nReferences:\n- https://nixos.org/manual/nixpkgs/stable/#importing-a-cargo.lock-file\n\nPrior efforts:\n- Existing work on fetchers in nixpkgs\n- https://github.com/nix-community/dream2nix\n- https://github.com/nix-community/crystal2nix\n\n## Refactor Remote Builder Library\n\n<!-- TODO: Needs more details -->\n\nEffort: Medium (175 hours)\n\nCurrently the remote builder code in the Nix daemon is implemented as a monolithic `processConnection` function, with customization limited to passing a custom store. This project aims to refactor this code into a separate library, making it easier to implement custom remote builders and improving code maintainability.\n\nSkills required:\n- C++ for Nix daemon internals\n- Understanding of Nix store architecture\n- Socket programming and SSH knowledge\n\nPossible mentors:\n- (Add yourself here!)\n\nDifficulty: Hard\n\nReferences:\n- https://nix.dev/manual/nix/stable/advanced-topics/distributed-builds.html\n- https://github.com/NixOS/nix/issues/10451\n\n## SBOM Accuracy and PURL Integration for Nixpkgs\n\nEffort: Small (90 hours)\n\nSoftware Bills of Materials (SBOMs) generated from nixpkgs packages often suffer from inaccurate package identifiers, making vulnerability scanning and supply chain analysis unreliable. This project aims to improve SBOM accuracy by adding proper PURL (Package URL) attributes to nixpkgs package metadata, ensuring consistent and accurate package identifier generation for SBOM output in multiple formats (SPDX, CycloneDX), and creating validation tools to verify SBOM accuracy. The project will integrate with existing tools and ensure compatibility with vulnerability scanners.\n\nSkills required:\n- Nix expression evaluation and metadata handling\n- Understanding of PURL specification\n- SBOM format knowledge (SPDX, CycloneDX)\n- JSON/XML processing\n\nPossible mentors:\n- (Add yourself here!)\n\nDifficulty: Medium\n\nReferences:\n- https://github.com/NixOS/nixpkgs/pull/454333\n- https://github.com/package-url/purl-spec\n- https://discourse.nixos.org/t/package-urls-purl-for-nix-packages/27934\n- https://discourse.nixos.org/t/how-to-do-vulnerability-scanning-with-nix-sboms/66161\n- https://arnout.engelen.eu/blog/nix-state-of-the-sbom/\n- https://spdx.github.io/spdx-spec/v3.0.1/annexes/pkg-url-specification/\n\nPrior efforts:\n- https://github.com/nikstur/bombon (CycloneDX SBOMs for Nix)\n- https://github.com/tiiuae/sbomnix (SBOM generation suite)\n- https://github.com/louib/nix2sbom (CycloneDX and SPDX from derivations)\n- https://github.com/tweag/genealogos (Nix SBOM generator)\n- https://determinate.systems/blog/determinate-secure-packages\n\n## Statix Nix Linter Improvements\n\nEffort: Small (90 hours)\n\nStatix is a linter for the Nix programming language. This project aims to continue its development, adding new lints, improving existing ones, and potentially expanding its capabilities for detecting anti-patterns and suggesting improvements in Nix code.\n\nSkills required:\n- Rust or Haskell (Statix is written in Rust)\n- Nix programming language expertise\n- Compiler/linter development\n\nPossible mentors:\n- @mightyiam\n\nDifficulty: Medium\n\nReferences:\n- https://github.com/oppiliappan/statix\n- https://discourse.nixos.org/t/statix-lints-and-suggestions-for-the-nix-programming-language/15714\n- https://discourse.nixos.org/t/list-of-nix-linters/19279\n\nSlightly progressed fork:\n- https://github.com/molybdenumsoftware/statix\n\n# Draft Ideas\n\n## Patch CVE Reference Cleanup\n\nProblem: Doesn't seem like code, more like data maintenance\n\nMany patches in nixpkgs fix CVEs but don't properly reference the CVE identifiers. This project involves auditing existing patches, identifying those that fix CVEs, and ensuring they properly reference the relevant CVE numbers. This improves the security tracking capabilities of the [Nixpkgs Security Tracker](https://tracker.security.nixos.org/).\n\nSkills required:\n- Basic Nix and nixpkgs knowledge\n- Research and documentation skills\n- Understanding of CVE identification\n\nReferences:\n- https://tracker.security.nixos.org/\n- https://vulnpatch.dev/\n\nPrior efforts:\n- https://github.com/NixOS/nixpkgs/issues/39392\n\n## Package Wrapper Metadata in Nixpkgs\n\nProblem: Unclear? How to go about this? What's the benenfit?\n\nSome packages in nixpkgs are wrappers around existing packages, but this metadata is not consistently tracked. This project would add proper metadata to identify wrapper packages and ensure the `unwrapped` attribute is consistently applied, improving package discoverability and maintenance.\n\nPossible mentors:\n- (Add yourself here!)\n\nSkills required:\n- Nixpkgs structure knowledge\n- Package evaluation understanding\n- Documentation skills\n\n## Greater usage of updateScript throughout Nixpkgs\n\nLet's make more use of the Ryan(Tm) update bot!\n\n- add updateScripts\n- add tests to existing scripts that are failing\n- create a metric to analyze existing script pass/fail/update-time"
  },
  {
    "name": "Joomla!",
    "slug": "joomla",
    "tagline": "The flexible platform empowering website creators.",
    "description": "The Joomla CMS is a PHP based application that powers about 2.2% of the web, 3.5% of all CMS based websites, as well as many intranets. Joomla has been downloaded over 119 Million times: https://downloads.joomla.org/\n\nThe Joomla project has hundreds of contributors, organized in a set of working groups and teams, and a leadership group. These are coordinated by the [Departments](https://volunteers.joomla.org/departments/ \"Joomla Departments\").\n\nJoomla is a community driven FOSS project developed and maintained by an international community encompassing over 150 countries. Joomla is used by millions of websites and web applications ranging from the hobbyist, professional web developer, to large enterprises, for both the World Wide Web and intranets.\n\nJoomla is available in 76 languages with an active and dedicated translation team\nhttps://community.joomla.org/translations/joomla-3-translations.html\n\n\nThe Joomla Project is a community effort which strives to engage contributors from diverse backgrounds and varying interests and skills in building and supporting great software together. The [mission, vision and values](https://www.joomla.org/about-joomla/the-project/mission-vision-and-values.html \"Joomla Mission vision and values\") of the Joomla Project reflect this.\n\nThe official umbrella organisation is Open Source Matters (OSM), the not for profit organization that manages financial and legal issues for the Joomla Project. A team of experienced people drawn from many areas of the project will manage the 2025 GSoC project for Joomla.",
    "ideas_url": "https://community.joomla.org/gsoc/projects-2026.html",
    "website_url": "https://www.joomla.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "mysql",
      "javascript",
      "html",
      "php",
      "ai"
    ],
    "topic_tags": [
      "web",
      "programming languages",
      "web development",
      "web applications",
      "cms"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/joomla",
    "ideas_content": "Welcome to the Joomla Google Summer of Code (GSoC) 2026 projects page. If you are interested in participating as a student, please review the materials on applying available at [Google](https://developers.google.com/open-source/gsoc/faq). We strongly encourage you to ask questions about the process and projects on our [Mattermost chat](https://joomlacommunity.cloud.mattermost.com/main/channels/gsoc-2026).\n\n\n**Project I: Ajaxified Backend**\n\n#ASYNC #Webcomponent #JavaScript\n\n**Project Description:**\n\n#### Backend actions without leaving the page\n\nSaving and other actions that return to the same page can be done with Ajax, without leaving the page and being redirected back. Challenge: make this feature as an extra, while the current system keeps working.\n\n#### Automatic Saving\n\nAutomatic saving of content while editing. Should work generally for all components. Challenge: find a solution for the interaction with versioning (not a new version for every edited character). Some Undo action would be great\n\n#### Extend filter\n\nEnhance the list filter function to support searching/filtering by custom fields.\n\n**Knowledge Prerequisite:**\n\n**Language Requisitions:**PHP, Javascript (Ajax)**Nice to have:**Webcomponents\n\n**Expected Outcome:**\n\n- List view backend actions (filter, publish, ...) are executed via Ajax and no site reload happens.\n- Automatic saving of all content in a time period (enable/disable).\n- Solutions for integration with versioning.\n\n**Difficulty:** Hard | **Project Hours:** 350 Hrs\n\n**Mentors: **Benjamin, Shivam\n\n**Project II: Automated Workflow**\n\n#Automation #PHP #JavaScript\n\n**Project Description:**\n\nFor a few years Joomla! Ships a Workflow feature and Scheduled Tasks. Now these two features should be combined, so that a user can set up assigned workflows in a way that the transitions are executed automatically offering a granular timing definition. It should be possible to create loops or straight scheduled workflows. The interface should consider a good UI, UX and modern accessibility standards\n\n**Knowledge Prerequisite:**\n\n**Language Requisitions:**PHP, JavaScript, HTML, CSS**Nice to have:**Joomla! workflow\n\n**Expected Outcome:**\n\n- A set-up area for timed workflow in categories and articles view\n- This function should be easy adaptable for any extension using the workflow\n\n**Difficulty:** Hard | **Project Hours:** 350 Hrs\n\n**Mentors:** Tushar Malik, Dileepkumar Adari\n\n**Project III: Multicategory**\n\n#PHP #Routing\n\n**Project Description: **\n\nJoomla! currently lacks the ability to assign a single item to multiple categories. While the tagging system is often used as a substitute, there is a strong demand for native multicategory support to bring Joomla! in line with other modern content management systems.\n\n**Knowledge Prerequisite:**\n\n**Language Requisitions:**PHP**Nice to have:**Joomla! 6\n\n**Expected Outcome:**\n\n- Every Item in Joomla can be connected with different categories.\n- The user must be able to connect/disconnect any item (also in batch mode) to different categories,\n- Every article must show its categories and much more.\n- For Routing reasons, there needs to be one main category defined.\n\n**Difficulty:** Medium | **Project Hours:** 175 Hrs\n\n**Mentors: **Christiane Maier-Stadtherr, Viviana\n\n**Project IV: Reinforcement Learning from Translators Feedback**\n\n#AI #LLM\n\n**Project Description:**\n\nWe are going to use automatic translations for documentation. Every language has its own Joomla specific words. We want to train Language Models with feedback from our translators, to continuously improve the quality of our translations and to incorporate the Joomla specific language properties.\n\n**Knowledge Prerequisite:**\n\n**Language Requisitions:**AI knowledge, PHP, Joomla extensions, Joomla Events, calling APIs, Machine Learning**Nice to have**: knowledge about Reinforcement Learning from Human Feedback\n\n**Expected Outcome:**\n\n- A Joomla extension package, with a complete workflow of having the initial (English) text translated in multiple languages, giving feedback by human translators and learning from that feedback.\n- This workflow is triggered by a Joomla Event when anything changes in the original, English text.\n- Per language a translator's interface for feedback. The core of this application is language independent, and must work for multiple languages.\n- The most important part of this system is the processing of the translator's feedback, so the (Joomla specific) translations will improve over time.\n\n**Difficulty:** Hard | **Project Hours:** 175 Hrs\n\n**Mentors: **Herman, Charvi"
  },
  {
    "name": "C2SI",
    "slug": "c2si",
    "tagline": "C2SI develops FOSS softwares for everyone!!!",
    "description": "The Ceylon Computer Science Institute (C2SI) conducts research in various domains, including security, artificial intelligence, mobile applications, cloud computing, and software tools. Our research aims to create computing solutions by identifying low-cost methodologies and strategies that promote sustainability. Currently, C2SI is at a pivotal stage in its evolution, having secured high donor confidence, as evidenced by multiple foreign-funded projects. The institute focuses on developing sustainable computing solutions that leverage low-cost computing and communication technologies, particularly for developing and emerging regions worldwide. We have developed several affordable and sustainable ICT solutions, with a special focus on the needs of the developing world. These solutions are briefly described in the projects section.",
    "ideas_url": "https://c2si.org/gsoc/",
    "website_url": "https://c2si.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "java",
      "go",
      "nodejs",
      "tensorflow"
    ],
    "topic_tags": [
      "security",
      "cloud",
      "ai",
      "mobile",
      "software"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/c2si",
    "ideas_content": "🚀 We’re excited to participate in GSoC for the 11th time, providing students and contributors with an opportunity to learn, collaborate, and contribute to impactful open-source projects.\n\n🌟 **Become a GSoC Contributor**\n\nAre you new to open source and looking for exciting projects to contribute to? Google Summer of Code (GSoC) is the perfect opportunity! With the guidance of experienced mentors, you’ll gain hands-on experience working on real-world projects.\n\n👉 **Why should you engage early?**\n\nIt’s very important to connect with organizations as soon as possible. The more you interact with mentors and the community before submitting your proposal, the better your chances of being selected for GSoC!\n\n🎥 Want to learn more about Google Summer of Code?\n\n🔹**Who Can Contribute?**\n\nAnyone interested is welcome to participate—whether you’re a **GSoC student, mentor, or simply passionate about open-source development!**\n\n🔹 **How to Contribute to a Project**\n\n- Select a project idea from the list below.\n- Engage with mentors and explore the project code.\n- Submit a small contribution to demonstrate your understanding.\n- Interact with mentors for feedback and improvements.\n- Prepare your proposal and submit it to Google Summer of Code.\n\n📢 Join Our Community\n\n💬 Slack: [C2SI Slack Workspace](https://c2si-org.slack.com/)\n\n📝 Proposal Template: [View Here](https://shorturl.at/dtR23)\n\n💻 Explore Our Projects: [C2SI GitHub Repository](https://github.com/c2siorg)\n\nLet’s build something great together! 🚀"
  },
  {
    "name": "openSUSE Project",
    "slug": "opensuse-project",
    "tagline": "Makers' choice for sysadmins, developers & users",
    "description": "The openSUSE Project is a worldwide effort that promotes the use of Linux, tools around it, and open source. The openSUSE community is made up of multiple contributing communities that collaborate as part of a global open-source network. The openSUSE community develops, builds and maintains many of the packages, tools and infrastructure for the distribution. The community works together in an open, transparent and friendly manner as part of the global Free and Open Source Software community. openSUSE creates one of the world's best Linux distributions, as well as a variety of tools, such as OBS, OpenQA, Kiwi, YaST, OSEM and Uyuni. Distributions include a rolling release (Tumbleweed), a stable annual release (Leap) and operating systems for edge, embedded, cloud and containers through MicroOS and ALP.\n\nThe project is controlled by its community and relies on the contributions of individuals, working as testers, writers, translators, usability experts, artists and ambassadors or developers. The project embraces a wide variety of technology, people with different levels of expertise, speaking different languages and having different cultural backgrounds.",
    "ideas_url": "https://github.com/openSUSE/mentoring/issues",
    "website_url": "https://get.opensuse.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "c/c++",
      "go",
      "ruby",
      "reactjs javascript"
    ],
    "topic_tags": [
      "AIML",
      "operating system developer tools",
      "containers kubernetes",
      "Security Cryptography",
      "systems management"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/opensuse-project",
    "ideas_content": "# Issues\n\n## Search results\n\n- Status: Open.#255 In openSUSE/mentoring;\n- Status: Open.#254 In openSUSE/mentoring;\n- Status: Open.#253 In openSUSE/mentoring;\n- Status: Open.#252 In openSUSE/mentoring;\n- Status: Open.#245 In openSUSE/mentoring;\n- Status: Open.#232 In openSUSE/mentoring;"
  },
  {
    "name": "Typelevel",
    "slug": "typelevel",
    "tagline": "We do functional programming together",
    "description": "Typelevel is an ecosystem of projects and a community of people united to foster an inclusive, welcoming, and safe environment around functional programming in Scala. We work together to develop projects that apply functional programming to challenging problems relevant in industry. Our community culture embraces curiosity and mentoring and we don't shy away from experimenting with new and exciting ideas. Most of all, we love to make programming joyful and social.",
    "ideas_url": "https://typelevel.org/gsoc/ideas.html",
    "website_url": "https://typelevel.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "linux",
      "node.js",
      "jvm",
      "scala",
      "wasm"
    ],
    "topic_tags": [
      "web",
      "functional programming",
      "cloud",
      "AI/ML",
      "cats"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/typelevel",
    "ideas_content": "# Google Summer of Code\n\nOur community has identified project ideas that we believe will significantly enhance the Typelevel ecosystem. Nothing is set in stone: we may be able to adjust a project’s length and difficulty to make it the right fit for you. So if you see something here that interests you or have an idea of your own, please [get in touch](https://typelevel.org/cdn-cgi/l/email-protection#0562766a6645717c756069607360692b6a7762)!\n\nServerless integrations for Feral\n\nFeral is a Typelevel library for building serverless functions that currently supports AWS Lambda and Google Cloud Run Functions. We want to add support for more types of serverless events and more cloud providers.\n\n**Prerequisites**\n\nScala, ideally experience with serverless\n\n**Expected Difficulty**\n\nMedium.\n\n**Expected Length**\n\nMedium (~ 175 hours)\n\n**Mentors**\n\n[@armanbilge](https://github.com/armanbilge) [@bpholt](https://github.com/bpholt) [@Chingles2404](https://github.com/Chingles2404)\n\n**Related Repositories**\n\n[feral](https://github.com/typelevel/feral)\n\nNative I/O backend for FS2 JVM\n\nFS2 on the JVM currently implements its networking API using JDK NIO. Unfortunately this indirection incurs a non-trivial performance penalty. We want to replace the use of JDK NIO with direct calls to system I/O APIs such as epoll and kqueue.\n\n**Prerequisites**\n\nScala, ability to read C\n\n**Expected Difficulty**\n\nMedium.\n\n**Expected Length**\n\nLong (~ 350 hours)\n\n**Mentors**\n\n[@antoniojimeneznieto](https://github.com/antoniojimeneznieto) [@djspiewak](https://github.com/djspiewak) [@mpilquist](https://github.com/mpilquist) [@armanbilge](https://github.com/armanbilge)\n\n**Related Repositories**\n\n[fs2](https://github.com/typelevel/fs2)\n\nFS2 Connection API\n\nTCP-based protocols are common (e.g. HTTP, Postgres, Redis) and are implemented by clients to interface with these services (e.g. Ember, Skunk, Rediculous). The goal of this project is to create a connection API that supports pooling, error conditions, and metrics and can be shared by all of our client libraries.\n\n**Prerequisites**\n\nScala, ideally some knowledge of networking\n\n**Expected Difficulty**\n\nHard.\n\n**Expected Length**\n\nLong (~ 350 hours)\n\n**Mentors**\n\n[@mpilquist](https://github.com/mpilquist) [@armanbilge](https://github.com/armanbilge)\n\n**Related Repositories**\n\n[fs2](https://github.com/typelevel/fs2)\n\nWeb Components for Calico\n\nCalico is a reactive UI library built with Cats Effect and FS2. Web Components are a standard for creating framework-agnostic, reusable UI elements. The goal of this project is to enable Calico users to access the vast array of web components available by improving its DSL and code-generation.\n\n**Prerequisites**\n\nScala, ideally experience with Web APIs\n\n**Expected Difficulty**\n\nMedium.\n\n**Expected Length**\n\nLong (~ 350 hours)\n\n**Mentors**\n\n[@armanbilge](https://github.com/armanbilge)\n\n**Related Repositories**\n\n[calico](https://github.com/armanbilge/calico)\n\nUpgrade sbt-typelevel to sbt 2\n\nsbt-typelevel is a plugin for sbt, the Scala build tool, used by hundreds of open source and enterprise projects. sbt 2 is in the final stages of development. We want to upgrade sbt-typelevel to sbt 2 and adopt its new features, such as project matrix for cross-building.\n\n**Prerequisites**\n\nScala\n\n**Expected Difficulty**\n\nMedium.\n\n**Expected Length**\n\nLong (~ 350 hours)\n\n**Mentors**\n\n[@mzuehlke](https://github.com/mzuehlke) [@armanbilge](https://github.com/armanbilge)\n\n**Related Repositories**\n\n[sbt-typelevel](https://github.com/typelevel/sbt-typelevel)\n\nRefresh Davenverse projects\n\nThe Davenverse is a collection of several popular Typelevel libraries, including Mules and cats-scalacheck. Unfortunately, we have fallen behind on their maintenance. We want to move these libraries under the Typelevel org, refresh their build tooling, and bring them up-to-date to ensure their longevity.\n\n**Prerequisites**\n\nScala\n\n**Expected Difficulty**\n\nMedium.\n\n**Expected Length**\n\nMedium (~ 175 hours)\n\n**Mentors**\n\n[@armanbilge](https://github.com/armanbilge) [@valencik](https://github.com/valencik)\n\n**Related Repositories**\n\n[davenverse](https://github.com/davenverse)\n\nCats Effect & FS2 on Wasm/WASI\n\nWeb Assembly and its System Interface are emerging technologies for deploying secure, modular applications. The goal of this project is to prototype porting the Cats Effect runtime and FS2 streaming I/O to the Wasm/WASI platform, also possibly generating feedback for the Scala WASM and WASI teams.\n\n**Prerequisites**\n\nScala, ideally some experience with Wasm/WASI\n\n**Expected Difficulty**\n\nHard. Wasm/WASI support in Scala is experimental.\n\n**Expected Length**\n\nLong (~ 350 hours)\n\n**Mentors**\n\n[@armanbilge](https://github.com/armanbilge) [@tanishiking](https://github.com/tanishiking) [@valencik](https://github.com/valencik)\n\n**Related Repositories**\n\n[cats-effect](https://github.com/typelevel/cats-effect) [fs2](https://github.com/typelevel/fs2)\n\nLaika enhancements for typelevel.org\n\nLaika is a purely functional site and e-book generator and customizable text markup transformer. We recently migrated the Typelevel website from Jekyll to Laika. The goal of this project is improve and streamline Laika's support for generating non-documentation websites, such as blogs.\n\n**Prerequisites**\n\nScala\n\n**Expected Difficulty**\n\nMedium.\n\n**Expected Length**\n\nMedium (~ 175 hours)\n\n**Mentors**\n\n[@armanbilge](https://github.com/armanbilge) [@valencik](https://github.com/valencik)\n\n**Related Repositories**\n\n[Laika](https://github.com/typelevel/Laika) [typelevel.org](https://github.com/typelevel/typelevel.github.com)\n\nA faster immutable list datatype\n\nImmutable linked lists are a core datatype in functional programming languages. The goal of this project is to explore implementing a list-like datatype with enhanced performance. Along the way, you will learn about algebraic datatypes, Cats typeclasses, and mechanical sympathy.\n\n**Prerequisites**\n\nInterest in functional programming\n\n**Expected Difficulty**\n\nMedium. This is a good project for beginners!\n\n**Expected Length**\n\nLong (~ 350 hours)\n\n**Mentors**\n\n[@armanbilge](https://github.com/armanbilge) [@johnynek](https://github.com/johnynek)\n\n**Related Repositories**\n\n[Cats Collections](https://github.com/typelevel/cats-collections)\n\nAre you interested in working on a GSoC project with mentorship from Typelevel maintainers?\n\n[Submit Proposal](https://typelevel.org/cdn-cgi/l/email-protection#6304100c0023171a13060f0615060f4d0c1104)"
  },
  {
    "name": "webpack",
    "slug": "webpack",
    "tagline": "webpack is the module bundler for web projects",
    "description": "webpack is THE build tool for modern web applications run on NodeJS\nwebpack is a module bundler. Its main purpose is to bundle JavaScript files for usage in a browser, yet it is also capable of transforming, bundling, or packaging just about any resource or asset.\n\nOverview\nCurrently in the web, modules are not fully adopted, and therefore we need tooling to help compile your module code into something that will work in the browser. webpack champions this by not only supporting CommonJS, AMD, RequireJS module systems, but also ECMAScript Modules (ESM).\n\nWhat makes webpack unique?\nExtensibility webpack is built using an extensible event-driven architecture. This means that a majority of our code is Plugins that hook into a set of lifecycle events. This means that it is infinitely flexible and configurable. This architecture also lets us pivot very quickly. Plugins isolate functionality (and can even be used in your configuration), and allow us to add and drop new functionality without breaking the rest of the system.\n\nFocused around Web Performance webpack revived a classic technique from Google Web Toolkit known as \"code splitting\". Code splitting let's developers write imperative instructions (as a part of their code), to split up their JavaScript bundles (at build time) into multiple pieces that can be loaded lazily.\n\nBuilt in JavaScript webpack's configuration format, and architecture is all built and run on NodeJS. This means that anyone comfortable with JavaScript can break open our source code with a low level of entry to learn, contribute to, and improve.\n\nUsed at Scale webpack is used by companies like AirBnB, Microsoft, Housing.com, Flipkart, Alibaba, to build high performance, scaled web applications.\n\nCommunity Owned webpack is not backed by a single organization, rather by its users, contributors, backers, sponsors, and shareholders. This means that every decision we make is for them, and them only.",
    "ideas_url": "https://docs.google.com/document/d/1Mr_IPVdbupGwmGtcvLlVqFEL8wYN_rlfHUghJ2EPBVE/edit?usp=sharing",
    "website_url": "https://webpack.js.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "javascript",
      "typescript",
      "node"
    ],
    "topic_tags": [
      "web development",
      "javascript",
      "webassembly",
      "Node.js",
      "webpack"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/webpack",
    "ideas_content": "Die Datei kann in Ihrem Browser nicht geöffnet werden, weil JavaScript nicht aktiviert ist. Aktivieren Sie JavaScript und laden Sie die Seite noch einmal.\nWebpack Google Summer of Code 2026 - Ideas List\nTab\nExtern\nFreigeben\nAnmelden\nDatei\nBearbeiten\nAnsicht\nTools\nHilfe\nBedienungshilfen\nFehlerbehebung"
  },
  {
    "name": "The NetBSD Foundation",
    "slug": "the-netbsd-foundation",
    "tagline": "Of course it runs NetBSD",
    "description": "NetBSD is a free, fast, secure, and highly portable Unix-like Open Source operating system. It is available for a wide range of platforms, from large-scale servers and powerful desktop systems to handheld and embedded devices. Its clean design and advanced features make it excellent for use in both production and research environments, and the source code is freely available under a business-friendly license. NetBSD is developed and supported by a large and vivid international community. Many applications are readily available through pkgsrc, the NetBSD Packages Collection.",
    "ideas_url": "https://wiki.NetBSD.org/projects/gsoc/",
    "website_url": "https://www.NetBSD.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "shell script",
      "make",
      "unix",
      "bsd"
    ],
    "topic_tags": [
      "kernel",
      "packaging",
      "userland",
      "unix",
      "bsd"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/the-netbsd-foundation",
    "ideas_content": "[NetBSD Wiki](https://wiki.NetBSD.org/)/\n\n[projects](https://wiki.NetBSD.org/)/ Google Summer of Code project proposals\n\nNetBSD participated successfully in the following Google's Summer of Code\nprograms (see our results of\n[2005](https://www.netbsd.org/foundation/press/soc-summary.html),\n[2006](https://www.netbsd.org/foundation/press/soc2006-summary.html),\n[2007](https://www.netbsd.org/foundation/press/soc2007-summary.html),\n[2008](https://www.netbsd.org/foundation/press/soc2008-summary.html),\n[2009](https://www.netbsd.org/foundation/press/soc2009.html),\n[2010](https://blog.netbsd.org/tnf/entry/google_summer_of_code_2010),\n[2011](https://blog.netbsd.org/tnf/entry/netbsd_s_google_summer_of),\n[2012](https://blog.netbsd.org/tnf/entry/netbsd_s_google_summer_of1),\n[2013](https://blog.netbsd.org/tnf/entry/netbsd_s_google_summer_of2),\n[2016](https://blog.netbsd.org/tnf/entry/google_summer_of_code_2016),\n[2017](https://blog.netbsd.org/tnf/entry/google_summer_of_code_2017),\n2018,\n2019,\n[2020](https://blog.netbsd.org/tnf/entry/google_summer_of_code_2020),\n2021,\n2022,\n2023,\n2024,\n2025).\n\nThis page contains a list of concrete suggestions for projects we would like to see applications for in the next Summer of Code. Note that they vary a lot in required skills and difficulty. We hope to get applications with a broad spectrum.\n\nIn addition, you may wish to discuss your proposal on IRC -- look for us on Libera.chat's #netbsd-code or for pkgsrc-related discussions, #pkgsrc. If you want to just meet the community, visit #netbsd.\n\nWe encourage you to come up with your own suggestions, if you cannot find a\nsuitable project here. You can find more project ideas on the\n[NetBSD projects page](https://wiki.NetBSD.org/)). These are not directly applicable to\nSummer-of-Code, but may serve as ideas for your own suggestions. You might\nfind other ideas in\n[src/doc/TODO](http://cvsweb.netbsd.org/bsdweb.cgi/src/doc/TODO?rev=HEAD&content-type=text/x-cvsweb-markup)\nand\n[pkgsrc/doc/TODO](http://cvsweb.netbsd.org/bsdweb.cgi/pkgsrc/doc/TODO?rev=HEAD&content-type=text/x-cvsweb-markup).\n\nDeadlines and directions for students' applications to the Google\nSummer-of-Code can be found\n[on the Google pages](https://developers.google.com/open-source/gsoc/).\n\n# Application process\n\nTo make the job of sorting out proposals and applications for NetBSD-related projects, e.g. in the Google Summer-of-Code, easier for us, there are a few questions that we would like to see answered.\n\nIf you are interested in working on any of the projects below, please\ncontact the mailing list referenced on each item, and possibly answer as\nmany questions from our [project application guidelines](https://wiki.NetBSD.org/application/) as\npossible. The interested developers will be glad to respond to you there.\n\n**Please note that Google Summer-of-Code projects are a full (day-) time job.**\n\nA positive mid-term evaluation is only possible if usable code has been committed by that time. Make sure your schedule allows for this.\n\n# Kernel-level projects\n\n## Easy\n\n## Medium\n\n## Hard\n\n# Userland projects\n\n## Easy\n\n## Medium\n\n-\n[Add UEFI boot options](https://wiki.NetBSD.org/project/Add_UEFI_boot_options/) -\n[Audio visualizer for the NetBSD base system (350h)](https://wiki.NetBSD.org/project/audioviz/) -\n[Light weight precision user level time reading (350h)](https://wiki.NetBSD.org/project/fast-time/) -\n[Query optimizer for find(1) (350h)](https://wiki.NetBSD.org/project/findoptimizer/) -\n[IKEv2 daemon for NetBSD (350h)](https://wiki.NetBSD.org/project/ikev2/) -\n[Port launchd (350h)](https://wiki.NetBSD.org/project/launchd-port/) -\n[Add support for OpenCL and Vulkan to NetBSD xsrc (175h)](https://wiki.NetBSD.org/project/mesavulkan/) -\n[Automatic tests for PAM](https://wiki.NetBSD.org/project/pam-tests/) -\n[SASL-C implementation for the OpenLDAP client (350h)](https://wiki.NetBSD.org/project/saslc_openldap/) -\n[Secure-PLT - supporting RELRO binaries (350h)](https://wiki.NetBSD.org/project/secureplt/) -\n[Research and integrate the static code analyzers with the NetBSD codebase (350h)](https://wiki.NetBSD.org/project/static-analyzers/) -\n[Sysinst alternative interface (350h)](https://wiki.NetBSD.org/project/sysinst-xinterface/)\n\n## Hard\n\n# Code Quality Improvement projects\n\n## Easy\n\n## Medium\n\n## Hard\n\n# pkgsrc projects\n\n## Easy\n\n## Medium\n\n## Hard\n\n# Other projects\n\n## Medium\n\n# Comments\n\nWe are trying to be fair; expect easy projects to require less knowledge and skill, but quite a bit of work.\n\nMedium and hard projects are hard enough to qualify as practical part of a master's thesis (it'll qualify as thesis topic if you can add sufficient quality theoretical parts). We had the honor to mentor several in past GSoCs. Talk to your adviser(s) if and how you can claim academic credit for the project you do with us.\n\nWe have not yet failed a student who worked hard and actually talked (and listened) to their mentors and the community. If unexpected roadblocks make your project goals too hard to reach in the time given, the goals can be re-negotiated. They will not be for rampant slacking, though.\n\nWhat we expect from contributors (both GSoC students and generally) is that they cooperate, that they are able to communicate (this will mean some English skills, sorry; we will try to support with mentors speaking the same contributor language if that can be a problem), and that they meet a minimum of good manners towards other people on our lists and other venues. Note that being a specific color, gender, nationality, religion, etc is not listed: If you are willing and able to contribute in a constructive manner, you are welcome."
  },
  {
    "name": "OpenWISP",
    "slug": "openwisp",
    "tagline": "The Hackable Network Management System",
    "description": "OpenWISP is an open source network management system which runs on low cost hardware and can be used to manage networks: from public wifi, university wifi, to mesh networks and IoT.",
    "ideas_url": "https://openwisp.io/docs/dev/developer/gsoc-ideas-2026.html",
    "website_url": "https://openwisp.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "django",
      "lua",
      "openwrt"
    ],
    "topic_tags": [
      "networking",
      "network management system",
      "wifi",
      "vpn",
      "sdn"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/openwisp",
    "ideas_content": "# GSoC Project Ideas 2026\n\nTip\n\nDo you want to apply with us?\n\nWe have a page that describes how to increase your chances of success.\n**Please read it carefully.**\n\n## General suggestions and warnings\n\n**Project ideas describe the goals we want to achieve but may miss details that have to be defined during the project**: we expect applicants to do their own research, propose solutions and be ready to deal with uncertainty and solve challenges that will come up during the project**Code and prototypes are preferred over detailed documents and unreliable estimates**: rather than using your time to write a very long application document, we suggest to invest in writing a prototype (which means the code may be thrown out entirely) which will help you understand the challenges of the project you want to work on; your application should refer to the prototype or other Github contributions you made to OpenWISP that show you have the capability to succeed in the project idea you are applying for.**Applicants who have either shown to have or have shown to be fast learners for the required hard and soft skills by contributing to OpenWISP have a lot more chances of being accepted**: in order to get started contributing refer to the[OpenWISP Contributing Guidelines](https://openwisp.io/contributing.html)**Get trained in the projects you want to apply for**: once applicants have completed some basic training by[contributing to OpenWISP](https://openwisp.io/contributing.html)we highly suggest to start working on some aspects of the project they are interested in applying: all projects listed this year are improvements of existing modules so these modules already have a list of open issues which can be solved as part of your advanced training. It will also be possible to complete some of the tasks listed in the project idea right now before GSoC starts. We will list some easy tasks in the project idea for this purpose.\n\n## Project Ideas\n\n### Automatic Extraction of OpenWrt Firmware Image Metadata\n\nImportant\n\nLanguages and technologies used: **Python**, **Django**, **Celery**,\n**OpenWrt**, **REST API**.\n\n**Mentors**: *Federico Capoano*, *TBA*.\n\n**Project size**: 350 hours.\n\n**Difficulty rate**: medium/hard.\n\nThis GSoC project aims to improve the user experience of [OpenWISP\nFirmware Upgrader](https://github.com/openwisp/openwisp-firmware-upgrader/issues/378) by\nautomatically extracting metadata from OpenWrt firmware images at upload\ntime.\n\nWhen uploading firmware images to OpenWISP Firmware Upgrader, users are currently required to manually provide metadata such as the image identifier, target, and board compatibility. This workflow is error prone, confusing for less experienced users, and does not scale as the number of supported images grows.\n\nRecent investigations revealed that most of the information requested from\nusers is already **present inside the firmware images**, but extracting it\nreliably requires understanding the image format, compressed kernels, and\ndevice tree structures.\n\n#### Expected outcomes\n\nIntroduce logic in OpenWISP Firmware Upgrader to automatically **extract\nmetadata from OpenWrt firmware images** upon upload, using it to pre-fill\nand validate image fields.\n\n**Initial upload**Images are flagged as\n\n**unconfirmed / draft**immediately after upload.Draft status prevents images from being used for upgrades until analysis completes successfully.\n\n\n**Automated analysis**(background Celery task)Analysis happens asynchronously in the background using Celery (we already use it heavily, so this fits right in).\n\n**Primary metadata extraction method**: OpenWrt`sysupgrade`\n\nimages already contain JSON metadata embedded by the`fwtool`\n\nutility. This metadata includes:`version.dist`\n\nand`version.version`\n\nâ OS identifier`version.target`\n\nâ target and architecture`version.board`\n\nand`supported_devices`\n\nâ board compatibilityExtraction is fast and does not require decompression.\n\nA minimal Python implementation for reference:\n\n[extract_metadata.py](https://gist.github.com/nemesifier/b5ed320f6d4ef0ef6782148b5d300c81)\n\n**Fallback method**(for images without`fwtool`\n\nmetadata, e.g., non-`sysupgrade`\n\nimages): May require kernel decompression and Device Tree Blob (DTB) extraction. See implementation notes below for details.`x86`\n\n&`armvirt`\n\n: These are disk images without`fwtool`\n\nmetadata; no board concept exists. Manual metadata input is required.Other compile targets may lack\n\n`fwtool`\n\nmetadata; more research is needed,*please include your findings in your GSoC proposal*.\n\nImages remain\n\n**unconfirmed**and invisible for upgrade operations while analysis runs.Basic file header validation should reject obviously invalid files (JPEGs, PDFs, etc.) early on.\n\n\n**Post-analysis outcomes**Images can end up in several states:\n\n**Success**: metadata extracted cleanly â mark image as**confirmed**, making it available for upgrades.**Analysis in progress**: extraction is running.**Failed - requires manual intervention**: extraction didn't work, but user can manually fill in the metadata.**Invalid**: clearly garbage file that can't possibly be a firmware image.**Manually confirmed**: user overrode auto-extracted data (we need this because sometimes our extraction might be wrong and users will be annoyed if they can't fix it).For failures:\n\nFile is clearly invalid/garbage â reject immediately if possible with a fast validation error. Otherwise, discard in the background and notify the user with a\n\n`generic_notification`\n\n.Image format is new or unsupported â notify via\n\n`generic_notification`\n\nand allow manual intervention via admin UI or REST API (fill metadata or delete/reupload).Out-of-memory during decompression â notify user, explain they may need to increase memory limits and reupload.\n\n\nGray-area failures (partial extraction, multiple boards detected) fall under scenario 2.\n\n\n\nWarning\n\nMetadata should be editable until the image is confirmed or paired with devices. After that, it becomes read-only - otherwise things break and it's too painful to handle all the edge cases.\n\n**Other constraints**Test coverage\n\n**must not decrease**, tests must follow the specs described in the*\"Testing strategy\"*section below.Documentation needs to be updated to account for this feature, including updating any existing screenshots that may change the look of the UI after implementation.\n\nOnce the project is completed, we will need a short example usage video for YouTube that we can showcase on the website/documentation.\n\n\n\n#### Build-level status\n\nSince builds are collections of images, we should add a status field to builds too:\n\nA build shouldn't be usable for mass upgrades until\n\n**all**its images have completed metadata extraction.The admin list view should show the status for builds so users know what's ready to use.\n\n**Dynamic status**: If new images are added to a build later (via admin or API), the build status should change back to \"analyzing\".**Completion notification**: When analysis completes for a build (all images done), send the user a`generic_notification`\n\nwith a link to the build page. Clicking the notification should take them straight to the updated build so they can see the results and take action if needed.\n\n#### Safety rules\n\nSystem must prevent using unconfirmed images for single or batch upgrades.\n\nSystem must prevent launching batch upgrades for builds where metadata extraction hasn't completed.\n\nSystem must not pair unconfirmed images with devices (existing or new) based on OS identifier and hardware model.\n\nOnce an image is confirmed, the existing auto-pairing mechanism kicks in.\n\n\n#### Implementation notes\n\n**Primary extraction method:** Firmware images built with OpenWrt's build\nsystem already contain JSON metadata embedded via the `fwtool`\n\nutility.\nThis has been standard practice for years and is present in all\n`sysupgrade`\n\nimages, including custom builds. The metadata can be\nextracted quickly without decompression. A minimal Python implementation\ndemonstrating this approach is available for reference:\n[extract_metadata.py](https://gist.github.com/nemesifier/b5ed320f6d4ef0ef6782148b5d300c81).\n\n**Fallback extraction method:** For images without `fwtool`\n\nmetadata\n(non-`sysupgrade`\n\nimages, `x86`\n\n/ `armvirt`\n\ndisk images, or edge\ncases), extraction may require decompressing the kernel and extracting the\nDevice Tree Blob (DTB). Contributors should research established tools and\ntechniques for this (e.g., kernel decompression, `binwalk`\n\nfor DTB\nlocation) rather than reinventing solutions. The specific implementation\ndetails are left to the contributor's research.\n\n**Memory management:** While `fwtool`\n\nmetadata extraction does not\nrequire decompression, fallback methods might. For cases requiring\ndecompression:\n\nMake memory limits configurable with reasonable defaults.\n\nHandle out of memory errors in the background task and notify users via\n\n`generic_notification`\n\n.Implement limits on max decompression output size to prevent zip bomb-style attacks.\n\n\n**Timeouts:** Use the same task timeouts we already use for firmware\nupgrades.\n\n**Retries:** Probably not worth auto-retrying failed extractions - if it\nfails once, it'll likely fail again. Users can just upload again if it was\na transient issue.\n\n**Task crashes:** Treat as failure, notify user, fallback to manual\nintervention.\n\n**Extensibility**: the mechanism for extracting metadata varies across\noperating systems.\n\nAlthough OpenWISP currently focuses exclusively on OpenWrt, it also manages devices running OpenWrt derivatives which can have varying degrees of difference with the standard OpenWrt source code.\n\nTo handle these differences, this module uses the concept of an **Upgrader\nClass**. Therefore, the logic described here should be implemented in a\nsimilar object-oriented structure, allowing for customization, extension,\nor complete override if needed. Each upgrader class must have a related\nmetadata extraction class.\n\n#### Benefits\n\nUsers cannot accidentally upgrade devices with invalid images.\n\nPartial or malformed uploads are quarantined safely.\n\nMetadata extraction improves incrementally without impacting system safety.\n\nEliminates the need to maintain a hard-coded list of supported devices (\n\n`hardware.py`\n\n).Simplifies end-user experience significantly.\n\n\n#### Testing strategy\n\nWe need to test this with real firmware images, but we can't bloat the repo:\n\nTest one firmware image for each supported type.\n\nStore images on\n\n`downloads.openwisp.io`\n\n(public HTTP access) with checksums stored in the repo for security.Integration tests download and cache images; only re-download if checksum changes.\n\nDirectory structure is an open question - anything reasonable works.\n\nWe can use official OpenWrt builds for testing; maintainers will upload them to\n\n`downloads.openwisp.io`\n\n.\n\n#### Additional context and research findings\n\n**``fwtool`` metadata**: OpenWrt has embedded JSON metadata in`sysupgrade`\n\nimages for years via the`fwtool`\n\nutility. This metadata is reliable and contains all essential information (OS identifier, target, board, supported devices).**``sysupgrade`` vs disk images**: Only`sysupgrade`\n\nimages contain`fwtool`\n\nmetadata.`x86`\n\nand`armvirt`\n\nimages are disk images and lack this metadata. Contributors should investigate whether other compile targets produce disk images.`/etc/board.json`\n\nand`/tmp/sysinfo/*`\n\nare runtime generated and not present in firmware images.For embedded targets without\n\n`fwtool`\n\nmetadata, the**only authoritative board identity**pre-installation is the DTB in the kernel.`x86`\n\nis a fundamental exception: no board concept exists, images are target wide.`rootfs`\n\nimages (`*-squashfs-rootfs.img`\n\n) are**not suitable for upgrades**and should not be treated as fully valid.A draft/unconfirmed workflow ensures the system remains safe while extraction runs or fails.\n\nThe issue containing design and implementation notes is available at:\n\n[#378](https://github.com/openwisp/openwisp-firmware-upgrader/issues/378).\n\n#### Downsides and challenges\n\nComplexity in handling all existing firmware image types across supported OSes.\n\nRequires robust handling of compressed kernels, DTB extraction, and image format edge cases.\n\nOut of scope for small projects; needs dedicated effort and assistance from an OpenWrt expert.\n\nSecurity: while only network admins can upload images currently (so we trust the user), we should add basic protections like file header validation and decompression limits.\n\n\n#### Open questions for contributors\n\n**Non-``sysupgrade`` images**: How should we handle images without`fwtool`\n\nmetadata (`x86`\n\n,`armvirt`\n\ndisk images, and potentially other targets)? Are there other compile targets that produce disk images instead of`sysupgrade`\n\nimages? What is the best approach for these cases?**Manual override workflow**: Design the complete admin UI flow for when extraction fails. What does the user see? How do they enter metadata manually? How do we validate their input?**Cross-version compatibility**: OpenWrt versions from 18.06 to 24.10 may have different metadata formats. How do we handle this? Should we detect the version and adjust extraction logic?**Downloading fw images for testing**: Best practices for downloading test images: part of test setup or separate command? How to handle caching efficiently?**Decompression limits**: For fallback methods requiring decompression, what's a reasonable default for maximum decompressed size? How do we detect compression bombs early?**Status UI**: What should the admin interface look like for showing analysis status? Status badges? Progress indicators? How do we communicate \"this image is being analyzed\" vs \"this needs your attention\"?**Error granularity**: How detailed should failure messages be? Technical details for admins vs. user-friendly summaries?**Derivatives and non OpenWrt firmware**: How do you intend to structure the code so that each Upgrader Class has its own metadata extraction logic?\n\n#### Prerequisites to work on this project\n\nApplicants must demonstrate a solid understanding of:\n\n**Python**,**Django**, and**JavaScript**.REST APIs and background task processing (Celery).\n\nOpenWrt image formats and basic Linux tooling.\n\nExperience with\n\n[OpenWISP Firmware Upgrader](https://github.com/openwisp/openwisp-firmware-upgrader)is essential. Contributions or resolved issues in this repository are considered strong evidence of the required proficiency.\n\n### WiFi Login Pages Modernization\n\nImportant\n\nLanguages and technologies used: **JavaScript**, **Node.js**,\n**React**.\n\n**Mentors**: *Federico Capoano*, *Gagan Deep*.\n\n**Project size**: 175 hours (medium).\n\n**Difficulty rate**: medium.\n\nThis project aims to modernize the [OpenWISP WiFi Login Pages](https://github.com/openwisp/openwisp-wifi-login-pages) application,\nwhich provides splash page functionality for WiFi hotspot networks. The\nfocus is on codebase improvements, architectural refactoring, dependency\nupgrades, and new features to enhance maintainability and user experience.\n\nAll refactoring work should maintain backward compatibility, since users interact with the application through their browsers, these internal code changes should be transparent to them.\n\n#### Key Objectives\n\n##### Code Refactoring and Architecture Improvements\n\nThe following structural improvements will enhance code maintainability and reduce technical debt:\n\n**Refactor status component to simplify logic and improve maintainability**([#918](https://github.com/openwisp/openwisp-wifi-login-pages/issues/918))The status component in\n\n`client/components/status/status.js`\n\nhas grown to handle multiple responsibilities including authentication, verification, payment, session management, captive portal logic, and UI rendering. This makes the codebase difficult to understand and maintain, increases the risk of bugs, and makes testing more difficult. The component should be refactored to separate concerns and improve maintainability.**Move redirect logic from OrganizationWrapper to each component**([#272](https://github.com/openwisp/openwisp-wifi-login-pages/issues/272))Currently, redirection logic is defined in the OrganizationWrapper component, which is re-rendered every time\n\n`setLoading()`\n\nis called. This causes multiple unnecessary HTTP requests and potential issues with external redirects (e.g., payment gateways). The redirect logic should be moved to individual components where it belongs, making OrganizationWrapper leaner.**Eliminate redundancy of header HTML**([#314](https://github.com/openwisp/openwisp-wifi-login-pages/issues/314))The header HTML is duplicated with separate desktop and mobile versions. This redundancy makes customization painful as it requires double the work. The header should be refactored to use a single HTML structure with responsive CSS to handle different screen sizes.\n\n**Add support for captive-portal API**([#947](https://github.com/openwisp/openwisp-wifi-login-pages/issues/947))Modern captive portals support\n\n[RFC 8908 Captive Portal API](https://datatracker.ietf.org/doc/html/rfc8908). This feature should be implemented as an optional feature (turned off by default) that adds support for:Checking if captive portal login is required\n\nDetecting \"internet-mode\" status\n\nConfigurable timeout (default 2 seconds) per organization\n\nConfigurable API URL per organization via YAML configuration\n\nProper documentation of the feature\n\nFallback to existing internet mode feature for browsers/devices without Captive Portal API support\n\n\n**Upgrade to latest version of React**([#870](https://github.com/openwisp/openwisp-wifi-login-pages/issues/870))Upgrade the application from its current React version to React 19. Contributors should research whether to perform the upgrade before or in parallel with refactoring tasks, considering that upgrading first may enable modern patterns but could introduce breaking changes. The upgrade involves:\n\nUpgrading to React 18.3 first to identify deprecation warnings\n\nRunning official React 19 codemods for automated refactoring\n\nUpdating all React-related dependencies (react-dom, react-router, react-redux, etc.)\n\nMigrating away from Enzyme (deprecated) to React Testing Library (RTL). Contributors should propose a migration strategy that balances thoroughness with contributor workload, whether to migrate all tests at once or incrementally alongside the React upgrade.\n\nEnsuring all dependencies are compatible with React 19\n\nComprehensive testing to catch regressions\n\n\n\n#### Prerequisites to work on this project\n\nApplicants must demonstrate a solid understanding of:\n\n**JavaScript**(ES6+) and modern frontend development practices.**React**components, hooks, state management, and testing.**Node.js**and npm/yarn package management.Experience with\n\n[OpenWISP WiFi Login Pages](https://github.com/openwisp/openwisp-wifi-login-pages)is essential. Contributions or resolved issues in this repository are considered strong evidence of the required proficiency.\n\n#### Implementation Approach\n\nEach task should be delivered as a separate pull request (one PR per task), following standard OpenWISP practices. This enables incremental review and reduces risk.\n\n##### Testing Strategy\n\nTesting should follow these guidelines:\n\nTDD (Test-Driven Development) is recommended but not mandatory, use judgment based on the specific task.\n\nTest coverage levels for refactored components should not decrease from current levels.\n\nFor the captive-portal API feature, mocked tests are acceptable.\n\nBrowser support follows the existing\n\n`browserslist`\n\nnpm package configuration covering major browsers.\n\n#### Expected Outcomes\n\nA refactored, more maintainable status component with clear separation of concerns.\n\nRedirect logic moved from OrganizationWrapper to individual components.\n\nA unified header component using responsive CSS instead of duplicated HTML.\n\nImplementation of RFC 8908 Captive Portal API support as an optional, configurable feature per organization (via YAML configuration).\n\nSuccessfully upgraded React to version 19 with all dependencies updated and Enzyme replaced by React Testing Library.\n\nComprehensive automated tests covering refactored components and new features. Test coverage should be maintained at current levels.\n\nUpdated documentation, including:\n\nMigration guide for the React upgrade.\n\nUsage instructions for the new captive-portal API feature.\n\nA short example usage video for YouTube that we can showcase on the website.\n\n\n\n### Mass Commands\n\nImportant\n\nLanguages and technologies used: **Python**, **Django**,\n**JavaScript**, **WebSockets**, **REST API**.\n\n**Mentors**: *Gagan Deep*, *Purhan Kaushik*, *Kapil Bansal*.\n\n**Project size**: 350 hours.\n\n**Difficulty rate**: medium.\n\nThis project idea aims to extend OpenWISP's remote device management capabilities by enabling users to execute shell commands on multiple devices simultaneously. Currently, OpenWISP supports executing commands on a single device at a time. This project will introduce a bulk execution feature while maintaining the existing security, rules, and limitations of the single-device command execution feature.\n\nThe mass command operation will be accessible from two main entry points:\n\nAn admin action on the device list page, allowing users to select multiple devices and send a shell command in bulk.\n\nA dedicated mass command admin section, where users can initiate bulk command execution with various targeting options:\n\nAll devices in the system (restricted to superusers).\n\nAll devices within a specific organization.\n\nAll devices within a specific device group.\n\nAll devices within a specific geographic location.\n\nSpecific selected devices.\n\n\n\nThe UI will guide users step-by-step, dynamically displaying relevant fields based on the selected target scope. For example, if a user selects \"All devices in a specific organization\", an auto-complete list of organizations will be displayed next.\n\nThe system will provide real-time tracking of command execution results. Inspired by OpenWISP Firmware Upgrader's mass upgrade feature, the UI will receive live updates via WebSockets, displaying command output as soon as it is received from the devices. Additionally:\n\nThe device detail page will show executed commands under the \"Recent Commands\" tab.\n\nCommands that were part of a mass operation will be clearly marked, with a link to the corresponding mass command operation page.\n\n\nTo support API-based management, the REST API will be extended with the following capabilities:\n\nCreate new mass command operations.\n\nRetrieve mass command operations and their results (with pagination).\n\nDelete mass command operations.\n\nModify the single-shell command API to reference the mass command operation ID if applicable.\n\n\n#### Prerequisites to work on this project\n\nApplicants must demonstrate a solid understanding of Python, Django, HTML,\nCSS, JavaScript, WebSockets, and [OpenWISP Controller](https://github.com/openwisp/openwisp-controller).\n\n#### Expected outcomes\n\nImplementation of mass shell command execution in OpenWISP, replicating the rules and limitations of single-device execution.\n\nDevelopment of an intuitive UI with the Django admin for selecting devices and tracking command results in real-time.\n\nAdmin action for device list page.\n\nEnhancement of the device detail page to reflect mass command history for individual devices.\n\nExtension of the REST API to support mass command operations.\n\nComprehensive automated tests covering the new feature.\n\nUpdated documentation, including:\n\nFeature description with usage instructions.\n\nA short example usage video for YouTube that we can showcase on the website.\n\n\n\n### X.509 Certificate Generator Templates\n\nImportant\n\nLanguages and technologies used: **Python**, **Django**,\n**JavaScript**.\n\n**Mentors**: *Federico Capoano*, *Aryaman*, *Nitesh Sinha*.\n\n**Project size**: 175 hours.\n\n**Difficulty rate**: medium.\n\nThis GSoC project aims to enhance OpenWISP's certificate management capabilities by enabling the generation of x509 certificates for general-purpose use, beyond OpenVPN.\n\nCurrently, OpenWISP supports generating x509 certificates exclusively for OpenVPN clients, where each VPN client template produces a certificate signed by the CA linked to the corresponding VPN server. However, many users require x509 certificates for other purposes, such as securing web services, internal APIs, or device authentication outside of VPN usage.\n\nThe proposed solution introduces a new certificate template type that\nallows users to generate x509 certificates using a selected Certificate\nAuthority (CA), while fully reusing the existing certificate\ninfrastructure provided by `django-x509`\n\n.\n\n#### Certificate template model and scope\n\nThe new template type will reference an existing x509 certificate object, which acts as a reusable blueprint for certificate generation.\n\nThe relation to the certificate object is optional:\n\nIf a certificate template is specified, its non-unique properties are copied when generating per-device certificates\n\nIf no certificate template is specified, certificate properties default to the selected CA's standard settings\n\n\nThe referenced certificate object is never issued or assigned to devices directly and is used exclusively as a template.\n\nNo custom certificate profile system will be introduced. Only fields\nalready supported by `django-x509`\n\nmay be used.\n\n#### Device property integration\n\nCertificates generated from templates shall include device specific properties resolved at generation time.\n\nSupported device properties include:\n\nDevice hostname\n\nDevice MAC address\n\nDevice UUID\n\n\nThese values may be included in:\n\nStandard subject fields supported by\n\n`django-x509`\n\n, the hostname in particular shall be used as common nameCustom x509 extensions stored in the existing\n\n`extensions`\n\nJSON field, using private OIDs\n\nDevice properties are resolved only when a template is assigned to a device.\n\nCertificates are automatically regenerated if the device's hostname or MAC\naddress fields are modified. This behavior must be explicitly stated in\nthe documentation; additionally, a UI notification of type\n`generic_message`\n\nmust be triggered once the regeneration process is\ncomplete.\n\n#### Certificate lifecycle and ownership\n\nCertificates are generated when a certificate template is assigned to a device, following the same lifecycle semantics as existing OpenVPN client certificates.\n\nAssignment generates a new certificate\n\nUnassignment deletes the certificate\n\nRenewal regenerates the certificate\n\nNo standalone certificates are generated without device assignment\n\n\nCertificates are always associated with a CA, and revocation is handled through the CA's existing Certificate Revocation List (CRL) mechanism. No additional revocation logic will be introduced.\n\n#### Storage, access, and security model\n\nPrivate keys and certificates are stored and protected using the existing\n`django-x509`\n\nmechanisms.\n\nThis project will not introduce:\n\nNew encryption schemes\n\nNew private key download endpoints\n\nNew permission models\n\n\nExisting OpenWISP access controls and organization scoping rules apply.\n\n#### Configuration management integration\n\nCertificate details will be exposed to OpenWISP's configuration management system as template variables, including:\n\nCertificate (PEM)\n\nPrivate key (PEM)\n\nCertificate UUID\n\n\nVariable names will follow a UUID-based namespace to ensure uniqueness and avoid conflicts with existing OpenWISP variables.\n\nCertificate renewal triggers cache invalidation and configuration updates to affected devices. No configuration updates are triggered unless a certificate is renewed or regenerated.\n\n#### API and admin interface\n\nThe new certificate template type will be available through:\n\nDjango admin\n\nExisting REST API template endpoints\n\n\nNo new API endpoints will be introduced. Existing RBAC and organization scoping rules will apply.\n\n#### Testing and documentation\n\nThe project requires:\n\nAutomated tests covering certificate generation and lifecycle behavior\n\nAdmin UI integration tests\n\nAPI tests\n\nSelenium browser tests\n\nShort video demonstration\n\n\nDocumentation updates include:\n\nA dedicated documentation page describing certificate templates\n\nStep-by-step usage instructions\n\nClear explanation of supported options and limitations\n\n\n#### Out of scope\n\nThe following items are explicitly out of scope for this project:\n\nSubject Alternative Name (SAN) support\n\nOCSP integration\n\nAutomated public CA issuance (e.g. Let's Encrypt)\n\nCustom cryptographic policy engines\n\nChanges to existing OpenVPN certificate behavior\n\n\n#### Prerequisites to work on this project\n\nApplicants must demonstrate a solid understanding of Python, Django, and JavaScript.\n\nExperience with [OpenWISP Controller](https://github.com/openwisp/openwisp-controller) and [django-x509](https://github.com/openwisp/django-x509) is essential. Contributions\nor resolved issues in these repositories are considered strong evidence of\nthe required proficiency.\n\n### Add more timeseries database clients to OpenWISP Monitoring\n\nImportant\n\nLanguages and technologies used: **Python**, **Django**, **InfluxDB**,\n**Elasticsearch**.\n\n**Mentors**: *Gagan Deep*, *Aryaman*, *Sankalp*.\n\n**Project size**: 350 hours.\n\n**Difficulty rate**: medium.\n\nThe goal of this project is to add more Time Series DB options to OpenWISP while keeping good maintainability.\n\n#### Prerequisites to work on this project\n\nThe applicant must demonstrate good understanding of [OpenWISP Monitoring](https://github.com/openwisp/openwisp-monitoring#openwisp-monitoring),\nand demonstrate basic knowledge of [NetJSON format](https://netjson.org/), **InfluxDB** and **Elasticsearch**.\n\n#### Expected outcomes\n\nComplete the support to\n\n[Elasticsearch](https://github.com/elastic/elasticsearch).[Support to Elasticsearch was added in 2020](https://github.com/openwisp/openwisp-monitoring/pull/164)but was not completed.The old pull request has to be updated on the current code base\n\nThe merge conflicts have to be resolved\n\nAll the tests must pass, new tests for new charts and metrics added to\n\n*InfluxDB*must be added (see[[feature] Chart mobile (LTE/5G/UMTS/GSM) signal strength #270](https://github.com/openwisp/openwisp-monitoring/pull/294))The usage shall be documented, we must make sure there's at least one dedicated CI build for\n\n**Elasticsearch**We must allow to install and use\n\n**Elasticsearch**instead of**InfluxDB**from[ansible-openwisp2](https://github.com/openwisp/ansible-openwisp2)and[docker-openwisp](https://github.com/openwisp/docker-openwisp/)The requests to Elasticsearch shall be optimized as described in\n\n[[timeseries] Optimize elasticsearch #168](https://github.com/openwisp/openwisp-monitoring/issues/168).\n\n[Add support for InfluxDB 2.0](https://github.com/openwisp/openwisp-monitoring/issues/274)as a new timeseries backend, this way we can support both`InfluxDB <= 1.8`\n\nand`InfluxDB >= 2.0`\n\n.All the automated tests for\n\n**InfluxDB 1.8**must be replicated and must passThe usage and setup shall be documented\n\nWe must make sure there's at least one dedicated CI build for Elasticsearch\n\nWe must allow choosing between\n\n**InfluxDB 1.8**and**InfluxDB 2.0**from[ansible-openwisp2](https://github.com/openwisp/ansible-openwisp2)and[docker-openwisp](https://github.com/openwisp/docker-openwisp/).\n\n\n### OpenWISP VPN Deployer Linux Package\n\nImportant\n\nLanguages and technologies used: **Linux**, **Python**, **Django**,\n**WebSockets**, **OpenVPN**, **WireGuard**, **WireGuard over VXLAN**,\n**ZeroTier**.\n\n**Mentors:** *Federico Capoano*, *Gagan Deep*, *Oliver Kraitschy*.\n\n**Project size:** 350 hours.\n\n**Difficulty level:** medium/hard.\n\nThis GSoC project aims to simplify the deployment and management of VPN servers integrated with OpenWISP.\n\nThe goal is to develop an easy-to-install program that automates the deployment of VPN servers synchronized with OpenWISP in real time. This reduces manual intervention and ensures configuration consistency between the VPN server objects in the OpenWISP database and the deployed VPN instances.\n\n#### Key Features\n\nThe program will run on Linux-based servers and will:\n\nBe implemented in\n\n**Python**to ensure maintainability and extensibility, it should be a Python package installable via`pip`\n\n.Use a\n\n**Makefile**to generate installation packages for major Linux distributions:**DEB**(for Debian, Ubuntu, and related distributions)**RPM**(for Red Hat, Fedora, and similar systems)\n\nProvide\n\n**Docker support**to run the VPN deployer as a containerized service, enabling easy deployment alongside docker-openwisp. We suggest running the deployer and VPN server(s) within the same container to keep the architecture simple, using host networking mode. Configuration management could be achieved via a configuration file (YAML is recommended for readability) mountable into the container. Contributors should verify these suggestions through research and propose the most suitable approach for their implementation.Establish a\n\n**WebSocket connection**with OpenWISP to listen for changes in VPN server configurations and synchronize local settings accordingly. The connection should handle reconnection automatically. We suggest retrying WebSocket connections indefinitely and using exponential backoff for HTTP requests, but contributors should propose a robust reconnection strategy.Keep the local list of peers updated whenever VPN clients are added, removed, or modified.\n\nReceive\n\n**real-time updates**via WebSocket when certificate revocation occurs, ensuring the**Certificate Revocation List (CRL)**is always current. The deployer needs to handle OpenVPN server reload when CRL updates are received. Initial research indicates that OpenVPN does not automatically reload CRL files when they change, and that sending a`SIGUSR1`\n\nsignal to the OpenVPN process may reload the CRL without disconnecting existing clients. Contributors must verify this approach and propose the best solution based on their findings.Support the following VPN tunneling technologies (in order of implementation priority):\n\n**OpenVPN**(most complex due to CRL requirements)**WireGuard****ZeroTier****WireGuard over VXLAN**(VXLAN part is tricky)\n\nProvide a\n\n**command-line utility**to simplify the initial setup. This utility will:Guide users step by step, making it accessible even to those with limited experience.\n\nSupport\n\n**non-interactive/scripted mode**for automation and Docker deployments (minimal implementation).Allow users to select the VPN technology to be deployed.\n\nVerify that the necessary system packages are installed and provide clear warnings if dependencies are missing. We suggest maintaining a mapping of required packages per distribution and VPN technology, as package names vary between Linux distributions (e.g., Debian\n\n`openvpn`\n\nvs. RHEL`openvpn`\n\n), but contributors should propose their approach.Store configuration in a YAML configuration file (mountable in Docker environments). Other formats may be considered if justified.\n\nAssist in securely connecting and synchronizing with OpenWISP.\n\nNote\n\nThe command-line utility must apply all necessary changes in the OpenWISP database via the\n\n**REST API**. If any required modifications cannot be performed with the current API, the contributor will be responsible for implementing the missing functionality.To facilitate authentication, the utility will\n\n[guide users in retrieving their OpenWISP REST API token](https://github.com/openwisp/openwisp-users/issues/240). A proposed approach is to provide a link to the OpenWISP admin interface, where users can generate and copy their API token easily. The WebSocket connection should authenticate using this API token.\n\n\nSupport running\n\n**multiple instances**, where each instance manages a separate VPN server independently. Each instance could be identified by a dedicated configuration file or other suitable mechanism.Implement\n\n**structured logging**with dedicated log files for each instance, adhering to Linux logging best practices and supporting log rotation.Provide\n\n**comprehensive documentation**in ReStructuredText format, following OpenWISP conventions:Documentation will be stored in a\n\n`/docs`\n\ndirectory, with a clear separation between user guides and developer documentation.A\n\n**video demonstration**will be included, which can be published on YouTube to increase project visibility.\n\nUpdate the\n\n**OpenWISP documentation**to cover installation, configuration, and best practices.To support this project,\n\n**OpenWISP Controller**will need to be updated as follows:Expose a\n\n**WebSocket endpoint**to allow the VPN synchronization program to receive real-time configuration updates.**Automatically include the Certificate Revocation List (CRL)**in generated OpenVPN server configurations. The CRL content should be provided as a configuration variable (e.g.,`crl_content`\n\n, similar to x509 certificates), eliminating the need for manual CRL file management. The CRL file path should be determined as part of the implementation. When certificates are revoked, the system must trigger WebSocket notifications to connected VPN deployer instances to ensure immediate CRL updates. Additionally, the deployer should periodically poll the CRL checksum via HTTP API as a redundancy measure.Define a\n\n**permission model**for the VPN deployer: the deployer requires a dedicated user account with organization manager role and permissions to add/change VPN servers within that organization.\n\n\n#### Prerequisites to work on this project\n\nApplicants should have a solid understanding of:\n\n**Python**and**Django**.**WebSockets**.Experience with\n\n[OpenWISP Controller](https://github.com/openwisp/openwisp-controller)is essential. Experience with[django-x509](https://github.com/openwisp/django-x509)[netjsonconfig](https://github.com/openwisp/netjsonconfig)is considered as a strong favorable point. Contributions in these repositories are considered strong evidence of the required proficiency.At least one of the supported VPN technologies (\n\n**OpenVPN, WireGuard, WireGuard over VXLAN, ZeroTier**).**System administration and Linux packaging**(preferred but not required).\n\n#### Expected Outcomes\n\nA Python-based VPN synchronization tool.\n\nA command-line setup utility for easy first-time configuration.\n\nWebSocket-based synchronization between VPN servers and OpenWISP.\n\nAutomated packaging for major Linux distributions (\n\n**DEB**and**RPM**).**Docker support**for running the VPN deployer as a containerized service, including integration with docker-openwisp.Structured logging with proper log rotation.\n\nEnhancements to\n\n**OpenWISP Controller**:Support for WebSocket-based synchronization.\n\nAutomatic inclusion of\n\n**Certificate Revocation List (CRL)**in OpenVPN server configurations with variable-based CRL content.WebSocket notifications triggered when certificates are revoked.\n\nAny required REST API modifications.\n\n\nAutomated tests to ensure reliability and stability:\n\n**Unit tests**with mocks for both openwisp-controller and VPN server interactions to enable fast development and testing of individual components.**Integration tests**using real openwisp-controller and VPN server instances to test core functionality: installation, configuration synchronization, and basic VPN server health checks. While initially minimal, these provide reliability and establish a foundation for expanded integration testing as the project matures and sees wider adoption.\n\nComprehensive\n\n**documentation**, including setup guides and best practices.A\n\n**short tutorial video**demonstrating installation and usage.\n\n### Persistent & Scheduled Firmware Upgrades\n\nImportant\n\nLanguages and technologies used: **Python**, **Django**, **Celery**,\n**REST API**, **JavaScript**.\n\n**Mentors**: *Federico Capoano*, *TBA*.\n\n**Project size**: 350 hours.\n\n**Difficulty rate**: medium.\n\nThis project aims to enhance [OpenWISP Firmware Upgrader](https://github.com/openwisp/openwisp-firmware-upgrader) with two\ncomplementary features that improve reliability and operational\nflexibility for mass firmware upgrades: **persistent retries** for offline\ndevices ([#379](https://github.com/openwisp/openwisp-firmware-upgrader/issues/379))\nand **scheduled execution** for planned maintenance windows ([#380](https://github.com/openwisp/openwisp-firmware-upgrader/issues/380)).\n\nCurrently, firmware upgrades in OpenWISP happen immediately via Celery tasks. If a device is offline at the moment of upgrade, the task fails and requires manual retry. In large deployments, this becomes unmanageable. Additionally, network operators need the ability to schedule upgrades during low-usage windows without manual intervention at execution time.\n\n#### Expected outcomes\n\nIntroduce support for **persistent mass upgrades** that automatically\nretry for offline devices and **scheduled mass upgrades** that execute at\na user-defined future time.\n\n**Persistent mass upgrades**([#379](https://github.com/openwisp/openwisp-firmware-upgrader/issues/379))Mass upgrade operations should be able to retry indefinitely for devices that are offline at the initial execution time.\n\nAdd a\n\n`persistent`\n\nboolean field to mass upgrade operations (visible in admin and REST API, checked by default, immutable after creation).Track retry count and scheduled retry time in the\n\n`UpgradeOperation`\n\nmodel.Implement\n\n**device online detection**:Prefer using the\n\n`health_status_changed`\n\nsignal from OpenWISP Monitoring (with mocking for testing).Fallback: periodic retries with randomized exponential backoff (configurable, max once every 12 hours).\n\n\nImplement\n\n**retry strategy**:Randomized exponential backoff with indefinite retries.\n\nPeriodic reminders (default every 2 months) via\n\n`generic_notification`\n\nto admins about devices still pending upgrade, with links filtering pending devices.Continue until admin cancels or all devices are upgraded.\n\n\n**Integration with Celery**: Use a new Celery task to \"wake up\" pending upgrades, with randomized delays to prevent system overload.**Failure handling**: Use`generic_notification`\n\nfor failures requiring attention (devices offline too long, upgrade errors).**Edge cases**: Handle concurrent signal triggers, ensure only one upgrade per device, no rollback support needed.\n\n**Scheduled mass upgrades**([#380](https://github.com/openwisp/openwisp-firmware-upgrader/issues/380))Allow users to schedule mass upgrades for future execution.\n\n**UI**: Add optional datetime scheduling on mass upgrade confirmation page. Default is immediate execution unless a future datetime is set.**Validation**: Scheduled datetime must be:In the future\n\nRespect minimum delay (e.g., 10 minutes)\n\nNot exceed maximum horizon (e.g., 6 months)\n\n\n**Timezone handling**: User input in browser timezone, storage in UTC, server timezone clearly indicated in UI.**Status model**: Extend to include`scheduled`\n\nstate with transitions: scheduled â running, scheduled â canceled, scheduled â failed.**Execution model**: Use Celery Beat periodic task (every minute) to scan and execute due upgrades.**Avoid Celery eta/countdown**for reliability with far-future tasks.**Runtime validation**: Re-evaluate devices, permissions, firmware availability at execution time. Cancel with error if all targets become invalid.**Conflict prevention**: Prevent creating conflicting mass upgrades (scheduled or immediate) when one is already pending.**Notifications**: Send`generic_notification`\n\nwhen scheduled upgrades start and complete.\n\n**Combined features**Scheduled upgrades should also support persistence. A scheduled upgrade that starts but has offline devices should continue retrying according to the persistence logic.\n\n**General requirements**Operations editable only while in\n\n`scheduled`\n\nstatus.Clear exposure of scheduled status and datetime in admin list, detail view, and REST API.\n\nFull feature parity between Django admin and REST API.\n\n\n**Testing and documentation**Test coverage\n\n**must not decrease**from current levels.**Browser tests**for the scheduling UI and admin interface workflows are required.Documentation has to be kept up to date, including:\n\nUsage instructions for persistent and scheduled upgrades.\n\nUpdated screenshots reflecting UI changes.\n\nOne short example usage video per each feature.\n\n\n\n\n#### Prerequisites to work on this project\n\nApplicants must demonstrate a solid understanding of:\n\n**Python**,**Django**, and**JavaScript**.REST APIs and background task processing (Celery, Celery Beat).\n\nTimezone handling and datetime management.\n\nExperience with\n\n[OpenWISP Firmware Upgrader](https://github.com/openwisp/openwisp-firmware-upgrader)is essential. Contributions or resolved issues in this repository are considered strong evidence of the required proficiency.\n\n#### Open questions for contributors\n\n**Persistence implementation**: What is the optimal database schema for tracking persistent upgrade state while maintaining compatibility with existing upgrade operation models?**Scheduling mechanism**: How exactly should the Celery Beat periodic task be configured to reliably detect and execute due scheduled upgrades without performance issues?**Timezone UX**: What is the best way to handle timezone display and input in the admin interface to minimize user confusion?**Backoff strategy**: What are the optimal parameters for randomized exponential backoff (initial delay, max delay, randomization factor)?**Conflict detection**: How should conflicting operations be detected and prevented? What defines a \"conflict\"?**Monitoring integration**: How exactly should the`health_status_changed`\n\nsignal from OpenWISP Monitoring be integrated for optimal online detection?**Notification frequency**: What are the optimal default periods for reminder notifications about pending persistent upgrades?**Edge case handling**: How should edge cases be handled, such as devices that are offline for months, or mass upgrades with very large device counts?\n\n### Resource Aware Priority Task Scheduling for OpenWISP\n\nImportant\n\nLanguages and technologies used: **Python**, **Django**, **Celery**,\n**gevent**.\n\n**Mentors**: *Federico Capoano*, *TBA*.\n\n**Project size**: 350 hours.\n\n**Difficulty rate**: medium/hard.\n\nThis project aims to improve task execution in OpenWISP Monitoring by implementing resource-aware priority scheduling and migrating I/O-bound tasks to gevent for better concurrency.\n\nThe deliverable is a reusable Python package for priority scheduling that benefits the entire Celery ecosystem, plus OpenWISP Monitoring running efficiently with gevent.\n\n#### Problem Statement\n\nOpenWISP currently runs multiple Celery workers, typically assigning one worker per queue. This approach ensures that high priority operations such as network management tasks are not blocked by lower priority workloads like monitoring or housekeeping. However, this architecture introduces several challenges:\n\nDeployment complexity increases due to multiple workers and queue assignments.\n\nScaling requires manual tuning of worker concurrency (\n\n`--autoscale=X,Y`\n\nvalues must be guessed).Small deployments waste resources because workers may remain idle.\n\nLarge deployments require predicting capacity in advance.\n\nNo automatic adjustment based on actual system resources (CPU, memory).\n\nWith the constant growth of networks, users need OpenWISP to be able to manage more devices with the same resources.\n\n\n**OpenWISP Monitoring specifically** performs thousands of I/O-bound tasks\n(ping checks, HTTP requests, device polling) that could benefit from high\nconcurrency via gevent, but currently uses blocking operations (`fping`\n\n)\nthat prevent this.\n\nThe project will create a resource and priority aware scheduler that works well in OpenWISP with the gevent/thread execution pools.\n\n#### Project Goals\n\nThe contributor will design and implement a scheduling system with the following capabilities:\n\n**Priority Aware Scheduling**Reserve guaranteed execution capacity for high-priority tasks.\n\nAllow lower-priority tasks to use unused reserved capacity.\n\nPrevent starvation: every priority tier gets execution slots.\n\nProvide configurable priority classes (e.g., critical, high, normal, low).\n\n\n**Resource Aware Autoscaling**Dynamically adjust worker concurrency based on CPU and memory usage.\n\nMaintain configurable resource headroom (e.g., keep 20% CPU free).\n\nEliminate need for administrators to guess\n\n`--autoscale`\n\nvalues.Learn average resource consumption per task over time.\n\n\n**Standalone Reusable Package**We'll create a new repository:\n\n`celery-elastic-priority`\n\n(or similar name) which will be a standalone Python package.It must work with both gevent (most common for I/O-bound tasks) and thread (this is what we currently use now) execution pools.\n\nDocument extension points for other pools (future work).\n\nPublish to PyPI with comprehensive documentation.\n\n\n**OpenWISP Monitoring Migration to gevent**Replace blocking operations (\n\n`fping`\n\n) with gevent-compatible alternatives (`icmplib`\n\n).Migrate monitoring tasks to run with gevent pool.\n\nConfigure two workers: one gevent (monitoring tasks) + one thread (blocking operations if needed).\n\nDemonstrate resource-aware priority scheduling in production use.\n\n\n\n**Note**: The project accepts that some tasks may require thread pool. The\ngoal is to maximize gevent usage for I/O-bound monitoring tasks, not to\nforce everything into a single worker.\n\n#### Inspiration\n\nPart of this project is inspired by [celery-resource-autoscaler](https://github.com/jcushman/celery-resource-autoscaler/), which\ndemonstrated that resource-based autoscaling works in practice. That\nproject has been abandoned and needs modernization for Celery 5.x+.\n\nThe contributor needs to:\n\nStudy the resource monitoring approach from celery-resource-autoscaler\n\nTest if the core concept still works with modern Celery (5.3+)\n\nIdentify what integration points (bootsteps, signals) are stable\n\nImplement priority-aware capacity reservation (the novel contribution)\n\n\n#### Technical Constraints\n\nThe solution should:\n\n**Primary focus**: gevent pool (OpenWISP Monitoring's I/O-bound workload)**Use stable Celery APIs**: bootsteps, signals, documented extension points**Accept pool-specific code**: Being gevent-specific is acceptable for a production-quality implementation**Document extension points**: Show how the design could be adapted to thread/`prefork`\n\npools (documentation only, not implementation)**Remain maintainable**: Target Celery 5.3+ compatibility, test across versions**GIL Consideration**: Since gevent is single-threaded, the contributor must identify the \"diminishing returns\" point where adding more concurrency stops improving throughput.\n\n**Realistic Expectation**: Some Celery internals will need to be used. The\ngoal is to minimize reliance on undocumented/unstable APIs, not to avoid\ninternals entirely.\n\n#### Proposed Architecture\n\nThis is research-driven engineering. The technical approach is unknown and must be validated by the contributor.\n\nThe document contains proposed solutions (e.g., `icmplib`\n\nfor ping,\nspecific architecture patterns). These are examples, not the expected\nfinal approach. Contributors are expected to challenge assumptions,\nvalidate feasibility with experiments, and propose better alternatives if\nevidence supports them.\n\nChoosing the right architecture based on evidence is part of the deliverable.\n\nThe system consists of three components:\n\n```\nBroker â Worker â Priority Scheduler â Gevent Pool\nâ\nResource Monitor\n```\n\n\n**Component 1: Resource Monitor**\n\nTracks system resources and calculates safe worker capacity. Includes an optional hard cap for production deployments:\n\n```\nclass ResourceMonitor:\ndef __init__(self, max_cpu_percent=80, max_memory_percent=85, max_concurrency=None):\nself.max_cpu = max_cpu_percent\nself.max_memory = max_memory_percent\nself.max_concurrency = max_concurrency # Optional hard cap for production\ndef get_available_capacity(self):\n\"\"\"Returns how many additional workers can be spawned\"\"\"\ncurrent_cpu = psutil.cpu_percent()\ncurrent_memory = psutil.virtual_memory().percent\n# Calculate headroom and convert to worker count\navailable = self.calculate_safe_workers(\ncpu_headroom=self.max_cpu - current_cpu,\nmem_headroom=self.max_memory - current_memory,\n)\n# Apply hard cap if configured\nif self.max_concurrency is not None:\navailable = min(available, self.max_concurrency)\nreturn available\n```\n\n\n**Component 2: Resource Autoscaler**\n\nDynamically adjusts total worker concurrency:\n\n```\nclass ResourceAutoscaler:\ndef adjust_concurrency(self):\navailable = self.monitor.get_available_capacity()\npending = self.get_pending_task_count()\nif pending > 0 and available > 10:\nself.scale_up(workers_to_add=min(available, pending // 2))\nelif self.utilization < 0.3:\nself.scale_down()\n```\n\n\n**Component 3: Priority Scheduler**\n\nAllocates workers across priority tiers:\n\n```\nclass PriorityScheduler:\ndef __init__(self, priorities, total_concurrency):\n# priorities = {'critical': 20%, 'high': 30%, ...}\nself.pools = self._create_priority_pools(total_concurrency)\ndef execute_task(self, task):\npriority = self._get_task_priority(task)\npool = self.pools[priority]\nreturn pool.spawn(task)\ndef adjust_to_new_total(self, new_total):\n# Called when autoscaler changes capacity\nfor priority, config in self.priorities.items():\nnew_size = int(new_total * config[\"reserve_percent\"] / 100)\nself.pools[priority].maxsize = new_size\n```\n\n\nThe contributor will research the best integration approach (bootsteps, custom consumer, worker hooks) during the community bonding period and document the decision.\n\n#### Migrating OpenWISP Monitoring to gevent\n\nRunning Celery with gevent provides high concurrency for I/O-bound tasks but introduces several challenges that must be addressed.\n\n##### Common Pitfalls for gevent + Celery + Django\n\n**1. Monkey-patching Order**\n\nMust patch before importing Django/other libraries.\n\nUse\n\n`celery worker --pool=gevent`\n\n(Celery handles patching automatically).Patching too late causes random blocking behavior.\n\n\n**2. Database Connection Handling**\n\nDjango's persistent connections (\n\n`CONN_MAX_AGE > 0`\n\n) + gevent can cause deadlocks.`greenlets`\n\nshare the same thread, confusing Django's thread-local connections.**Django 5.1+ with PostgreSQL**: It seems that`psycopg3`\n\nwith native connection pooling is the recommended solution. This only works with PostgreSQL and it does NOT work with`psycopg2`\n\n, MySQL, SQLite, or other backends.**Solution for other databases or earlier Django**: Set`CONN_MAX_AGE=0`\n\nor use a gevent-aware connection pool.\n\n**3. Blocking Operations**\n\nFile I/O on slow filesystems (NFS, network drives) still blocks.\n\n`subprocess`\n\ncalls block unless using gevent-compatible methods.**OpenWISP Monitoring specific**:`fping`\n\nsubprocess calls block`greenlets`\n\n.\n\n##### Replacing fping with gevent-compatible ICMP\n\nThe monitoring module currently uses `fping`\n\nfor network checks. This\nmust be replaced with a gevent-compatible alternative. The `icmplib`\n\nlibrary provides non-privileged ping capabilities:\n\n```\nfrom gevent import monkey\nmonkey.patch_all()\nimport gevent\nfrom icmplib import ping\ndef ping_host(host):\n# Uses ICMP datagram sockets (no root required)\nresult = ping(host, count=10, interval=0.2, privileged=False)\nreturn {\"host\": host, \"avg_rtt\": result.avg_rtt, \"packet_loss\": result.packet_loss}\n# Concurrent pings with gevent\nhosts = [\"192.168.1.1\", \"10.0.0.1\"]\njobs = [gevent.spawn(ping_host, host) for host in hosts]\ngevent.joinall(jobs)\nresults = [job.value for job in jobs]\n```\n\n\n**System Configuration**: Using `icmplib`\n\nwith `privileged=False`\n\nrequires one-time `sysctl`\n\nconfiguration:\n\n```\n# Allow unprivileged ICMP sockets\nsudo sysctl -w net.ipv4.ping_group_range=\"0 2147483647\"\n# Make persistent in /etc/sysctl.conf\nnet.ipv4.ping_group_range = 0 2147483647\n```\n\n\nThe contributor should verify this works reliably with gevent and provides equivalent functionality to fping.\n\n#### Expected Outcomes\n\nThe project will deliver working implementations across multiple repositories:\n\n**Core Package: celery-elastic-priority**\n\nStandalone Python package published to PyPI.\n\nResource monitor, autoscaler, and priority scheduler components.\n\n95%+ test coverage.\n\nComprehensive documentation (API reference, examples, migration guide).\n\nCI/CD with automated testing using the last 2 stable Celery versions available.\n\nDesign document explaining architecture decisions.\n\n\n**OpenWISP Monitoring**\n\nReplace\n\n`fping`\n\nwith`icmplib`\n\nfor ping checks.Ensure all monitoring tasks are gevent-compatible.\n\nConfiguration for gevent worker with priority scheduling.\n\n**All existing tests must pass**, coverage must not decrease.Documentation updates for gevent deployment.\n\n\n**Ansible Role: ansible-openwisp2**\n\nConfigure two workers:\n\nWorker 1: gevent pool for monitoring tasks (with priority scheduling)\n\nWorker 2: thread pool for any remaining blocking tasks (if needed)\n\n\nTask routing configuration separating gevent-safe vs blocking tasks.\n\nDocumentation for the new deployment approach.\n\n**All existing tests must pass**.\n\n**Benchmarking & Analysis**\n\nPerformance comparison: multi-worker vs priority-scheduled workers.\n\nResource utilization measurements (CPU, memory, task throughput).\n\ngevent vs thread pool performance for monitoring workloads.\n\nAnalysis of trade-offs and limitations (documented in design doc).\n\n\n**Documentation & Media**\n\nDesign document produced after initial research (community bonding).\n\nUpdated documentation across affected repositories.\n\nShort demo video (5-10 minutes) for YouTube/blog.\n\n\n**General Requirements**\n\n**Test Coverage**: All new code must have tests. Existing tests must continue to pass. Target 95%+ coverage for new package.**Documentation**: All changes must be documented.**Code Quality**: Follow OpenWISP coding standards.**Communication**: Daily progress updates, active participation in community discussions, responsive to mentor feedback.**Video Demo**: Once completed, create 5-10 minute demo video for YouTube showing the system working and explaining benefits.\n\n#### Success Criteria (Measurable)\n\nThe project aims to meet these observable capabilities:\n\n**Priority Scheduling**\n\nHigh-priority tasks should have better latency than lower-priority tasks under load.\n\nReserved capacity is configurable per priority tier.\n\nNo starvation: Every priority tier receives execution capacity under normal load.\n\n\n**Resource Autoscaling**\n\nWorker concurrency adjusts automatically based on CPU and memory usage.\n\nSystem maintains configured resource headroom.\n\n\n**OpenWISP Monitoring with gevent**\n\nMonitoring tasks run successfully with gevent pool.\n\nRemaining blocking tasks use thread pool worker.\n\nPing checks provide comparable results to the current implementation.\n\n\n**Package Quality**\n\nTest coverage:\n\n**95%+**.Documentation: API reference, quickstart, migration guide.\n\nCompatibility: Works with Celery 5.3+ and Python 3.9+.\n\nPublished to PyPI with automated CI/CD.\n\n\n**Performance Benchmarks**\n\nMeasure resource utilization (CPU, memory, task throughput).\n\nCompare gevent vs thread pool performance for monitoring tasks.\n\nDocument findings in design document.\n\n\n#### Midterm Pass Conditions\n\nMidterm passes only if the contributor delivers:\n\n**Working Prototype**: A working prototype demonstrating priority scheduling and gevent compatibility.**OpenWISP Monitoring Changes**: Changes to openwisp-monitoring to support gevent (e.g., replacing`fping`\n\nwith`icmplib`\n\n).**Ansible Role Changes**: Changes to ansible-openwisp2 to deploy the new work done up to now in staging, which will help us to test it and validate it.\n\n#### Project Approach\n\nThe project follows an iterative approach with clear checkpoints:\n\n**Research Phase (Community Bonding)**\n\nFinalize architecture decisions\n\nBuild proof-of-concept\n\nGet mentor approval to proceed\n\n**Checkpoint**: Design document + working PoC code\n\n**Implementation Phase (Coding Period)**\n\nSee [Midterm Pass Conditions](https://openwisp.io#midterm-pass-conditions) and [Success Criteria (Measurable)](https://openwisp.io#success-criteria) for\ndetailed requirements.\n\n#### Prerequisites to Work on This Project\n\nApplicants must demonstrate solid understanding of:\n\n**Python**(decorators, context managers, async concepts).**Django**and database connection handling.**Celery**(tasks, workers, pools, routing).**gevent**or similar`greenlet`\n\n-based concurrency.**OpenWISP Monitoring**module (at least basic familiarity).\n\n**Strong Evidence of Required Proficiency**:\n\nPrior contributions to OpenWISP repositories (especially openwisp-monitoring).\n\nDemonstrated understanding of concurrent programming (portfolio/projects).\n\nPast contributions in projects which made use of background queues and concurrency.\n\n\n**Application Requirements**:\n\nPropose specific technical approach for priority scheduling integration.\n\nDemonstrate understanding of gevent pitfalls and solutions.\n\nInclude preliminary research on the open questions listed above.\n\nShow examples of prior work with Celery, Django, or concurrent systems.\n\n\n#### Open Questions for Contributors\n\nDuring the application and community bonding phases, contributors should research and propose solutions for:\n\n**Monitoring Tasks Inventory**: Create complete list of blocking vs non-blocking operations in openwisp-monitoring. Are there any tasks besides fping that need thread pool?**Integration Strategy**: Should priority scheduling use Celery bootsteps, custom consumer, worker middleware, or a combination? What are the trade-offs for maintainability and stability?**Dynamic Pool Resizing**: What is the safest way to resize gevent pools at runtime? How does this interact with Celery's prefetch behavior?**Capacity Borrowing**: Should lower-priority tasks be allowed to temporarily use high-priority reserved capacity when idle? If so, how to implement safely without breaking guarantees?**Task Priority Assignment**: How should tasks declare their priority? Custom task headers, routing keys, task decorators, or configuration?**Database Connection Limits**: How will the Priority Scheduler detect and handle database connection exhaustion? Should the autoscaler scale down or pause when connections are near the limit?\n\nContributors should include preliminary research on these questions in their application to demonstrate understanding of the problem space."
  },
  {
    "name": "NumFOCUS",
    "slug": "numfocus",
    "tagline": "NumFOCUS promotes open source scientific software.",
    "description": "NumFOCUS supports and promotes world-class, innovative, open source scientific software. Most individual projects, even the wildly successful ones, find the overhead of a non-profit to be too large for their community to bear. NumFOCUS provides a critical service as an umbrella organization for this projects.",
    "ideas_url": "https://github.com/numfocus/gsoc/blob/master/2026/ideas-list.md",
    "website_url": "https://numfocus.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "c++",
      "r",
      "julia"
    ],
    "topic_tags": [
      "data science",
      "graphics",
      "ai",
      "scientific computing",
      "numerical computation"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/numfocus",
    "ideas_content": "# Ideas Pages\n\nThis is the home page of projects ideas of NumFOCUS for Google Summer of Code 2026.\nSince NumFOCUS is an umbrella organization you will only find links to the ideas\npage of each organization under the NumFOCUS umbrella at this page.\n\n- [AiiDA](https://github.com/aiidateam/aiida-core/wiki/GSoC-2026-Projects)\n- [ArviZ](https://github.com/arviz-devs/arviz/wiki/GSoC-2026-projects)\n- [CVXPY](https://github.com/cvxpy/GSOC)\n- [Data Retriever](https://github.com/weecology/retriever/wiki/GSoC-2026-Project-Ideas)\n- [gammapy](https://github.com/gammapy/gammapy/wiki/GSoC-2026-Project)\n- [GRASS](https://grasswiki.osgeo.org/wiki/GRASS_GSoC_Ideas_2026)\n- [HoloViz](https://github.com/holoviz/holoviz/wiki/2026-GSoC-Project-List)\n- [Gridap](https://github.com/gridap/GSoC/blob/main/2026/ideas-list.md)\n- [JuMP](https://github.com/jump-dev/GSOC)\n- [matplotlib](https://github.com/matplotlib/matplotlib/wiki/Matplotlib-GSoC-2026-Ideas)\n- [pvlib](https://github.com/pvlib/pvlib-python/wiki/GSoC-2026-Projects)\n- [PyMC](https://github.com/pymc-devs/pymc/wiki/GSoC-2026-projects)\n- [PySAL](https://github.com/pysal/pysal/wiki/Google-Summer-of-Code-2026)\n- [QuTiP](https://github.com/qutip/qutip/wiki//Google-Summer-of-Code-current)\n- [scikit-bio](https://github.com/scikit-bio/scikit-bio/wiki/GSOC-2026-project-ideas)\n- [SciML](https://sciml.ai/dev/#google_summer_of_code)\n- [Stan](https://github.com/stan-dev/stan/wiki/GSOC-2026-Proposed-Projects)\n- [sbi](https://github.com/sbi-dev/sbi/wiki/GSoC%E2%80%902026%E2%80%90Projects)\n- [toqito](https://github.com/vprusso/toqito/wiki/GSoC-2026-Projects)\n- [pytorch-ignite](https://github.com/pytorch/ignite/wiki/GSoC-2026-project-idea)\n  \n<!-- Be transparent about AI tool usage\n\n- [ArviZ](https://github.com/arviz-devs/arviz/wiki/GsoC-2025-projects)\n- [conda / rattler](https://github.com/conda/rattler/issues/1058)\n- [DISCOVER Cookbook](https://github.com/numfocus/DISCOVER-Cookbook/discussions/208)\n- [igraph](https://github.com/igraph/igraph/wiki/Mentored-Projects)\n- [matplotlib](https://matplotlib.org/devdocs/devel/contribute.html#restrictions-on-generative-ai-usage)\n- [mlpack](https://github.com/mlpack/mlpack/wiki/SummerOfCodeIdeas)\n- [NetworkX](https://networkx.org/documentation/latest/developer/projects.html)\n- [Open2C](https://github.com/open2c/open2c.github.io/wiki/GSoC-2025)\n- [optimagic](https://github.com/optimagic-dev/optimagic/discussions/559)\n- [PyBaMM](https://pybamm.org/gsoc/2025/)\n- [sbi](https://github.com/sbi-dev/sbi/wiki/GSoC_2025_Projects)\n- [SciML](https://sciml.ai/dev/#google_summer_of_code)\n- [TNL](https://gitlab.com/tnl-project/tnl/-/wikis/GSoC-2025)\n- [Zarr](https://github.com/zarr-developers/gsoc/blob/main/2025/ideas-list.md)\n\n-->\n\nSee the [README](https://github.com/numfocus/gsoc/blob/master/README.md#organizations-confirmed-under-numfocus-umbrella) for contact information of each org."
  },
  {
    "name": "Internet Archive",
    "slug": "internet-archive",
    "tagline": "Universal Access to All Knowledge",
    "description": "The Internet Archive is a non-profit digital library.\n\nWe are the home of the Wayback Machine.",
    "ideas_url": "https://docs.google.com/document/d/1EjzrHVapOZuzdI_Qqd_ravaTgiDWnxlMRbjjbzfd_-I/edit?tab=t.0",
    "website_url": "http://archive.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "go",
      "elasticsearch",
      "hadoop"
    ],
    "topic_tags": [
      "library",
      "media",
      "archiving"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/internet-archive",
    "ideas_content": "Die Datei kann in Ihrem Browser nicht geöffnet werden, weil JavaScript nicht aktiviert ist. Aktivieren Sie JavaScript und laden Sie die Seite noch einmal.\nInternet Archive - Google Summer of Code 2026 - Call For Proposals (CFP)\nTab\nExtern\nFreigeben\nAnmelden\nDatei\nBearbeiten\nAnsicht\nTools\nHilfe\nBedienungshilfen\nFehlerbehebung"
  },
  {
    "name": "OpenStreetMap",
    "slug": "openstreetmap",
    "tagline": "Create and distribute free geodata for the world",
    "description": "OpenStreetMap is a crowdsourcing project that creates and distributes free geographic data for the world. Our data is collected by hundreds of thousands of contributors around the globe and released with an open-content license. We allow free access not only to our map products, but all the underlying map data, which powers websites and apps used by billions of people worldwide.\n\nOSM data can be freely used in both open and closed source software, and has attracted many commercial users. Still, the success of OSM wouldn't be possible without open source software and volunteer developers. The database, website and API running on our own servers, the editing tools used by contributors to improve the map, and many of the most popular libraries and end-user applications within the OSM software ecosystem are all open source software, and developed through a community-driven process.\n\nAs our Google Summer of Code participation spans this diverse set of software projects, most of which are maintained as independent efforts under the OSM umbrella, contributors will encounter a wide range of programming languages, paradigms and use cases. We hope that we have interesting challenges to offer for any developer, no matter their background!",
    "ideas_url": "https://wiki.openstreetmap.org/wiki/Google_Summer_of_Code/2026/Project_ideas",
    "website_url": "https://www.openstreetmap.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "c++",
      "docker",
      "glTF"
    ],
    "topic_tags": [
      "databases",
      "web",
      "routing",
      "ui",
      "geodata"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/openstreetmap",
    "ideas_content": "# Google Summer of Code/2026/Project ideas\n\n[Jump to navigation](https://wiki.openstreetmap.org#mw-head)\n\n[Jump to search](https://wiki.openstreetmap.org#searchInput)\n\nThis page lists a number of ideas for **potential Google Summer of Code 2026 projects**. This page's primary purpose is to help to give potential applicants ideas that they can build on to turn into applications for the program. Members of the OSM developer community are encouraged to identify ideas for projects, and indicate whether they would be willing to act as a mentor for a GSoC contributor attempting the project, using the\n\n[GSoC idea template](https://wiki.openstreetmap.org/wiki/Template:GSoC_idea).\n\n## Note on using AI tools\n\nWe recognize that generative AI tools like ChatGPT or Copilot can be a tremendous help when writing code and project proposal texts. However, always keep in mind that they are only tools. They cannot do the work for you. In that spirit, you are welcome to use generative AI tools when preparing your application and during GSoC but you must always ensure that you have read, understood and verified the output. Do not copy and paste ChatGPT answers without thoroughly rereading what it has said. We expect that you will be able to answer questions about the content at any time. Furthermore, *when you use generative AI, you must mention the tool(s) you used*.\n\n## Participant project ideas\n\nGSoC contributors can base their application on one of the ideas below, but we also encourage potential GSOC contributors to come up with their own ideas for projects around OpenStreetMap software. Do you have a pet annoyance you want fixed? A feature you think should be implemented? If you believe you are capable of implementing it and it fits within the time constraints and the GSOC eligibility criteria feel free to bring the idea forward.\n\nPlease get in touch with the organizers (at gsoc-orga@openstreetmap.org) as soon as possible if you want to work on something not listed here, so that we can make sure you get the best support possible. We would suggest supplying the same information as in the templates below, if you don't have a potential mentor it may be possible for us to find one for you.\n\n## Searching\n\n|\nSuggested By\nSummary\nLast year we've introduced the concept of categories\nMandatory skills\nPython, basic SQL\nUseful skills\nsome knowledge of Lua\nLength\n350 hours\nDifficulty\nchallenging\nPossible Mentors\nNotes\nThe goal of this project to prepare the database structure and processing chain to work with the category concepts.\nComments\nPlease also see the general hints for contributing to Nominatim for GSOC at\n|\n\n|\nSuggested By\nSummary\nImporting the full OpenStreetMap planet into a Nominatim database takes 3 days by now. This is getting too long. In this project we want to explore some possible changes to how the\nSkills\nPython, basic SQL\nLength\n350 hours\nDifficulty\nchallenging\nPossible Mentors\nNotes\nThe two main changes I have in mind here: A) Currently the main placex table has a column with the marker what needs to be updated. This means that the table is written more often than necessary. We should move the TODO list in a separate table. B) Indexing is parallelized in a way that the parallel processors all need to write to the same tables getting in each others way. We should distribute the data, so that write contentions is less likely.\nComments\nPlease also see the general hints for contributing to Nominatim for GSOC at\n|\n\n\n\n## Routing\n\n|\nSuggested By\nSimonPoole (simon at osmfoundation.org)\nSummary\nclosures.osm.ch was started in GSoC 2025, this year we want to integrate it more closely with at least one routing application and tie up some of the remaining loose ends (see the github repo).\nMandatory skills\npython, docker, routing algorithms and knowledge of the implementation language of the target routing app.\nUseful skills\nPractical experience using OSM data and contributing.\nLength\n350 hours\nDifficulty\nmedium\nPossible Mentors\nSimonPoole\nNotes\nOnly applications that fulfill our minimum requirements will be accepted.\n|\n\n|\nSuggested By\nChristian Beiwinkel / Valhalla Community\nSummary\nWe are currently introducing a multi-modal costing called \"auto_walk\" which combines vehicle and pedestrian routing: directions for driving to the nearest parking lot, followed by walking directions to the destination. This project aims to parse, store and use parking lot data in OSM to mark parking opportunities in the graph.\nMandatory skills\nC++, basic SQL\nUseful skills\nLua\nLength\n350 hours\nDifficulty\nchallenging\nPossible Mentors\nKevin Kreiser, Nils Nolde, Christian Beiwinkel\nNotes\nI'll write a lengthier issue about this in the upcoming days, in the meantime there is [this discussion](\n|\n\n|\nSuggested By\nNils Nolde\nSummary\nWe introduced a landmark/POI-based guidance concept (e.g. \"Turn right after 50 m before the next Wells Fargo branch\") in a previous GSoC. However, it's not ready yet to be hosted on the\nMandatory skills\nC++, basic sqlite\nUseful skills\nLua\nLength\n175 hours\nDifficulty\nmedium (for someone with decent C++ skills)\nPossible Mentors\nKevin Kreiser, Nils Nolde, Christian Beiwinkel\nNotes\nProfiling the current POI ingestion performance to pinpoint improvable performance sinks and debugging the code will be part of the project.\n|\n\n|\nSuggested By\nNils Nolde\nSummary\nWe (re-)introduced public transit routing based on GTFS (only for now) in a previous GSoC. However, it's not ready yet to be hosted on the\nSkills\nC++\nLength\n350 hours\nDifficulty\nchallenging\nPossible Mentors\nKevin Kreiser, Nils Nolde, Christian Beiwinkel\nNotes\nThis project needs a pretty strong and curious C++ developer.\n|\n\n|\nSuggested By\nKevin Kreiser\nSummary\nPedestrian routing is becoming increasingly important in modern applications with the tendency toward walkable cities and the rise of alternative navigation modalities such as wearables. This project aims to improve a user's ability to follow a given pedestrian route by enhancing the metadata attached to it. One of the main challenges that arises in pedestrian navigation is the lack attribution for pedestrian only ways. Sidewalks don't have names, park pathways, similarly, don't have names. While we can still give guidance in these situation it is more ambiguous, eg. \"turn left\". Landmark routing can certainly mitigate these scenarios but its coverage can also be lacking. This project focuses on improving the situation by enhancing the data in the graph by spatially joining metadata from nearby OSM features to the part of the graph where pedestrian attribution is lacking. This may be done by eg. copying road names to unnamed sidewalks that abut them, or by eg. marking nodes as park entrances where area features intersect.\nMandatory skills\nC++\nUseful skills\nspatial/geometric operations\nLength\n175 hours\nDifficulty\nmedium\nPossible Mentors\nKevin Kreiser, Nils Nolde, Christian Beiwinkel\nNotes\nThis is an open ended project in the sense that we may discover better opportunities for improvement during investigation and pivot to working on those instead of those already mentioned examples above.\n|\n\n## Rendering\n\n|\nSuggested By\nMike Barry\nSummary\nPlanetiler is a tool that converts OpenStreetMap data to vector tiles that can be used with web-based mapping libraries like MapLibre GL. There are a few full-featured profiles written in Java with industry-wide adoption like\nMandatory skills\nJava\nUseful skills\nExperience with Java and API design. Familiarity with frontend development and intrepreters a plus.\nRequired experience\nIntermediate experience with Java\nLength\n350 hours\nDifficulty\nmedium\nPossible Mentors\nNotes\nPhases: (1) allow adding layers from a yaml config to any planetiler profile (2) config-driven feature and attribute filtering (3) convert maplibre style(s) to a filter config\n(3) builds on (1) and (2) and will unlock new workflows where users can iterate on a style against a \"raw\" tileset then \"publish\" optimized tiles from it by generating a new tileset using the style as a filter.\n|\n\n|\nSuggested By\nFrank Elsinga / MapLibre Community\nSummary\nCurrent benchmarks for tile servers compare \"apples to oranges\" (e.g., cached vs. uncached responses) or rely on outdated, static snapshots.\nThis leads to misinformation where users choose a server based on theoretical maximums rather than their specific constraints (memory vs. CPU vs. latency). This project aims to build the Tileserver Tradeoff Observatory: an automated system that runs nightly \"Performance Labs\" in CI. Instead of a simple \"speed test,\" this suite will isolate and visualize specific architectural tradeoffs that a user can choose (e.g., PostGIS vs. PMTiles vs MBTiles, gzip vs. brotli overhead). The results will be published to a self-regenerating \"Living Whitepaper\" website that educates users on how to configure their tileserver for their specific needs.Mandatory skills\n- Docker & Scripting to set up the isolated test environments\n- Frontend dev to write a nice dashboard providing insights into the tradeoffs\nUseful skills\nBasic knowledge of statistics\nRequired experience\nIntermediate to advanced. Prior experience with web development, scripting and good benchmarking is required.\nLength\n350h\nDifficulty\nMedium(Requires systems thinking to ensure benchmarks are scientifically valid and reproducible in a noisy CI environment)\nPossible Mentors\nNotes\nExisting state of the art to build upon:\n|\n\n|\nSuggested By\nFrank Elsinga / MapLibre Community\nSummary\nAdd first-class DuckDB support to Martin using DuckDB’s spatial extension and native\n`ST_AsMVT` / `ST_AsMVTGeom` functions. This enables efficient vector tile serving directly from analytical, file-based datasets such as GeoParquet/Flatgeobuf, without requiring PostGIS. The project focuses on a clean integration with Martin’s core architecture, useful feature parity with the transactional PostGIS backend, and clear guidance on when an analytical DuckDB backend is the right choice.Mandatory skills\nWillingness to learn and dive into the rust geospatial ecosystem\nUseful skills\n- Rust programming skills\n- SQL knowledge\n- Familiarity with geospatial concepts (CRS, tiling, MVT)\n- Ability to read and extend existing backend code\n- Writing tests and technical documentation\nRequired experience\nIntermediate to advanced. Prior experience with Rust backends or spatial databases is recommended, but not required.\nLength\n350h(Full GSoC project (medium to large scope))\nDifficulty\nMedium(Requires understanding Martin’s internal architecture, spatial SQL, and performance trade-offs between analytical and transactional databases.)\nPossible Mentors\nNotes\nInitial focus is on GeoParquet-backed DuckDB databases. Support for additional DuckDB file formats is intentionally limited to keep maintenance costs low and performance predictable. Maybe other formats make sense too to add via this, like GeoArrow or Flatgeobuf.\nComments\nThe project emphasizes useful feature parity rather than full PostGIS compatibility. Design quality, documentation, and tests are as important as raw functionality.\n|\n\n## Editing\n\n|\nSuggested By\nBryce Cogswell (bryceco)\nSummary\nGo Map!! is an iPhone app used to edit OpenStreetMap in the field. The iD desktop editor has a robust set of validation functions that warn mappers when they create or modify an object in a way that is inconsistent with best practices. This project would migrate the logic used by iD (written in JavaScript) to Go Map!! (written in Swift, and with a very different architecture).\nMandatory skills\nSwift, some UIKit.\nUseful skills\nJavaScript\nLength\n175 hours\nDifficulty\nmedium\nPossible Mentors\nbryceco\nNotes\nThis project requires a Mac, with development using Xcode.\nComments\nIt may be possible to perform parts of the port using AI, but the two projects have such different architectures that it may be of limited use.\n|\n\n|\nSuggested By\nSimonPoole\nSummary\nDevelop a solution to extract text from a captured image or directly from the camera. The captured text should either be able to be used as a tag value, or to generate a set of tags that can be directly applied to an osm object. It is mandatory that this only uses resources available on device.\nMandatory skills\nJava or Kotlin\nUseful skills\ngradle, experience with Android development\nLength\n350 hours\nDifficulty\nmedium to challenging\nPossible Mentors\nSimonPoole\nNotes\nThe successful candidate will need to have access to a suitably powerful Android device. Googles MLkit might be a potential starting point for text recognition. Note that the use of models and code that cannot be distributed on open terms is not possible. Vespucci repo:\n|\n\n|\nSuggested By\nSummary\nThe goal of this project would be to implement a user interface widget which should a) provide a better visual interpretation of already mapped\nMandatory skills\nJavaScript\nUseful skills\nExperience with the D3.js framework, OSM tagging/mapping workflows, and iD development\nRequired experience\nintermediate\nLength\n175 hours\nDifficulty\nmedium\nPossible Mentors\nNotes\nPotentially, this project could be extended by enhancing the functionality of the widget also to UI fields for tags with temporal\n|\n\n|\nSuggested By\nSummary\nCurrently, the\nMandatory skills\nJavaScript\nUseful skills\nFront end web development & UI/UX experience, OSM tagging/mapping\nRequired experience\nintermediate\nLength\n175 hours\nDifficulty\nmedium\nPossible Mentors\nNotes\nThis tool could also provide some parts of the code that are currently directly implemented in iD in form of a library that can act as a \"reference implementation\" for other consumers of the tagging schema.\n|\n\n## Other\n\n|\nSuggested By\nSummary\nThe goal is to enhance client-side rendering of 3d models and add support for editing features to improve the contributor experience at the 3D Model Repository\n- Replace the current implementation of flat map view with an interactive, on globe rendering of 3D models.\n- Provide an API endpoint for lower-res \"thumbnail models\", use it to improve site performance\n- Support in-browser model editing (shift origin/rotate/re-scale) during model upload.\nMandatory skills\nJavaScript, Python\nUseful skills\n3D graphics\nLength\n175 hours\nDifficulty\nmedium\nPossible Mentors\nNotes\nA potential contributor would have familiarity/prior experience with 3D model rendering pipelines.\n|"
  },
  {
    "name": "Eclipse Foundation",
    "slug": "eclipse-foundation",
    "tagline": "The Global Open Source Foundation",
    "description": "The Eclipse Foundation provides our global community of individuals & organizations with a mature, scalable, and business-friendly environment for OSS collaboration and innovation.\n\nEclipse is an open source community that's focused around key principles of transparency, openness, and vendor neutrality: the work that we do is done in a manner that can be observed by anybody with an interest; project teams welcome new ideas, and invites others to participate;  and vendor neutrality ensures that no single vendor can dominate a project and that everybody plays by the same set of rules (a so-called \"level playing field\").\n\nNaturally, Eclipse projects are also all about the code. With over three hundred and\nsixty (https://projects.eclipse.org/) open source projects covering a diverse set of of\ntechnologies, there's something here for everybody. \n\nEclipse projects build technology in areas such as Internet of Things (https://projects.eclipse.org/technology-type/internet-things), Programming Languages and IDE (https://projects.eclipse.org/technology-type/language), and\nRuntimes (https://projects.eclipse.org/technology-type/runtime) like Jetty and\nEE4J (http://www.eclipse.org/ee4j) (currently known as Java EE).\n\nFor those students interested in research, we have an entire working group focused\non Science (https://projects.eclipse.org/projects/science) where researches from\nsome of the world's most prestigious labs do open source development to support\ntheir research areas.",
    "ideas_url": "https://gitlab.eclipse.org/eclipsefdn/emo-team/gsoc-at-the-ef/-/issues/?sort=created_date&state=opened&label_name%5B%5D=GSoC%202026&first_page_size=100",
    "website_url": "https://www.eclipse.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "java",
      "rtos",
      "eclipsejavaide",
      "jakartaee",
      "softwaredefinedvehicles"
    ],
    "topic_tags": [
      "robotics",
      "automotive",
      "tools",
      "cloud native java",
      "iot & edge"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/eclipse-foundation",
    "ideas_content": "Copyright © Eclipse Foundation AISBL. All rights reserved.     [Privacy Policy](https://www.eclipse.org/legal/privacy.php) | [Terms of Use](https://www.eclipse.org/legal/termsofuse.php) | [Copyright Agent](https://www.eclipse.org/legal/copyright.php)"
  },
  {
    "name": "DBpedia",
    "slug": "dbpedia",
    "tagline": "Global and Unified Access to Knowledge Graphs.",
    "description": "DBpedia is a crowd-sourced community effort to extract structured information from Wikipedia and make this information available on the Web. It allows for a global and unified access to Knowledge Graphs.",
    "ideas_url": "https://forum.dbpedia.org/tag/gsoc2026-ideas",
    "website_url": "https://www.dbpedia.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "java",
      "scala",
      "rdf"
    ],
    "topic_tags": [
      "machine learning",
      "semantic web",
      "linked data",
      "knowledge graph",
      "largelanguagemodel"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/dbpedia",
    "ideas_content": "[DBpedia Hindi Chapter 2026: Fine-Tuning Indic Models for Hindi Relational Triple Extraction + Human-in-the-Loop Feedback — GSoC 2026](https://forum.dbpedia.org/t/dbpedia-hindi-chapter-2026-fine-tuning-indic-models-for-hindi-relational-triple-extraction-human-in-the-loop-feedback-gsoc-2026/4788)\n|\n[\n](https://forum.dbpedia.org/u/tiwarisanju18)\n[\n](https://forum.dbpedia.org/u/vishakha14)\n[\n](https://forum.dbpedia.org/u/Anushtup)\n[\n](https://forum.dbpedia.org/u/sid0858)\n[\n](https://forum.dbpedia.org/u/5051a9b40975112c9b4a)\n|\n16\n|\n223\n|\nFebruary 18, 2026\n|\n[Towards a Neural Extraction Framework — GSoC 2026](https://forum.dbpedia.org/t/towards-a-neural-extraction-framework-gsoc-2026/4778)\n|\n[\n](https://forum.dbpedia.org/u/tsoru)\n[\n](https://forum.dbpedia.org/u/ab7461a45fe384a2298d)\n[\n](https://forum.dbpedia.org/u/949729d22e8d29245d24)\n[\n](https://forum.dbpedia.org/u/u2084511felix)\n[\n](https://forum.dbpedia.org/u/sid0858)\n|\n9\n|\n202\n|\nFebruary 14, 2026\n|\n[Building the Amharic DBpedia Language Chapter with Large Language Models (LLMs)](https://forum.dbpedia.org/t/building-the-amharic-dbpedia-language-chapter-with-large-language-models-llms/4792)\n|\n[\n](https://forum.dbpedia.org/u/hizclick)\n[\n](https://forum.dbpedia.org/u/SyedaAlizah)\n|\n1\n|\n89\n|\nFebruary 6, 2026\n|\n[Modernizing & Multilingualizing DBpedia NLP Pipeline — GSoC 2026 ⚠️ mentors needed](https://forum.dbpedia.org/t/modernizing-multilingualizing-dbpedia-nlp-pipeline-gsoc-2026-mentors-needed/4786)\n|\n[\n](https://forum.dbpedia.org/u/Charithakottu)\n[\n](https://forum.dbpedia.org/u/tsoru)\n|\n2\n|\n98\n|\nFebruary 2, 2026\n|\n[Stabilizing, Completing, and Upstreaming the Hindi DBpedia IE Pipeline — GSoC 2026 ⚠️ mentors needed](https://forum.dbpedia.org/t/stabilizing-completing-and-upstreaming-the-hindi-dbpedia-ie-pipeline-gsoc-2026-mentors-needed/4776)\n|\n[\n](https://forum.dbpedia.org/u/SyedaAlizah)\n|\n0\n|\n98\n|\nJanuary 22, 2026\n|"
  },
  {
    "name": "D Language Foundation",
    "slug": "d-language-foundation",
    "tagline": "Write fast, read fast, and run fast.",
    "description": "The D Language Foundation manages the D programming language and its entire ecosystem.",
    "ideas_url": "https://dlang.github.io/GSoC/gsoc-2026/project-ideas.html",
    "website_url": "https://dlang.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "linux",
      "make",
      "d",
      "windows",
      "C\\C++"
    ],
    "topic_tags": [
      "operating systems",
      "programming languages",
      "algorithms",
      "data structures",
      "optimizations"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/d-language-foundation",
    "ideas_content": "# DLang GSoC 2026 Project Ideas\n\nD is a general-purpose programming language with static typing, systems-level access, and C-like syntax. With the D Programming Language, write fast, read fast, and run fast.\n\nD allows writing large code fragments without redundantly specifying types, like dynamic languages do. On the other hand, static inference deduces types and other code properties, giving the best of both the static and the dynamic worlds.\n\nAutomatic memory management makes for safe, simple, and robust code. D also supports scoped resource management (aka the RAII idiom) and scope statements for deterministic transactional code that is easy to write and read.\n\nBuilt-in linear and associative arrays, slices, and ranges make daily programming simple and pleasant for tasks, both small and large.\n\nD offers an innovative approach to concurrency, featuring true immutable data, message passing, no sharing by default, and controlled mutable sharing across threads.\n\nFrom simple scripts to large projects, D has the breadth to scale with any application’s needs: unit testing, information hiding, refined modularity, fast compilation, precise interfaces.\n\n## Mentors\n\n- Dennis Korpel - dkorpel@gmail.com\n- Razvan Nitu - razvan.nitu1305@gmail.com\n- Atila Neves - atila.neves@gmail.com\n- Nicholas Wilson - iamthewilsonator@hotmail.com"
  },
  {
    "name": "Open Science Labs",
    "slug": "open-science-labs",
    "tagline": "The community open to science and technology.",
    "description": "Open Science Labs is a global community dedicated to creating an open space for\nteaching, learning, and sharing information about open science and computational\ntools. Our community develops tools that address real-world problems and\ncollaborates with other projects and workgroups to improve technology and create\ninternational opportunities for our community. Although our focus may seem\nbroad, we initially prioritize supporting Research Software Engineers (RSEs) who\noften face computational challenges in their work. We recognize that many\ncolleagues in scientific fields may not be familiar with programming languages,\ncomputational libraries, version control systems, databases, DevOps, and other\ncomputational tools. Therefore, we aim to provide a safe and open space for\nindividuals to learn and share their knowledge. Our community is open to\neveryone, including students, professors, and industry professionals, as we\nbelieve that the challenges and technologies used in these fields are frequently\nsimilar, if not the same (in many cases).",
    "ideas_url": "https://opensciencelabs.org/opportunities/gsoc/project-ideas",
    "website_url": "https://opensciencelabs.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "llvm",
      "c++",
      "docker"
    ],
    "topic_tags": [
      "web",
      "ai",
      "devops",
      "devtools",
      "open-science"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/open-science-labs",
    "ideas_content": "# OSL Project Ideas for GSoC 2026[ #](https://opensciencelabs.org#osl-project-ideas-for-gsoc-2026)\n\n\nNote 1:This is the list of projects we intend to propose forGSoC 2026(subject to change).Note 2:TheGSoC 2026 Mentoring Organizationapplication has not opened yet.Stay tuned!\n\nWelcome to the Open Science Labs (OSL) project ideas page for Google Summer of Code 2026. As an umbrella organization, OSL hosts links to the ideas pages of each member organization. You can explore these projects here.\n\nAt OSL, we've assembled a selection of project ideas that not only embody our mission but also provide enriching experiences for student and newcomers open-source developpers. These projects cover a variety of topics and technologies, catering to diverse interests. Below, we've outlined some potential project ideas we're considering for GSoC. We believe these projects provide students with a valuable chance to engage with open-source efforts and develop their skills under the mentorship of seasoned professionals.\n\nThis page details the sub-organizations available for GSoC 2026 participants.\nApplicants are welcome to reach out to us on our\n[Discord](https://opensciencelabs.org/discord).\n\n## Sub-Organizations[ #](https://opensciencelabs.org#sub-organizations)\n\n*Note: Each organization includes a designated list of mentors. Please get in\ntouch with them directly if you have any inquiries.*\n\n### Alpha One Labs[ #](https://opensciencelabs.org#alpha-one-labs)\n\n**Description**: Alpha One Labs is an education platform designed to facilitate both learning and teaching. The platform provides a comprehensive environment where educators can create and manage courses, while students can learn, collaborate, and engage with peers. With features like study groups, peer connections, and discussion forums, we aim to create a collaborative learning environment that goes beyond traditional online education.**Project WEB Page**:[https://www.alphaonelabs.com/](https://www.alphaonelabs.com/)**Repository**:[https://github.com/alphaonelabs/education-website](https://github.com/alphaonelabs/education-website)**Communication channel**:[Slack](https://join.slack.com/t/alphaonelabs/shared_invite/zt-7dvtocfr-1dYWOL0XZwEEPUeWXxrB1A)**Project Ideas**:[link](https://github.com/alphaonelabs/education-website/wiki/GSOC-2025-Ideas-Refined)\n\n### ArxLang/IRx[ #](https://opensciencelabs.org#arxlangirx)\n\n**Description**: IRx aims to provide a translator to LLVM-IR from ASTx objects. IRx uses llvmlite in order to generate LLVM-IR source and binary generation.**Project WEB Page**:[https://irx.arxlang.org/](https://irx.arxlang.org/)**Repository**:[https://github.com/arxlang/irx](https://github.com/arxlang/irx)**Communication channel**:[Discord](https://arxlang.org/discord)**Project Ideas**:[link](https://github.com/arxlang/irx/wiki/Project-Ideas)\n\n### Extralit[ #](https://opensciencelabs.org#extralit)\n\n**Description**: Extralit is an open-source platform for researchers to extract structured data from scientific literature. It combines advanced document AI with collaborative human validation workflows to create analysis-ready datasets fit-for-purpose to any scientific domain, enabling faster evidence synthesis and meta-analysis.**Project WEB Page**:[https://docs.extralit.ai/](https://docs.extralit.ai/)**Repository**:[https://github.com/extralit/extralit](https://github.com/extralit/extralit)**Communication channel**:[Slack](https://join.slack.com/t/extralit/shared_invite/zt-32blg3602-0m0XewPBXF7776BQ3m7ZlA)**Project Ideas**:[link](https://github.com/extralit/extralit/wiki/GSoC-Project-Ideas-2025)\n\n### Hiperhealth[ #](https://opensciencelabs.org#hiperhealth)\n\n**Description**: Hiperhealth provides a set of tools and libraries for health care services empowered by AI. It includes screening, diagnosis, treatments, prescriptions, clinical records, etc.**Project WEB Page**:[https://hiperhealth.github.io/hiperhealth/](https://hiperhealth.github.io/hiperhealth/)**Repository**:[https://github.com/hiperhealth/hiperhealth](https://github.com/hiperhealth/hiperhealth)**Communication channel**:[Discord](https://discord.gg/Nu4MdGj9jB)**Project Ideas**:[link](https://github.com/sdx-org/sdx/wiki/Project-Ideas)\n\n### Sugar (swarm-external-secrets)[ #](https://opensciencelabs.org#sugar-swarm-external-secrets)\n\n**Description**: swarm-external-secrets is a Docker plugin that bridges external secrets management systems with Docker Swarm's native secrets infrastructure.**Project WEB Page**:[https://sugar-org.github.io/swarm-external-secrets/](https://sugar-org.github.io/swarm-external-secrets/)**Repository**:[https://github.com/sugar-org/swarm-external-secrets](https://github.com/sugar-org/swarm-external-secrets)**Communication channel**:[Discord](https://opensciencelabs.org/discord)**Project Ideas**:[link](https://github.com/sugar-org/swarm-external-secrets/wiki/Project-Ideas)"
  },
  {
    "name": "libssh",
    "slug": "libssh",
    "tagline": "The SSH library",
    "description": "This project is for programmers needing a working SSH implementation by the mean of a library. The complete control of the client is made by the programmer. With libssh, you can remotely execute programs, transfer files, use a secure and transparent tunnel for your remote programs. With its Secure FTP implementation, you can play with remote files easily, without third-party programs others than libcrypto (from openssl), libgcrypt or mbedTLS.",
    "ideas_url": "https://www.libssh.org/development/google-summer-of-code/",
    "website_url": "https://www.libssh.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "git",
      "ci",
      "ssh",
      "sftp"
    ],
    "topic_tags": [
      "security",
      "cryptography"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/libssh",
    "ideas_content": "## Contributors guidance\n\n### The application process consists of next steps:\n\n- Become acquainted with application process for GSoC.\n- Join to gsoc mailing list:\n[https://groups.google.com/group/google-summer-of-code-announce](https://groups.google.com/group/google-summer-of-code-announce) - Join libssh mailing list:\n[https://www.libssh.org/communication/](https://www.libssh.org/communication/) - Search mentor for chosen project in mailing list discuss or propose your own project and find a mentor for it.\n- Submit the application/proposal including all requirements at the Google Summer of Code Site.\n\n### Requirements before starting search for mentor:\n\n- Clone and build libssh sources:\n[https://www.libssh.org/development/](https://www.libssh.org/development/) - Review existing issues in bug tracker and try to solve some simpler one, providing a merge request on gitlab mirror\n[https://gitlab.com/libssh/libssh-mirror/-/issues](https://gitlab.com/libssh/libssh-mirror/-/issues). This is REQUIRED and project proposals without any prior interactions and non-trivial MR will not be considered. - Prepare answers to questions about own participation in project.\n\n### Application requirements/recommendations:\n\n- All applications\n*must*go through Google’s application system; we can’t accept any application unless it is submitted there. - Use a descriptive title in Google’s system. Good example: “libssh: Improve SSH connection fuzzing” Bad example: “My gsoc project”\n- Make it easy for your mentors to give you feedback. If you’re using Google docs, enable comments and submit a “draft” (we can’t see the “final” versions until applications close). If you’re using a format that doesn’t accept comments, make sure your email is on the document and don’t forget to check for feedback!\n- Use the following template for the your project application. It will help you to answer the questions we want to hear answers for and prepare yourself for the project itself:\n[https://docs.google.com/document/d/1H1BDf0gZZkPwTOKuu7cOsPq40DBuOCY8qcF8e49pXUY](https://docs.google.com/document/d/1H1BDf0gZZkPwTOKuu7cOsPq40DBuOCY8qcF8e49pXUY)\n\n### AI usage\n\nIf you are using any AI/LLM tools to help you with the contributions or proposal, you need to provide a description of the tools used and extent of this use (ex. Proofreading proposal using XXX, Code review by YYY, Coding assistant ZZZ to draft test cases …)”. That said, AI usage is not bad, but it needs to be used as and addition to your intelligence and not a replacement.\n\n### GSoC libssh organization administrators:\n\n- Jakub Jelen (jakuje on Matrix)\n- Sahana Prasad (saprasad on Matrix)\n- Andreas Schneider (asn on Matrix)\n\n### libssh mentors:\n\n- Jakub Jelen (jakuje on Matrix)\n- Sahana Prasad (saprasad on Matrix)\n- Eshan Kelkar (eshan_k on Matrix)\n\n## Project ideas\n\n### Introduce Rust into libssh\n\nlibssh in written in C which has it strength and weaknesses. It is fast and you have a lot of freedom but it is also easy to “shoot yourself in the foot”. To improve memory safety we should start replacing the core parts with Rust.\n\nThe project would involve two things. Create a CMake module to deal with Rust and convert string.c to string.rs. If time permits buffer.c to buffer.rs. The plan would be to bring the CMake module upstream.\n\n- Difficult: Medium\n- Project length: 350 hours\n- Language(s): Good knowledge of C and/or Rust\n- Possible Mentors: Jakub Jelen and Andreas Schneider\n- References:\n[CMake Rust Integration Plan](https://hackmd.io/@asn/r19DwWZwbx)\n\n### OpenSSH-compatible CLI\n\nThe libssh is provided as a library and only provided binaries are examples implementing either specific client or server examples without an attempt to implement a CLI that can support most of the OpenSSH’s CLI use cases and could be used as a drop-in replacement. The libssh should already support most of the use cases (and if not, new issues should be opened and implemented). Similar exercise can be done for server, but there will many more gaps.\n\n- Difficulty: Medium\n- Project length: 350 hours\n- Language(s): Good knowledge of C or Rust\n- Possible Mentors: Jakub Jelen\n- References:\n- Manual page for ssh:\n[https://linux.die.net/man/1/ssh](https://linux.die.net/man/1/ssh)\n\n- Manual page for ssh:\n\n### Improve configuration compatibility with OpenSSH\n\nThe libssh is trying to be compatible with the OpenSSH configuration files to make the experience for our users as smooth as possible to be able to use only one configuration file for both. But OpenSSH configuration file options grow in complexity and we are not catching up with all the corner cases, which sometimes got reported to us. This project is about understanding the SSH configuration, how it is handled by OpenSSH and adjusting the libssh configuration parser to match as closely as possible, including adding a automated test coverage that can compare results with the OpenSSH parser.\n\nIt might be possible to create a fuzzer for the configuration file, that would feed the inputs into both openssh and libssh to verify they result in the same effective configuration.\n\n- Difficulty: Hard\n- Project length: 350 hours\n- Language(s): Good knowledge of C, understanding of fuzzing testing is a plus\n- Possible Mentors: Jakub Jelen\n- References:\n- Manual page for ssh_config:\n[https://linux.die.net/man/5/ssh_config](https://linux.die.net/man/5/ssh_config)\n\n- Manual page for ssh_config:\n\n### Design and implement API to communicate with SSH-Agent\n\nThe libssh can communicate with an ssh-agent/pageant, but only internally in the function `ssh_userauth_agent()`\n\n. This has disadvantage that the agent can not be used on the server, the agent can not be used for signing data (sshsig) and there is no API to operate on the agent from the calling application (list keys, add keys, …).\n\nThe rough idea is to have a new set of APIs that will allow list the keys, returning opaque ssh_key structures, that will transparently redirect the key operation to agent.\n\n- Difficulty: Medium\n- Project length: 175 hours\n- Language(s): Good knowledge of C, API design understanding, knowledge about ssh-agent is a plus\n- Possible Mentors: Jakub Jelen\n- References:\n\n## Completed projects\n\n### Support for FIDO/U2F keys on the client side (2025)\n\nThe server side support (signature verification) and key type definitions are in place so authenticating using these keys from openssh client to libssh server should already work. But the libssh clients can not use the U2F based keys as well as it can not be used to enroll the hardware for authentication with ssh.\n\nThe project should involve adding code paths to create U2F signatures, as well as possibility to test them without the actual hardware in the CI. Here we can get inspiration from OpenSSH, as they provide sk-dummy.so, which can simulate fido/u2f devices. This is packaged in Fedora.\n\n- Difficulty: Medium\n- Project length: 350 hours\n- Language(s): Good knowledge of C, knowledge about elliptic curves cryptography or u2f is a plus 😉\n- Possible Mentors: Jakub Jelen, Sahana Prasad, Eshan Kelkar\n- References:\n- Student: Praneeth Sarode\n[https://darkphoenix42.github.io/posts/gsoc-2025/](https://darkphoenix42.github.io/posts/gsoc-2025/)\n\n### Support for OpenSSH certificates (2024)\n\nThe libssh supports OpenSSH certificates as opaque blobs alongside the client keys only to pass them along with the key to some compatible server to verify the authentication. This is ok for basic interoperability with OpenSSH servers configured to accept certificates signed with Users CA, but it does not cover the server use cases (authenticating users), nor the Hosts CA (authenticating servers to clients) use case at all.\n\n- Difficulty: Medium\n- Project length: 350 hours\n- Language(s): Good knowledge of C, knowledge about certificates is a plus\n- Mentors: Jakub Jelen, Sahana Prasad, Eshan Kelkar\n- References:\n- Student: Francesco Rollo\n[https://medium.com/@eferollo/my-google-summer-of-code-2024-journey-with-libssh-802e72f935e3](https://medium.com/@eferollo/my-google-summer-of-code-2024-journey-with-libssh-802e72f935e3)\n\n### Test coverage for GSSAPI Authentication (2024)\n\nThe libssh supports GSSAPI authentication for ages. But there is no automated test coverage for neither client nor server, making the code Schrodinger code (both working but more likely broken). This project involves learning how the GSSAPI authentication in SSH protocol works, proposing test cases and implementing them inside of the upstream testsuite with help of the [cwrap](https://cwrap.org/) wrappers. Stretch goal is looking into the GSSAPI Key exchange defined in the same RFC and [RFC8732](https://datatracker.ietf.org/doc/html/rfc8732) and testing it well.\n\n- Difficulty: Medium\n- Project length: 350 hours\n- Language(s): Good knowledge of C, knowledge about kerberos and GSSAPI is a plus\n- Mentors: Jakub Jelen, Sahana Prasad, Eshan Kelkar\n- References:\n- Student: Gauravsingh Sisodia\n[https://xaerru.github.io/gsoc24/](https://xaerru.github.io/gsoc24/)\n\n### async SFTP client (2023)\n\nThe SFTP implementation in libssh requires application to call libssh API to send each chunk of data, which is not the fastest option. Our idea is that libssh should provide an API similar to io_uring, where you set up the transfer of the file and libssh will take care of the rest.\n\n- Difficulty: hard\n- Project length: 350 hours\n- Language(s): Good knowledge of C, network programming and IO handling\n- Mentors: Sahana Prasad, Jakub Jelen, Norbert Pocs\n- References:\n- Student: Eshan Kelkar\n[https://summerofcode.withgoogle.com/programs/2023/projects/CdkiroFH](https://summerofcode.withgoogle.com/programs/2023/projects/CdkiroFH)\n\n### Support for OpenSSH connection multiplexing (2023)\n\nThe OpenSSH supports sharing several sessions over a single TCP connection, which makes opening new channels faster from cli. The usage of the same MUX protocol is not mandatory, but as we already work with openssh configuration files so, it would probably make sense to implement it in compatible way.\n\n- Difficulty: medium/hard\n- Project length: 175 hours\n- Language(s): Good knowledge of C, knowledge about communication between processes is a plus 😉\n- Mentors: Norbert Pocs, Sahana Prasad\n- References:\n- Student: Ahsen Kamal\n[https://summerofcode.withgoogle.com/programs/2023/projects/GdK87jbe](https://summerofcode.withgoogle.com/programs/2023/projects/GdK87jbe)\n\n**Callback based sftp server** (2022)\n\nCurrently, the sftp server implementation is based on a huge switch handling all the possible messages. Changing to callback-based model can provide much better customization by the library users\n\n- Difficulty: medium\n- Project length: 175 hours\n- Language(s): Good knowledge of C and network programming\n- Mentors: Jakub Jelen\n- References:\n- The ssh server in libssh is using callback to handle various SSH protocol messages or authentication types\n\n- Student: Zeyu Sheng\n[https://summerofcode.withgoogle.com/programs/2022/projects/Hm79LwKE](https://summerofcode.withgoogle.com/programs/2022/projects/Hm79LwKE)"
  },
  {
    "name": "LibreCube Initiative",
    "slug": "librecube-initiative",
    "tagline": "Open Source Space Exploration",
    "description": "LibreCube develops an ecosystem of open source space technology for exploration systems. \n\nOur vision is to enable everyone to get involved in building systems for exploration using open source hardware and software.\n\nLibreCube is based on these three pillars: \n\n\n1) Open Source: Everything we do at LibreCube is made available to the public free and open source. Also, we only use free and open source tools for our work – this way, really everyone can get involved!\n\n\n2) Free and Open Standards: We rely on proven and tested standards for our system designs, with preference for standards from the space domain.\n\n\n3) Reference Architecture: Defining a generic architecture of system that have standardized interfaces makes it possible to combine and re-use elements for various different mission applications.",
    "ideas_url": "https://librecube.org/google-summer-of-code/",
    "website_url": "https://librecube.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "docker",
      "raspberry pi",
      "micropython"
    ],
    "topic_tags": [
      "robotics",
      "automation",
      "space"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/librecube-initiative",
    "ideas_content": "LibreCube is applying for the [Google Summer of Code](https://summerofcode.withgoogle.com) (GSoC) program this year!\n\nGSoC is a vital opportunity for attracting new members to the LibreCube community and the open source world in general. We heavily rely on contributors to extend our open source ecosystem for semi-autonomous exploration systems and technology. Listed below are the project ideas for this year. Please send us an email ([info@librecube.org](mailto:info@librecube.org)) with a short text about yourself (your skills and interests) and what of the project(s) you find interesting to work on. You may want to structure your project application according to [this template](https://librecube.org/google-summer-of-code-proposal/).\n\n**Notes:**\n\n- As always, we aim for a\n**diverse participation**and encourage applications from women and under-represented groups! - Most projects require at least a basic knowledge of Python language. Basic experience with Git is also needed.\n- We do not restrict the use of AI tooling for code generation. However, we strongly encourage to build the code step by step, and will expect you to explain what you are coding.\n\n#### 1. SpaceCAN Tester\n\n**Description**: [SpaceCAN](https://librecube.gitlab.io/standards/spacecan/) is the robust onboard communication bus for CubeSats and other autonomous vehicles, developed by the LibreCube community. Currently we have a reference implementation in Python and an embedded version in MicroPython. A SpaceCAN network is composed of a controller node and several attached responder nodes. To help during the development of responder nodes, we developed the [SpaceCAN Tester](https://gitlab.com/librecube/elements/LC3301) application.The task here is to improve this application with several features, to improve the user experience and to extend its capabilities. The list of features to add can be found [here](https://gitlab.com/librecube/elements/LC3301/-/issues).\n\n**Skills**: Python, Web Framework (NiceGUI)\n\n**Proposed Mentors**: Peter, Shayan\n\n**Project Size**: 350 hours\n\n**Difficulty**: medium\n\n#### 2. ZED PLUTO Language Plugin\n\n**Description**: [PLUTO](https://ecss.nl/standard/ecss-e-st-70-32c-test-and-operations-procedure-language/) is a domain specific language for writing procedures to be used for test and operation of space system. PLUTO procedures are both human-readable and can be parsed by machines (for example, we have developed a [PLUTO to Python parser](https://gitlab.com/librecube/prototypes/python-pluto-parser) to demonstrate it). The goal here is to create a language support plugin for the [ZED editor](https://zed.dev/) to support syntax highlighting and code formatting. This will greatly assist in writing PLUTO procedures. Previously we had developed a [plugin](https://gitlab.com/librecube/tools/vscodium-pluto-syntax) for VS Code, which can serve as a guideline.\n\n**Skills**: Python, PLUTO\n\n**Proposed Mentors**: Sai, Artur\n\n**Project Size**: 90 hours\n\n**Difficulty**: easy\n\n#### 3. Blockly PLUTO Procedure Editor\n\n**Description**: In a previous GSoC project, we developed a [blockly-based application](https://developers.google.com/blockly) to support the creation of [PLUTO](https://ecss.nl/standard/ecss-e-st-70-32c-test-and-operations-procedure-language/) procedures using block programming. A demo of the application can be found [here](https://lc6401-5e3d9b.gitlab.io/#). PLUTO is predominantly used in European space missions. This application is targeted for students and engineers of space mission automation. It provides them an easy-to-use tool to create valid PLUTO procedures. The task here is to improve the editor in a number of ways. Some improvements pertain to the improvement of user experience. The bulk of improvements however concern the implementation of missing functionalities, which are listed [here](https://gitlab.com/librecube/elements/LC6401/-/issues).\n\n**Skills**: JavaScript, Blockly, Docker\n\n**Proposed Mentors**: Artur, Sai\n\n**Project Size**: 350 hours\n\n**Difficulty**: medium/hard\n\n#### 4. CC1120 GNU Radio Receiver & Decoder\n\n**Description**: LibreCube is developing an [UHF CubeSat communications board](https://gitlab.com/librecube/prototypes/proto-LC2302). This project will complement this activity by creating GNU Radio flowgraphs (and an optional small OOT module) to receive, demodulate, and decode TI CC1120 packets from provided baseband IQ recording, no hardware setup needed. The work will take inspiration from the existing CC1101 GNU Radio decoder (gr-cc_sdr, gr-satellites) and adapt it for CC1120 packet formats. Deliverables include working flowgraphs, packet/frame decoding, examples and clear documentation with sample datasets.\n\n**Skills**: C++, GNU Radio, Signal Processing\n\n**Proposed Mentors**: Tamara, Shayan\n\n**Project Size**: 350 hours\n\n**Difficulty**: hard"
  },
  {
    "name": "Django Software Foundation",
    "slug": "django-software-foundation-8o",
    "tagline": "Web framework for perfectionists with deadlines",
    "description": "Django is a high-level Python Web framework originally developed at the Lawrence-Journal World. Django was designed to handle two challenges: the intensive deadlines of a newsroom and the stringent requirements of the experienced Web developers who wrote it. It lets you build high-performing, elegant Web applications quickly.",
    "ideas_url": "https://code.djangoproject.com/wiki/SummerOfCode2026",
    "website_url": "https://www.djangoproject.com",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "django"
    ],
    "topic_tags": [
      "web",
      "python"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/django-software-foundation-8o",
    "ideas_content": "-\n[Google's Summer of Code 2026](https://code.djangoproject.com#GooglesSummerofCode2026)-\n[Mentors](https://code.djangoproject.com#Mentors) -\n[Students](https://code.djangoproject.com#Students) -\n[How can I improve my chances of being accepted?](https://code.djangoproject.com#HowcanIimprovemychancesofbeingaccepted) -\n[Communication](https://code.djangoproject.com#Communication) -\n[Ideas](https://code.djangoproject.com#Ideas) -\n[Experimental feature flags and processes](https://code.djangoproject.com#Experimentalfeatureflagsandprocesses) -\n[Add types to parts of Django](https://code.djangoproject.com#AddtypestopartsofDjango) -\n[Add ergonomic control over behaviour of missing variables in templates](https://code.djangoproject.com#Addergonomiccontroloverbehaviourofmissingvariablesintemplates) -\n[Switch to Playwright tests for integration testing](https://code.djangoproject.com#SwitchtoPlaywrighttestsforintegrationtesting) -\n[Add support for generate_series in postgres](https://code.djangoproject.com#Addsupportforgenerate_seriesinpostgres) -\n[[PLACEHOLDER] Project name](https://code.djangoproject.com#PLACEHOLDERProjectname) -\n[Or Create Your Own](https://code.djangoproject.com#OrCreateYourOwn)\n\n-\n\n\n# Google's Summer of Code 2026\n\nDjango is a mentor organization for the 2026 Google Summer of Code.\nRead [Google's page](https://summerofcode.withgoogle.com) for more information on how the program works.\n\nDjango's GSoC program is being coordinated by Bhuvnesh Sharma and Apoorv Garg.\n\n## Mentors\n\nIf you're interested in mentoring -- supervising a student in work on Django-related activities -- please let us know: [https://forum.djangoproject.com/t/call-for-project-ideas-and-prospective-mentors-for-gsoc-2025/38017](https://forum.djangoproject.com/t/call-for-project-ideas-and-prospective-mentors-for-gsoc-2025/38017)\n\n## Students\n\nStudent application period runs until March 31st, 2026.\n\nIf you'd like to get started on your proposal early, we'll be looking for a few things.\n\n- You'll need to have a concrete task in mind along with a solid idea of what will constitute \"success\" (you tell us).\n- If your proposal is a single large feature, library or site, you'll need to present\na detailed design specification. This proposal should be posted to\n[the Django Forum](https://forum.djangoproject.com/c/internals/mentorship/10), where it can be refined until it is accepted by the developer community. - We'll want to know a bit about you -- links to previous work are great, if any. If you're proposing something ambitious, you'll need to convince us that you're up to the task.\n- You'll also need to provide us with a schedule, including a detailed work breakdown and major milestones so your mentor can know if and when to nag you :)\n\nHere's an example of an accepted proposal from a previous year:\n\nNote that none of the ideas below are good enough to be submissions in their own right (so don't copy and paste)! We'll want to know not just what you want to do but how you plan to pull it off.\n\nDon't feel limited to the ideas below -- if you've got a cool project you want to work on, we'll probably be able to find you a mentor. We plan on approving as many projects as we possibly can.\n\nWe're accepting any GSOC proposal that fits one of the following three categories:\n\n- Work on Django itself - such as the ORM, forms, etc. This is what we've traditionally accepted GSoC entries in.\n- Work on tools to support Django - the issue tracker dashboard (\n[https://dashboard.djangoproject.com/](https://dashboard.djangoproject.com/)) is a good example of an existing tool that would have fit into this category. - Work on libraries that supplement or add new features to Django to ease development -\n`django-stubs`\n\nand Django Debug Toolbar are good examples of existing projects that would have fit here.\n\nHere are the projects that were accepted last year: [https://summerofcode.withgoogle.com/archive/2025/organizations/django-software-foundation-8o](https://summerofcode.withgoogle.com/archive/2025/organizations/django-software-foundation-8o)\n\nUnless explicitly mentioned below, we're **not** looking for people to work on\nexisting third-party libraries - we aren't able to guarantee commit access to\nthem. We may allow an exception if a maintainer of the library in question\nagrees to help mentor beforehand.\n\nThe broadening in scope is to allow people to work on new ideas to help Django development and developers without tying you down to having to implement it in the core codebase (and thus ruling out some projects that might otherwise be useful).\n\nWe're still going to be strict with what we accept - you'll need to provide a strong use case for your idea and show that it would be useful to a majority of developers or significantly improve the development of Django itself.\n\nWe're not looking for small groups of incremental updates - like \"improve Django's Trac\" - nor are we looking for impossible tasks, like \"replace Trac with this brand new issue tracker I'm writing\". What you propose should be a single project, achievable within the time period of GSoC, and something the core developers can help mentor you on.\n\nWe're also not looking for sites or projects that are merely written in Django — this GSoC is not for you to propose your new forum hosting site or amazing Django-based blogging engine.\n\nNote that when you contribute code, you will be expected to adhere to the same\ncontribution guidelines as any other code contributor. This means you will be\nexpected to provide extensive tests and documentation for any feature you add,\nyou will be expected to participate in discussion on the\n[Django Forum](https://forum.djangoproject.com) when your topic of interest is\nraised. If you're not already familiar with [Django's contribution guidelines](http://docs.djangoproject.com/en/dev/internals/contributing/), now would be a good time to read them - even if\nyou're not applying to work on Django core directly, we'll still want the same\nlevel of contribution.\n\n## How can I improve my chances of being accepted?\n\nThe best thing you can do to improve your chances to be accepted as a Django\nGSoC student is to start contributing now. Read up on [Django’s contribution documentation](https://docs.djangoproject.com/en/dev/internals/contributing/) and make yourself known to the other contributors by your\ncontributions (ideally, related to the area of your proposal). That way, when\nit comes time to evaluate student applications, you’ll be a **known individual**\nand more likely to be able to get the attention you need to develop a proposal.\n\nWe're looking for candidates who can demonstrate that they can engage in work of a project scope on an independent basis. We're there to help but we can't watch you every step of the way, so we need to see that motivation from you. Being active before the submissions process is the best way to demonstrate this.\n\n## Communication\n\nAll GSOC-related communication is handled via the [Django Forum, in the Mentoring channel](https://forum.djangoproject.com/c/internals/mentorship/10). Any proposals for GSoC should be submitted there, as\nwell as discussion on the proposed projects and any updates that students post.\n\nPlease be careful to keep content to the forum clear and purposeful; if you have an idea, update, or criticism, please make sure you describe it in detail; it can be tedious asking people to clarify any vague statements.\n\n## Ideas\n\nHere are some suggestions for projects students may want to propose (please\nfeel free add to this list!). This isn't by any means the be-all and end-all of\nideas; please feel free to submit proposals for things not on this list.\nRemember, we'd much prefer that you posted a draft proposal and your rough\ntimeline / success conditions to the the [Django Forum, in the Mentoring channel](https://forum.djangoproject.com/c/internals/mentorship/10),\neven if it's already on the list below; it will help you get feedback on\nchoosing the right part of a problem, as well as helping to see if there is any\ninterest before you start drafting a full proposal.\n\nWhen developing your proposal, try to scope ideas/proposals to size of your project (175hrs or 350hrs) -- you need to be ambitious, but not too ambitious. The GSoC does not cover activities other than coding, so certain ideas (\"Write a more detailed tutorial\" or \"Create demonstration screencasts\") are not suitable for inclusion here.\n\nOn the other side, though, be sure to be concrete in your proposal. We'll want to know what your goals are, and how you plan to accomplish them.\n\nThe project ideas below list key skill, but all assume a knowledge of Python, and familiarity with Django itself.\n\nIn no particular order:\n\n## Experimental feature flags and processes\n\n| Difficulty | Hard |\n| Size | 350hr |\n| Mentors | Andrew Miller |\n| Key Skills | Python, Django, Documentation |\n\nThe current development process of Django is slow. This is in part due to our commitment to backwards compatibility. This means it is hard to test a new feature API directly in django/django because if we get it wrong we can't easily change it. An experimental feature flag would help us overcome this, possibly making Django development faster\n\nComplete discussion here: [https://github.com/django/new-features/issues/3](https://github.com/django/new-features/issues/3)\n\n## Add types to parts of Django\n\n| Difficulty | Hard |\n| Size | 350hr |\n| Mentors | Thibaut Decombe |\n| Key Skills | Python, Django |\n\nRight now, when working with Django, it’s quite common to refer back to the documentation just to understand what a function returns or what types its arguments expect. Although this idea has been proposed several times before, the Python typing ecosystem has matured significantly, making it a more practical direction today. There are certainly areas — particularly the ORM — where typing can be challenging or may even introduce complexity that outweighs the benefits. However, other parts of Django, such as request and response objects, URL routing, and class-based views, stand to gain clear usability improvements from better type support.\n\nWe see [this comment](https://forum.djangoproject.com/t/revisiting-types-in-django-dep-14/37832/11) by Simon Charette as a good starting point for gradually introducing types, with the ORM being an especially valuable area where typing could help contributors reason about the codebase more effectively. The scope would include defining the necessary protocols and applying them throughout the ORM. This effort would also involve exploring CI integrations for type checking and deciding how types should be presented in the documentation — whether they should appear in every relevant definition, only in selected examples, or be omitted entirely.\n\nThis would also help solve many of the issues here [https://groups.google.com/g/django-developers/c/at-G0hZrfXE](https://groups.google.com/g/django-developers/c/at-G0hZrfXE).\n\nGithub reference: [https://github.com/django/new-features/issues/23](https://github.com/django/new-features/issues/23)\n\n## Add ergonomic control over behaviour of missing variables in templates\n\n| Difficulty | Medium |\n| Size | 350hr |\n| Mentors | TBD |\n| Key Skills | python, django, template internals |\n\nTemplates silently convert missing variables to an empty string. This behaviour is useful in many situations:\n\nPages still render instead of returning a 500 error when a minor programming error is made. Template authors can deliberately design a section to be omitted when variables are not in the context. However, this implicit behaviour is inconvenient for people who want to get an error during development when a variable that should always be present is omitted by mistake. By adding explicit syntax for required and optional variables, we give developers and teams extra control to opt-in to the desired behaviour where appropriate.\n\nGithub reference: [https://github.com/django/new-features/issues/5](https://github.com/django/new-features/issues/5)\n\n## Switch to Playwright tests for integration testing\n\n| Difficulty | Medium |\n| Size | 175 hr |\n| Mentors | TBD |\n| Key Skills | python, django, playwright, CI/CD, testing |\n\nThis project aims to modernize Django’s integration testing by introducing Playwright as an alternative to Selenium. The work includes integrating Playwright with Django’s test framework, migrating existing browser-based tests, and ensuring compatibility with Django’s CI infrastructure. The goal is to improve test reliability, performance, and developer experience for Django core contributors.\n\nFull reference: [https://github.com/django/new-features/issues/13](https://github.com/django/new-features/issues/13)\n\n## Add support for generate_series in postgres\n\n| Difficulty | Hard |\n| Size | 350hr |\n| Mentors | Sage Abdullah, Lily (needs confirmation) |\n| Key Skills | django, python, postgres, ORM |\n\nThis project aims to extend Django’s ORM with native support for PostgreSQL’s `generate_series`\n\nfunction. Currently developers must use raw SQL to access this powerful function. The work involves designing ORM expressions or query APIs to integrate `generate_series`\n\nin a way that feels natural within Django’s ORM, writing tests, and ensuring compatibility with Django’s PostgreSQL contrib utilities.\n\nReferences:\n\n[https://github.com/django/new-features/issues/25](https://github.com/django/new-features/issues/25)[https://forum.djangoproject.com/t/proposal-add-generate-series-support-to-contrib-postgres/21947](https://forum.djangoproject.com/t/proposal-add-generate-series-support-to-contrib-postgres/21947)\n\n## [PLACEHOLDER] Project name\n\n| Difficulty | Medium or Hard |\n| Size | 175hr or 350hr |\n| Mentors | (need confirmation) |\n| Key Skills | - |\n\nProject description including the expected outcome of the project.\n\n## Or Create Your Own\n\nWe have around 900 accepted tickets on Django. Browse the issue tracker by\ncomponent — here's an\n[example filter for contrib.staticfiles](https://code.djangoproject.com/query?status=assigned&status=new&component=contrib.staticfiles&col=id&col=summary&col=status&col=owner&col=type&col=component&col=version&desc=1&order=id). What's the bit of the framework that interests you?\nWhat contribution do you want to make to it?\n\nUse the tickets as guides here. Remember the advice above, that your project needs to be both on Django itself here, and achievable in the timescale of GSoC.\n\nCould be scoped as a 175hr or a 350hr project, depending on your idea.\n\nWe're open to all good ideas!\n\n[Last modified](https://code.djangoproject.com/wiki/SummerOfCode2026?action=diff&version=5)\n\n[12 days ago](https://code.djangoproject.com/timeline?from=2026-02-08T16%3A07%3A24-06%3A00&precision=second)Last modified on Feb 8, 2026, 4:07:24 PM\n\n**Note:**See\n\n[TracWiki](https://code.djangoproject.com/wiki/TracWiki)for help on using the wiki."
  },
  {
    "name": "CircuitVerse.org",
    "slug": "circuitverseorg",
    "tagline": "Build and learn logic circuits in the cloud!",
    "description": "CircuitVerse is an easy to use digital logic circuit simulator which aims at providing a platform to create, share and learn digital circuits. It can run on almost any device without the need for installing any software. The platform has been designed for use by students, professionals and hobbyists alike. The vision is to develop a community around the platform that will aid students to self-learn digital logic design. The platform is currently used by several universities worldwide. Apart from the simulator, users can create, learn, collaborate and share their work. Teachers can create groups and host assignments on the platform. The platform’s impact has been more evident than ever in the Covid 19 pandemic as CircuitVerse enabled schools and colleges to move their courses online.",
    "ideas_url": "https://github.com/CircuitVerse/CircuitVerse/wiki/GSoC'26-Project-List",
    "website_url": "http://circuitverse.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "javascript",
      "ruby",
      "rails",
      "canvas",
      "vue"
    ],
    "topic_tags": [
      "education",
      "web",
      "simulation",
      "pedagogy",
      "digital logic design"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/circuitverseorg",
    "ideas_content": "# CircuitVerse GSoC 2026 Project Ideas\n\nThis document presents the project ideas for CircuitVerse's participation in **Google Summer of Code (GSoC) 2026**. CircuitVerse is an open-source platform dedicated to digital logic education, and we invite motivated candidates to contribute to its continued growth and improvement. The following projects aim to enhance functionality, performance, scalability, and user experience. Candidates are also encouraged to submit original proposals aligned with the platform's long-term objectives.\n\nMany of the ideas listed below may be **intentionally over-scoped**. This is done to provide flexibility for candidates to tailor their proposals based on interests and strengths. The final set of deliverables will be decided through discussions between mentors and selected contributors to ensure realistic goals and effective use of the GSoC timeline.\n\n---\n\n## Essential Information\n\n* **Community Engagement:** Join discussions and receive updates via our [Slack Channel](https://circuitverse.org/slack).\n* **Proposal Submission:** Use the official [Proposal Template](https://docs.google.com/document/d/1oeYPAuqWxeC79d-R5I9uFJywQJv4ooO4obF4pwifyTY/edit?usp=sharing) (Google Docs recommended).\n* **Project Discussions:** Collaborate and refine ideas on [GitHub Discussions](https://github.com/orgs/CircuitVerse/discussions/6489).\n\n---\n\n## Project 1: Structured Format for Saved Circuit Data\n\n**Duration:** 175 – 350 hours  \n**Difficulty:** Hard  \n**Technologies:** Ruby on Rails, JavaScript, JSON\n\nCurrently, CircuitVerse stores circuits as unstructured JSON objects where components are serialized based on placement order rather than logical hierarchy. As a result, two logically identical circuits can produce entirely different saved files. This makes the data unsuitable for advanced use cases such as Verilog generation, robust version control, circuit diffing, and large-scale machine learning or LLM-based analysis.\n\nThis project aims to design and implement a **structured, canonical data format** for saving circuits. The new format should be deterministic, logically consistent, and independent of visual layout. Circuits will be represented as ordered netlists or graph-based structures, enabling future features such as automated synthesis, AI-assisted circuit design, and semantic comparisons between circuits.\n\n**Key Deliverables:**\n\n* Canonical, deterministic representation of circuits\n* Logical netlist-based serialization independent of placement order\n* Backward compatibility with existing circuit files\n\n**Additional Features:**\n\n* **Human-Readable Schema:** Define a strict JSON schema for easier debugging and manual inspection.\n* **Visual–Logic Separation:** Decouple logical connectivity from visual metadata (x, y coordinates, canvas layout).\n* **Idempotent Converter:** Build a migration tool to convert legacy `.cv` files into the new standardized format without data loss.\n\n**Learning Path:**\n\n* JSON Schema design and validation\n* CircuitVerse simulator internals (serialization of `CircuitElement`)\n* Graph Theory: Graph isomorphism and canonical graph representations\n* EDA standards such as SPICE and EDIF for inspiration\n\n**Possible Mentors:** [JoshVarga](https://github.com/JoshVarga), [Arnabdaz](https://github.com/Arnabdaz), [Aryann Dwivedi](https://github.com/aryanndwi123)\n\n---\n\n## Project 2: Assignment Suite & Classroom Workflow Enhancement\n\n**Duration:** 175 hours  \n**Difficulty:** Easy  \n**Technologies:** Ruby on Rails, JavaScript\n\nThis project focuses on strengthening CircuitVerse's classroom and assignment infrastructure to better support educators and students. Contributors will extend the assignment suite with multi-level classroom structures, enabling subgroup formation for collaborative projects and flexible submission workflows.\n\nThe project also includes enhancing assignments with pre-built circuit templates, integrated test cases, and auto-verification from practice sessions. Improvements to Canvas LMS integration and Learning Tools Interoperability (LTI) support will further enhance CircuitVerse's adoption in academic environments.\n\n**Key Deliverables:**\n\n* Multi-level classroom and subgroup support\n* Group and individual assignment workflows\n* Pre-configured circuit assignments with test cases\n* Improved Canvas LMS and LTI integration\n\n**Learning Path:**\n\n* Ruby on Rails via The Odin Project\n* JavaScript fundamentals via MDN Web Docs\n* Canvas LMS Developer APIs\n* Learning Tools Interoperability (LTI)\n\n**Possible Mentors:** [Anas Khan](https://github.com/anxkhn), [Aman Asrani](https://github.com/Asrani-Aman), [Harsh Bhadu](https://github.com/senbo1)\n\n---\n\n## Project 3: Simulator Real-Time Collaboration\n\n**Duration:** 175 – 350 hours  \n**Difficulty:** Hard  \n**Technologies:** JavaScript, Canvas API, Ruby on Rails\n\nThis project introduces real-time collaborative editing in the CircuitVerse simulator, allowing multiple users to work on the same circuit simultaneously. The goal is to enable seamless collaboration similar to shared document editors, making it easier for teams, classrooms, and study groups to design and debug circuits together.\n\nThe collaboration layer must handle concurrent edits safely and efficiently, ensuring consistency across clients even under conflicting updates.\n\n**Key Deliverables:**\n\n* Real-time multi-user circuit editing\n* Session-based collaboration system\n* User presence indicators (avatars and names)\n* Permission-based access control\n\n**Follow-up Features:**\n\n* Session creation and invite links\n* Read-only vs edit permissions\n* CRDT-based conflict resolution (e.g., Yjs or similar graph-friendly CRDTs)\n\n**Learning Path:**\n\n* CircuitVerse simulator architecture\n* Real-time systems and WebSockets\n* Conflict-Free Replicated Data Types (CRDTs)\n* Existing CRDT research and implementations ([https://crdt.tech/](https://crdt.tech))\n\n**Possible Mentors:** [Vaibhav Upreti](https://github.com/VaibhavUpreti), [Aman Asrani](https://github.com/Asrani-Aman), [Harsh Rao](https://github.com/ThatDeparted2061)\n\n---\n\n## Project 4: FSM to Circuit Synthesizer\n\n**Duration:** 175 hours  \n**Difficulty:** Medium  \n**Technologies:** HTML5, CSS, JavaScript, Ruby on Rails\n\nFinite State Machines (FSMs) are foundational concepts in digital logic and automata theory. This project aims to introduce an FSM editor within CircuitVerse that allows users to visually design FSMs and automatically synthesize them into corresponding digital circuits.\n\nThe project will support Moore and Mealy machines and can be extended to demonstrate additional computational models such as DFA, NFA, PDA, and Turing Machines. Contributors are encouraged to build upon or integrate existing open-source FSM editors.\n\n**Expected Outcomes:**\n\n* Visual FSM editor inside CircuitVerse\n* Automatic FSM-to-circuit synthesis\n* Support for Moore and Mealy machines\n\n**Resources:**\n\n* [http://www.cburch.com/proj/autosim/](http://www.cburch.com/proj/autosim/)\n* [http://madebyevan.com/fsm/](http://madebyevan.com/fsm/)\n\n**Possible Mentors:** [Vivek Kumar](https://github.com/092vk), [Harsh Rao](https://github.com/ThatDeparted2061)\n\n---\n\n## Project 5: Interactive Circuit Debugging Suite\n\n**Duration:** 175 – 350 hours  \n**Difficulty:** Hard  \n**Technologies:** HTML5, CSS, JavaScript, Canvas API\n\nCircuitVerse currently provides limited control over simulation execution, making it difficult for users to precisely identify when and where logical errors occur. This project aims to build a comprehensive, interactive debugging suite that allows users to inspect, pause, rewind, and analyze circuit behavior over time.\n\nThe debugging tools will significantly improve learning outcomes by making circuit execution transparent and explorable.\n\n**Key Features:**\n\n* **Bidirectional Time-Stepping:** Step forward and backward through simulation states using a state history buffer.\n* **Timeline Scrubbing:** Visual timeline slider for navigating simulation history.\n* **Logic-Triggered Breakpoints:** Automatically pause simulation when specific wires or components reach defined states.\n* **Live Probes & Hover Inspection:** Inspect wire values and bus data via tooltips or a watch panel.\n* **State Snapshots:** Save and restore complete circuit states instantly.\n* **Visual Signal Propagation:** Optional slow-motion mode highlighting active signal paths.\n\n**Learning Path:**\n\n* CircuitVerse simulator internals\n* State replay and time-travel debugging concepts\n* Existing circuit replay and visualization\n\n**Possible Mentors:** [Nihal Rajpal](https://github.com/Nihal4777), [Arnabdaz](https://github.com/Arnabdaz), [Niladri Adhikary](https://github.com/niladrix719)\n\n---\n\n## Project 6: CircuitVerse Mobile App: Feature Parity with Web Platform and Deployment Readiness\n\n**Duration:** 175 hours  \n**Difficulty:** Medium  \n**Technologies:** Flutter, Dart, JavaScript\n\nThe CircuitVerse mobile application currently lacks several core features and stability compared to the web platform, which limits its effectiveness as a learning tool. This project aims to enhance the mobile application by achieving feature parity with the CircuitVerse website while improving performance, usability, and maintainability.\n\nThe primary objective is to stabilize authentication, restore and enhance the interactive book module, and resolve existing technical and UI issues. The project will ensure a consistent user experience across platforms by aligning mobile UI components with the web interface and improving accessibility.\n\nAdditionally, the project will prepare the application for production deployment by improving code quality, fixing critical bugs, and implementing scalable architecture. Support for localization and region-specific language requirements will be strengthened, including improvements to the simulator and learning modules for multilingual users.\n\nBy the end of the project, the CircuitVerse mobile application will be fully functional, reliable, and ready for public deployment, providing students worldwide with seamless access to CircuitVerse's interactive learning resources.\n\n**Key Deliverables:**\n\n* Implementation of core web features in the mobile application\n* Stable and secure authentication system\n* Fully functional interactive book module\n* Improved UI consistency and accessibility\n* Bug fixes and performance optimization\n* Enhanced localization and multilingual support\n* Production-ready deployment configuration\n\n**Learning Outcomes:**\n\nParticipants will gain hands-on experience in:\n\n* Flutter and Dart application development\n* API integration and authentication systems\n* Mobile–Web architecture and WebView integration\n* Localization and internationalization techniques\n* Mobile UI/UX design and accessibility standards\n* Software testing, debugging, and deployment practices\n\n**Possible Mentors:** [Hardik Sachdeva](https://github.com/hardik17771), [Yashvant Singh](https://github.com/JatsuAkaYashvant)\n\n---\n\n## Project 7: Enterprise & Institutional Organization Features\n\n**Duration:** 350 hours  \n**Difficulty:** Medium – Hard  \n**Technologies:** Ruby on Rails, PostgreSQL, Devise, OAuth/OIDC\n\nCurrently, CircuitVerse handles users and classrooms individually. However, large universities and organizations need a way to manage multiple groups, instructors, and students under a single umbrella. This project aims to introduce an Organization layer to the platform, allowing for hierarchical management and professional-grade security features.\n\nThis will involve architecting a multi-tenant-like structure where \"Org Admins\" can oversee multiple classrooms and ensure seamless onboarding through Single Sign-On (SSO).\n\n**Key Deliverables:**\n\n* **Hierarchical Org Structure:** Ability to create an Organization and nest multiple \"Groups\" or \"Departments\" within it.\n* **SSO Support:** OpenID Connect (OIDC) to allow students to log in using institutional credentials (e.g., Google Workspace, Microsoft Azure AD).\n* **Role-Based Access Control (RBAC):** Distinct permissions for Org Admins, Department Leads, and Instructors.\n* **Custom Branding (Optional):** Basic support for custom subdomains (e.g., university.circuitverse.org) and logo placement for institutional identity.\n\n**Learning Path:**\n\n* Multi-tenancy patterns in Ruby on Rails\n* Authentication protocols (OAuth 2.0, OIDC)\n* Advanced PostgreSQL indexing for organizational queries\n* Security best practices for enterprise software\n\n**Possible Mentors:** TBD\n\n---\n\n## Project 8: Client-Side Verilog Synthesis via Yosys-Wasm\n\n**Duration:** 350 hours  \n**Difficulty:** Hard  \n**Technologies:** C++, WebAssembly (Emscripten), JavaScript, Yosys\n\nCircuitVerse currently supports Verilog, but synthesis often happens server-side or via complex bridges. This project aims to bring the power of Yosys (Open Synthesis Suite) directly to the browser using WebAssembly (Wasm). By migrating the synthesis engine to the client side, we can offer instantaneous Verilog-to-Circuit conversion without taxing server resources or requiring an internet connection for synthesis.\n\nThis is a highly technical project that involves cross-compiling a large C++ codebase (Yosys) and creating a high-performance JavaScript wrapper to interface with the CircuitVerse simulator.\n\n**Key Deliverables:**\n\n* **Yosys-Wasm Port:** A stable, optimized build of Yosys compiled to WebAssembly.\n* **Local Synthesis Pipeline:** An integrated workflow where users type Verilog code and see it transformed into a CircuitVerse netlist locally.\n* **Virtual Filesystem Integration:** Mapping browser-based Verilog files to the Wasm environment for multi-file module support.\n* **Performance Benchmarking:** Comparative analysis of client-side vs. server-side synthesis times.\n\n**Learning Path:**\n\n* Compiling C/C++ to WebAssembly using Emscripten\n* Understanding RTL (Register Transfer Level) synthesis and Netlists\n* Yosys internals and the RTLIL (RTL Intermediate Language)\n* Browser-side performance optimization and Web Workers\n\n**Possible Mentors:** TBD\n\n---\n\n## Propose Your Own Project Idea\n\nCandidates are encouraged to submit original project proposals. Submissions should include:\n\n1. A clear description of the proposed concept and the problem it addresses.\n2. Supporting visual materials, such as wireframes, mockups, or screenshots.\n3. Identification of the intended beneficiaries (e.g., students, educators, or hardware users).\n4. A detailed implementation plan outlining the approach and timeline.\n\nPrior to submission, candidates should consult with mentors on [Slack](https://circuitverse.org/slack) or [GitHub Discussions](https://github.com/orgs/CircuitVerse/discussions/5388) to refine their proposals.\n\n---\n\n## Conclusion\n\nThe projects outlined above provide a foundation for meaningful contributions to CircuitVerse during GSoC 2026. Each initiative offers opportunities for skill development and collaboration within an open-source community dedicated to advancing digital logic education. Candidates may select a listed project or propose a unique idea, and we look forward to working together to enhance the platform's capabilities."
  },
  {
    "name": "LibreOffice",
    "slug": "libreoffice",
    "tagline": "LibreOffice is a free and open source office suite",
    "description": "LibreOffice is a modern Free & Open Source Office suite, one of the largest open source projects, and used by millions of users worldwide. LibreOffice is compatible with many file formats like Microsoft® Word, Excel, PowerPoint and Publisher. At its heart though, LibreOffice is built around an open standard, the OpenDocument Format, as its native file format.\nLibreOffice is developed by users who, just like you, believe in the principles of Free Software and in sharing their work with the world in non-restrictive ways. The development of LibreOffice is supported by The Document Foundation which provides the infrastructure for the project.\nWe believe that users should have the freedom to run, copy, distribute, study, change and improve the software that we distribute. While we do offer no-cost downloads of the LibreOffice suite of programs, Free Software is first and foremost a matter of liberty, not price. We campaign for these freedoms because we believe that everyone deserves them.\nThough the members of our community hail from many different backgrounds, we all value personal choice and transparency, which translates practically into wider compatibility, more utility, and no end-user lock-in to a single product. We believe that Free Software can provide better-quality, higher-reliability, increased-security, and greater-flexibility than proprietary alternatives. LibreOffice is a large project (approx. 6MLOC), which makes it interestingly complex, but at the same time, provides a place for all sorts of contribution & skills.\nThe community behind LibreOffice is the heart of the project, without which we would not have the resources to continue developing our software. The passion and drive that every individual brings to the community results in collaborative development that often exceeds our own expectations. With tons of different roles in the project, we invite everyone to join us in our work and help us to make LibreOffice known, prosper, and accessible to all.",
    "ideas_url": "https://wiki.documentfoundation.org/Development/GSoC/Ideas",
    "website_url": "https://www.libreoffice.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "java",
      "c++"
    ],
    "topic_tags": [
      "office suite",
      "desktop application",
      "end user application"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/libreoffice",
    "ideas_content": "# Making sure you're not a bot!\n\nLoading...\n\nYou are seeing this because the administrator of this website has set up Anubis to protect the server against the scourge of AI companies aggressively scraping websites. This can and does cause downtime for the websites, which makes their resources inaccessible for everyone.\n\nAnubis is a compromise. Anubis uses a Proof-of-Work scheme in the vein of Hashcash, a proposed proof-of-work scheme for reducing email spam. The idea is that at individual scales the additional load is ignorable, but at mass scraper levels it adds up and makes scraping much more expensive.\n\nUltimately, this is a placeholder solution so that more time can be spent on fingerprinting and identifying headless browsers (EG: via how they do font rendering) so that the challenge proof of work page doesn't need to be presented to users that are much more likely to be legitimate.\n\nPlease note that Anubis requires the use of modern JavaScript features that plugins like JShelter will disable. Please disable JShelter or other such plugins for this domain."
  },
  {
    "name": "Debian",
    "slug": "debian",
    "tagline": "The Universal Operating System",
    "description": "The Debian Project is an association of Free Software developers who\nvolunteer their time and effort in order to produce and maintain a completely free\noperating system Debian. Since its launch, the Debian project has grown to comprise more than 1,000 members with official developer status, alongside many more volunteers and contributors. Today, Debian encompasses over 50,000 packages of free, open source applications and documentation.",
    "ideas_url": "https://wiki.debian.org/SummerOfCode2026/Projects",
    "website_url": "https://debian.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "java",
      "perl",
      "c++",
      "rust"
    ],
    "topic_tags": [
      "ai",
      "CI/CD",
      "autopkgtest",
      "raspberrypi_builds",
      "mobian"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/debian",
    "ideas_content": "Contents\n\n-\n[Approved Projects](https://wiki.debian.org#Approved_Projects)-\n[Attack Of The Clones: Fight Back Using Code Duplication Detection from Security Patches](https://wiki.debian.org#SummerOfCode2026.2FApprovedProjects.2FAttackOfTheClonesFightBack.Attack_Of_The_Clones:_Fight_Back_Using_Code_Duplication_Detection_from_Security_Patches) -\n[DebNet: Visualising the Bus Factor – Graph Analysis of Debian's Infrastructure](https://wiki.debian.org#SummerOfCode2026.2FApprovedProjects.2FDebNet:_Visualising_the_Bus_Factor_.2BIBM_Graph_Analysis_of_Debian.27s_Infrastructure.DebNet:_Visualising_the_Bus_Factor_.2BIBM_Graph_Analysis_of_Debian.27s_Infrastructure) -\n[Debusine: debuginfod server](https://wiki.debian.org#SummerOfCode2026.2FApprovedProjects.2FDebusineDebuginfodServer.Debusine:_debuginfod_server) -\n[Debusine: git-first development](https://wiki.debian.org#SummerOfCode2026.2FApprovedProjects.2FDebusineGitFirstDevelopment.Debusine:_git-first_development) -\n[Debusine: live log streaming](https://wiki.debian.org#SummerOfCode2026.2FApprovedProjects.2FDebusineLiveLogStreaming.Debusine:_live_log_streaming) -\n[Debusine: replace archive-wide reports in UDD](https://wiki.debian.org#SummerOfCode2026.2FApprovedProjects.2FDebusineReplaceUDDWorkers.Debusine:_replace_archive-wide_reports_in_UDD) -\n[Debusine: usability and papercuts](https://wiki.debian.org#SummerOfCode2026.2FApprovedProjects.2FDebusineUsabilityAndPapercuts.Debusine:_usability_and_papercuts) -\n[Improving Salsa CI](https://wiki.debian.org#SummerOfCode2026.2FApprovedProjects.2FImprovingSalsaCI.Improving_Salsa_CI) -\n[Linux Livepatching](https://wiki.debian.org#SummerOfCode2026.2FApprovedProjects.2FLinuxLivePatching.Linux_Livepatching)\n\n-\n-\n[Unapproved Projects with confirmed mentors](https://wiki.debian.org#Unapproved_Projects_with_confirmed_mentors)\n\nThe main page is at [SummerOfCode2026](https://wiki.debian.org/SummerOfCode2026).\n\n\n# Approved Projects\n\n\n## Attack Of The Clones: Fight Back Using Code Duplication Detection from Security Patches\n\nThe clone attack where identical copies of vulnerable code are embedded across multiple executables is a distribution wide security problem. The current approach necessitates extensive tracking of code duplication and individual patching or recompiling of each affected binary, significantly increasing the complexity and overhead of security updates. As a result, ensuring timely remediation across all instances of the code becomes challenging, leaving systems more susceptible to prolonged exposure to vulnerabilities.\n\nThe goal of this project is to automate the detection of code duplication in the archive by using security patches, converting these patches into loose regex patterns, and then scanning the archive for security‑related code duplication.\n\n**Confirmed Mentor**: Bastien Roucaries**How to contact the mentor:**[rouca+gsoc2025@debian.org](mailto:rouca+gsoc2025@debian.org)**Confirmed co-mentors:**Arnaud Valence (associate professor ESIA, Laval, France)**Difficulty level**: Medium**Project size:**350 hours (large), but useful progress can be made in 175 hours if needed**Deliverables of the project**: A proof a concept that will write attack of clone report for security team**Desirable skills**: python, git**What the intern will learn:**how to write good documentation, HTTP api, writing automatic report (template), finding bibliography, AI if needed, python programming**Application tasks:**- Extract patch metadata from debian security tracker. May need to standardization of patch annotation and writing a custom parser\n- Research way to transform patch to loosely code signature using limited regex (re2) that could be used by codesearch.debian.net\n- Use codesearch.debian.net to find code duplication in the archive\n- write report about attack of clone found\n\n**Related projects:**[https://hal.science/hal-05334923v1/document](https://hal.science/hal-05334923v1/document)**AI usage policy:**: We will not accept applications written using LLMs, and we expect accepted students to write code themselves, not via an LLM.\n\n\n## DebNet: Visualising the Bus Factor – Graph Analysis of Debian's Infrastructure\n\n**Description of the project:**Debian has more than 70.000 packages in the archives, which are all held together by a decentralised community of a few thousand volunteers.[?](https://wiki.debian.org/DebNet)DebNet aims to visualise the resilience of the archive by modelling the archive as a graph. You will collaborate with mentors to define specific KPIs (e.g. Bus Factor, Centrality, ...) to evaluate archive health. The goal is to identify critical packages that are abandoned or rely on too few maintainers which need more support. You will build a FastAPI application to provide all analysed data through HTTP endpoints. This project offers the chance to actively shape how we detect single points of failure within the distribution.**Confirmed Mentor**: Christian Kastner, Arian Ott**How to contact the mentor:**Christian Kastner <[ckk@debian.org](mailto:ckk@debian.org)>, Arian Ott <[arian.ott@ieee.org](mailto:arian.ott@ieee.org)>**Confirmed co-mentors:**Debian AI Team <[debian-ai@lists.debian.org](mailto:debian-ai@lists.debian.org)>**Difficulty level**: Hard**Project size:**350h**Deliverables of the project**: FastAPI backend (which does all the analytics etc.)**Desirable skills**:- Foundational knowledge of Graph Theory\n- Python programming\n- Basic knowledge of SQL\n\n**What the intern will learn:**- Using Graph theory to analyse the debian archive\n- Building secure and performant FastAPI applications\n\n**Application tasks:**Solve the tasks from this repo:[https://salsa.debian.org/Arian-Ott/debnet-application-tasks](https://salsa.debian.org/Arian-Ott/debnet-application-tasks)**Related projects:**None (maybe UDD?)**AI usage Policy:**We will not accept applications written using LLMs, and we expect accepted students to write code themselves, not via an LLM.\n\n[[SummerOfCode2026/ApprovedProjects/DebNet: Visualising the Bus Factor – Graph Analysis of Debian's Infrastructure]](https://wiki.debian.org/SummerOfCode2026/ApprovedProjects/DebNet%3A%20Visualising%20the%20Bus%20Factor%20%E2%80%93%20Graph%20Analysis%20of%20Debian%27s%20Infrastructure)\n\n[[edit]](https://wiki.debian.org/SummerOfCode2026/ApprovedProjects/DebNet%3A%20Visualising%20the%20Bus%20Factor%20%E2%80%93%20Graph%20Analysis%20of%20Debian%27s%20Infrastructure?action=edit&backto=SummerOfCode2026%2FProjects)\n\n\n## Debusine: debuginfod server\n\n**Description of the project:** Debusine provides Debian developers and maintainers with a way to host package repositories. We would like to [support debug symbol packages](https://salsa.debian.org/freexian-team/debusine/-/issues/957) as well, serving them in a way that’s compatible with debuginfod(8). This would make it easy for users of those packages to provide meaningful backtraces in the event of crashes.\n\n**Confirmed Mentor**: Colin Watson**How to contact the mentor:**[cjwatson@debian.org](mailto:cjwatson@debian.org)**Confirmed co-mentors:**None confirmed, but other people from the[Debusine team](https://freexian-team.pages.debian.net/debusine/reference/development-team-organization.html#current-team-organization)can help if needed.**Difficulty level**: Hard**Project size:**175 hours (medium)**Deliverables of the project**:Debusine transforms\n\n`*-dbgsym`packages into suitable artifacts with individual elements broken out.Debusine’s archive views have\n\n`buildid/*`endpoints compatible with debuginfod(8).`gdb`can fetch debug symbols from such repositories, and Debusine documents how to configure it to do so.\n\n**Desirable skills**: Competent Python, basic Django and/or SQL, and the ability to read C/C++ well enough to analyze the details of what debuginfod(8) does (writing C/C++ is unlikely to be required).**What the intern will learn:**How`gdb`finds debug symbols. How a real-world repository hosting system works, and how to extend it with new features.**Application tasks:**Pick a\n\n[Quick fix](https://salsa.debian.org/freexian-team/debusine/-/issues?sort=created_date&state=opened&label_name%5B%5D=Quick%20fix&first_page_size=100)issue from our list and try to fix it, including full test coverage for your changes.Look at\n\n[debuginfod(8)’s web API documentation](https://manpages.debian.org/stable/debuginfod/debuginfod.8.en.html#WEBAPI)and the`elf_classify`function in[debuginfod.cxx](https://sourceware.org/git/?p=elfutils.git;a=blob;f=debuginfod/debuginfod.cxx). Prepare an initial high-level summary of what would need to be extracted from incoming debug symbol packages in order to handle the`/buildid/BUILDID/debuginfo`` endpoint.\n\n**AI usage policy:**We will not accept applications written using LLMs, and we expect accepted students to write code themselves, not via an LLM.\n\n\n## Debusine: git-first development\n\n**Description of the project:** Many people are much more familiar with git than with Debian source package tools; even Debian developers often find the latter to be a bit of a maze. The [dgit](https://manpages.debian.org/testing/dgit/dgit.1.en.html) maintainers have been working for some time on allowing contributors to use git directly for their uploads, and [tag2upload](https://wiki.debian.org/tag2upload) allows people to upload simply by pushing the right kind of signed tag.\n\nHowever, Debusine doesn’t integrate well with this yet. Members of the Debusine and dgit teams have had some [productive design discussions](https://salsa.debian.org/freexian-team/debusine/-/issues/815), and we would like to turn some of those into reality.\n\n**Confirmed Mentor**: Colin Watson**How to contact the mentor:**[cjwatson@debian.org](mailto:cjwatson@debian.org)**Confirmed co-mentors:**None confirmed, but other people from the[Debusine team](https://freexian-team.pages.debian.net/debusine/reference/development-team-organization.html#current-team-organization)can help if needed.**Difficulty level**: Medium**Project size:**350 hours (large), but useful progress can be made in 175 hours if needed**Deliverables of the project**:Debusine has a new\n\n[artifact](https://freexian-team.pages.debian.net/debusine/explanation/concepts.html#artifacts)category representing a source package version in a git repository, and a new[task](https://freexian-team.pages.debian.net/debusine/explanation/concepts.html#tasks)to turn those into traditional source packages as needed.- Debusine can send an outgoing webhook to notify the tag2upload manager when a workflow completes.\n- (Optional, depending on the student:) Work with the dgit team to design a system to add additional metadata to signed tags to specify testers. The mentor can help with cross-project communication.\n(Stretch goal:) Tie this all together using some kind of\n\n`git debpush`configuration that requests that a git tag be tested by Debusine before pushing it to the Debian archive.\n\n**Desirable skills**: Solid understanding of git’s data model. Competent Python. The ability to read Perl and shell scripts well enough to find answers to questions in dgit’s source code.**What the intern will learn:**How typical git workflows correspond to the Debian archive. Webhooks and other aspects of typical web service design. Running a cross-functional project.**Application tasks:**Pick a\n\n[Quick fix](https://salsa.debian.org/freexian-team/debusine/-/issues?sort=created_date&state=opened&label_name%5B%5D=Quick%20fix&first_page_size=100)issue from our list and try to fix it, including full test coverage for your changes.Explain how a git tag gets from\n\n`git debpush`to the Debian archive.\n\n**AI usage policy:**We will not accept applications written using LLMs, and we expect accepted students to write code themselves, not via an LLM.\n\n\n## Debusine: live log streaming\n\n**Description of the project:** Debusine allows viewing logs for tasks after they have been completed, but it should also [allow viewing logs of tasks that are in progress](https://salsa.debian.org/freexian-team/debusine/-/issues/854).\n\n**Confirmed Mentor**: Stefano Rivera**How to contact the mentor:**[stefanor@debian.org](mailto:stefanor@debian.org)**Confirmed co-mentors:**None confirmed, but other people from the[Debusine team](https://freexian-team.pages.debian.net/debusine/reference/development-team-organization.html#current-team-organization)can help if needed.**Difficulty level**: Medium to hard**Project size:**175 hours (medium); this project can be split into multiple stages**Deliverables of the project**:- Debusine workers incrementally collect output from tasks as they run, and send it to the server which stores that output in a suitable backend database.\n- (Stretch goal:) The Debusine web UI shows streaming output from running tasks.\n\n**Desirable skills**: Python systems programming, Python async programming, websocket communication, Redis and/or PostgreSQL, Django application development. For later stages, HTML+CSS+[?](https://wiki.debian.org/JavaScript)JavaScript development without[?](https://wiki.debian.org/JavaScript)JavaScript frameworks.**What the intern will learn:**Development practices for a medium-sized real-world software development platform. Systems design architecture, with care for latency and scalability. Web user interface design.**Application tasks:**Pick a\n\n[Quick fix](https://salsa.debian.org/freexian-team/debusine/-/issues?sort=created_date&state=opened&label_name%5B%5D=Quick%20fix&first_page_size=100)issue from our list and try to fix it, including full test coverage for your changes.- Write a \"producer\" command line tool that runs a program and streams its output to Redis.\n- Write a \"consumer\" command line tool that takes output streamed to Redis and writes it on its output. Ideally, while one producer is running, one could start multiple consumers and see the same output streaming on both.\n\n**Additional details:**- Development would have multiple milestones. The first two would be required for successful completion of the project, and the remaining two would count towards rewarding user-visible bragging rights:\n- Worker-side, collecting relevant output on the worker code and sending it back to the server via the websocket interface\n- Server-side, collecting incoming output from workers and dispatching it to an appropriate Redis structure or a PostgreSQL table\n- Server-side, providing a view to make incoming output lines available to code on the browser side\n- Browser-side, subscribing to updates and viewing them streaming on the page\n\n\n- Development would have multiple milestones. The first two would be required for successful completion of the project, and the remaining two would count towards rewarding user-visible bragging rights:\n**AI usage policy:**We will not accept applications written using LLMs, and we expect accepted students to write code themselves, not via an LLM.\n\n\n## Debusine: replace archive-wide reports in UDD\n\n**Description of the project:** The Ultimate Debian Database (UDD) gathers data about many aspects of Debian in a single database, which in turn is used to provide many useful reports to Debian contributors. Some of its tables (e.g. Lintian analysis or information about new upstream versions) import their data from workers that the UDD maintainers run. This overlaps heavily with Debusine: we already need to run Lintian on packages uploaded to Debusine, we can store results in a collection for regression analysis, and we maintain our own worker farm. It seems worth consolidating these and having Debusine generate the necessary data in a way that can be imported by UDD.\n\nWe would not expect a student to replace all the uses of external workers in UDD, but we would like to establish a pattern that can be used for the future.\n\n**Confirmed Mentor**: Stefano Rivera**How to contact the mentor:**[stefanor@debian.org](mailto:stefanor@debian.org)**Confirmed co-mentors:**Raphaël Hertzog ([hertzog@debian.org](mailto:hertzog@debian.org))**Difficulty level**: Medium (but the student will need to do some design work)**Project size:**175 hours (medium)**Deliverables of the project**:Debusine has a mechanism to regularly run a\n\n[workflow](https://freexian-team.pages.debian.net/debusine/explanation/concepts.html#workflows)to keep Lintian analyses of Debian unstable and experimental up to date in a[debian:qa-results](https://freexian-team.pages.debian.net/debusine/reference/collections/specs/qa-results.html)collection.- Debusine has a suitable API endpoint to allow UDD to query current Lintian analyses in bulk.\n- (Stretch goal:) UDD uses this new API endpoint and can retire its Lintian worker.\n\n**Desirable skills**: Competent Python, and basic Django and/or SQL.**What the intern will learn:**Debusine workflow design. How the plumbing behind Debian’s QA systems works.**Application tasks:**Pick a\n\n[Quick fix](https://salsa.debian.org/freexian-team/debusine/-/issues?sort=created_date&state=opened&label_name%5B%5D=Quick%20fix&first_page_size=100)issue from our list and try to fix it, including full test coverage for your changes.- Investigate how UDD’s Lintian importer works and prepare a brief report on the information it needs.\n\n**AI usage policy:**We will not accept applications written using LLMs, and we expect accepted students to write code themselves, not via an LLM.\n\n\n## Debusine: usability and papercuts\n\n**Description of the project:** Debusine is now usable by Debian developers and maintainers to perform a variety of QA-related experiments and to host package repositories. However, we have often needed to focus mainly on feature development, and there are plenty of areas where the system is not as usable as we would like. Many of these are relatively small and self-contained tasks that would be ideal for an enthusiastic student to try.\n\n**Confirmed Mentor**: Stefano Rivera**How to contact the mentor:**[stefanor@debian.org](mailto:stefanor@debian.org)**Confirmed co-mentors:**None confirmed, but other people from the[Debusine team](https://freexian-team.pages.debian.net/debusine/reference/development-team-organization.html#current-team-organization)can help if needed.**Difficulty level**: Easy to medium, depending on issue selection**Project size:**This project can be split into many small pieces and so can be any of 90 (small), 175 (medium), or 350 (large) hours depending on student availability.**Deliverables of the project**:- Improvements to the usability of Debusine, scope to be defined with the student.\n\n**Desirable skills**: Web application development, preferably in Python with Django. Debian packaging skills are helpful in order to properly understand the problem domain, but can also be taught as we go along.**What the intern will learn:**Development practices for a medium-sized real-world software development platform. Web user interface design. How the pieces of preparing high-quality changes to sets of Debian packages fit together.**Application tasks:****AI usage policy:**We will not accept applications written using LLMs, and we expect accepted students to write code themselves, not via an LLM.\n\n\n## Improving Salsa CI\n\n**Description of the project:** Salsa CI is a custom-built continuous integration framework that is used in the Debian Gitlab instance (Salsa) and helps Debian maintainers manage tens of thousands projects. The Salsa CI pipeline emulates the Debian build process and runs several Debian quality tests, helping to detect issues **before** packages are uploaded to the Debian archive. When new source code triggers a Salsa CI pipeline, several different jobs run to build and test it automatically. Salsa CI checks to see whether the to-be-uploaded packages build on multiple architectures, runs autopkgtest test suites to try to identify potential regressions, and checks for common errors with our custom linter, lintian, among other tests. There are different ways to improve Salsa CI that could benefit from the work of a GSoC student.\n\n**Confirmed Mentor**: Santiago Ruano Rincón**How to contact the mentor:**[santiago@debian.org](mailto:santiago@debian.org)/ santiago @ irc.oftc.net**Confirmed co-mentors:**Emmanuel Arias <[eamanu@debian.org](mailto:eamanu@debian.org)>**Difficulty level**: Medium**Project size:**175 (medium) or 350 (large), depending on student's availability**Deliverables of the project**: Fix issues reported against Salsa CI (see below). Specially issues labeled as \"Nice-to-have\", \"Accepting MRs\".**Desirable skills**: Awareness of the Gitlab CI/CD support. Collaborative work relying on 'git' and asynchronous-remote tools. Basic knowledge of Debian packaging.**What the intern will learn:**Debian Release process, Debian package building, Debian CI process, Basic QA of Debian packages. Development on a collaborative small team, inside a large community (Debian).**Application tasks:**Pick issues from here (\n\n[https://salsa.debian.org/salsa-ci-team/pipeline/-/issues/?sort=created_asc&state=opened&first_page_size=20=](https://salsa.debian.org/salsa-ci-team/pipeline/-/issues/?sort=created_asc&state=opened&first_page_size=20=), discuss with the team and aim to fix them. Example of priority issues:[https://salsa.debian.org/salsa-ci-team/pipeline/-/issues/318](https://salsa.debian.org/salsa-ci-team/pipeline/-/issues/318)(to minimise the changes of introducing regressions when doing a MR against the pipeline)[https://salsa.debian.org/salsa-ci-team/pipeline/-/issues/498](https://salsa.debian.org/salsa-ci-team/pipeline/-/issues/498)(to make it possible to have runners different to the instance shared runner) More resources:\n\n**AI usage policy:**We will not accept applications written using LLMs, and we expect accepted students to write code themselves, not via an LLM.\n\n\n## Linux Livepatching\n\n**Description of the project:** Evaluate if it's possible to rely on klp-build and clang-extract to bootstrap linux livepatching in Debian. There has been a first attemp to support linux livepatching in Debian, relying on kpatch. However, starting with trixie, kpatch does no longer support the kernel, which prevents us to continue using this approach. SUSE's klp-build overcomes the difficulties found with kpatch, but we need to confirm it's actually possible to package and use it. Also, Debian currently lacks a standardized workflow to build, distribute and publish livepatches for its kernels. The goal of this project is not only package and evaluate klp-build, but also explore and propose a solution about how linux livepatches could built, packaged and made available to Debian users in a controlled, safety and reproducible way.\n\n**Confirmed Mentor**: Emmanuel Arias**How to contact the mentor:**[eamanu@debian.org](mailto:eamanu@debian.org)**Confirmed co-mentors:**Santiago Ruano Rincón <[santiago@debian.org](mailto:santiago@debian.org)>**Difficulty level**: Medium to Hard**Project size:**350 hour (large)**Deliverables of the project**:- Packaging of clang-extract and klp-build\n- Study of support of the debian kernel by klp-build.\n- Proposal of a mechanism to release Kernel patches.\n\n**Desirable skills**: C Language knowledge. Linux Kernel knowledge desirable. Basic knowledge about Debian packaging. Competent Python. Collaborative work relying on 'git' and asynchronous tools.**What the intern will learn:**- How Linux livepatching works.\n- Debian Packaging.\n- Development on a collaborative small team, inside a large community (Debian).\n\n**Application tasks:**Finish the linux-livepatching Intent to Package (ITP) bug (\n\n[https://bugs.debian.org/1070494](https://bugs.debian.org/1070494)), and for that, the student will need to:Package clang-extract (\n\n[https://bugs.debian.org/1117623](https://bugs.debian.org/1117623)) and klp-build.- Confirm that klp-build is useful for the current Debian Linux Kernels.\n- Propose a distributable Linux Kernel livepatch format to Debian users.\n- Propose a mechanism to release Kernel patches.\n\n\n**More resources:****AI usage policy:**We will not accept applications written using LLMs, and we expect accepted students to write code themselves, not via an LLM.\n\nTo add a new project proposal, please enter a WikiName in one of the boxes below (the contents will be used as a wiki page name, please **avoid spaces**) and hit the button! Then, fill in the template, and drop us a line on the debian-outreach mailing-list.\n\n**Please note that below projects aren't approved yet. Please don't apply for non-approved projects. The list of approved projects is available above. **\n\n\n# Unapproved Projects with confirmed mentors"
  },
  {
    "name": "Sugar Labs",
    "slug": "sugar-labs",
    "tagline": "Learning software for children",
    "description": "Sugar is an activity-focused, free/libre open-source software (FLOSS) learning platform for children. Collaboration, reflection, and discovery are integrated directly into the user interface. Through Sugar's clarity of design, children and teachers have the opportunity to use computers on their own terms. Students can reshape, reinvent, and reapply both software and content into powerful learning activities. Sugar's focus on sharing, constructive criticism, and exploration is grounded in the culture of free software and the ideals of learn-by-doing \"Constructionism\".",
    "ideas_url": "https://github.com/sugarlabs/GSoC/blob/master/Ideas-2026.md",
    "website_url": "https://sugarlabs.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "gtk",
      "typescript",
      "javascipt",
      "LLM"
    ],
    "topic_tags": [
      "education",
      "programming languages",
      "games",
      "desktop",
      "generative AI"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/sugar-labs",
    "ideas_content": "# Google Summer of Code 2026 Project Ideas\n\n* [Git Backend for Music Blocks Part 2](#git-backend-for-music-blocks-part-2)\n* [GTK4 Transition Part 1 Fructose](#gtk4-transition-part-1-fructose)\n* [GTK4 Transition Part 2 Sugar Shell](#gtk4-transition-part-2-sugar-shell)\n* [GTK4 Transition Part 3 Wayland](#gtk4-transition-part-3-wayland)\n* [Sugar Activity on Demand](#sugar-activity-on-demand)\n* [AI Optimization](#ai-optimization)\n* [AI Reflection in the Sugar Journal](#ai-reflection-in-the-sugar-journal)\n* [Music Blocks Maintenance](#music-blocks-maintenance)\n* [Music Blocks Performance](#music-blocks-performance)\n* [Music Blocks Temperament](#music-blocks-temperament)\n* [Music Blocks v4](#music-blocks-v4)\n* [Sugarizer Connect the Dots Activity](#sugarizer-connect-the-dots-activity)\n* [Speak-AI Multilingual Support](#speak-ai-multilingual-support)\n\n------------\n\n## Git Backend for Music Blocks Part 2\n\n**Prerequisites**<br>\n - Experience with Git\n - Experience with JavaScript\n - Experience with Music Blocks\n\n**Description**<br>\n\nPortfolio creation, reflection, and collaboration are important parts\nof the educational philosophy at Sugar Labs, and Git version control\nis a great way to explore all these things.\n\nLast summer (2025), Nikhil implemented the foundation for\ntransitioning the Music Blocks to a \"git-like\" version control\nsystem. His work included both backend and frontend implementations.\n\nThe goals for this summer are:\n\n* Smooth Transition from Planet: Fully transition existing Planet\n  projects to the new Git backend, ensuring students retain access to\n  their previous work.\n\n* Educate Students on Git: Introduce guided tutorials and interactive\n  features within Music Blocks to help students understand version\n  control and Git concepts.\n\n* Enhanced Collaboration & Reflection: Add features to encourage\n  students to explore, fork, and contribute to peers' projects while\n  reflecting on their own progress and learning journey.\n\nReferences:\n - <https://github.com/benikk/GSoC-2025>\n\n**Project Length**<br>\n\n**350** hours\n\n**Difficulty**<br>\n\n**Hard**<br>\n\n**Coding Mentors**<br>\n[Nikhil Bhatt](https://github.com/benikk) [Walter Bender](https://github.com/walterbender/)<br>\n\n**Assisting Mentors**<br>\n[Devin Ulibarri](https://github.com/pikurasa/) [Sumit Srivastava](https://github.com/sum2it)<br>\n\n-----------\n\n## GTK4 Transition Part 1 Fructose\n\n**Prerequisites**<br>\n- Experience with C\n- Experience with Python\n- Experience with GTK\n- Good understanding of Sugar Core architecture\n\n**Description**<br>\n\nGTK3, the toolkit Sugar has been built on for years, is approaching\nend-of-life. Meanwhile, GTK4 brings us:\n\n* Better performance with a modern rendering pipeline\n* Wayland support: critical for modern display servers\n* Improved accessibility out of the box\n* Future-proofing: GTK4 is where GNOME and the Linux desktop ecosystem are headed\n\nBut here's the thing: migrating isn't just about updating version\nnumbers. It's about ensuring Sugar can run on today's hardware,\ntoday's distros, and continue being relevant for the next generation\nof learners.\n\nLast summer (2025), Krish made [great\nheadway](https://www.sugarlabs.org/news/all/2026-1-11-how-to-gtk4) by\nmirgating the Sugar toolkit. That will be the basis of a number of\nprojects this summer.\n\nPart 1. Migrating the [Fructose](https://wiki.sugarlabs.org/go/Development_Team/Release/Modules) activity set\n\n**Project Task Checklist**\n\n**Steps to start**\n1. Set up the environment\n2. Pick an activity\n3. Port the activity\n4. Do extensive testing\n5. Review with your mentors\n\n**Project length**<br>\n**350** hours\n\n**Difficulty:**<br>\n**High**\n\n**Coding Mentors**<br>\n[Krish Pandya](https://github.com/mostlykiguess) [Ibiam Chihurumnaya](https://github.com/chimosky/)<br>\n\n**Assisting Mentors**<br>\n[Walter Bender](https://github.com/walterbender/) [Juan Pablo Ugarte](https://github.com/xjuan)\n\n-------------\n\n## GTK4 Transition Part 2 Sugar Shell\n\n**Prerequisites**<br>\n- Experience with C\n- Experience with Python\n- Experience with GTK\n- Good understanding of Sugar Core architecture\n\n**Description**<br>\n\nGTK3, the toolkit Sugar has been built on for years, is approaching\nend-of-life. Meanwhile, GTK4 brings us:\n\n* Better performance with a modern rendering pipeline\n* Wayland support: critical for modern display servers\n* Improved accessibility out of the box\n* Future-proofing: GTK4 is where GNOME and the Linux desktop ecosystem are headed\n\nBut here's the thing: migrating isn't just about updating version\nnumbers. It's about ensuring Sugar can run on today's hardware,\ntoday's distros, and continue being relevant for the next generation\nof learners.\n\nLast summer (2025), Krish made [great\nheadway](https://www.sugarlabs.org/news/all/2026-1-11-how-to-gtk4) by\nmirgating the Sugar toolkit. That will be the basis of a number of\nprojects this summer.\n\nPart 2. Migrating the Sugar Shell -- the desktop environment\nitself. This includes:<br>- The frame (the iconic Sugar border)<br>-\nThe Journal<br>- The neighborhood view<br>- Clipboard and palette\nsystems.\nThere's an open [PR](https://github.com/sugarlabs/sugar/pull/1019) for this, so look at it and base your work off it.\n\n**Project Task Checklist**\n\n**Steps to start**\n1. Set up the environment - Sugar Live Build.\n2. Install sugar-toolkit-gtk4\n3. Port and test Sugar shell\n4. Do extensive testing\n5. Review with your mentors\n\n**Project length**<br>\n**350** hours\n\n**Difficulty:**<br>\n**High**\n\n**Coding Mentors**<br>\n[Krish Pandya](https://github.com/mostlykiguess) [Ibiam Chihurumnaya](https://github.com/chimosky/)<br>\n\n**Assisting Mentors**<br>\n[Walter Bender](https://github.com/walterbender/) [Juan Pablo Ugarte](https://github.com/xjuan)\n\n-------------\n\n## GTK4 Transition Part 3 Wayland\n\n**Prerequisites**<br>\n- Experience with C\n- Experience with Python\n- Experience with GTK\n- Good understanding of Sugar Core architecture\n\n**Description**<br>\n\nGTK3, the toolkit Sugar has been built on for years, is approaching\nend-of-life. Meanwhile, GTK4 brings us:\n\n* Better performance with a modern rendering pipeline\n* Wayland support: critical for modern display servers\n* Improved accessibility out of the box\n* Future-proofing: GTK4 is where GNOME and the Linux desktop ecosystem are headed\n\nBut here's the thing: migrating isn't just about updating version\nnumbers. It's about ensuring Sugar can run on today's hardware,\ntoday's distros, and continue being relevant for the next generation\nof learners.\n\nLast summer (2025), Krish made [great\nheadway](https://www.sugarlabs.org/news/all/2026-1-11-how-to-gtk4) by\nmirgating the Sugar toolkit. That will be the basis of a number of\nprojects thuis summer:\n\nPart 3. Full Wayland support. Wayland is the modern display server\nprotocol replacing X11. Wayland is not today’s problem, but today’s\nGTK4 work is what makes it possible later. Some GTK4 work already\nhelps with Wayland (hello, Gtk.Popover!), but full integration\nrequires deep work in the shell and core systems.\nThere's an open [PR](https://github.com/sugarlabs/sugar/pull/1019)\nfor this, so look at it and base your work off it.\nThis PR uses [Casilda](https://gitlab.gnome.org/jpu/casilda/-/tree/main?ref_type=heads)\nas a wayland compositor for Sugar.\n\n**Project Task Checklist**\n\n**Steps to start**\n1. Set up the environment - Sugar Live Build.\n2. Install sugar-toolkit-gtk4\n3. Port and test Sugar shell\n4. Do extensive testing\n5. Review with your mentors\n\n**Project length**<br>**350** hours\n\n**Difficulty:**<br> High**\n\n**Coding Mentors**<br> [Krish Pandya](https://github.com/mostlykiguess) [Ibiam Chihurumnaya](https://github.com/chimosky/)<br>\n\n**Assisting Mentors**<br> [Walter Bender](https://github.com/walterbender/) [Juan Pablo Ugarte](https://github.com/xjuan)\n\n-------------\n\n## Sugar Activity on Demand\n\n**Prerequisites**<br>\n- Experience with Python\n- Good understanding of AI model deployment\n- Experience with Sugar activities\n\n\n**Description**<br>\n\nSugar Activities are the primary vehicle through which our user engage\nwith Sugar and its various features, such as collaboration, the\nJournal, etc. While we offer a wide variety of Activities, there are\nundoubtedly gaps. While we provide support for Activity development\n(including a pathway from Turtle Art through Pippy to Sugar Activity)\nand add new Activities, we could do more to support the user\ncommunity.\n\nAI-assisted code generation has turned a corner in terms of quality,\nwhich suggests we should be asking this question: \"Can we use LLMs to\ngenerate Sugar Activities on demand?\" In other words, have we reached\na threshold of quality in LLM-generated code where a student or\nteacher could describe an Activity to a model and get a fully\nfunctioning Sugar Activity in response?\n\nYou can take a look at the [Hello World](https://github.com/sugarlabs/hello-world) activity to see how a\nbasic Sugar activity looks and works.\n\nThis idea also requires that you have a working Sugar development environment,\n[setup a development environment](https://github.com/sugarlabs/sugar/blob/master/docs/development-environment.md) will help you setup one.\n\n**Project Length**<br>\n\n**350** hours\n\n**Difficulty**<br>\n\n**Hard**<br>\n\n**Coding Mentors**<br>\n[Walter Bender](https://github.com/walterbender/) [Ibiam Chihurumnaya](https://github.com/chimosky/)<br>\n\n-------------\n\n## AI Optimization\n\n**Prerequisites**<br>\n- Experience with Python\n- Good understanding of AI model deployment\n\n**Description**<br>\n\nWe deploy AI in many parts of Sugar, for example, in the Reflection\nWidget, the debugger, the Write Activity, etc. Last summer (2025), we\nbuilt Sugar-AI as a backend to support a variety of models and\ninterfaces. It is currently hosted on AWS and we have some credits\navailable to support the further development and testing of AI\nservices.\n\nThe goal of this project is to enable individuals and schools to use\ntheir own models. This is both to support the use of the plethora of\nemerging open models and to enable individuals and organizations that\nhave access to credits to utilize them. (Sugar Labs does not have the\nresources to provide free AI hosting on a large scale, hence we want\nto enable our users to leverage any resources that they have at hand.)\n\n**Steps to start**\nFamiliarize yourself with Sugar-AI\n\n**Project length**<br>**150** hours\n\n**Difficulty:**<br> Medium**\n\n**Coding Mentors**<br> [Krish Pandya](https://github.com/mostlykiguess) [Ibiam Chihurumnaya](https://github.com/chimosky/)<br>\n\n**Assisting Mentors**<br> [Walter Bender](https://github.com/walterbender/) [Sumit Srivastava](https://github.com/sum2it) [Om Santosh Suneri](https://github.com/omsuneri)<br>\n\n-------------\n\n## AI Reflection in the Sugar Journal\n\n**Prerequisites**<br>\n - Experience with Python\n - Experience with LLMs/Chatbots\n\n**Description**<br>\n\nWhile off-the-shelf Generative AI tools are great at helping a learner\nto create, they offer little in regard to reflecting upon those\ncreations. But reflection is a critical (and too often overlooked)\npart of the Constructionist learning pedagogy. With some prompting --\nsomething LLMs are quite good at -- we can engage the learner in a\nquality reflective practice. The dialog could occur when exiting any\nSugar activity as part of the journaling process. Rather than\njust being presented with an empty form, the learner will be prompted\nto talk about what they did, why they did it, what they learned and\nwhat they might do next.\n\nLast summer, Diwangshu built a [reflection\nwidget](https://www.sugarlabs.org/news/all/2025-09-01-gsoc-25-diwangshu-final-report)\nfor Music Blocks. This summer, we'd like to do the same for the Sugar\nJournal so that AI-assisted reflection is part of the overall Sugar\nexperience.\n\nSpecifically, we would be working toward accomplishing the following:\n\n- Research different approaches to reflective practice\n- Train open source LLM to generate code to prompt the learn with a multitude of these approaches to reflection\n- Develop FastApi endpoints to deploy the model.\n- Deploy this model in the Sugar Journal to be triggered whenever a project is paused or saved\n\n**Project Length**<br>\n\n**350** hours\n\n**Difficulty**<br>\n\n**Hard**<br>\n\n**Coding Mentors**<br>\n[Walter Bender](https://github.com/walterbender/) [Ibiam Chihurumnaya](https://github.com/chimosky/)<br>\n\n**Assisting Mentors**<br>\n[Diwangshu Kakoty](https://github.com/Commanderk3)\n[Aman Naik](https://github.com/amannaik247)\n\n-------------\n\n## Music Blocks Maintenance\n\n**Prerequisites**\n* Proficiency in **JavaScript**\n* Proficiency with CI/CD workflows\n* Familiarity with Music Blocks\n\n**Description**<br>\n\nWhile we are anticipating the arrival of Music Blocks v4 this summer,\nwe still need to maintain Music Blocks v3. This is largely a matter of\nensuring we have test coverage and we are keeping packages up to date.\n\nThis project is both to bring to completion the test suite that Om\nSantosh began last year (2025). It is also to review the packages used\nby Music Blocks and ensure that, whereever possible, the latest\npackages are being used. (Package dependency is a bit of a nightmere\nin Music Blocks.) The latter will require some updates to various\nsubsections -- for example, the latest JQuery breaks the search\nfunctionality.\n\n**Project Length**<br>\n\n**150** hours\n\n**Difficulty**<br>\n\n**Medium**<br>\n\n**Coding Mentors**<br>\n[Walter Bender](https://github.com/walterbender/) [Om Santosh Suneri](https://github.com/omsuneri)<br>\n\n-------------\n\n## Music Blocks Performance\n\n**Prerequisites**\n* Proficiency in **JavaScript**\n* Proficiency with CI/CD workflows\n* Familiarity with Music Blocks\n\n**Description**<br>\n\nWhile we are anticipating the arrival of Music Blocks v4 this summer,\nwe still have a large Music Blocks v3 community to support. In\nparticular three aspects of performance are impacting our users: (1)\nthe time needed to take to load the page; (2) lag in performance for\ncomplex projects; and (3) memory usage, especially as it impacts\noperations such as recursion.\n\nWhile we have done some incremental work, such as deferring the\nloading of some package loading, a hollistic approach is\nneeded. Google PageSpeed is a great tool to analysizing some aspects\nof performance and provides insights into where we can make\nimprovements.\n\nIn addition, this project can take a data-driven approach to prioritization. \nThis may include analyzing real-world usage patterns such as:\n(1) most-used blocks, (2) frequently combined blocks, (3) recursion depth,\n(4) project size, and (5) memory-intensive operations. \nThese insights can help guide optimization efforts and reduce testing time\nby telling us areas that have the greatest impact on users.\nThis might be done by implementing lightweight, privacy-friendly\ninstrumentation to collect anonymous statistical data (as mentioned above).\n\nThis project is try to address the performance issues.\n\n**Project Length**<br>\n\n**150** hours\n\n**Difficulty**<br>\n\n**Medium**<br>\n\n**Coding Mentors**<br>\n[Walter Bender](https://github.com/walterbender/) [Om Santosh Suneri](https://github.com/omsuneri)<br>\n\n-------------\n\n## Music Blocks Temperament\n\n**Prerequisites**\n* Proficiency in **JavaScript**\n* Familiarity with Music Blocks\n* Familiarity with temperament and mode in music\n\n**Description**\n\nTemperament and mode in music are seemingly advanced topics in music\ntheory, but we have an opportunity in Music Blocks to engage in these\nconcepts at the start of a student's musical education, leading a\nfuller, more musically rich experience.\n\nA simple, but compelling example is the [Musical Galton\nBox](https://github.com/sugarlabs/musicblocks/blob/master/examples/Galton-music.html),\nwhich drives home the power of mode using a random sequence of note\nprogressions.\n\nThe [Temperament\nWidget](https://github.com/sugarlabs/musicblocks/tree/master/Docs/guide#412-changing-temperament)\nmakes it possible to change and create different tuning systems within\nMusic Blocks. While most music software geared towards beginners is\nrestricted to 12 EDO (equal temperament or \"piano tuning\"), Music\nBlocks allows almost unlimited tuning options.\n\nThe problem is that when Music Blocks was first written, it did not\naccommodate this full range of temperaments. The current\nimplementation still has some artificts that cause some tuning choices\nto fail under some conditions, such as generating chords or pitch\nstepping.\n\nWith Music Blocks v4, we built a version of \"music utils\" that is more\nrobust regarding temperament. The goal of this project is to backport\nthis code to Music Blocks v3 so that we have the full expression of\ntemperament available.\n\n**Project Length**<br>\n\n**150** hours\n\n**Difficulty**<br>\n\n**Medium**<br>\n\n**Coding Mentors**<br>\n[Walter Bender](https://github.com/walterbender/) [Devin Ulibarri](https://github.com/pikurasa/)<br>\n\n-------------\n\n## Music Blocks v4\n\n**Prerequisites**\n\n* Proficiency in **TypeScript**\n* Proficiency in **JavaScript DOM API**\n* Experience with **React Functional Components and Hooks**\n\n**Description**\n\nPLACEHOLDER\n\n**Project Length:** **350** hours\n\n**Difficulty:** **Hard**\n\n**Tech Stack**\n\nTypeScript 5, React 18, Sass, Storybook, Vitest, Vite\n\n**Mentors**<br/>\n[Anindya Kundu](https://github.com/meganindya/)\n\n**Assisting Mentors**<br/>\n[Justin Charles](https://github.com/justin212407)<br/>\n[Safwan Sayeed](https://github.com/sa-fw-an)\n\n-------------\n\n## Sugarizer Connect the Dots Activity\n\n**Prerequisites**\n\n* Experience with Sugarizer platform and existing activities\n* Proficiency with JavaScript/HTML5 in VanillaJS or with Vue.js\n* Experience with Sugarizer activity development\n* Understanding of Sugarizer Core architecture\n\n**Project length**<br>\n**175** hours\n\n**Difficulty:** &#9733; &#9733; &#9734; (medium)\n\n**Description**<br>\nCreate a new activity inspired by the classic \"Connect the Dots\" game.\nThis activity will combine several modes of interaction to engage users in creative drawing, learning shapes, and strategic gameplay.\n\nThree distinct modes will be implemented:\n\n* ***Draw mode***: A very basic mode for young users. Let users create freely like in Gridpaint activity - inspired by [pok pok](https://playpokpok.com/res/img/video/connect-the-dots.mp4). In shared mode, all users are drawing together on the same board like in Paint activity.\n* ***Number mode***: The user chooses a template with numbered dots and has to connect them in the correct order - inspired by [connect-the-dots-activity](https://github.com/sugarlabs/connect-the-dots-activity/tree/master). In shared mode, all users compete to finish the template first like in Maze activity. It should also be possible to create and share new templates like in Calligra or Tangram activities.\n* ***Game mode***: Strategic mode to conquer territory, each users should fill a maximum part of the screen starting from a little square in a border - inspired by [paper io](https://github.com/sugarlabs/connect-the-dots-activity/tree/master). If the user is alone, an AI opponent will try to beat him. In shared mode, all users compete to conquer the most territory.\n\n**First steps to starts**<br>\n\n* Complete the [Sugarizer Vanilla Javascript activity development tutorial](https://github.com/llaske/sugarizer/blob/dev/docs/tutorial/VanillaJS/tutorial.md) or the [Sugarizer Vue.js activity development tutorial](https://github.com/llaske/sugarizer/blob/dev/docs/tutorial/VueJS/tutorial.md). Publish on [Discord](https://sugarizer.org/discord) a video of the Pawn activity running.\n* Think about the different modes features and how to implement them\n* Create a mockup of the activity UI\n* Develop a running prototype of some features\n\n**Mentor**<br>\n[Lionel Laské](https://github.com/llaske/)\n\n\n-------------\n\n## Speak-AI Multilingual Support\n\n**Prerequisites**<br>\n - Experience with Python\n - Experience with Text-to-Speech (TTS) systems\n\n**Description**<br>\n\nThe [Speak-AI activity](https://github.com/sugarlabs/speak-ai) is an enhanced version of the classic Speak activity that uses Kokoro TTS to provide more natural-sounding voices. However, current language support is limited.\n\nThis project aims to significantly expand Speak-AI's multilingual capabilities by adding support for the most commonly used languages, with a strong emphasis on achieving high-quality, natural pronunciation. Getting pronunciation right is the top priority, as accurate and natural-sounding speech is essential for language learning and accessibility.\n\n**Project Goals:**\n\n1. **Multilingual TTS Support**: Here are some of the languages that we want to add support for:\n   - Spanish\n   - Portuguese (Brazilian)\n   - Hindi\n   - French\n   - Arabic\n   - Swahili\n   - Quechua/Aymara\n   - Chinese (Mandarin)\n   - Kinyarwanda\n   - Gurani\n\n2. **Pronunciation Quality**: Prioritize accurate pronunciation through:\n   - Extending or replacing the current G2P (Grapheme-to-Phoneme) layer to better support non-Latin scripts (Arabic, Devanagari for Hindi, Chinese characters, etc.)\n   - Evaluating and potentially integrating alternative open-source TTS models that may provide better multilingual support\n   - Creating a language-specific testing and evaluation framework\n\n3. **Performance Optimization**: Improve the efficiency of the TTS system through:\n   - Investigating ONNX runtime integration for faster inference\n   - Optimizing TTS model loading and memory usage for resource-constrained devices\n   - Implementing caching strategies for commonly used phrases\n\n4. **Community Validation**: Work with native speakers from the Sugar Labs community to:\n   - Test and validate pronunciation quality for each added language\n   - Gather feedback\n   - Iterate on improvements based on community input\n\n**Technical Approach:**\n\nThe project will require research into various TTS backends and G2P systems to determine the best approach for each language family. Special attention must be paid to languages with complex phonological rules.\n\n**Steps to start:**\n1. Familiarize yourself with the current Speak-AI implementation\n2. Research TTS and G2P models for target languages\n3. Implement new TTS models / G2P systems within Speak-AI\n\n**Project length**<br>\n**90** hours\n\n**Project Size:**<br>\n**Small**\n\n**Coding Mentors**<br>\n[Mebin Thattil](https://github.com/mebinthattil) [Ibiam Chihurumnaya](https://github.com/chimosky/)<br>\n\n**Assisting Mentors**<br>\n[Walter Bender](https://github.com/walterbender/) [Devin Ulibarri](https://github.com/pikurasa/)<br>\n\n-------------\n\n# Administrative Notes\n\nAbove are a list of ideas we've planned for GSoC 2026 projects.\nIf you have any ideas which can be useful to us, but are not in the\nlist, we'd love to hear from you.  You need not be a potential\nstudent or a mentor to suggest ideas.\n\n   * [Criteria for Ideas](#criteria-for-ideas)\n   * [Coding Mentors](#coding-mentors)\n   * [Assisting Mentors](#assisting-mentors)\n   * [Everyone Else](#everyone-else)\n   * [Suggested Issues](#suggested-issues)\n\n## Criteria for Ideas\n\n1. Does it fill an empty pedagogy niche in the activity set for Sugar\n   or Sugarizer,\n2. Does it increase quality of our software products (Sugar, activities,\n   Music Blocks, or Sugarizer),\n3. Does it _not_ involve any project infrastructure, e.g. not another\n   app store, web site, or developer landing page,\n4. Do we have a developer _now_ who would be willing and able to do it\n   if a student was not available, and who can _promise_ to do it if a\n   student is not selected; these are shown as a _coding mentor_,\n\n## Coding Mentors\n\nFor each idea, we must have offers from one or more _coding mentors_\nwilling and able to assist students with coding questions.\n\nRequirements for a _coding mentor_ are a demonstrated coding ability\nin the form of contributions of code to Sugar Labs.\n\nMentors for a project will be assigned after proposals are received.\n\n## Assisting Mentors\n\nFor each idea, we may have offers from mentors _who do not code_ but\nare willing to assist students in various other ways, such as\ngathering requirements, visual design, testing, and deployment; these\nare shown as an _assisting mentor_.\n\nThe only requirement for an _assisting mentor_ is _knowledge of\nthe project_.\n\nMentors for a project will be assigned after proposals are received.\n\n## Everyone Else\n\nEveryone else in Sugar Labs may also be involved with these\nprojects, through mailing lists, Wiki, and GitHub.\n\nThe difference between a _mentor_ and _everyone else_, is that a\n_mentor_ is obliged to respond when a student has a question, even if\nthe answer is \"I don't know.\"  When a _mentor_ receives a question for\nwhich the best forum is _everyone else_, then they are to respectively\nredirect the student to ask _everyone else_.  See [\"Be\nflexible\"](https://github.com/sugarlabs/sugar-docs/blob/master/src/CODE_OF_CONDUCT.md#be-flexible)\nand [\"When you are unsure, ask for\nhelp\"](https://github.com/sugarlabs/sugar-docs/blob/master/src/CODE_OF_CONDUCT.md#when-you-are-unsure-ask-for-help)\nin our Code of Conduct.\n\n## Suggested Issues\n\nFor some ideas, there is a list of 'Suggested issues to work on'.\nThese may help you to get familiar with the project.  The more\nyou work on these issues, the more experienced you will be for\nthe project.  However, this is not a strict list.  You _should_\ntry and explore other issues as well."
  },
  {
    "name": "The ns-3 Network Simulator Project",
    "slug": "the-ns-3-network-simulator-project",
    "tagline": "ns-3 is a simulation tool for computer networks.",
    "description": "Are you interested in contributing to a widely-used performance evaluation tool for computer networking research? ns-3 is a *discrete-event, packet-level network simulator* with an emphasis on networking research and education. Users of ns-3 can construct simulations of computer networks using models of traffic generators, protocols such as TCP/IP, and devices and channels such as Wi-Fi and LTE, and analyze or visualize the results. Simulation plays a vital role in the research and education process, because of the ability for simulations to obtain reproducible results (particularly for wireless protocol design), scale to large networks, and study systems that have not yet been implemented. A particular emphasis in ns-3 is a high degree of realism in the models (including frameworks for using real application and kernel code) and integration of the tool with virtual machine environments and testbeds. Very large scale simulations are possible; simulations of hundreds of millions of nodes have been published.  ns-3 has been in development since 2005 and has been making regular releases since June 2008.  The simulator is written in C++, with bindings for Python scripting, and uses the CMake build system.  We use a GPLv2 licensing model and heavily use mailing lists and Zulip chat, but typically not other social media.",
    "ideas_url": "https://www.nsnam.org/wiki/GSOC2026Projects",
    "website_url": "https://www.nsnam.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "django",
      "c++"
    ],
    "topic_tags": [
      "computer networking",
      "network simulation"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/the-ns-3-network-simulator-project",
    "ideas_content": "# GSOC2026Projects\n\n[Jump to navigation](https://www.nsnam.org#mw-head)\n\n[Jump to search](https://www.nsnam.org#searchInput)\n\n[Main Page](https://www.nsnam.org/wiki/Main_Page) - [Roadmap](https://www.nsnam.org/wiki/Roadmap) - [Summer Projects](https://www.nsnam.org/wiki/Summer_Projects) - [Project Ideas](https://www.nsnam.org/wiki/Project_Ideas) - [Developer FAQ](https://www.nsnam.org/wiki/Developer_FAQ) - [Tools](https://www.nsnam.org/wiki/Tools) - [Related Projects](https://www.nsnam.org/wiki/Related_Projects)\n\n[HOWTOs](https://www.nsnam.org/wiki/HOWTOs) - [Installation](https://www.nsnam.org/wiki/Installation) - [Troubleshooting](https://www.nsnam.org/wiki/Troubleshooting) - [User FAQ](https://www.nsnam.org/wiki/User_FAQ) - [Samples](https://www.nsnam.org/wiki/Category:Samples) - [Models](https://www.nsnam.org/wiki/Category:Models) - [Education](https://www.nsnam.org/wiki/Education) - [Contributed Code](https://www.nsnam.org/wiki/Contributed_Code) - [Papers](https://www.nsnam.org/wiki/Papers)\n\nThis page contains 2026 Google Summer of Code project ideas for ns-3.\n\n[GSoC Frequently Asked Questions](https://developers.google.com/open-source/gsoc/faq)[ns-3's 2026 GSoC Contributor guide](https://www.nsnam.org/wiki/GSOC2026ContributorGuide)[GSoC contributor/student guide (not ns-3 specific)](https://developers.google.com/open-source/gsoc/resources/guide)[2026 GSoC Contributor application template](https://www.nsnam.org/wiki/GSOC2025ApplicationTemplate)[ns-3's GSoC Mentor guide](https://www.nsnam.org/wiki/GSOCMentorGuide)[GSoC Mentor guide (not ns-3 specific)](https://archive.flossmanuals.net/gsocmentoring/index.html)[GSoC Contributor Selection Process](https://www.nsnam.org/wiki/GSOCSelectionProcess)*Get in contact with the ns-3 team*:[ns-developers mailing list](https://groups.google.com/g/ns-developers)|*chat*[https://ns-3.zulipchat.com/](https://ns-3.zulipchat.com/)\n\n### About the ns-3 project\n\nns-3 is a discrete-event network simulator, with a particular emphasis on network research and education.\n\nUsers of ns-3 can construct simulations of computer networks using models of traffic generators, protocols such as TCP/IP, and devices and channels such as WiFi, and analyze or visualize the results. Simulation plays a vital role in the research and education process, because of the ability for simulations to obtain reproducible results (particularly for wireless protocol design), scale to large networks, and study systems that have not yet been implemented. A particular emphasis in ns-3 is the high degree of realism in the models (including frameworks for real application and kernel code) and integration of the tool with virtual machine environments and testbeds; we view that researchers need to move more effortlessly between simulation, testbeds, and live experiments, and ns-3 is designed to facilitate that.\n\nns-3 has participated in past GSoCs during 2008-10, 2012-15, and 2017-25. We seek contributors interested in the intersection of wireless and computer networking, performance analysis, and open source software.\n\n### Org admins\n\nGoogle Summer of Code organizational admins for ns-3 are [Tommaso Pecorella](mailto:tpecorella@mac.com) and [Mohit P. Tahiliani](mailto:tahiliani.nitk@gmail.com); contact them with any questions. They also hang out on [Zulip](https://ns-3.zulipchat.com).\n\n### Mentors\n\nMentors will be paired with contributors based on the projects that are selected. Mentors from companies are welcome, if the employer will permit the mentor sufficient time to perform the mentoring. Prospective mentors should notify Mohit P. Tahiliani or Tommaso Pecorella of interest. Mentors familiar with ns-3 development practices will be preferred, to improve the chances of code merge. We are going to be seeking two-person or multiple-person mentoring teams for projects, to help with the mentoring workload and bring more expertise.\n\nThe current list of prospective mentors can be found among the ideas listed below.\n\n### How to apply\n\nFor students or contributors interested in applying to ns-3 for GSoC, please go through the following list to get started:\n\n- Read the official\n[GSoC contributor guide](https://developers.google.com/open-source/gsoc/resources/guide). - Read\n[ns-3's 2026 GSoC contributor guide](https://www.nsnam.org/wiki/GSOC2026ContributorGuide) - Look through our\n[#Project Ideas](https://www.nsnam.org#Project_Ideas)below to see if you find a project that interests you. - Review the\n[tutorial and contributing guide](https://www.nsnam.org/documentation/development-tree/)thoroughly, if you have not already done so. - Once it is posted, look through the\n[GSoC application template](https://www.nsnam.org/wiki/GSOC2024ApplicationTemplate)to start preparing your proposal. We will wait to see whether we are actually part of GSoC before updating the above link for 2026, but it will be similar to last year's application. - Next, proceed to get in touch with the developers on the mailing list or Zulip chat room and refine your proposal.\n- In parallel, make sure you prepare a patch as per the patch requirement guidelines. Your application to ns-3 will not be considered if you do not fulfill this requirement.\n\nBelow is a list of [#Project Ideas](https://www.nsnam.org#Project_Ideas) proposed by the ns-3 team for Google Summer of Code 2026. Please note that these ideas are not limited to GSoC; anyone is welcome to work on them. Please email the [ns-developers list](https://groups.google.com/g/ns-developers) if you have a different idea that you'd like to work on, to see if a mentor may be interested. Applicants are encouraged to look over this list, pick one that especially interests them, think about it, and discuss potential approaches on the [ns-developers list](https://groups.google.com/g/ns-developers). Previous experience with the Google Summer of Code programs suggests that the more you discuss and refine your proposal on the mailing list beforehand, the stronger the proposal it will develop into, and the higher your chances of being accepted into the program.\n\nEach project idea within a particular priority has been tagged with the following properties:\n\n\nRequired Experience:Languages, concepts, or packages with which applicants must be familiar.Bonus Experience:Other experience or familiarity which would be greatly helpful to applicants for this project.Interests:Areas of particular relevance to this project, and an indicator of where successful contributors might apply their experiences coming out of this project.Difficulty:easy, medium or difficultRecommended reading:pointers to documentation, papers, specific bugs, etc.Note that all of the projects require some experience and comfort with C++. Project ideas for which C++ is noted as a required experience will require more and deeper familiarity with the language. A similar notion applies to computer networking, BSD sockets, etc: Familiarity is strongly preferred, but is not required except where explicitly noted due to the topic being more advanced in that regard. A few projects are more Python-centric.\n\n\n### Patch requirement guidelines\n\nIn past years, we have asked applicants to submit a patch related to an open issue or a suggested coding exercise. We are undecided at this time whether we will ask for this in 2026; check back later.\n\n### Mentors: how to participate\n\nThe ns-3 project is open to the proposal of new project ideas by developers interested in being a GSoC mentor. For mentors who're adding project ideas to the list below, please ensure that:\n\n- The projects are sized such that there can be a code merge by the end of the coding period. The scope of the project should be such that it is very difficult to *not* have a code merge by the end of the summer.\n- The proposed projects are not too open-ended. That is, if the deliverables or a clear path to the same are not well understood, it is better kept outside GSOC.\n- There should be a clear merge path to one of the main project code repositories (ns-3-dev, ns-3-dce, bake) by the end of the summer, either because the patches directly apply to these repositories, or because they apply to an ns-3 module that is in the process of being merged with ns-3-dev.\n\n## Project Ideas\n\n**Note to contributors:** These ideas are not listed in any priority order.\nThe projects can be grouped depending on their scope and/or their size. Below they are organized according to their scope. Please check each idea for details about its foreseen difficulty level.\n\n### Internet models enhancements\n\n[#Flent Application API in ns-3](https://www.nsnam.org#Flent_Application_API_in_ns-3)(small size project, 90h)[#Ping and TraverouteV4 enhancements](https://www.nsnam.org#Ping_and_TraverouteV4_enhancements)(small size project, 90h)[#Internet routing refactory](https://www.nsnam.org#Internet_routing_refactory)(small size project, 90h)[#AODVv2 Protocol enhancements](https://www.nsnam.org#AODVv2_Protocol_enhancements)(medium size project, 175h)[#Linux-like CAKE queue discipline for ns-3](https://www.nsnam.org#Linux-like_CAKE_queue_discipline_for_ns-3)(large size project, 350h)[#Switched Ethernet](https://www.nsnam.org#Switched_Ethernet)(large size project, 350h)\n\n### IoT models enhancements\n\n[#6LoWPAN mesh-under routing enhancements](https://www.nsnam.org#6LoWPAN_mesh-under_routing_enhancements)(medium size project, 175h)[#6LoWPAN neighbor discovery protocol](https://www.nsnam.org#6LoWPAN_neighbor_discovery_protocol)(medium size project, 175h)[#Mesh Link Establishment (MLE) protocol](https://www.nsnam.org#Mesh_Link_Establishment_(MLE)_protocol)(large size project, 350h)\n\n### 5G NR models enhancements\n\nThe general idea is to improve the usability of the 5G NR module by adding new examples that help users start building scenario scripts. Also, an interesting improvement could be integration with other modules, like those for AI or visualizations. Here are some project ideas. Depending on the contributor's interest and skills we can adjust these projects' definitions.\n\n[#OLLA Link Adaptation and Spec-Compliant TBS Calculation for 5G-LENA](https://www.nsnam.org#OLLA_Link_Adaptation_and_Spec-Compliant_TBS_Calculation_for_5G-LENA)(medium size project, 175h)[#Enabling 5G NR examples visualization](https://www.nsnam.org#Enabling_5G_NR_examples_visualization)(medium size project, 175h)[#Energy Consumption Modeling and Power-Aware Extensions for 5G-LENA](https://www.nsnam.org#Energy_Consumption_Modeling_and_Power-Aware_Extensions_for_5G-LENA)(medium size project, 250h)[#5G NR module integration with ns-3-ai](https://www.nsnam.org#5G_NR_module_integration_with_ns-3-ai)(large size project, 250h)\n\n## Small sized projects (90 hours)\n\n### Flent Application API in ns-3\n\nMentors: [Mohit P. Tahiliani](mailto:tahiliani.nitk@gmail.com)\n\nFlexible Network Tester (Flent) is a network benchmarking tool. It is written in Python and wraps well-known network benchmarking tools (such as netperf and iperf) into aggregate, repeatable tests, such as a number of tests for Bufferbloat. A basic structure for Flent Application API in ns-3 has been developed. It is a wrapper around existing ns-3 applications. This project has four main goals: (1) update this implementation to match the current ns-3-dev, (2) integrate a JSON library properly (for Flent-style result handling) (3) validate correctness of Flent results produced by ns-3, and (4) Add more Flent-style test examples useful for ns-3 users. The goal of this project is to merge the Flent Application API into ns-3 mainline, not the app store.\n\n*Required Experience:*Familiarity with Flent and C++ programming.*Bonus Experience:*Familiarity with applications supported in ns-3.*Interests:*Bufferbloat, TCP, AQM algorithms and ECN.*Difficulty:*Medium.*Recommended Reading:*- Flexible Network Tester [\n[Paper](https://flent.org/flent-the-flexible-network-tester.pdf)] [[Tool](https://flent.org/)] [Existing Applications in ns-3](https://www.nsnam.org/doxygen/d9/dc9/group__applications.html#details)[Prior work on Flent application API in ns-3](https://gitlab.com/tomhenderson/ns-3-dev/-/commits/flent?ref_type=heads)\n\n- Flexible Network Tester [\n\n### Internet routing refactory\n\nMentors: [Tommaso Pecorella](mailto:tommaso.pecorella@unifi.it), [TBD].\n\nTraditionally IP routing tables are organized in tuples {Dst, DstMask, GatewayAddr}, e.g., {10.42.66.0, 255.255.255.0, 169.254.10.1}, plus other flags and data, like the interface to be used. In ns-3 this is accomplished by storing three separate objects, two Ipv[4,6]Address, and one Ipv[4Mask,6Prefix].\n\nWhile this is quite simple to implement, this has some notable drawbacks, e.g., the Dst address must be a network address (Dst & ~DstMask == 0), it is not efficient (the mask or prefix could be represented by a simple integer), and more. In order to improve code readability and consistency between IPv4 and IPv6, !2645 introduces two new classes: Ipv[4,6]NetworkAddress.\n\nThe goal is to refactor the existing routing classes, along with Ipv[4,6]RotingTable classes, so that they use the new classes. The candidate should provide a clear and convincing plan to pursue the above mentioned goal, all while keeping backward compatibility. The APIs of the existing classes must be kept as they are (at most the can be deprecated), and new APIs should be introduced only where strictly necessary. Another very important requirement will be to break down the work in multiple sub-tasks, so that the merge process can be gradual.\n\nIt is not required that the candidate will update the code for all the routing schemes, but the choice of which routing algorithms will be considered during the project must be clear and motivated.\n\n*Required Experience:*Fundamentals of IPv6 addressing and routing, C++ programming.*Interests:*IPv4 and IPv6 routing*Difficulty:*Easy.*Recommended reading:*\n\nPossible tasks to fulfill the patch requirement:\n\n- Use !2645 to modify all or in part the `Rip` protocol.\n\n### Ping and TraverouteV4 enhancements\n\nMentors: [Tommaso Pecorella](mailto:tommaso.pecorella@unifi.it), [TBD].\n\nThe Ping and TraverouteV4 ns-3 application have some small limitations.\n\nIn particular 2 of them are annoying. 1. Neither Ping nor TracerouteV4 reacts to ICMP errors or informative messages. 2. As the name implies, TracerouteV4 is IPv4-only and can't be used on IPv6.\n\nThe goal is to remove the above mentioned limitations, all or in part. A proposal should clearly outline the plan and improvements to the existing code (e.g., the list of the ICMP messages that will be considered), and a clear breakdown of the work. For the TracerouteV4 refactoring to use IPv6 as well, the proposal must consider the Ping implementation as a guideline.\n\n*Required Experience:*Fundamentals of IPv4, IPv6, ICMP, and ICMPv6. C++ programming.*Interests:*IPv4 and IPv6.*Difficulty:*Easy.*Recommended reading:*\n\nPossible tasks to fulfill the patch requirement:\n\n- MR to have Ping react to one ICMP message.\n\n## Medium sized projects (175 hours)\n\n### 6LoWPAN mesh-under routing enhancements\n\nMentors: [Tommaso Pecorella](mailto:tommaso.pecorella@unifi.it), [TBD].\n\nThe 6LoWPAN module offers a simple option to implement a multi-hop topology by using a contolled flooding. However, the implemented controlled flooding is very simple, and is not efficient in complex networks. This is mainly due to the lack of congestion control, or rather its naive implementation. Better approaches are possible, e.g., by leveraging some concepts from RFC 7731, by using SNR as a guidance, or by measuring the local network activity.\n\nThe candidate should outline the proposed approach, what parts of code are going to be affected, and how they can be enhanced.\n\n*Required Experience:*Fundamentals of IPv6 addressing, C++ programming.*Bonus Experience:*Familiarity with mesh routing and 6LoWPAN ns-3*Interests:*IPv6 mesh routing*Difficulty:*Easy.*Recommended reading:*[Mesh-under in ns-3 6LoWPAN](https://www.nsnam.org/docs/models/html/sixlowpan.html#mesh-under-routing)[RFC 7731](https://datatracker.ietf.org/doc/html/rfc7731)[Meshtastic controlled flooding](https://meshtastic.org/docs/overview/mesh-algo/)[Routing by controlled flooding in communication networks](https://ieeexplore.ieee.org/document/91339)(if the document can not be accessed, PM the mentors)\n\n\nPossible tasks to fulfill the patch requirement:\n\n- The current code is hardwired, i.e., the mesh-under routing scheme is embedded into the SixLowPanNetDevice. Propose a patch to decouple it, using a SixLowPanMeshUnderRouting class to determine the \"next hop\". The behavior of the actual protocol should be unchanged.\n\n### 6LoWPAN neighbor discovery protocol\n\nMentors: [Tommaso Pecorella](mailto:tommaso.pecorella@unifi.it), [Adnan Rashid](mailto:adnan.rashid@poliba.it).\n\nThe 6LoWPAN-ND (RFCs 4944, 6775, and 8505) is a replacement for IPv6 DAD and NDP for 6LoWPAN networks, and it is important to ensure address uniquness across a network that can potentially use different MAC/PHY layers.\n\nThere is a model for 6LoWPAN-ND, but it still not merged in the main ns-3 branch. The goal is to help merging the code (if it's not already merged) and add some features that are not yet considered in the model.\n\nThe candidate should outline in the proposal the features that are planned to be added, and a code mockup (or a complete class diagram) for said features.\n\n*Required Experience:*Fundamentals of IPv6 addressing, C++ programming.*Bonus Experience:*Familiarity with 6LoWPAN and 6LoWPAN-ND*Interests:*IPv6 and IoT networks*Difficulty:*Easy.*Recommended reading:*\n\n### OLLA Link Adaptation and Spec-Compliant TBS Calculation for 5G-LENA\n\nMentors: [Sandra Lagen](mailto:slagen@cttc.es), [Biljana Bojovic](mailto:bbojovic@cttc.es), [Gabriel Ferreira](mailto:gcarvalho@cttc.es), [Katerina Koutlia](mailto:kkoutlia@cttc.es)\n\nThis project would focus on improving the realism and correctness of the CTTC 5G-LENA (NR module) by implementing Outer Loop Link Adaptation (OLLA) in the scheduling/link adaptation workflow, and by improving the Transport Block Size (TBS) calculation to be aligned with the 5G NR specification. OLLA is commonly used to track a target BLER by updating an SINR (or CQI) offset based on HARQ ACK/NACK feedback, leading to more stable and realistic link adaptation behavior. In addition, the project would include a performance evaluation comparing the new OLLA-enabled behavior against the current baseline and across multiple existing NR schedulers. The evaluation should consider throughput, latency, achieved BLER, convergence behavior, and fairness.\n\nFor starters, we would suggest adding the CTTC 5G-LENA (nr module) to ns-3 (as a module in the contrib/ directory), building and running the NR examples, and becoming familiar with the current scheduler, HARQ feedback flow, CQI/MCS selection, and TBS computation. Documentation is available here: [https://5g-lena.cttc.es/](https://5g-lena.cttc.es/). There is an overview tutorial video available here: [https://acmse.net/2021/tutorials-offered/#tut-work03](https://acmse.net/2021/tutorials-offered/#tut-work03). That is the background information.\n\n- Required Experience: C++ programming, understanding of 5G NR MAC concepts (scheduling, CQI/MCS, HARQ), wireless networking fundamentals\n- Interests: 5G NR simulations, scheduling, link adaptation, performance evaluation\n- Difficulty: Medium\n- Project size: Medium\n- Patch requirement: See the\n[description](https://www.nsnam.org/wiki/GSOC2024PatchRequirement). You can also consider some of the[nr good to start issues](https://gitlab.com/cttc-lena/nr/-/issues/?label_name%5B%5D=good%20first%20issue). Or, you can start writing some APIs for the selected project proposal. Also, if you have some previous MRs to ns-3 or the nr module, you can contact us to check whether it is enough for the patch requirement.\n\n### Enabling 5G NR examples visualization\n\nMentors: [Amir Ashtari Gargari](mailto:aashtari@cttc.es), [Gabriel Ferreira](mailto:gcarvalho@cttc.es), [Biljana Bojovic](mailto:bbojovic@cttc.es) and [Katerina Koutlia](mailto:kkoutlia@cttc.es)\n\nThe main idea of this project is to allow easier visualization of 5G NR examples by integrating the NR module with some ns-3 visualization tools like NetAnim, or by implementing a kind of web-based visualization, e.g., through Jupyter notebook. The new feature should allow the visualization of already existing traces, visualization of topology, or even some new relevant simulation aspects could be considered. The idea is that users better understand how the metrics collection works, and how changing parameters can affect simulation results. In this project, we are open to other ideas on how to implement visualizations.\n\nFor starters, we would suggest adding the CTTC 5G-LENA (nr module) to ns-3, in the typical way (as a module in the contrib/ directory), then building and running the examples. After getting used to C++, then proceed to use the Python bindings, as described by the documentation: [https://www.nsnam.org/docs/manual/html/python.html#using-the-bindings-from-the-ns-3-source](https://www.nsnam.org/docs/manual/html/python.html#using-the-bindings-from-the-ns-3-source).\nDocumentation is available here: [https://5g-lena.cttc.es/](https://5g-lena.cttc.es/). There is an overview tutorial video available here: [https://acmse.net/2021/tutorials-offered/#tut-work03](https://acmse.net/2021/tutorials-offered/#tut-work03). That is the background information. For more specific guidelines, please view this [Google document](https://docs.google.com/document/d/1cQLIF1cdft1yj3vyWrjrxN2xDJMx8PuWaa9NP_nKf64/edit?usp=sharing).\n\n- Required Experience: C++ and Python programming, understanding of 5G NR, LTE, and wireless networks\n- Interests: 5G NR simulations\n- Difficulty: Medium.\n- Patch requirement: See the\n[description](https://www.nsnam.org/wiki/GSOC2024PatchRequirement). You can also consider some of the[nr good to start issues](https://gitlab.com/cttc-lena/nr/-/issues/?label_name%5B%5D=good%20first%20issue). Or, you can start writing some APIs for the selected project proposal. Also, if you have some previous MRs to ns-3 or the nr module, you can contact us to check whether it is enough for the patch requirement.\n\n### AODVv2 Protocol enhancements\n\nMentors: [Tommaso Pecorella](mailto:tommaso.pecorella@unifi.it), [TBD].\n\nns-3 contains models for proactive (DSDV and OLSR) and reactive (AODV and DSR) ad hoc routing protocols. AODVv2 is currently an IETF draft, and its implementation in ns-3 is ongoing. This project aims at enhancing the AODVv2 model for ns-3.\n\nIn particular the project should address the following points:\n\n- Alignment with the latest drafts,\n- Model finalization and testing (in particular for the IPv6 part),\n- AODVv2 examples and documentation,\n- \"External\" network routing support.\n\nCollaboration with the draft authors is also highly suggested.\n\n*Required Experience:*Fundamentals of IPv6 addressing, C++ programming.*Bonus Experience:*Familiarity with AODV implementations in ns-3 and AODVv2*Interests:*Ad hoc routing*Difficulty:*Medium.*Recommended reading:*\n\nPossible tasks to fulfill the patch requirement:\n\n[Issue #368](https://gitlab.com/nsnam/ns-3-dev/-/issues/368)- aodv: aodv parameters can be set to \"impossible\" values\n\n## Large projects (350 hours)\n\n### Mesh Link Establishment (MLE) protocol\n\nMentors: [Tommaso Pecorella](mailto:tommaso.pecorella@unifi.it), [Alberto Gallegos Ramonet](mailto:alramonet@is.tokushima-u.ac.jp).\n\nThe Mesh Link Establishment (MLE) is a proposed IETF protocol for establishing and configuring secure radio links in IoT networks. It was originally proposed for IEEE 802.15.4, and the IETF draft seems to be not progressing. However, MLE is being used in Thread, and it can be useful to implement it.\n\nThe goal of the project is to study the differences between the IETF version of MLE and the one being used in Thread, and propose an implementation that complies with either, or both.\n\n*Required Experience:*Fundamentals of IPv4 and IPv6 sockets, C++ programming.*Interests:*Sockets and API interface implementation.*Difficulty:*Hard.*Recommended reading:*\n\nPossible tasks to fulfill the patch requirement:\n\n- TBD, contact the mentors if interested.\n\n### Energy Consumption Modeling and Power-Aware Extensions for 5G-LENA\n\nMentors: [Katerina Koutlia](mailto:kkoutlia@cttc.es), [Biljana Bojovic](mailto:bbojovic@cttc.es), [Marco Miozzo](mailto:mmiozzo@cttc.es) and [Amir Ashtari Gargari](mailto:aashtari@cttc.es)\n\nThis project would add energy consumption modeling to the CTTC 5G-LENA (NR module). While 5G-LENA provides a detailed and validated simulation of the 5G NR protocol stack behavior, it currently lacks energy models for UEs and/or gNBs, limiting research on energy efficiency, green networking, 6G sustainability, and potentially AI-driven power-aware control.\nThe project would first evaluate reuse of the ns-3 Energy Framework (e.g., EnergySource, DeviceEnergyModel) by defining a clean interface between 5G-LENA and the energy module. If existing models are insufficient, the project would design and implement a 5G-specific device energy model (e.g., NrDeviceEnergyModel) and connect it to relevant 5G-LENA state/procedure events.\nFor starters, we would suggest adding the CTTC 5G-LENA (nr module) to ns-3 (as a module in the contrib/ directory), building and running the NR examples, and studying the Energy Framework integration patterns. Documentation is available here: [https://5g-lena.cttc.es/](https://5g-lena.cttc.es/). Tutorial video: [https://acmse.net/2021/tutorials-offered/#tut-work03](https://acmse.net/2021/tutorials-offered/#tut-work03).\n\nScope (expected deliverables):\n\n- Energy consumption accounting for UEs and/or gNBs\n- Per-state (and if feasible per-procedure) modeling, e.g.\n- gNB: idle/active/sleep, TX/RX, processing; dependence on bandwidth/PRBs, TX power, MIMO layers/streams/RF chains, load\n- UE: TX/RX, measurements, CSI-RS/SRS activity, beamforming-related processing, handover\n\n- Tracing, example(s), and documentation\n\nOptional (time permitting): a simple energy-aware scheduling extension to explore QoS trade-offs (e.g., energy-per-bit or energy-aware MIMO under GBR)\n\n- Required Experience: C++ programming, wireless networking fundamentals (energy/state-machine modeling is a plus)\n- Interests: 5G NR simulations, energy efficiency, green networking, 6G sustainability\n- Difficulty: Medium\n- Project size: Medium\n- Patch requirement: See the\n[description](https://www.nsnam.org/wiki/GSOC2024PatchRequirement). You can also consider some of the[nr good to start issues](https://gitlab.com/cttc-lena/nr/-/issues/?label_name%5B%5D=good%20first%20issue). Or, you can start writing some APIs for the selected project proposal. Also, if you have some previous MRs to ns-3 or the nr module, you can contact us to check whether it is enough for the patch requirement.\n\n### 5G NR module integration with ns-3-ai\n\nMentors: [Katerina Koutlia](mailto:kkoutlia@cttc.es), [Gabriel Ferreira](mailto:gcarvalho@cttc.es), [Amir Ashtari Gargari](mailto:aashtari@cttc.es) and [Biljana Bojovic](mailto:bbojovic@cttc.es)\n\nThe objective of this project is to integrate the ns-3 5G NR module with [ns-3-ai](https://apps.nsnam.org/app/ns3-ai/). In GSoC 2024 we had a project in which 5G NR was integrated with [ns-3 gym](https://www.nsnam.org/wiki/GSOC2024RLUsability5G). While ns-3 gym is a popular ns-3 module for AI, it is limited to the application of reinforcement learning techniques in networking research. On the other hand, ns-3-ai module provides a more general solution that enables the data interaction between ns-3 and other Python-based AI frameworks, like [Tensorflow C++ APIs](https://www.tensorflow.org/api_docs/cc) and [PyTorch C++ APIs](https://pytorch.org/cppdocs/), which opens the door to use different machine learning-based techniques in 5G NR models. The correct functioning of the integration should be tested, and documented, and a fully working example using ns-3-ai should be provided. The contributor can propose a use-case scenario for matching learning. One option is to use it for MAC scheduling, but it could be used for other 5G related research problems, and the contributor is encouraged to propose the use case of his/her interest.\n\nFor starters, we would suggest adding the CTTC 5G-LENA (nr module) to ns-3, in the typical way (as a module in the contrib/ directory), and building and running the examples. Documentation is available from here: [https://5g-lena.cttc.es/](https://5g-lena.cttc.es/). There is an overview tutorial video available here: [https://acmse.net/2021/tutorials-offered/#tut-work03](https://acmse.net/2021/tutorials-offered/#tut-work03). That is the background information.\nFor more specific guidelines, please view this [Google document](https://docs.google.com/document/d/1cQLIF1cdft1yj3vyWrjrxN2xDJMx8PuWaa9NP_nKf64/edit?usp=sharing).\n\n- Required Experience: C++ programming, understanding of 5G NR, LTE, and wireless networks\n- Interests: 5G NR simulations\n- Difficulty: Medium.\n- Patch requirement: See the\n[description](https://www.nsnam.org/wiki/GSOC2024PatchRequirement). You can also consider some of the[nr good to start issues](https://gitlab.com/cttc-lena/nr/-/issues/?label_name%5B%5D=good%20first%20issue). Or, you can start writing some APIs for the selected project proposal. Also, if you have some previous MRs to ns-3 or the nr module, you can contact us to check whether it is enough for the patch requirement.\n\n### Linux-like CAKE queue discipline for ns-3\n\nMentors: [Mohit P. Tahiliani](mailto:tahiliani.nitk@gmail.com)\n\nCommon Applications Kept Enhanced (CAKE) is the most recent queue discipline added in Linux 4.19. It is a comprehensive queue management framework targeted for home Internet gateways, and integrates the following four components: bandwidth shaping, a new Active Queue Management (AQM) algorithm called COBALT (CoDel BLUE Alternate), handling Differentiated Services (DiffServ) and TCP ACK filtering. The main tasks in this project include: implementation, testing and documentation of individual components of CAKE in ns-3, followed by the integration of these components to form CAKE queue discipline in ns-3.\n\n*Required Experience:*Familiarity with queue disciplines, TCP and C++ programming.*Bonus Experience:*Familiarity with CAKE framework in Linux 4.19*Interests:*Active Queue Management, Packet scheduling and TCP.*Difficulty:*Medium to Hard*Recommended reading:*\n\n### Switched Ethernet\n\nMentors: [Tommaso Pecorella](mailto:tommaso.pecorella@unifi.it), TBD.\n\nThe current ns-3 models for wired connections are fine for simple networks, but the lack of a switched Ethernet model is a limitation in some cases.\n\nThe goal of the idea is to create, test, and document a Switched Ethernet model, able to simulate (at least) 1, 10, and 40 GbE links and model for a switch.\n\nThe model of the NetDevice and Channel shall take into account the link delays and errors, similarly to what is done by the point-to-point model. Futhermore, it should be able to set the link speed and if it is full-duplex or half-duplex. Additional support for flow control is a bonus, but not strictly required. Link speed auto-negotiation is not considered to be interesting.\n\nThe model for the switch should be modular (i.e., allowing the development of different switch types), and include auto-learning of I/O ports based on the MAC address, i.e., have a MAC/port table, and a basic store-and-forward operation. Features like advanced I/O buffer handling and ARP/NDP spoofing detection are not a priority and shall be left for future implementations.\n\nThe model should consider the future implementaion of algorithms like VLANs (IEEE 802.1Q, 802.1ad), and the Spanning Tree Protocol (IEEE 802.1D, 802.1w, and 802.1s). Their implementaion is not required, but the model design should allow their development.\n\n*Required Experience:*Fundamentals of Ethernet sitched networking, C++ programming.*Interests:*Ethernet networks and switched data networks.*Difficulty:*Medium.*Recommended reading:*\n\nPossible tasks to fulfill the patch requirement:\n\n- TBD, contact the mentors if interested."
  },
  {
    "name": "Processing Foundation",
    "slug": "processing-foundation",
    "tagline": "To empower all people to learn to program",
    "description": "Our mission is to promote software learning within the arts, artistic learning within technology-related fields, and to celebrate the diverse communities that make these fields vibrant, liberatory, and innovative. Our goal is to support people of all backgrounds in learning how to program and make creative work with code, especially those who might not otherwise have access to tools and resources. We also believe that some of the most radical futures and innovative technologies are being built by communities that have been pushed to the margins by dominant tech. We hope to support those who have been marginalized by technology in continued self-determination by providing time, space, and resources.\n\nWe work toward our goals by developing and distributing a group of related software projects, which includes Processing (Java), p5.js (JavaScript), and p5.js Editor (JavaScript), and by facilitating partnerships and collaborations with allied organizations and individuals to build a more diverse community around software and the arts.",
    "ideas_url": "https://github.com/processing/Processing-Foundation-GSoC/wiki/Project-Ideas-List-(GSoC-2026)#project-ideas-list",
    "website_url": "http://processingfoundation.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "javascript",
      "java",
      "typescript",
      "webgl",
      "GitHub Actions"
    ],
    "topic_tags": [
      "education",
      "web",
      "graphics",
      "creative coding",
      "design"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/processing-foundation",
    "ideas_content": "## About the Processing Foundation\n\nOur mission at the Processing Foundation is to promote software learning within the arts, artistic learning within technology-related fields, and to celebrate the diverse communities that make these fields vibrant, liberatory, and innovative. Our goal is to support people of all backgrounds in learning how to program and make creative work with code, especially those who might not otherwise have access to tools and resources. We also believe that some of the most radical futures and innovative technologies are being built by communities that have been pushed to the margins by dominant tech.\n\nTo learn more about the Processing Foundation, see our official website at [processingfoundation.org](https://processingfoundation.org/).\n\n\n## Feedback & Proposal Process\n\nInterested? Great! We're excited to read all this year's projects. Below are some essential resources for all applicants.\n\n* [This thread on our forum](https://discourse.processing.org/t/updates-about-gsoc-2026-org-application-in-progress/47450) is the best place to ask your questions, org admins and mentors will regularly answer public questions!\n\n* [Please carefully review the GSoC timeline and guidelines](https://opensource.googleblog.com/2025/12/shape-future-with-google-summer-of-code.html)\n\n* Right now, project proposal applications are **not open** - we are in the process of applying as an organization. Once applications open on March 16, an applications **template** will be linked here, as well as details of the selection process. Be sure to use this template to improve your application.\n\n* It is possible to get feedback on your proposals before you submit. The final deadline to submit proposals is March 31, and we will have a signup form to submit your drafts up to one week before. If you have a draft (even if it has parts missing! Even if it doesn't quite follow the template! Everything is OK at this stage.) ready before March 23rd, org admin(s) / mentor(s) will definitely review it. If you have a draft ready earlier, more than one round of review might be possible - but it depends on volume of requests, and is not guaranteed. We will do our best to support all applicants as well as we can!\n\n## Important Notes\n\nWhether your proposals focuses on one of the below ideas or a custom project, please keep the following in mind.\n\n* Do not rely on AI in your proposal or PRs: AI use in your proposal should be clearly disclosed based on our [GSoC AI usage guideline](https://github.com/processing/Processing-Foundation-GSoC?tab=readme-ov-file#ai-text-generation-policy). Fully or largely AI-generated PRs may be closed, and are not in line with our [AI usage policy](https://github.com/processing/p5.js/blob/main/AI_USAGE_POLICY.md).\n\n* PRs are not required, and PRs (and other activity in online community spaces) that consistently ignore contribution and community guidelines can actually make your proposal less likely to succeed. Before making any PR, please be sure to [read the contributor guidelines](https://p5js.org/contribute/contributor_guidelines/) carefully.\n\n* We're especially interested in why you are interested in the idea you propose! Please include Processing or p5.js sketches you've worked on, or any other artistic or programming projects that help us understand your perspective.\n\n## Project Ideas List\n\nThese ideas indicate important areas of work across [p5.js Web Editor](https://github.com/processing/p5.js-web-editor), [p5.js JavaScript library](https://github.com/processing/p5.js), [p5.js Reference Website](https://github.com/processing/p5.js-website), [Processing4 Java library](https://github.com/processing/processing4/), and a new implementation of Processing/p5 in Lua, [L5](https://l5lua.org/). Creative interpretations or custom projects are welcome, but keep in mind that proposals very different from the below topics will require research while writing your proposal. In proposing custom projects, be sure to review carefully existing work, and get in touch using the forum above. We expect most applications to propose 175H/Medium sized projects, though if a different scope is well justified in the proposal, larger projects would also be considered.\n\n### Eyedropper Color Debugging in the p5.js Editor\n\nEnable eyedropper debugging in the p5.js Web Editor, in or near the simplified console log pane. This project would require a design proposal, as well as a plan for iteration. It came up during discussion of the new p5.strands feature ([read more](https://beta.p5js.org/tutorials/intro-to-p5-strands/)), that it would be helpful to show the RGBA channel values, each in 0-1 range, when user hovers on any pixels in the canvas with the mouse. An eyedropper tool may be helpful for any type of sketch, but since it is especially important for shader programming, the focus would be on 0,1 range. It would be important to consider how to turn this debugging feature on or off to not interfere with the sketch; for example, you can review how injection is used currently by the Accessibility Settings in the editor. \n\n* Expected Outcomes: Improve accessibility of shader programming education resources by surfacing the most foundational debugging tool - eyedropper - in a clear and easy to use place.\n* Skills/tech: Familiarity with p5.strands as a user - be sure to include at least one p5.strands in your application! JavaScript skills are required; experience with shader programming is a plus but not required.\n* Mentor: Diya Solanki (proposal review supported by Claudine Chen)\n* Size and Rating: 175H, Medium\n\n### E2E Testing for the p5.js Web Editor\n\nThe [p5.js Web Editor](https://github.com/processing/p5.js-web-editor) is undergoing some current and future refactor work (eg. Typescript Migration, self-hosting support). In order to prevent silent regressions, we should enhance the existing automated test suite to include end-to-end tests to cover key front-end user-flows.\n\nThese user flows will be defined by the mentee and mentor, but the definition will be driven primarily by the mentee. The new e2e test suite should be able to be run locally by contributors, and be automatically run on every PR into ‘development’.\n\n#### Expected Outcomes:\n- New PRs into the `develop` branch of the p5.js Web Editor will automatically trigger a new test suite called `e2e`\n- The test will include some integration with a test database for `users` & `projects`\n- Any core user flows that have not been implemented yet are documented in a designated section in ‘Contributing’ docs & clearly defined for other contributors to pick up.\n\n<details>\n  <summary>\n    Examples of core user flows could include:\n  </summary>\n  - Unauthenticated flow:\n    - User can write code and run previews of sketches without logging in\n    - User sees prompt to sign up when they try to save a sketch\n    - User can download a sketch without logging in\n  - Authenticated flow:\n    - User can write code and run previews of sketches\n    - User can save sketches, and see their changes reflected upon re-navigating to the saved sketch\n    - User can edit existing sketches and save them\n    - User can log out\n</details>\n\n#### Skills/tech: \n- Prior experience with testing frontend code is required. Playwright or Cypress preferred, but experience with Vitest or Jest with frontend code will satisfy the requirement.\n- Ability to empathize with non-technical users & communicate technical details in non-technical language is required.\n- Prior experience with the p5.js web editor is preferred.\n- Some prior experience with Github Actions is preferred but not necessary and will be learned during the project.\n- Interest or experience in product-management is preferred but not necessary and will be learned during the project.\n\n**Mentor:** [Claire Peng](https://www.linkedin.com/in/pengclaire/) (proposal review supported by Claudine Chen)<br><br>\n**Size and Rating:** 175H Medium\n\n<details>\n  <summary><strong>Useful links</strong></summary>\n\n  <ul>\n    <li>\n      <a href=\"https://github.com/processing/p5.js-web-editor/blob/develop/client/index.integration.test.jsx\">\n        Current frontend integration test\n      </a> - This current test is only a snapshot of the components on the web editor, so it does not yet cover ‘end-to-end’ user flows. Please see Playwright or Cypress documentation for examples.\n    </li>\n    <li>\n      <a href=\"https://github.com/processing/p5.js-web-editor/tree/develop/.github/workflows\">\n        Current test workflow definitions\n      </a>\n    </li>\n    <li>\n      <a href=\"https://github.com/processing/p5.js-website/pull/933\">\n        Playwright setup example (Accessibility Testing)\n      </a>\n    </li>\n  </ul>\n</details>\n\n### Full Texture Support for `.mtl` Files\n\nThis enhancement in the WEBGL sub-area of p5.js would increase reach and would make it easier for people to use pre-made 3D-models within their p5.js projects. Currently p5.js supports `.obj` files for 3D models with materials loaded from `.mtl` files but only vertex colors (`map_Kd`). Implementing this feature would involve proposing a new data structure capable of handling both 3D models and their associated textures, potentially multiple per model. You can review previous [discussion](https://github.com/processing/p5.js/issues/6924) and [work](https://github.com/processing/p5.js/pull/6710).\n\nAim: A model can have multiple materials, each with its own texture. The structure needs to: (1) Store loaded textures per material, (2) Map materials to faces/vertices, (3) Handle multiple textures per model, (4) Support other MTL texture maps (map_Ka, map_Ks, map_Ns, map_Bump, etc.), (5) Handle models with mixed materials/textures.\n\nThis would broaden access and creative possibilities, as users could use textured models from common sources, with more detailed and textured 3D models used by artists/creative technologists, and following  industry standards of supporting OBJ/MTL workflows.\n\n* Expected Outcomes: Full Texture support for pre-made 3D-models, including visual tests. \n* Skills/tech: WEBGL,  JavaScript, Experience using p5.js \n* Mentor: Diya Solanki (proposal review supported by Claudine Chen)\n* Size and Rating: 175H/300H, medium\n\n### Continued Development of Translation Tracker\n\nPropose an extension of the [Translation Tracker GitHub Action](https://github.com/processing/p5.js-website/tree/main/.github/actions/translation-tracker) on the p5.js reference website. This tooling supports community translation of the p5.js documentation across five languages (English, Spanish, Simplified Chinese, Korean, and Hindi).\n\nIn your proposal, focus on extending and improving this translation tracker infrastructure. What would make it easier for new contributors to start translating? Potential directions include: expanding tracking to cover all content types, creating translation stub files to lower the barrier for new translators, improving issue-to-PR workflows (such as auto-closing issues when translations are merged), building a translation progress dashboard - or your own creative ideas! The p5.js community values human translation over automation, so the goal is tooling that assists translators rather than replaces them.\n\n* Expected Outcomes: Enhanced GitHub Action(s) and/or companion tooling in the p5.js [website repository](https://github.com/processing/p5.js-website) that improves the translation contributor experience and helps increase documentation coverage across supported languages.\n* Skills/tech: JavaScript, Astro, Github Actions/Workflows; optional: JSDoc, documentation.js\n* Mentor: Divyansh Srivastava (proposal reviews supported by Claire Peng)\n* Size and Rating: 175H, Medium\n\n\n### Extend Tests in Processing4\n\nWe would like to extend the testing ecosystem for [Processing4](https://github.com/processing/processing4) to eventually include extensive unit tests, integration tests, end-to-end tests, and visual regression tests. Tests are important to ensuring there are few regressions as we develop and maintain the codebase. What experience do you already have in developing tests for an application? Currently, Processing4 already includes both unit and visual regression tests. A strong proposal is based on and effectively extends the existing testing infrastructure. We invite you to suggest your own scope and focus, and will prioritize a realistic proposal over an ambitious one.\n\n* Expected Outcomes: Additional tests that can run for Processing4 locally and as a part of CI/CD\n* Possible Mentors: [Claudine Chen](https://mingness.github.io/)\n* Skills required/preferred: Preferably, some familiarity with types of tests and writing tests in Java or another programming language. Some familiarity with Processing, so they have some idea of what we need tests for; also ideally familiarity with git and Github.\n* Size and Rating: 175H, Medium/Hard\n\n### Expanding L5: Sound, Video and Core Improvements \n\nL5 (L5lua.org) is a new Processing-inspired creative coding library in Lua and built on the LÖVE/Love2d framework designed for longevity and low-resource computing. This project focuses on expanding L5’s capabilities through new sound and video libraries, improving a programmer’s experience with better error messages, and achieving feature parity with Processing/p5.js core functionality.\n\n* Expected Outcomes: Possible outcomes include building out L5sound and L5video libraries, implementing friendly error messages to improve the beginner experience, and debugging/fixing errors to achieve feature parity with Processing/p5.js. Additional work could involve improving bezier curves, adding stateful styles to push()/pop() transformation matrices, expanding input/output options (JSON), and contributing to documentation.\n* Skills/tech: Experience with p5.js and/or Processing essential; Familiarity with Lua programming and the LÖVE/Love2d framework a plus but not required. Optional: experience with p5.sound.js, Processing Sound library, or audio/video programming. \n* Mentor: [Lee Tusman](https://leetusman.com/)\n* Size and Rating: 175H Medium\n\n### Code Translation between Processing Sound and p5.sound.js\n\nBoth p5.js and Processing support sound synthesis, playback, and analysis, but only p5.js does it directly in the web browser with [p5.sound.js](https://github.com/processing/p5.sound.js). An automated tool or interface for converting [Processing Sound](https://processing.org/reference/libraries/sound/index.html) to p5.sound.js and vice versa would benefit both communities: Processing Sound users could more easily share work on the web, and p5.sound.js users could more easily adapt their sketches to a wide variety of devices. We are especially excited about creative approaches to the problem of sharing sound sketches across the ecosystem even if they are not specifically translating code!\n\n* Expected Outcomes: A possible technical outcome could be a standalone interactive webpage with user-friendly settings that helps convert Processing Sound sketches into p5.sound.js sketches, and vice versa. The community impact extends to both users of Processing Sound and p5.sound.js, and to current and future contributors!\n* Possible Mentors: Kevin Stadler (proposal review supported by Lee Tusman)\n* Skills: experience with both Java and JavaScript essential; optionally: some familiarity with p5.sound.js, Processing Sound, or Web Audio technologies can be a plus\n* Size and Rating: 175H, Medium"
  },
  {
    "name": "PostgreSQL",
    "slug": "postgresql",
    "tagline": "The Most Advanced Open Source Relational Database",
    "description": "PostgreSQL is a powerful, open source object-relational database system with over 30 years of active development that has earned it a strong reputation for reliability, feature robustness, and performance.",
    "ideas_url": "https://wiki.postgresql.org/wiki/GSoC_2026",
    "website_url": "https://postgresql.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "python",
      "postgresql",
      "javascript",
      "go"
    ],
    "topic_tags": [
      "web",
      "database",
      "ui",
      "sql",
      "Benchmark"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/postgresql",
    "ideas_content": "# GSoC 2026\n\n[Jump to navigation](https://wiki.postgresql.org#column-one)\n\n[Jump to search](https://wiki.postgresql.org#searchInput)\n\nThis page is for Google Summer of Code 2026 project ideas.\n\nIF YOU ARE A MENTOR: there is a top-level GSoC page for PostgreSQL here:[PostgreSQL General GSoC Page]-please read this first before proceeding to contact the admins! PLEASE make sure you have read everything thoroughly.\n\nIF YOU ARE A CONTRIBUTOR: there is a top-level GSoC page for PostgreSQL here:[PostgreSQL General GSoC Page]-please read this first before proceeding to contact mentors! Contribution guidelines, channels and communication methods are in this page too. PLEASE make sure you have read everything thoroughly.\n\n**Note on Project Selection and Mentor Availability**\n\nPlease be aware that the list of ideas below is a starting point. Due to the competitive nature of GSoC:\n\n- Not all ideas will be funded. Google provides us with a limited number of \"slots,\" and we can only accept the highest-quality proposals as determined by our mentors.\n- Mentor Bottlenecks: Primary mentors will only take on one contributor. If several people apply for ideas listed under the same mentor, only the strongest application will be selected.\n- Be Selective: We encourage you to check our communication channels (e.g., Slack) to see if many other contributors are already targeting a specific idea\n\n**Mentors mailing list for proposals**: gsoc-mentors@lists.postgresql.org\n\n## Admins\n\n- Jesper Pedersen <jesperpedersen (dot) db (at) gmail (dot) com>\n- Pavlo Golub <pavlo (dot) golub (at) gmail (dot) com>\n\n## Mentors\n\nThe following individuals have been listed as mentors on the below projects:\n\n- Pavlo Golub\n- Jesper Pedersen\n- Mark Wong\n- Ahmed Gouda\n- Luca Ferrari\n- Tejas Tyagi\n- Haoran Zhang\n- Mohab Yassar\n- Ashutosh Sharma\n- Bassam Adnan\n- Konstantina Skovola\n- Akshat Jaimini\n- Sachin Beniwal\n- Arth Thapa\n- Nik Samokhvalov\n- Kirk Wolak\n- Andrei Lepikhov\n- Andreas Karlsson\n\n## Timeline\n\n- January 19 - Mentoring organizations can begin submitting applications to Google\n- February 3 - Mentoring organization application deadline\n- February 19 - List of accepted mentoring organizations published\n- March 16 - GSoC contributor application period begins\n- March 31 - GSoC contributor application deadline\n- April 21 - GSoC contributor proposal rankings due from Org Admins\n- April 30 - Accepted GSoC contributor projects announced\n- May 4 - GSoC 2026 begins !\n\n## Test Development in C/C++: Implementing event-driven concurrency in OLTP test tool (dbt5)\n\n### Project Description\n\nThis project is a learning exercise in developing event-driven code by converting a thread-based concurrency model in a C++ application to use an event-driven model. DBT-5 is the application that is an open source implementation of the TPC Benchmark(TM) E Specification. This specification is an OLTP workload modeling a brokerage house. DBT-5 is currently using a thread (pthreads) based model in several programs and we want to convert that to a concurrency model that has shown itself to be significantly less resource intensive.\n\nThe general outline of the project, which can be adapted depending on the contributor's skill level:\n\n- Learn how to program a simple event-driven program using libev\n- Learn how to use DBT-5 to run a small scale test against PostgreSQL\n- Replace the threaded model in the DBT-5, one program at a time\n\n### Skills needed\n\n- C\n- C++\n\n### Difficulty level\n\nModerate\n\n### Project size\n\nLong (350 hours)\n\n### Mentors\n\n- Mark Wong <markwkm (at) gmail (dot) com>\n- Akshat Jaimini\n\n### Expected outcomes\n\n- Successful and working event-driven code.\n\n### References\n\n- DBT-5 code:\n[https://github.com/osdldbt/dbt5](https://github.com/osdldbt/dbt5) - libev homepage:\n[https://software.schmorp.de/pkg/libev.html](https://software.schmorp.de/pkg/libev.html) - Code example of using libev to convert DBT-2 (another OLTP test kit):\n[https://github.com/osdldbt/dbt2/commit/0e6214381867dd608221a2ec30b37e560115d4e3](https://github.com/osdldbt/dbt2/commit/0e6214381867dd608221a2ec30b37e560115d4e3) - TPC Benchmark(TM) E Specification, DBT-5 implements this:\n[https://www.tpc.org/tpce/](https://www.tpc.org/tpce/)\n\n## Adding features to the Julia Procedural Language: pl/julia\n\n### Project Description\n\nThis project is a learning exercise in how procedural languages get implemented. pl/Julia allows stored procedures and user defined functions to be created using the Julia programming language. pl/Julia currently supports:\n\n- Triggers functions\n- Event triggers\n- Anonymous code blocks\n- Directly access the database\n- Some, but not all, PostgreSQL data types\n\nThe general outline of the project, which can be adapted depending on the contributor's area of interests:\n\n- Updating pl/Julia to build and with the current version of Julia's C API's\n- Support additional datatypes:\n- DateTime / Time / Timestamp\n- bytea\n\n- Handle arrays passed as IN parameters\n- Additional suggestions by contributor allowed here\n\n### Skills needed\n\n- C\n- Julia may be helpful\n\n### Difficulty level\n\nIntermediate\n\n### Project size\n\nLong (350 hours)\n\n### Mentors\n\n- Konstantina Skovola\n- Mark Wong <markwkm (at) gmail (dot) com>\n\n### Expected outcomes\n\n- Successful and working extension.\n\n### References\n\n- pl/Julia project page:\n[https://github.com/pljulia/pljulia](https://github.com/pljulia/pljulia) - Previous\n[pl/Julia status report](https://docs.google.com/presentation/d/1cTnsUWiH6o0YH6MlZoPLofna3eNT3P3r9HSL9Dyte5U/edit?usp=sharing) - Julia language homepage:\n[https://julialang.org/](https://julialang.org/) - Julia documentation for embedding in C:\n[https://docs.julialang.org/en/v1/manual/embedding/](https://docs.julialang.org/en/v1/manual/embedding/)\n\n## Implement AI copilot for pgwatch\n\n### Project Description\n\nThis project proposes building a standalone, CLI-based AI copilot for PostgreSQL monitoring, designed to work with metrics collected by pgwatch.\n\npgwatch is a mature, PostgreSQL-specific monitoring system that stores a rich set of performance metrics and statistics. However, analyzing these metrics during incidents still requires significant manual effort: navigating dashboards, correlating multiple data sources, and relying on expert knowledge.\n\nThe goal of this project is to allow engineers to use pgwatch and analyze its metrics using natural language prompts.\n\n### Skills needed\n\n- Go\n- PostgreSQL\n\n### Difficulty level\n\n- Moderate\n\n### Project size\n\n- Large (350 hours).\n\n### Mentors\n\n- Ahmed Gouda <gouda0x (at) gmail (dot) com>\n- Pavlo Golub\n\n### Expected outcomes\n\n- A CLI-based AI copilot for PostgreSQL monitoring that works with pgwatch.\n\n### References\n\n- pgwatch:\n[https://github.com/cybertec-postgresql/pgwatch](https://github.com/cybertec-postgresql/pgwatch) - GitHub Copilot CLI (conceptual inspiration):\n[https://github.com/features/copilot/cli](https://github.com/features/copilot/cli)\n\n## pgagroal: High-available (HA) functionality\n\n### Project Description\n\nThe goal of this project is to allow pgagroal operate in a high-available environment.\n\nThis project requires to analyze, design and implement a solution where read-only queries can be executed on a replica instance. Or even be delegated from the primary instance to a replica.\n\nThe final solution should describe the architecture of a solution where 2 pgagroal instances works against a PostgreSQL cluster in a primary/replica setup - including the additional components needed (if necessary) in a bare metal / container / Kubernetes environment.\n\n### Skills needed\n\n- C\n- PostgreSQL\n\n### Difficulty level\n\n- Hard\n\n### Project size\n\n- Large (350 hours).\n\n### Mentors\n\n- Luca Ferrari <fluca1978 <at> gmail (dot) com>\n- Jesper Pedersen <jesperpedersen (dot) db (at) gmail (dot) com\n\nContact mentors for submission requirements.\n\n### Expected outcomes\n\n- Using a replica for read-only queries.\n\n### References\n\n- pgagroal:\n[https://github.com/pgagroal/pgagroal](https://github.com/pgagroal/pgagroal)\n\n## pgagroal: Advanced security\n\n### Project Description\n\nThe goal of this project is to add advanced security functionality to pgagroal.\n\nThe main focus is to add full pooling support for pgagroal to PostgreSQL communication. Note, that this might require a clean-room TLSv1.2+ implementation where we can cache and update the security context. Additionally areas such as client certificate authentication, SCRAM-SHA-256-PLUS and enhanced vault security can be investigated.\n\n### Skills needed\n\n- C\n- Transport Layer Security (TLS)\n- PostgreSQL\n\n### Difficulty level\n\n- Hard\n\n### Project size\n\n- Large (350 hours).\n\n### Mentors\n\n- Tejas Tyagi <tejastyagi (dot) tt (at) gmail (dot) com>\n- Luca Ferrari <fluca1978 <at> gmail (dot) com>\n\nContact mentors for submission requirements.\n\n### Expected outcomes\n\n- End-to-end TLS communication from client to PostgreSQL with pooling support\n\n### References\n\n- pgagroal:\n[https://github.com/pgagroal/pgagroal](https://github.com/pgagroal/pgagroal)\n\n## pgmoneta: Model Context Server implementation\n\n### Project Description\n\nThe goal of this project is to enhance the Model Context Protocol server for pgmoneta.\n\nThe main focus is to support all the commands of pgmoneta, and their parameters. And, the requirements outside the commands such as security.\n\nPart of the implementation should make it easy to test the functionality when new functionality is added to pgmoneta\n\n### Skills needed\n\n- Rust\n- PostgreSQL\n\n### Difficulty level\n\n- Moderate\n\n### Project size\n\n- Large (350 hours).\n\n### Mentors\n\n- Haoran Zhang <andrewzhr9911 (at) gmail (dot) com>\n- Jesper Pedersen <jesperpedersen (dot) db <at> gmail (dot) com>\n\nContact mentors for submission requirements.\n\n### Expected outcomes\n\n- A MCP server that support all the pgmoneta CLI commands\n\n### References\n\n## pgmoneta: Write-Ahead Log (WAL) & Model Context Server (MCP)\n\n### Project Description\n\nThe goal of this project is to enhance the Write-Ahead Log (WAL) functionality of pgmoneta and its tools. Especially pgmoneta-walfilter. This work will include expanding the test cases, and making sure that PostgreSQL 14 to PostgreSQL 19 are fully supported.\n\nThis project also need to implement WAL functionality into the Model Context Protocol (MCP) server in order to create WAL streams for recovery in an easy way.\n\n### Skills needed\n\n- C\n- Rust\n- PostgreSQL\n\n### Difficulty level\n\n- Moderate\n\n### Project size\n\n- Large (350 hours).\n\n### Mentors\n\n- Mohab Yaser <mohabyaserofficial2003 (at) gmail (dot) com>\n- Haoran Zhang <andrewzhr9911 (at) gmail (dot) com>\n\nContact mentors for submission requirements.\n\n### Expected outcomes\n\n- Enhance pgmoneta-walfilter, increase code coverage of WAL generation and support WAL based commands in the MCP server\n\n### References\n\n## pgmoneta: Legacy incremental backup\n\n### Project Description\n\nThe goal of this project is to complete the support of incremental backups of PostgreSQL version before 17.\n\nThe main focus is to get tablespaces supported, and expand the test suite to cover for the different scenarios between PostgreSQL 14 and PostgreSQL 16.\n\nThis project should complete full support for full and incremental backup and restore for legacy PostgreSQL versions.\n\n### Skills needed\n\n- C\n- PostgreSQL\n\n### Difficulty level\n\n- Moderate\n\n### Project size\n\n- Large (350 hours).\n\n### Mentors\n\n- Ashutosh Sharma <ash2003sharma (at) gmail (dot) com>\n- Haoran Zhang <andrewzhr9911 (at) gmail (dot) com>\n\nContact mentors for submission requirements.\n\n### Expected outcomes\n\n- Support PostgreSQL 14-16 incremental backups with tablespaces\n\n### References\n\n- pgmoneta:\n[https://github.com/pgmoneta/pgmoneta](https://github.com/pgmoneta/pgmoneta)\n\n## pgmoneta: Storage engines\n\n### Project Description\n\nThe goal of this project is to implement support for using external storage engines - such as SSH and S3 - for all of pgmoneta's commands.\n\nThe main focus is to create a unified interface that can be used across all storage engines to minimize integration into the pgmoneta infrastructure.\n\nIt should be possible to use one or more storage engines per cluster setup.\n\n### Skills needed\n\n- C\n- PostgreSQL\n\n### Difficulty level\n\n- Hard\n\n### Project size\n\n- Large (350 hours).\n\n### Mentors\n\n- Jesper Pedersen <jesperpedersen (dot) db (at) gmail (dot) com>\n- Haoran Zhang <andrewzhr9911 (at) gmail (dot) com>\n\nContact mentors for submission requirements.\n\n### Expected outcomes\n\n- Unified storage engine interface, and a full implementation of one or more engines\n\n### References\n\n- pgmoneta:\n[https://github.com/pgmoneta/pgmoneta](https://github.com/pgmoneta/pgmoneta)\n\n## pgexporter: Historic data\n\n### Project Description\n\nThe goal of this project to add a history to pgexporter such that metrics are stored over time based on the configuration. Backends should be sqlite, PostgreSQL or TimescaleDB.\n\nThis data can then be used to look at trends through reports or UIs, or even a Model Context Protocol (MCP) server.\n\n### Skills needed\n\n- C\n- Prometheus\n- PostgreSQL\n\n### Difficulty level\n\n- Moderate\n\n### Project size\n\n- Large (350 hours).\n\n### Mentors\n\n- Bassam Adnan <mailbassam (at) gmail (dot) com>\n- Jesper Pedersen <jesperpedersen (dot) db (at) gmail (dot) com>\n\nContact mentors for submission requirements.\n\n### Expected outcomes\n\n- Infrastructure for historic data that can be retrieved through various UIs\n\n### References\n\n- pgexporter:\n[https://github.com/pgexporter/pgexporter](https://github.com/pgexporter/pgexporter)\n\n## pg_ai_query: Improving AI Query Generation Accuracy and Configuration\n\n### Project Description\n\npg_ai_query is a PostgreSQL extension that generates SQL queries from natural language using AI models. While functional, production usage reveals that LLMs frequently hallucinate PostgreSQL syntax generating non-existent functions or version-incompatible queries.\n\nThis project aims to dramatically improve query accuracy by integrating real-time PostgreSQL documentation context (e.g., Context7 MCP), and to solve configuration challenges where PostgreSQL extensions cannot access environment variables or secrets managers.\n\nStudents will design and implement an architecture that decouples AI logic from the extension, enabling accurate, version-aware query generation with flexible configuration.\n\n### Skills needed\n\n- C (PostgreSQL extension development, SPI)\n- Python/Go/Rust (optional)\n- HTTP/REST API integration\n- Basic understanding of LLM behavior\n\n### Difficulty level\n\nModerate\n\n### Project size\n\nMedium\n\n### Mentors\n\n- Sachin Beniwal <sachinbeniwal0101 (at) gmail (dot) com>\n- Arth Thapa <probablyarth (at) gmail (dot) com>\n\n### Expected outcomes\n\n- Measurable improvement in query generation accuracy\n- Flexible configuration support (environment variables, secrets)\n- Decoupled architecture enabling independent updates and testing\n- Documentation and test suite\n\n### References\n\n[https://github.com/benodiwal/pg_ai_query](https://github.com/benodiwal/pg_ai_query)[https://benodiwal.github.io/pg_ai_query/](https://benodiwal.github.io/pg_ai_query/)[https://github.com/upstash/context7](https://github.com/upstash/context7)\n\n## Join Removal Based on Foreign Key Constraints\n\n### Project Description\n\nThe project focuses on adding the ability to remove joins to tables when the join is on a foreign key column and only the child table columns are needed in the query result.\n\nThis is a common optimization in enterprise databases (Oracle, DB2) that PostgreSQL currently lacks. When a view joins multiple tables but a query only needs columns from some of them, the optimizer should be able to eliminate unnecessary joins if foreign key constraints guarantee referential integrity.\n\nExample scenario:\n\n-- View joining orders to customers CREATE VIEW order_summary AS SELECT o.* FROM orders o JOIN customers c ON o.customer_id = c.id; -- Query only uses order columns - join should be eliminated SELECT order_id, amount FROM order_summary;\n\nThe optimizer should recognize that the join to customers table is unnecessary since:\n\n- Only columns from orders are selected\n- The foreign key constraint guarantees the join will succeed\n- No filtering on customers columns exists\n\n### Skills needed\n\n- C programming\n- SQL\n- PostgreSQL\n\n### Difficulty level\n\nHard\n\n### Project size\n\nLarge: approximately ~350 hours of work.\n\n### Mentors\n\n- Nik Samokhvalov <nik (at) postgres (dot) ai>\n- Kirk Wolak <wolakk (at) gmail (dot) com>\n- Andrei Lepikhov <lepihov (at) gmail (dot) com>\n\n### Expected outcomes\n\n- A working implementation of FK-based join elimination in the query optimizer\n- Updated cost estimation to account for eliminated joins\n- Comprehensive regression tests covering various join patterns\n- Documentation outlining the optimization rules and limitations\n- Performance benchmarks demonstrating query speedups\n\n### References\n\n## B-tree Index Bloat Reduction (Page Merge)\n\n### Project Description\n\nThe project focuses on implementing efficient B-tree index bloat reduction through page merging. B-tree indexes can become severely bloated after heavy UPDATE/DELETE workloads - in production systems, indexes with 90%+ bloat are common.\n\nCurrent solutions have significant drawbacks:\n\n**REINDEX**: Requires AccessExclusiveLock for entire duration (blocks all access)**REINDEX CONCURRENTLY**: Very long duration, requires 2x disk space**pg_repack**: External tool, complex setup, requires double space\n\nThis project would implement in-core page merging that:\n\n- Merges sparsely populated leaf pages with their neighbors\n- Uses two-phase locking (light lock for planning, brief exclusive lock for execution)\n- Provides crash safety through WAL logging\n- Achieves 30-50% bloat reduction with minimal disruption\n\nA prototype extension (pg_btree_compact) has been developed demonstrating the approach. This project would work toward integrating similar functionality into core PostgreSQL, potentially as part of VACUUM or as a new REINDEX variant.\n\n### Skills needed\n\n- C programming\n- PostgreSQL\n- B-Tree structures\n\n### Difficulty level\n\nHard\n\n### Project size\n\nLarge: approximately ~350 hours of work.\n\n### Mentors\n\n- Kirk Wolak <wolakk (at) gmail (dot) com>\n- Nik Samokhvalov <nik (at) postgres (dot) ai>\n- Andrei Lepikhov <lepihov (at) gmail (dot) com>\n\n### Expected outcomes\n\n- Working implementation of B-tree page merging\n- Integration with VACUUM or as standalone command\n- Proper WAL logging for crash safety\n- Minimal exclusive lock duration (<1ms per 100 page merges)\n- Performance benchmarks and bloat reduction measurements\n- Comprehensive tests using amcheck for index integrity verification\n\n### References\n\n## Monitoring Tools Performance: pg_stat_statements and LWLock Contention\n\n### Project Description\n\nThe project focuses on improving the performance and reducing lock contention in PostgreSQL's monitoring infrastructure, particularly pg_stat_statements and related statistics collectors. Keeping in mind that the more executing backends you have running queries need to lock this structure for writing. Then monitoring software needs to lock this structure for reading. The faster the system, the more locking/unlocking takes up most of the time. Also, as the number of statements being tracked increases, the reading takes longer. Finally, sampling could reduce some of this.\n\npg_stat_statements is essential for query performance analysis, but it has known scalability issues:\n\n**Lock contention**: High-frequency queries cause contention on the shared hash table**Memory pressure**: Limited entries (default 5000) cause eviction churn on busy systems**Reset overhead**: pg_stat_statements_reset() can cause significant pauses\n\nSimilar issues affect other monitoring tools:\n\n- pg_stat_activity updates\n- pg_stat_user_tables/indexes statistics\n- Custom statistics collectors\n\nGoals of this project:\n\n- Analyze and profile current lock contention patterns\n- Implement lock-free or reduced-lock data structures where possible\n- Add partitioned/sharded hash tables for better scalability\n- Consider/test ideas on timing out (and not logging) if having to wait too long for the lock\n- Consider/test a secondary queue for things to add when we have time\n- Consider/test a circular buffer so reading always returns the previous portion of the buffer w/o locking\n- Improve statistics aggregation efficiency\n- Reduce impact on production workloads\n\nThis work is critical for observability in high-throughput PostgreSQL deployments where monitoring overhead must be minimized.\n\n### Skills needed\n\n- C programming\n- Performance profiling\n- Concurrency/locking patterns\n- PostgreSQL\n\n### Difficulty level\n\nHard\n\n### Project size\n\nLarge: approximately ~350 hours of work.\n\n### Mentors\n\n- Kirk Wolak <wolakk (at) gmail (dot) com>\n- Nik Samokhvalov <nik (at) postgres (dot) ai>\n- Andrei Lepikhov <lepihov (at) gmail (dot) com>\n\n### Expected outcomes\n\n- Measurable reduction in lock contention for pg_stat_statements\n- Improved scalability under high query rates (target: 100k+ queries/sec)\n- Benchmarks comparing before/after performance\n- Documentation of new architecture and trade-offs\n- Regression tests ensuring correctness of statistics collection\n\n### References\n\n## Wait Event Coverage Improvements\n\n### Project Description\n\nThe project focuses on improving PostgreSQL's wait event coverage to provide more accurate observability into what the database is doing at any given moment. More importantly, what the database is waiting on. While PostgreSQL has many waits being properly recorded, this project is designed to find as many places as possible where we wait, and we should clarify what we are waiting on/for. This project will add the code required to track those new wait areas properly.\n\nMany monitoring tools that implement wait event analysis (AWS RDS Performance Insights, pgsentinel, pg_wait_sampling, and others) visualize samples where \"wait_event IS NULL\" as \"CPU\" time, typically shown in green. This convention originated from Oracle and has become widespread.\n\nHowever, this assumption can make analysis inaccurate because there are many places in PostgreSQL code that are not covered by wait events but technically should be - and such places cannot accurately be labeled as \"CPU\". When a backend shows NULL wait_event, it might be:\n\n- Actually doing CPU work (legitimate)\n- Performing I/O that isn't instrumented\n- Waiting on internal synchronization not covered by wait events\n- Executing extension code without proper instrumentation\n\nThis project would:\n\n- Systematically analyze PostgreSQL source code to identify non-instrumented waits\n- Categorize gaps by type (I/O, synchronization, extension hooks, etc.)\n- Propose and implement new wait events for significant gaps\n- Ensure backward compatibility with existing monitoring tools\n- Document the new wait events and their meanings\n\nInitial analysis has identified potential gaps in areas like:\n\n- Some file I/O operations\n- Internal memory allocation paths\n- Extension hook execution\n- Background worker coordination\n- Certain replication scenarios\n\n### Skills needed\n\n- C programming\n- PostgreSQL\n- Basic understanding of performance analysis\n\n### Difficulty level\n\nModerate\n\n### Project size\n\nLarge: approximately ~350 hours of work.\n\n### Mentors\n\n- Nik Samokhvalov <nik (at) postgres (dot) ai>\n- Kirk Wolak <wolakk (at) gmail (dot) com>\n- Andreas Karlsson <andreas (at) proxel (dot) se>\n\n### Expected outcomes\n\n- Comprehensive analysis of current wait event coverage gaps\n- Implementation of new wait events for significant uninstrumented code paths\n- Improved accuracy of \"CPU\" vs \"waiting\" distinction in monitoring tools\n- Documentation of all new wait events\n- Regression tests ensuring wait events fire correctly\n- Backward compatibility with existing monitoring infrastructure\n- Getting and applying feedback (especially on naming) from the Hackers group"
  },
  {
    "name": "RTEMS Project",
    "slug": "rtems-project",
    "tagline": "A real-time operating system for Earth & Space",
    "description": "RTEMS (Real-Time Executive for Multiprocessor Systems) is a free real-time operating system (RTOS) designed for deeply embedded systems such as automobile electronics, robotic controllers, and on-board satellite instruments. \n\nRTEMS is free open source software that supports multi-processor systems for over a dozen CPU architectures and over 150 specific system boards. In addition, RTEMS is designed to support embedded applications with the most stringent real-time requirements while being compatible with open standards such as POSIX. RTEMS includes optional functional features such as TCP/IP and file systems while still offering minimum executable sizes under 20 KB in useful configurations.\n\nThe RTEMS Project is the collection of individuals, companies, universities, and research institutions that collectively maintain and enhance the RTEMS software base. As a community, we are proud to be popular in the space application software and experimental physics communities. RTEMS has been to Venus, circles Mars, is aboard Curiosity, is in the asteroid belt, is on its way to Jupiter, and is circling the sun. It is in use in many high energy physics research labs around the world. There are many RTEMS users who do not belong to the space or physics communities, but our small part in contributing to basic scientific knowledge makes us proud.",
    "ideas_url": "https://projects.rtems.org/gsoc/",
    "website_url": "https://www.rtems.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "c/c++",
      "assembly",
      "posix"
    ],
    "topic_tags": [
      "kernel",
      "embedded",
      "real-time",
      "multicore",
      "rtos"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/rtems-project",
    "ideas_content": "RTEMS is proud to have been in multiple editions of the Google Summer of Code and we are applying to be a participating organization in [Google Summer of Code 2025](https://summerofcode.withgoogle.com).\n\nThis page is a jumping off point for participating with RTEMS. The best thing you can do for yourself is to join our [Discord](https://www.rtems.org/discord) and ask questions. We want you to be a part of the RTEMS community!\n\n**APPLYING GSOC CONTRIBUTORS MUST FILL OUT A Google APPLICATION**\n\nOur users forum for GSoC is located at [https://users.rtems.org/c/programs/gsoc/47](https://users.rtems.org/c/programs/gsoc/47)\n\nThe Git tracking repository is on our GitLab [https://gitlab.rtems.org/rtems/programs/gsoc](https://gitlab.rtems.org/rtems/programs/gsoc)\n\n## Potential Contributors\n\n- Read through all the material on this page.\n\n### Communications\n\n- Talk to us on\n[Discord](https://www.rtems.org/discord)or the[RTEMS Users Forum](https://users.rtems.org/c/programs/gsoc/47). The best place to find answers to common questions is the Users Forum! You can also use the #gsoc channel on our Discord. You can usually expect a response in a day or two. - Do not privately message RTEMS community members including mentors. You may publicly ask for permission to speak with someone privately. Unsolicited private messsages are likely to be ignored.\n\n### AI Usage\n\n- Do not use Generative AI (e.g., chatgpt, other LLM) tools to write and format your communications. These tools inject their own style and make your thoughts more verbose without adding any value. In most cases, the prompt you give an LLM is more useful to us than the output you get from the tool. Before you submit something written with AI assistance, you should ask yourself if it is something that you would have written on your own.\n- When you do use AI, you are expected to disclose what you used and how you used it. You may also be asked to provide the prompts and inputs you provided to the tool. You should make it a habit to keep track of how you use these tools and the lineage of your content when you co-create it with the assistance of any tool, but especially with the use of a generative AI tool.\n- When in doubt, ask first.\n\n### Getting Started\n\n- We require you to build, modify, and run RTEMS from git. The details are explained in our\n[GSoC Getting Started Guide](https://docs.rtems.org/docs/main/user/start/gsoc.html). Ask on the Users Forum for help. - Note the current, unreleased version of the RTEMS development on git is 7.\n\n### Researching a Project Idea\n\n- Pick a project from the list below. This is by no means an all-inclusive list and we are open to suggestions. Submissions of ports to new architectures, new BSPs, new device drivers, and test improvements are always welcomed. Mentors can be reached on Discord.\n- The order of projects in the list does not reflect their importance, difficulty, or feasibility. Our project list is not exclusive: if you have an idea, solicit feedback in the GSoC topic area of our\n[Users Forum](https://users.rtems.org/c/programs/gsoc/47). - Work with potential mentors to appropriately scope projects for the time available through the program. The project descriptions often require additional knowledge to flesh out a project proposal. Scoping a project is especially challenging as each contributor brings their own experience and capabilities to bear. Since some projects have multiple steps, contributors should work with prospective mentors to define the scope of work in their proposal. Similarly, some projects might be a starting point for a class project or graduate thesis. We generally underspecify our project descriptions for students and new contributors on purpose. The scope that can be accomplished in the timeframe varies depending on individual contributor’s experience and skills. So, we like to let new contributors explore the projects and discuss with potential mentors in order to shape the proposal in a way that suits the contributor’s and mentors’ interests with a scope that is appropriate.\n- You might also like to check out our full list of identified\n[projects](https://projects.rtems.org)which has some projects we have not tagged as suitable for GSoC. Some of those projects can be good for beginners. Ask on Discord or the Users Forum!\n\n### Writing a Proposal\n\n- Contributors applying to the RTEMS Project will need to fill out an application at\n[Google Summer of Code](https://summerofcode.withgoogle.com)using our[template](https://docs.google.com/document/d/1F5XCodvX8AYNqWX5ssu7dfjkmFT__83uf8ABKbB_Pkg/edit).\n\n# Ideas List\n\n# Large Projects (350 hours)\n\n| Project name | Created | Updated | Language | Architecture | Loading... |\n|---|\n\n# Medium Projects (175 hours)\n\n| Project name | Created | Updated | Language | Architecture | Loading... |\n|---|\n\n# Small Projects (90 hours)\n\n| Project name | Created | Updated | Language | Architecture | Loading... |\n|---|"
  },
  {
    "name": "52°North Spatial Information Research GmbH",
    "slug": "52north-spatial-information-research-gmbh",
    "tagline": "Innovative ideas & technologies in geoinformatics",
    "description": "52°North is an open source initiative in the field of geoinformatics. Core topics of our activities are for example sensor web, web-based geoprocessing and earth observation.",
    "ideas_url": "https://52north.org/outreach-dissemination/google-summer-of-code/project-ideas/",
    "website_url": "https://52north.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "javascript",
      "android",
      "java",
      "web services",
      "ogc standards"
    ],
    "topic_tags": [
      "citizen science",
      "spatial information infrastructures",
      "open standards",
      "data analytics",
      "Geoinformation"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/52north-spatial-information-research-gmbh",
    "ideas_content": "## GSoC 2026\n\n### Previous Projects\n\nCheck out our [Blog Post Series](https://blog.52north.org/category/gsoc/) for more information on previous projects!\n\n## 1. MCP for OGC APIs\n\n#### Developing Multi Context Protocols for the suite of OGC APIs\n\n**Explanation**\n\nThe Multi Context Protocol (MCP) offers a structured mechanism to seamlessly bridge the gap between natural language input, often processed via Large Language Models (LLMs), and well-defined, executable program code. In essence, MCP translates natural language instructions into precise actions. The [Open Geospatial Consortium](https://www.ogc.org/) (OGC) has developed several [OGC API](https://ogcapi.ogc.org/)s that have achieved widespread adoption across the geospatial domain and are natively understood by many prominent open-source Geo-IT solutions (e.g., [pygeoapi](https://pygeoapi.io/), [QGIS](https://qgis.org/), [geoserver](https://geoserver.org/)). The goal is to lower the barriers in using GIS tools for non-experts through LLM supported agents that use MCP to access spatial data and processes via OGC APIs.\n\nTo illustrate the underlying requirements and potential, consider the following scenario: A local municipality’s urban planner needs to conduct a [cool spot analysis](https://meetingorganizer.copernicus.org/EGU22/EGU22-10358.html) (for context, see our [blog post](https://blog.52north.org/2022/12/16/cool-spots-in-munster/)). Critically, this planner does not possess specialized GIS expertise but interacts with an urban analytics bot. A natural language prompt such as, “Conduct a cool spot analysis based on the new parks I have designed for the city,” should be fully understood and acted upon. Technically, we assume an OGC API process capable of this analysis is available. The bot’s role would be to suggest this functionality, then intelligently prompt for—or even prefill—the required defined input data sources (like the park boundaries) and clearly explain the expected outputs. Once the process is fully configured and validated, it is executed, and the results are returned and visualized for the planner. While this serves as a concrete OGC API Processes example, similar use cases and functional requirements apply to other OGC APIs and associated geospatial services.\n\n**Expected Results**\n\n**A Modular MCP Mapping for a Set of OGC APIs**:- Create a formal, extensible, and machine-readable specification (e.g., JSON schema) that translates core functionality of selected OGC APIs (Features, Records, EDR) into MCP concepts.\n- The design must be modular, allowing independent and reusable translations for each API component.\n\n**A Showcase Implementation Illustrating the Benefit of the MCP Mapping:**- Develop an open-source client library or proxy service (reference implementation) that uses the unified MCP concepts to consume data from diverse OGC API instances.\n- The showcase must demonstrate key benefits: seamless interoperability across different OGC API types, reduced client-side complexity due to abstraction, and decoupling from underlying API specification changes.\n\n\n**Code Challenge**\n\n**Establishment and Configuration of an OGC API – Processes Backend**:**Goal**: To deploy and meticulously configure a robust backend service that fully implements the specifications of the Open Geospatial Consortium (OGC) API – Processes standard.**Scope**: This includes selecting an appropriate open-source or proprietary implementation (e.g., based on technologies like pygeoapi, PyWPS, GeoServer (with plugins), or a custom microservice architecture), setting up the execution environment (e.g., containerization with Docker/Kubernetes), defining the necessary configuration parameters, and ensuring the service adheres to the required endpoints (e.g., /processes, /jobs, /results). Attention must be paid to security protocols, authentication mechanisms, and scaling considerations for potential production use.\n\n**Execution of a Sample Process within the Established Environment:****Goal**: To validate the setup and configuration by successfully invoking and completing a representative OGC API – Processes operation.**Scope**: A simple, yet meaningful, geospatial or analytical process must be defined (e.g., a buffer operation, zonal statistics calculation, or a simple data aggregation). This process will be registered with the newly configured backend. Subsequently, the full lifecycle of the process execution will be tested: submission of the processing request via the API, monitoring the job status, and retrieving the final processed output and/or job result metadata. This task serves as the critical ‘proof-of-concept’ to confirm the entire system is operational and correctly handles input parameters, asynchronous execution, and output delivery according to the OGC API – Processes standard.\n\n\n**Community and Code License**\n\nApache Software License, Version 2\n\n**Mentors**\n\nBenjamin Pross (b.pross @52north.org) , Benedikt Gräler (b.graeler @52north.org)\n\n**Project Duration**\n\nThe duration of the project is estimated at **175** hours. An extension is possible.\n\n**Chat**\n\nTBD\n\n## 2. Weather Routing Tool – QGIS Plugin\n\n### Explanation\n\nThe open-source 52°North [Weather Routing Tool (WRT)](https://github.com/52North/WeatherRoutingTool) was initially developed during the [MariData project](https://52north.org/solutions/marigeoroute/) and is currently being further developed and used in the [TwinShip project](https://twin-ship.eu/). It provides a way to find the optimal route for a ship that minimizes fuel consumption under varying weather conditions. Several constraints can be integrated into the optimization process, such as water depth and traffic separation zones. Currently, there are two algorithms available: an isofuel algorithm and a genetic algorithm. Details of the MariData project and example applications of the Weather Routing Tool can be found in the following publication “[MariData – Digital Twin for Optimal Vessel Operations Impacting Ship Design](https://proceedings.open.tudelft.nl/imdc24/article/view/875.)“.\n\n### Expected Results\n\nA new QGIS plugin for the WRT should be implemented. The implementation should be done in Python.\n\nThe following features are expected:\n\n- Configuration wizard containing\n- a clearly structured interface (considering mandatory, optional, conditional variables)\n- map interactions to set source, destination and intermediate waypoints\n- the possibility to download the final configuration as a json file (to be used to run the WRT)\n\n- Visualization capabilities for\n- weather data including proper styling, time slider and subsetting with statistics (e.g., what is the average wave height in the subset?)\n- routes including their properties (ship speed, fuel consumption, etc.)\n\n\nOptional:\n\n- Mock-ups\n- Before starting with the actual implementation of the GUI components, mock-ups could be created to better plan the design and proposed user interactions\n\n- Running the WRT directly from QGIS\n- Using a quick algorithm (e.g., GCR slider); possibly with live visualization\n- Using the full capabilities of the WRT (including the genetic algorithm etc.)\n\n\n**Links**\n\n[https://github.com/52North/WeatherRoutingTool](https://github.com/52North/WeatherRoutingTool)[https://52north.github.io/WeatherRoutingTool/source/configuration.html](https://52north.github.io/WeatherRoutingTool/source/configuration.html)[https://docs.qgis.org/3.40/en/docs/pyqgis_developer_cookbook/plugins/index.html](https://docs.qgis.org/3.40/en/docs/pyqgis_developer_cookbook/plugins/index.html)[https://g-sherman.github.io/Qgis-Plugin-Builder/](https://g-sherman.github.io/Qgis-Plugin-Builder/)\n\n### Code Challenge\n\n**Run the WRT**- Prepare weather data\n- You are free to choose the geographic region and time. We recommend choosing a small subset to make it easier to handle.\n- Options:\n- Create your own synthetic weather conditions.\n- Download actual historical or forecast data from public portals (Copernicus, NOAA, …).\n\n- Create a configuration file\n- Define a source and destination within the bounding box of the weather data.\n- We recommend using the genetic algorithm (“ALGORITHM_TYPE”) and the direct power method (“BOAT_TYPE”).\n\n\n\n- Prepare weather data\n**Load the final route into QGIS and calculate the total distance from source to destination via the waypoints.**\n\nWhich method is used is up to the user as long as it is done with QGIS. If the QGIS Python console is used, the script has to be shared. If a manual workflow is chosen, the steps have to be clearly documented, e.g., using screenshots.**Document your steps and provide the final route (json file)**.\n\n### Community and Code License\n\nMIT License\n\n### Mentors\n\nMartin Pontius (m.pontius @52north.org), Katharina Demmich (k.demmich @52north.org)\n\n### Project duration\n\nThe duration of the project is estimated at **175** hours. An extension is possible.\n\n### Chat\n\nTBD\n\n## 3. Weather Routing Tool – Improve Test Framework\n\n### Explanation\n\nThe open-source 52°North [Weather Routing Tool (WRT)](https://github.com/52North/WeatherRoutingTool) was initially developed during the [MariData project](https://52north.org/solutions/marigeoroute/) and is currently being further developed and used in the [TwinShip project](https://twin-ship.eu/). It provides a way to find the optimal route for a ship that minimizes fuel consumption under varying weather conditions. Several constraints can be integrated into the optimization process, such as water depth and traffic separation zones. Currently, there are two algorithms available: an isofuel algorithm and a genetic algorithm. Details of the MariData project and example applications of the Weather Routing Tool can be found in the following publication “[MariData – Digital Twin for Optimal Vessel Operations Impacting Ship Design](https://proceedings.open.tudelft.nl/imdc24/article/view/875.)“.\n\n### Expected Results\n\nThe WRT’s apparent test framework shall be extended and available tests improved to achieve a better test coverage as well as better readability. The implementation shall be done using the pytest framework of Python and/or shell scripts.\n\nThe following features are expected:\n\n- Harmonization of available unit tests and improvement of their readability e.g. by\n- the introduction of pytest fixtures,\n- combining test groups into classes,\n- separation into unit and integration test\n\n- Separation of unit tests and monitoring tests:\n- Clear separation of unit/integration tests with hard assertions and tests that produce monitoring figures. While unit tests shall be executed by default, tests that produce monitoring figures shall be executed on demand.\n- If the generation of monitoring figures is demanded, a pdf shall be generated automatically that summarizes the figures.\n\n- Development of regression tests:\n- Automated tests for the reproducibility of routes with the full routing tool for specific configurations.\n- The execution time of the integration tests shall be minimized.\n- Optional: structured summary of potential differences with respect to the test routes provided on demand.\n\n\n**Links:**\n\n### Code Challenge\n\n**Run the WRT**- Prepare weather data\n- You are free to choose the geographic region and time. We recommend chooseing a small subset to make it easier to handle.\n- Options:\n- Create your own synthetic weather conditions.\n- Download actual historical or forecast data from public portals (Copernicus, NOAA, …).\n\n\n- Create a configuration file\n- Define a source and destination within the bounding box of the weather data.\n- We recommend using the genetic algorithm (“ALGORITHM_TYPE”) and the direct power method (“BOAT_TYPE”).\n\n\n- Prepare weather data\n**Implement a unit test for the function RoutingProblem.get_power**assuming that the current results provided by the function are correct. The unit test shall be embedded in the WRT’s test framework.\n\n### Community and Code License\n\nMIT License\n\n### Mentors\n\nMartin Pontius (m.pontius @52north.org), Katharina Demmich (k.demmich @52north.org)\n\n### Project Duration\n\nThe duration of the project is estimated at **175** hours. An extension is possible.\n\n## 4. Weather Routing Tool – Extension of Weather Module for Statistical Analysis\n\n### Explanation\n\nThe open-source 52°North [Weather Routing Tool (WRT)](https://github.com/52North/WeatherRoutingTool) was initially developed during the [MariData project](https://52north.org/solutions/marigeoroute/) and is currently being further developed and used in the [TwinShip project](https://twin-ship.eu/). It provides a way to find the optimal route for a ship that minimizes fuel consumption under varying weather conditions. Several constraints can be integrated into the optimization process, such as water depth and traffic separation zones. Currently, there are two algorithms available: an isofuel algorithm and a genetic algorithm. Details of the MariData project and example applications of the Weather Routing Tool can be found in the following publication “[MariData – Digital Twin for Optimal Vessel Operations Impacting Ship Design](https://proceedings.open.tudelft.nl/imdc24/article/view/875.)“.\n\n### Expected Results\n\nThe weather module of the WRT should be extended to allow statistical analysis. It already allows downloading data subsets from different providers as in-memory objects (xarray.Dataset) or NetCDF file, i.e., as space-time cube or along trajectories. However, there is no built-in functionality to analyse these subsets statistically. Statistical methods from xarray could directly be used. The main challenges are related to memory and/or hard drive storage and runtime (including download time of data). Applications should clearly describe strategies for tackling these challenges.\n\nOne expected use of the statistics feature is to identify suitable scenarios for simulation studies.\n\nThe following investigations are expected:\n\n- Analysis of different methods to store and later on access weather data to achieve optimal runtime without memory issues. Possible alternatives or addons to the current implementation could be to use the Python package dask or the file format Zarr.\n- A summary of the results as well as the implementation of the best-performing method into the WRT.\n- Implementation of the functionality to visualize statistical parameters for a certain area and time spans of the order of one year. The following statistical distributions are desired:\n- Time series plot of the average wind speed (wave height) and direction per day for one year\n- Correlation of wind speed (wave height) and direction for a desired time span\n- Probability distribution of wind speed (wave height) for one year\n\n- Operations which should be supported: subsetting along each dimension (time, space, variables), interpolation, statistics (min, max, mean, …)\n\nOptional:\n\n- Adapters for additional open datasets could be implemented. Currently, data from the\n[Copernicus Marine Service](https://marine.copernicus.eu/)and the[Global Forecast System](https://www.ncei.noaa.gov/products/weather-climate-models/global-forecast)are integrated.\n\n**Links:**\n\n[https://github.com/52North/WeatherRoutingTool](https://github.com/52North/WeatherRoutingTool)[https://github.com/52North/maridatadownloader](https://github.com/52North/maridatadownloader)[https://docs.xarray.dev/en/latest/user-guide/io.html](https://docs.xarray.dev/en/latest/user-guide/io.html)[https://www.dask.org/](https://www.dask.org/)[https://zarr.dev/](https://zarr.dev/)\n\n### Code Challenge\n\n**Run the WRT**- Prepare weather data\n- You are free to choose the geographic region and time. We recommend choosing a small subset to make it easier to handle.\n- Options:\n- Create your own synthetic weather conditions.\n- Download actual historical or forecast data from public portals (Copernicus, NOAA, …).\n\n\n- Options:\n\n- You are free to choose the geographic region and time. We recommend choosing a small subset to make it easier to handle.\n- Create a configuration file\n- Define a source and destination within the bounding box of the weather data.\n- We recommended using the genetic algorithm (“ALGORITHM_TYPE”) and the direct power method (“BOAT_TYPE”).\n\n\n- Prepare weather data\n**Use a profiler to analyze run time and/or memory consumption of the WRT’s execution and summarize the results.****Document your steps and provide the final route (json file)****Visualize the wave height and wind direction for the chosen time period and calculate the respective mean value, median and standard deviation.**\n\n### Community and Code License\n\nMIT License\n\n### Mentors\n\nMartin Pontius (m.pontius @52north.org), Katharina Demmich (k.demmich @52north.org)\n\n### Project Duration\n\nThe duration of the project is estimated at **175** hours. An extension is possible.\n\n## 4. Your Idea\n\nWe are also open to your own ideas for developing open source software that addresses 52°North’s software or fits within the scope of 52°North. Before writing a detailed proposal, we strongly recommend that you contact our org-admin with a project pitch (~1 page) that addresses at least the following points\n\n- Project name:\n- Reference to existing open source solution (if any):\n- Explanation of the software’s scope/purpose/context:\n- Expected results of the proposed project:\n- Community and Code License in use/planned:\n- Mentor candidates (if any):"
  },
  {
    "name": "JabRef e.V.",
    "slug": "jabref-ev",
    "tagline": "Stay on top of your Literature",
    "description": "JabRef is one of the most widely used citation and reference management tools. It helps students and researchers to stay on top of their literature by assisting at every step of a research project: collecting and organizing literature sources, discovering the latest research, citing references in LaTeX and other text editors, and sharing interesting papers with collaborators.\n\nJabRef is open-source and cross-platform. It is written in Java using JavaFX as the user interface technology. It is licensed under the MIT license.\n\nSince 2020 JabRef is maintained by the non-profit organization JabRef e.V.",
    "ideas_url": "https://jabref.github.io/GSoC/projects/",
    "website_url": "https://www.jabref.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "java",
      "javafx",
      "ai",
      "bibtex"
    ],
    "topic_tags": [
      "science",
      "library",
      "literature",
      "latex",
      "bibliography"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/jabref-ev",
    "ideas_content": "# Projects\n\n### Improved Journal Abbreviations\n\nCurrently, JabRef has a single list of journal abbreviations. This list is a combined list of the `.csv`\n\nfiles at [https://github.com/JabRef/abbrv.jabref.org/tree/main/journals](https://github.com/JabRef/abbrv.jabref.org/tree/main/journals). Instead of the dropdown of JabRef should not show a single “JabRef built in list”, but should show the various lists we offer: built-in lists, external lists, custom lists. Then, one can enable and disable with a click. This eases the users to find issues in abbreviation lists and allows users to customize the lists according to their field (e.g., physics, information science, …).\n\nFore more context, see: [https://github.com/JabRef/jabref/issues/12364](https://github.com/JabRef/jabref/issues/12364) and list of all abbreviation issues: [https://github.com/jabref/jabref/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22component%3A%20journal%20abbreviations%22](https://github.com/jabref/jabref/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22component%3A%20journal%20abbreviations%22). Please also check existing pull requests and comments on them.\n\n**Skills required:**\n\n- Java, JavaFX\n\n**Expected Outcome:**\n\nA UI view which allows selecting/including journal abbreviations by category.\n\n**Possible Mentors:**\n\n**Project size:**\n\n- 90h (small) to medium\n\n### Improved LibreOffice-JabRef integration\n\n**Description:**\n\nJabRef can connect to LibreOffice to offer premier reference management by allowing users to cite library entries directly into the document, and then generate bibliographies based on the cited entries. See [JabRef LibreOffice Integration](https://docs.jabref.org/cite/openofficeintegration).\n\nWe have a collection of independent projects available for the LibreOffice/OpenOffice integration feature of JabRef.\n\n**BST style support:**Currently, custom styles (JStyles) and CSL styles are supported. In the LaTeX-world, BST styles (specified via`.bst`\n\nfiles) are still popular. JabRef already has BST support, but it is currently not accessible via the UI.- Expected deliverable: It should be possible to select a\n`.bst`\n\nfile, which is then used for rendering into the LibreOffice document. [Details:[#624](https://github.com/JabRef/jabref/issues/624)]\n\n- Expected deliverable: It should be possible to select a\n**Improved support for CSL styles:**Support for CSL styles in the LibreOffice integration has been a popular new feature in JabRef that[users look forward to](https://discourse.jabref.org/t/error-when-connecting-to-libreoffice/5431/14?u=subhramit). This project aims to enhance the integration further by introducing**Footnote-based citation support for CSL styles**. Currently, using CSL styles in footnotes of the LibreOffice document causes unexpected behavior, especially for numeric styles. There should be a proper definition of the “global order” of the citations so that they can be used in footnotes. This problem is already solved for JStyles (see a high-level overview[here](https://devdocs.jabref.org/code-howtos/openoffice/order-of-appearance.html)), so the solution needs to be extended/adapted for CSL styles (and BST styles, if project 1 is also undertaken).- Expected deliverable: It is possible to use CSL styles in the footnotes of the documents, without any unexpected/broken ordering in the bibliography or numeric citations. [Tracking issue:\n[#12484](https://github.com/JabRef/jabref/issues/12484)]\n\n- Expected deliverable: It is possible to use CSL styles in the footnotes of the documents, without any unexpected/broken ordering in the bibliography or numeric citations. [Tracking issue:\n**Cross-compatibility with other reference management software**: In case of CSL styles, reference management software like[Zotero](https://www.zotero.org/)and[Mendeley](https://www.mendeley.com/)can read each other’s citations in LibreOffice. This is made possible by following a specific format of document annotations, embedding information in CSL JSON. In JabRef, the internal format of references is currently a JabRef-custom format. It should be changed to a format used by Zotero, so that cross-compatibility can be ensured. See the discussion at[https://github.com/JabRef/jabref/issues/2146#issuecomment-891432507](https://github.com/JabRef/jabref/issues/2146#issuecomment-891432507)for details. This includes: i) Implementation of that format, ii) Implementation of a converter from the “old” JabRef-Format to the new one. The converter could be implemented within OpenOffice (similar to[JabRef_LibreOffice_Converter](https://github.com/teertinker/JabRef_LibreOffice_Converter?tab=readme-ov-file#jabref_libreoffice_converter)).- Expected deliverable: One can seamlessly switch working with LibreOffice documents having citations from Zotero and JabRef.\n\n**Seamless citation style type switching:**JabRef in LibreOffice should support auto-updation of references when switching from CSL-based formats to JStyle (or BST)-based formats and back. Currently, if the user messes up and realizes that they had to use another style family, the workaround is to re-cite all entries again with the new style, then refresh the bibliography. This may not be very user-friendly when citation styles need to be updated when submitting papers to different journals (one use-case), or simply because of last-minute change in decisions. For this project, the starting step will be unifying the “reference mark” (document annotation) format for all these style types, so that the entry information can be parsed across styles. This project thus goes very well coupled with Project 1 and Project 3.- Expected deliverable: On changing style type (CSL/BST/JStyle), all references in the documents should seamlessly adapt to the new style.\n\n\n**Skills required:**\n\n- Java, JavaFX\n\n**Possible Mentors:**\n\n**Project size:**\n\n**350h (large)**: If (Project 1 + Project 2 + Project 3 + Project 4)**175h (medium)**: If (Project 1 + Project 2)**OR**(Project 2 + Project 3)**OR**(Project 1 + Project 3)**90h (small)**: If Project 1**OR**Project 2**OR**Project 3\n\n### Improve handling of older documents by OCR and AI\n\nJabRef, comprehensive literature management software, currently supports both handling metadata and text-based PDF documents. However, a significant limitation arises with scanned PDFs, particularly historical articles, which are not text-searchable due to their image-based format. This project aims to bridge this gap by integrating advanced OCR (Optical Character Recognition) technology, enabling full-text search in scanned PDFs.\n\n**Useful links:**\n\n[OCR Integration in JabRef - Meta Issue](https://github.com/JabRef/jabref/issues/13267)- A Document AI Package: https://github.com/deepdoctection/deepdoctection\n- Hand-written text recognition in historical documents: https://github.com/githubharald/SimpleHTR#handwritten-text-recognition-with-tensorflow\n- Java OCR with Tesseract:\n[Baeldung Guide](https://www.baeldung.com/java-ocr-tesseract) - Tesseract OCR Library:\n[Official Documentation](https://tesseract-ocr.github.io/) - OCRmyPDF Installation and Usage:\n[GitHub Repository](https://github.com/ocrmypdf/OCRmyPDF#installation) - ChatOCR and ChatGPT Integration:\n[Blog Article](https://www.blogmojo.de/chatgpt-plugin/chatocr/) - AI-Powered OCR:\n[Addepto Blog](https://addepto.com/blog/ai-powered-ocr-optical-character-recognition-enhancing-accuracy-and-efficiency-in-document-analysis/) - Tika OCR Integration:\n[Apache Tika Wiki](https://cwiki.apache.org/confluence/display/tika/tikaocr) - Surya AI powered OCR, apparently better than Tesseract, but coded in python\n[VikParuchuri/Surya](https://github.com/VikParuchuri/surya) - SOTA (October 2025) language model for OCR:\n[PaddleOCR-VL](https://huggingface.co/PaddlePaddle/PaddleOCR-VL); Supported by[llama.cpp with PR 16701](https://github.com/ggml-org/llama.cpp/pull/16701)\n\n**Some aspects:**\n\n- Add an option to call an OCR engine from JabRef, e.g., cloud based or local installs\n- Define a common interface to support multiple OCR engines\n- Provide a good default set of settings for the OCR engines\n- Support expert configuration of the settings\n- Add the extracted text as a layer to the pdf so that Apache Lucene can parse it\n- Add an option to further process the text with Grobid for training and metadata extraction\n\n**Expected outcome:**\n\nA) Develop a common interface within JabRef to accommodate multiple OCR engines, ensuring flexibility and expandability. B) Enable expert users to fine-tune OCR settings, catering to specific needs or document formats.\n\nC) Incorporate the OCR-extracted text as a searchable layer in PDFs, allowing Apache Lucene to index and look for the content.\n\n**Skills required:**\n\n- Proficiency in Java programming.\n- A keen interest and curiosity in document processing and AI technologies.\n\n**Possible mentors:**\n\n[@Siedlerchr](https://github.com/Siedlerchr), [@InAnYan](https://github.com/InAnYan/), [@calixtus](https://github.com/calixtus), [@subhramit](https://github.com/subhramit)\n\n**Project size:**\n\n90h (small)\n\n### JabRef components as native images\n\nJabRef consists of multiple parts: JabKit, JabLS, JabSrv, and JabRef (the GUI).\n\nJabKit is the command-line tool of JabRef offering all the “cool” functionality using a command-line interface. Currently, JabKit is distributed by jpackage and JBang. JPackage creates an installer and portable version. The startup time is way too long for a CLI application. While the installer and portable version include a JDK, JBang downloads the JRE for itself and “just” downloads the Maven artifact jablib to enable execution.\n\nIn the Java compiler space, there is the option of [GraalVM and “native image”](https://www.graalvm.org/latest/reference-manual/native-image/). This enables generating an executable file (.exe on Windows) which promises a faster startup.\n\nThis GSoC project has two phases:\n\n- Phase 1: Adapt JabKit+jablib to be compatible with\n`graalvm-native`\n\n- Phase 2: Adapt JabGui to be compatible with\n`graalvm-native`\n\n- Phase 3: Adapt JabLS to be compatible with\n`graalvm-native`\n\n- Phase 4: Adapt JabSrv to be compatible to\n`graalvm-native`\n\n\nEspecially phase 2 might require exchanging libraries in JabRef.\n\n**Why is this a nice project?**\n\nOne can learn about fields of Java known to a little group of developers only. One touches areas very new in the Java space. Finally, one can learn about [WASM-compiling of Java](https://github.com/oracle/graal/issues/3391).\n\n**Expected outcomes:**\n\n- jabkit.exe (JabRef’s CLI tool)\n- jabref.exe (JabRef GUI)\n- jabls.exe\n- jabsrv.exe\n\n**Skills required:**\n\n- Strong Java-coding skills\n- Endurance, because this project might include much trial-and-error\n\n**Possible Mentors:**\n\n**Links:**\n\n- Source of JabKit:\n[https://github.com/JabRef/jabref/tree/main/jabkit](https://github.com/JabRef/jabref/tree/main/jabkit) - Initial PR trying it:\n[https://github.com/JabRef/jabref-koppor/pull/693](https://github.com/JabRef/jabref-koppor/pull/693) - JBang runner for JabKit:\n[https://github.com/JabRef/jabref/tree/main/.jbang#running-jabkit](https://github.com/JabRef/jabref/tree/main/.jbang#running-jabkit) - Way to have a single binary running on multiple platforms:\n[https://github.com/oracle/graal/pull/12865](https://github.com/oracle/graal/pull/12865)\n\n**Project size:**\n\n175h (medium)\n\n### Use PostgreSQL as full GUI data backend for JabRef\n\nCurrently, JabRef GUI holds all entries in memory. It even converts LaTeX to Unicode and vice versa to support better search. While this is a great UX, this leads to a huge memory consumption. The more “proper” way is to use a database (such as PostgreSQL) to store the entries. Then, not all entries need to be loaded in memory. The first step is to introduce a data-access layer: The maintable should read from SQL database, not from all in-memory. Possible future work may be: [https://www.zotero.org/support/dev/client_coding/direct_sqlite_database_access](https://www.zotero.org/support/dev/client_coding/direct_sqlite_database_access) and [https://github.com/zotero/zotero/blob/main/resource/schema/userdata.sql](https://github.com/zotero/zotero/blob/main/resource/schema/userdata.sql).\n\nThere can be an initial phase to evaluate whether PostgreSQL is the right DBMS as backend for JabRef. For instance, DuckDB and SQLite were also discussed. Currently, PostgeSQL turned out best (especially for handling regular expression search on the database itself), but things may have changed in 2026.\n\nThis is issue [https://github.com/JabRef/jabref/issues/12708](https://github.com/JabRef/jabref/issues/12708).\n\n**Skills required:**\n\n- PostgreSQL, Java, JavaFX\n\n**Code places to start to look at:**\n\n- org.jabref.gui.maintable.MainTableFieldValueFormatter#formatFieldsValues\n\n**Starting points:**\n\n- Document the maintable of JabRef using Markdown and UML (starting point:\n`org.jabref.gui.util.ValueTableCellFactory`\n\n)\n\n**Possible Mentors:**\n\n**Project size:**\n\n175h (medium)\n\n### Improved SLR Support\n\nWith the ever-growing number of publications in computer science and other fields of research, conducting secondary studies becomes necessary to summarize the current state of the art. For software engineering research, Kitchenham popularized the systematic literature review (SLR) method to address this issue. The main idea is to systematically identify and analyze the majority of relevant publications on a specific topic. This is usually an activity that takes extensive manual effort. Some tool support does exist, but the full potential of tools has not been exploited yet. JabRef also offers basic functionality for systematic literature reviews that is used by a number of researchers to systematically “harvest” related work based on the fetching capabilities of JabRef. While using the feature, various additional feature requests came up. For instance, created search queries are currently transformed internally by JabRef to the query format of the publisher. It should also be possible to directly input a query at the publisher site, e.g., for IEEE or ACM.\n\nMore background information: [Paper: Systematic Literature Tools: Are we there yet?](https://ceur-ws.org/Vol-2839/paper13.pdf); ** Presentation**.\n\nOne key aspect would be the improvement of the fetcher infrastructure in JabRef to better adapt to new and changing Publisher/Journal websites and to offer a more direct integration. As an inspiration, see [BibDesk](https://bibdesk.sourceforge.io/).\n\nExample SLRs: [https://dl.acm.org/doi/full/10.1145/3690632](https://dl.acm.org/doi/full/10.1145/3690632)\n\n**Expected outcome:**\n\nAn advanced SLR functionality, where a researcher is supported to execute a systematic-literature-review.\n\nWe did an initial project organization at [https://github.com/users/koppor/projects/2](https://github.com/users/koppor/projects/2).\n\n**Skills required:**\n\n- Java, JavaFX\n\n**Possible mentors:**\n\n[@koppor](https://github.com/koppor), [@calixtus](https://github.com/calixtus), [@subhramit](https://github.com/subhramit)\n\n**Project size:**\n\n175h (medium)\n\n### Sync with Zotero Storage\n\nZotero is an alternative to JabRef with features focused on collaboration (and less on BibTeX quality). Zotero offers a [Storage](https://www.zotero.org/storage). It would be great if JabRef could synchronize with the storage.\n\nZotero offers an [API](https://www.zotero.org/support/dev/web_api/v3/start) to access the data. It should be used to synchronize data from and to Zotero.\n\nSpecial attention should be put on synchronization of data if the local BibTeX file changes in parallel. Different scenarios of synchronization should be regarded. This knowledge should also be used to enhance the git support and OneDrive/Dropbox support.\n\n**Possible Mentors:**\n\n[@koppor](https://github.com/koppor), [@InAnYan](https://github.com/InAnYan/), [@calixtus](https://github.com/calixtus), [@subhramit](https://github.com/subhramit)\n\n**Project size:**\n\n175h (medium)\n\n### More Generic Preferences\n\nJabRef’s strength is that everything is configurable. There are more than 100 parameters to tweak. This is loved and hated by users at the same way.\n\nTwo major pain points exist.\n\n- In the BibTeX (.bib) file, the preferences are stored using a custom format.\n- Some preferences can be configured for each Bib file, but not all.\n\nIn this project, two things should be tackled:\n\n- Rewrite preferences storage in the BibTeX file to JSON\n[#10371](https://github.com/JabRef/jabref/issues/10371) - Offer preferences to be configured in the library.\n[#8701](https://github.com/JabRef/jabref/issues/8701)\n\nNote that 2 does NOT mean that all preferences should be stored in the library; only the ones the user wants to store.\n\n**Possible Mentors:**\n\n**Project size:**\n\n350h (large)\n\n### {Your own project}\n\nThe list of projects is by no means a closed list. You can propose other projects. JabRef offers various places where it can be improved. Think as a user or talk to other users. The following places are a good start:\n\n- Big projects:\n[https://github.com/JabRef/jabref/issues?q=sort%3Aupdated-desc+state%3Aopen+label%3A%22size%3A+big%22](https://github.com/JabRef/jabref/issues?q=sort%3Aupdated-desc+state%3Aopen+label%3A%22size%3A+big%22) - General list of feature requests:\n[https://discourse.jabref.org/c/features](https://discourse.jabref.org/c/features) - Candidates of university projects, the large ones:\n[https://github.com/orgs/JabRef/projects/3/views/3?filterQuery=status%3A%22free+to+take%22+size-of-project%3Alarge&sortedBy%5Bdirection%5D=desc&sortedBy%5BcolumnId%5D=8246261](https://github.com/orgs/JabRef/projects/3/views/3?filterQuery=status%3A%22free+to+take%22+size-of-project%3Alarge&sortedBy%5Bdirection%5D=desc&sortedBy%5BcolumnId%5D=8246261) - Issues tagged with GSoC:\n[https://github.com/JabRef/jabref/issues?q=sort%3Aupdated-desc+state%3Aopen+label%3A%22project%3A+gsoc%22](https://github.com/JabRef/jabref/issues?q=sort%3Aupdated-desc+state%3Aopen+label%3A%22project%3A+gsoc%22) - The\n[GitHub issue tracker](https://github.com/JabRef/jabref/issues)might serve as an additional source of inspiration) - Switch to Apache Velocity:\n[https://github.com/JabRef/jabref/issues/12418](https://github.com/JabRef/jabref/issues/12418)"
  },
  {
    "name": "MoganLab",
    "slug": "moganlab",
    "tagline": "Make acedemic writing as nature as breathing",
    "description": "Moganlab develops Mogan STEM, a professional scientific writing platform specifically designed for mathematics, physics, statistics, and computer science, targeting complex formula-based documents. It is deeply optimized from GNU TeXmacs, with emphasis on performance and user experience. With Mogan STEM, you can create documents 100 times faster than LaTeX",
    "ideas_url": "https://github.com/MoganLab/GSoC-2026-MoganLab/blob/main/idelas/main.md",
    "website_url": "https://mogan.app/en/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c++",
      "qt",
      "scheme"
    ],
    "topic_tags": [
      "editor",
      "latex",
      "AI for math"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/moganlab",
    "ideas_content": "# GSoC 2026 Project Ideas with MoganLab\n\n## Introduction\nMoganLab is a nonprofit organization dedicated to building innovative, open-source tools for science and education. Our flagship project, **Mogan**, is a modern, structured editor designed for scientific and technical writing, forked from GNU TeXmacs.\n\nFor GSoC 2026, we offer exciting projects that combine deep technical challenges with real-world impact. Contributors will work on the frontier of interactive scientific software, gain mentorship from experienced developers, and become part of our global community. We look forward to collaborating with passionate students to push the boundaries of what's possible in open-source scientific tools.\n\n## Project Ideas\n\n### 1. Project Title: Web-Based Collaborative Editing Core\n- **Description:** Mogan currently operates as a powerful desktop application. This project aims to bring its core editing experience to the web. The main technical challenge is to port the essential editing engine to run efficiently in a modern browser using technologies like WebAssembly, enabling real-time collaborative writing and editing sessions.\n- **Expected Outcomes:** A functional web-based prototype capable of opening standard `.tmu` files, rendering document structure, and performing basic collaborative editing operations (e.g., concurrent text editing) in a browser. This will serve as the foundational backend for future collaborative features.\n- **Recommended Skills:** Strong C++ (for understanding and porting core logic), proficiency in JavaScript/TypeScript and modern web frameworks, familiarity or strong interest in WebAssembly (Emscripten). Experience with real-time communication (WebSockets) is a plus.\n- **Difficulty:** High\n- **Potential Mentors:** [Darcy Shen/Email da@liii.pro]\n- **Reference:** [https://research.mogan.app/research.html]\n\n### 2. Project Title: Julia Plugin with Virtual Environment Support\n- **Description:** Mogan excels at integrating computational code within documents, similar like Jupyter Notebook but with thesis-level editing support. This project focuses on deeply enhancing Mogan's support for the Julia programming language. The goal is to build a robust plugin that not only executes Julia code but also seamlessly manages Julia project environments (`Project.toml`) and packages, allowing users to reproduce computations inside the document. \n- **Expected Outcomes:**\n    1.  A fully functional Julia plugin within Mogan that can execute code snippets and scripts.\n    2.  Integration with Julia's package manager (Pkg) to activate and manage project-specific virtual environments from within the editor.\n    3.  Basic support for resolving and loading dependencies specified in a `Project.toml` file.\n    4.  Support copy and paste between Mogan to Julia. For example, one can directly copy a matrix from the math mode in mogan to Julia Session for computation and vice versa.\n- **Recommended Skills:** Proficiency in the Julia programming language, understanding of Julia's package and project management system. Experience with C++ and Scheme (for plugin integration with Mogan's API) is beneficial.\n- **Difficulty:** Medium\n- **Potential Mentors:** [Jack Li/Email yansong@liii.pro]\n- **Reference:** [https://github.com/mgubi/tm-julia]"
  },
  {
    "name": "TARDIS RT Collaboration",
    "slug": "tardis-rt-collaboration",
    "tagline": "Exploring supernovae made easy",
    "description": "TARDIS is a tool that creates synthetic observations (spectra) for exploding stars (supernovae). \n\nA supernova marks the brilliant death throes of a star, during which it outshines its entire galaxy. Through their explosive stellar death, supernovae enrich the Universe with new elements necessary for the formation of planets and life as we know it. From the iron in your blood to the silicon in your laptop, supernovae are responsible for producing many important elements from the primordial hydrogen and helium left over from the Big Bang.\n\nTARDIS provides a link between theory and observations: by creating synthetic spectra from theoretical assumptions and comparing these to observations, we can both interpret data and test models for why, when and how supernova explosions occur.\nWe, the community around TARDIS, are interested in combining astronomy, computer science, statistics and modern software design to build a tool that is useful both in research and teaching alike (with supporting documentation that would, in theory, allow anyone to recreate the project from scratch). Please join us on https://gitter.im/tardis-sn/gsoc.",
    "ideas_url": "https://tardis-sn.github.io/summer_of_code/ideas/",
    "website_url": "https://tardis-sn.github.io",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "numba",
      "numpy",
      "jupyter",
      "pandas"
    ],
    "topic_tags": [
      "visualization",
      "big data",
      "simulation",
      "astrophysics"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/tardis-rt-collaboration",
    "ideas_content": "## Table of Contents\n\n### Astronomy and Astrophysics Background:\n\nA [supernova](https://en.wikipedia.org/wiki/Supernova)(here we show SN1994D in the Galaxy NGC4526 - image source: wikipedia) marks the brilliant death throes of a star, during which it outshines its entire galaxy. It not only marks death, though: supernova ejecta change the evolution of the universe and enable the formation of planets and life as we know it. From the iron in your blood to the silicon in your laptop, supernovae return heavy elements assembled from the primordial hydrogen and helium left after the big bang.\n\nWith sophisticated computer simulations astronomers try to reproduce the observed spectra to draw conclusion about the properties of the supernova ejecta and ultimately the explosion mechanism and progenitor stars. TARDIS is such a numerical code. It calculates theoretical spectra based on a number of input parameters, such as the supernova brightness and the abundances of the different chemical elements present in the ejecta (e.g. Oxygen, Silicon, Iron, etc.). The main idea for this procedure is that by finding a close match between theoretical and observed spectra we identify the parameters that actually describe the supernovae.\n\n### The TARDIS Project\n\nAs mentioned in the background information above, TARDIS is a scientific tool (more specifically a Monte Carlo radiative transfer code) whose primary goal is the calculation of theoretical spectra for supernovae. Below, you find the typical result of a TARDIS calculation. It shows the calculated synthetic spectra for a simple supernova model. This particular setup (tardis_example) is officially provided by the TARDIS collaboration on the [documentation](https://tardis-sn.github.io/tardis/).\n\n### List of GSoC 2026 Project Ideas\n\nIn the TARDIS collaboration we first establish a detailed plan on implementing new features before starting the actual work. This is an important step that ensures that the entire TARDIS collaboration is informed about the development efforts and that the team members can help shape the ideas during the discussion phase. We call these documents TEP - TARDIS Enhancement Proposals. We already have a great list of ideas [here](https://github.com/tardis-sn/tep) that we need help with. Some of these we have specially selected for GSoC 2026 and are listed with specific “warm-up” tasks below. But feel free to propose your own TEP and make a PR on that.\n\nIf you use one of our TEPs, you can definitely add more detail to the implementation, but what we really want to see is a detailed timeline with milestones that shows us that you have thought about how to implement the feature in three months. For any questions about the projects, please ask on [Gitter](https://gitter.im/tardis-sn/gsoc).\n\nPutting in a [Pull Request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request) with the First objective is essential for each proposal to allow to see how you work.\n\n* NOTE:*\nPlease also read our\n\n[AI and LLM Usage Policy](https://tardis-sn.github.io/ai_usage_policy).\n\n#### Rewrite the Custom Abundance Widget in Panel\n\n**Project Length:** 350 Hours**Difficulty:** Hard**Mentors:** Andrew Fullard, Atharva Arya, James Gillanders, Jaladh Singhal**Description:** TARDIS has a collection of visualisation tools and widgets to interactively explore TARDIS simulations which run inside Jupyter Notebooks. A lot of these modules currently depend on dependencies like ipywidgets which do not work well with our Sphinx documentation. Some of these tools have already been migrated but we want to migrate the rest of our widgets to panel too. For this project, you will be working on migrating the custom abundance widget to Panel.\n\nVisualisation Module:\n[https://tardis-sn.github.io/tardis/analyzing_tardis/visualization/index.html#tardis-widgets-graphical-user-interfaces](https://tardis-sn.github.io/tardis/analyzing_tardis/visualization/index.html#tardis-widgets-graphical-user-interfaces)\n\n**First Objective:** The line info and shell info widgets are already migrated to panel but they are not fully interactive on the documentation. For instance, in shell info widget, switching the first table does not switch the other ones unlike in a live notebook. As the first objective of this project, your task is to make the widget fully interactive so that the widget mimics its behaviour as if it were in a notebook.\nSee [documentation here](https://tardis-sn.github.io/tardis/analyzing_tardis/visualization/how_to_generating_widgets.html#How-to-Generate-Data-Exploration-Widgets).\n\n**Expected Outcomes:**\n\n- The custom abundance widget moved to Panel.\n- Visualisation tools and widgets can be embedded on the website allowing users to interact with them.\n- Comprehensive documentation and tests for all code written.\n\n#### TARDIS Setups Generated Plots and Gallery\n\n**Project Length:** 350 Hours**Difficulty:** Medium**Mentors:** Josh Shields, Andrew Fullard**Description:** The TARDIS umbrella includes a repository for people to put models and simulations that have been used in scientific studies, found at [tardis-setups](https://github.com/tardis-sn/tardis-setups). However, there is very little ability for people to look at what is there, or glean information from the TARDIS models that would be produced by the inputs that live in the repository. This project proposes to develop a template notebook that would be run with every set of TARDIS inputs in the TARDIS setups repository. This notebook would provide a brief overview of the inputs used to generate TARDIS spectra, and an analysis visualization output generated with those TARDIS inputs. This would allow for a quick glimpse into which models exist in the repository, and could also serve as a jumping off point for people who want to create new models, since they will have access to a suite of verified working TARDIS inputs and simulations.\n\nThis project could be extended to include a web development component, where the notebook described in the last paragraph could be displayed for each set of inputs that exist in TARDIS setups, and could be easily browsed. This would also include either a pipeline for new submissions to the TARDIS setups repository to automatically produce new notebooks as well.\n\n**First Objective:** Begin by making a notebook that produces a simulation with the inputs in our quickstart notebook, which can be found high up in our documentation page. Then, create a “SDec plot” and a “LIV plot” with those simulation inputs. Once you know how to do this, create a standalone script that produces those two plots and saves them to pdf or png, accepting a yml and atomic data file as inputs to your script. Validate your script by trying it out with different TARDIS .yml inputs found in the TARDIS setups repository.\n\n**Expected Outcomes:**\n\n- Visualization notebook that demonstrates a run of TARDIS, as well as the various analysis tools TARDIS offers.\n- A revamping of the TARDIS setups repository to accommodate generating the notebook with the models that exist in the TARDIS setups repository.\n- An easy to use pipeline that runs for new submissions to the TARDIS setups repository.\n\n#### Continuum Opacity Source Reader\n\n**Project Length:** 350 Hours**Difficulty:** Medium**Mentors:** Andrew Fullard, Josh Shields**Description:** There’s a lot of literature with useful tables for the TARDIS codebase and other scientific codes in pdfs (e.g. [this paper](https://academic.oup.com/mnras/article/266/4/805/982644)), or often in dataproducts. [Carsus](https://tardis-sn.github.io/carsus/) currently reads in data from standard sources and archives ([Chianti](https://www.chiantidatabase.org/), [CMFGEN](https://sites.pitt.edu/~hillier/web/CMFGEN.htm)), but does not flexibly read data from sources in the literature. The goal of this project is to expand Carsus to read datatables like ones in this work, with potential expansion for a future-proof workflow (new opacity tables). These could all go in a new tardis repository called “carsus-literature-tables” or something along those lines. You can look at [carsus-data-molecules-barklem2016](https://github.com/tardis-sn/carsus-data-molecules-barklem2016) for a preprocessed datatables ready to be ingested by Carsus might look.\n\n**First Objective:** Read one of the datatables from [this archive](https://cdsarc.cds.unistra.fr/viz-bin/cat/VI/80#/browse) (try s92.201.gz, under ftp) and process it into a pandas dataframe. Look to do this in a programmatic way that could be reused for similar files, like the other tables found here. See section 6.4 of [this paper](https://articles.adsabs.harvard.edu/pdf/1994MNRAS.266..805S) for more details on table contents and formatting if desired.\n\n**Expected Outcomes:**\n\n- Code that reads in the new dataproducts and integrates with Carsus.\n- Comprehensive documentation and tests for all code written.\n\n#### Benchmark Optimisation\n\n**Project Length:** 350 Hours**Difficulty:** Hard**Mentors:** Andrew Fullard, Atharva Arya**Description:** TARDIS commits are monitored by a benchmarking framework to detect performance regressions. But the current framework only tests 5 commits at a time and not with much detail. The goal of this project is to improve the benchmarking framework by adding more benchmarks. This project will also add more benchmarks to STARDIS, a related code. The second stage of the project will use the benchmarks to investigate possible performance improvements to TARDIS and STARDIS.\n\n[TARDIS Benchmarks](https://tardis-sn.github.io/tardis-benchmarks/) | [STARDIS Benchmarks](https://tardis-sn.github.io/stardis-benchmarks/)\n\n**First Objective:** Benchmark the Plasma solver factory: [base.py](https://github.com/tardis-sn/tardis/blob/master/tardis/plasma/assembly/base.py) and share the ASV results for the last 5 commits along with the code in a pull request.\n\n**Expected Outcomes:**\n\n- Exhaustive benchmarks that time important TARDIS modules like plasma, transport, visualisation to name a few.\n- Larger history of benchmarks (currently only 5) and regenerating benchmarks for failed commits to avoid losing benchmark history.\n- Comprehensive documentation and tests for all code written.\n\n#### Improving Test Coverage for Plasma Module\n\n**Project Length:** 350 Hours**Difficulty:** Medium**Mentors:** Andrew Fullard, Atharva Arya, Josh Shields**Description:** TARDIS has an extensive test suite, but automated test coverage metrics (i.e., CodeCov) do not accurately report coverage of the TARDIS Plasma due to the details of its implementation. The goal of this project is to comprehensively test the plasma by making tests that are easy to find and test each part of the plasma respectively. Additionally, several parts of the module are indirectly tested using the regression data and are missing focussed tests. This makes debugging harder during failures since its hard to pin point the root cause of the failures in multiple tests. The project will begin by taking inventory of which parts of the plasma have existing tests and which do not. The student will then fill in the gaps in the plasma test coverage. Along the way, the student will learn various details of plasma physics and testing infrastructure in a large scientific codebase.\n\n**First Objective:** For both objectives, indicate why that is a good test. BONUS - write in the PR description what other tests you would test.\n\n*Level 1:* The DilutePlanckianRadiationField class is tested in various places indirectly via the regression tests but no direct test exists. Write a test for this class using regression data. For first objective purposes, modify the path of the regression data so that you don’t need to open a pull request in the regression data repository too.\n\n*Level 2:* Write tests for the RadiativeRatesSolver class, using the regression data as in Level 1. Modify the path of the regression data similarly.\n\n**Expected Outcomes:**\n\n- Comprehensive test coverage for the plasma module.\n\n#### Visualizing Packet History with Sankey Diagram\n\n**Project Length:** 350 Hours**Difficulty:** Medium**Mentors:** Connor McClellan, Jaladh Singhal, Jared Goldberg**Description:** A TARDIS simulation propagates a large number of Monte Carlo packets throughout the simulation domain and the last packets form the output synthetic spectrum. There is a collection of existing [visualization tools](https://tardis-sn.github.io/tardis/analyzing_tardis/visualization/index.html) that help researchers analyze the packet information, especially the last interaction. However, there are no tools/widgets to visualize the full packet history from the start to end yet. The goal of this project is to build a widget to visualize the full packet interaction history using a Sankey Diagram. The full packet history is stored within the `workflow.transport_state.tracker_full_df`\n\ndataframe if the setting `config.montecarlo.tracking.track_rpacket`\n\nis set to True.\n\n**First Objective:** Extract a single packet’s interaction history from the full tracker dataframe and filter out “boundary” interactions. Try to find a packet that has a few different types of physical interactions before it escapes. Print out a list of interactions or create a simple plot showing this single packet’s interaction history.\n\n**Expected Outcomes:**\n\n- Parametrize the plotter to customise it, such as select a specific starting/end condition and/or a subset of interaction types (e.g., electron scattering, specific line interactions).\n- Visualization tool that’s documented and tested similar to SDEC plot and other existing visualization tools.\n\n#### Standardizing Test Tolerances\n\n**Project Length:** 350 Hours**Difficulty:** Medium**Mentors:** Andrew Fullard, Atharva Arya, Josh Shields**Description:** The TARDIS test suite verifies accuracy of the codebase using data files stored in the regression data repository. However, the tolerance levels at which data is compared is different across different parts of the code. The goal of this project is to standardize test tolerances for each test function or module, taking into account numerical differences between the different platforms for which TARDIS is developed (Mac versus Linux, for example). Since these tolerances vary based on the module due to the intricacies of the codebase, you will also have to find out which parts of the code cause these levels to rise.\n\nFor instance, [test_sdec_plot.py](https://github.com/tardis-sn/tardis/blob/6c9897f95301023b155e9714e495d1dc25819ddf/tardis/visualization/tools/tests/test_sdec_plot.py#L16) has its tolerance level set.\n\n**First Objective:** Find the tolerance levels of tests of TestBlackBodySimpleSource class and make a pull request.\n\n**Expected Outcomes:**\n\n- Known causes for different tolerance levels in different parts of the code.\n- All test assertions with set tolerance levels."
  },
  {
    "name": "Open Technologies Alliance - GFOSS",
    "slug": "open-technologies-alliance-gfoss",
    "tagline": "Promote Open Standards and Open Source",
    "description": "Open Technologies Alliance (GFOSS)  is a non-profit organization, with 37 Universities and Research Centers as its shareholders. Our main goal is to promote Openness.\nGFOSS – Open Technologies Alliance  is a platform for Open Standards, Free Software, Open Content, Open Data & Open Hardware in Greece. The major Greek Universities and Research Centers participate in GFOSS – Open Technologies Alliance, while leading members of the Greek community of developers play a key role in the implementation of our policies. Through our initiatives we aspire to contribute and coordinate the efforts of groups of volunteers, public servants, university researchers and students enabling them to form the backbone of Greek FOSS development and implementation. GFOSS is one of the strategic actors for the promotion of OSS throughout Greece (see https://joinup.ec.europa.eu/sites/default/files/inline-files/OSS%20Country%20Intelligence%20Report_GR.pdf ). Many public administrations and academic institutions collaborate with GFOSS to implement open source projects and through Google Summer of Code we give the opportunity to students to actively engage in the production and the actual implementation of an open source project. GFOSS also contributes and advises on the development of various open source projects related to e-government and digital transformation in Greece (e.g. https://howto.gov.gr/ - https://forma.gov.gr/) and actively promotes the use of Open Source software and hardware in the Greek primary and secondary education through the Open Educational Technologies Competition (https://openedtech.ellak.gr/ )",
    "ideas_url": "https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas",
    "website_url": "http://www.gfoss.eu",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "javascript",
      "c/c++",
      "nodejs",
      "python 3",
      "Machine Learning (ML)"
    ],
    "topic_tags": [
      "web",
      "robotics",
      "open hardware",
      "c++",
      "Artificial Inteligence"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/open-technologies-alliance-gfoss",
    "ideas_content": "# Google Summer of Code 2026 proposed ideas\n\n[Μετάβαση στην πλοήγηση](https://ellak.gr#mw-head)\n\n[Πήδηση στην αναζήτηση](https://ellak.gr#searchInput)\n\nContributors interested to participate should check which of the following projects fits their interests and skills.\n\n**Τo communicate with the mentors and ask questions about the projects, students should subscribe to this** [list](https://lists.ellak.gr/gsoc-developers/listinfo.html) **and post relevant questions. Please follow the Proposal Template**\n\nFor practical information, developers should visit this ** page**.\n\n\n\n**VS Code pluggin for CScout**[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=1) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=1)]\n\n#### Brief Explanation[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=2) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=2)]\n\nThe objective of the proposed project is to create a Visual Studio Code plugin for accessing the functionality of the CScout source code analyzer and refactoring browser for collections of C programs.\n\nCScout can process workspaces of multiple projects (a project is defined as a collection of C source files that are linked together) mapping the complexity introduced by the C preprocessor back into the original C source code files. CScout takes advantage of modern hardware (fast processors and large memory capacities) to analyze C source code beyond the level of detail and accuracy provided by current compilers and linkers. The analysis CScout performs takes into account the identifier scopes introduced by the C preprocessor and the C language proper scopes and namespaces. CScout has already been applied on projects of tens of thousands of lines to millions of lines, like the Linux and FreeBSD kernels and the Apache web server.\n\nHaving VSCode act as a front-end to CScout’s existing batch analysis will work as follows.\n\n- Trigger explicit runs (command palette / tasks), not on-save analysis.\n- Present results as:\n- Navigable diagnostics\n- Cross-reference views (definitions, uses, dependencies)\n- Refactoring previews as diffs\n- Project-wide facts (identifier scopes, file coupling, macro effects) that are otherwise buried in textual reports\n\n\nThis will offer the following advantages\n\n- Lower adoption barrier: developers are far more likely to try CScout if results appear inside their editor instead of via reports or bespoke UIs.\n- Natural fit for whole-program analysis: VS Code already supports long-running, cancellable tasks with progress reporting.\n- Superior comprehension UX: jump-to-definition, peek views, code lenses, and diff previews make CScout’s semantic information immediately actionable.\n- Safer refactoring workflow: preview-first refactorings reduce fear of large, semantics-preserving transformations.\n- Separation of concerns: keeps CScout as a standalone engine while the plugin handles visualization and navigation.\n- Research leverage: enables realistic user studies (e.g., acceptance of large-scale refactorings, tolerance of latency).\n- Longevity and reuse: the same backend can serve CLI, CI, and IDE use; the plugin becomes a thin, replaceable shell.\n\nThus the plugin will combine CScout’s strengths (macro-aware parsing, precise identifier resolution, and whole-system reasoning) that are hard to appreciate via static reports and tricky to use through the existing rudimentary web front-end. The VSCode plugin combines two open source software projects to provide immediate developer value.\n\n#### Expected Results[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=3) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=3)]\n\nA VS Code plugin that can act as an interface to CScout\n\n#### Duration of the Project[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=4) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=4)]\n\nLarge Project – 350 hrs\n\n#### Related Repositories[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=5) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=5)]\n\n[https://github.com/dspinellis/cscout](https://github.com/dspinellis/cscout)\n\n#### Knowledge Prerequisites[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=6) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=6)]\n\nTypescript, C/C++, VS Code API\n\n#### Mentors[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=7) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=7)]\n\nDiomidis Spinellis\n\n**OpenTRIM**[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=8) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=8)]\n\n#### Brief Explanation[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=9) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=9)]\n\nOpenTRIM is an open-source code for simulating the passage of energetic ions through materials and calculating the associated modifications and damage that they cause to these materials. It is based on the kinetic Monte-Carlo method and employs the Binary Collision Approximation to describe the interaction between ions and target atoms. OpenTRIM comprises a set of C++ libraries, a command-line program for executing simulations in batch mode, and a Qt-based graphical user interface for configuring, running, and evaluating simulations. Several parts of the codebase require improvements and extensions.\n\n#### Expected Results[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=10) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=10)]\n\nReal-time 3D visualization tool for simulated ion tracks\n\nPython bindings for running simulations and retrieving results directly from Python\n\n#### Duration of the Project[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=11) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=11)]\n\nLarge Project – 350 hrs\n\n#### Related Repositories[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=12) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=12)]\n\n[https://github.com/ir2-lab/OpenTRIM](https://github.com/ir2-lab/OpenTRIM)\n\n#### Knowledge Prerequisites[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=13) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=13)]\n\nC++\n\nPython (optional)\n\nOpenGL (optional)\n\n#### Mentors[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=14) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=14)]\n\nGeorge Apostolopoulos\n\nMichail Axiotis\n\nEleni Mitsi\n\n**Open-Source AI Framework for Thermal Satellite Payload Data Analysis**[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=15) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=15)]\n\n#### Brief Explanation[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=16) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=16)]\n\nThis project aims to develop a general-purpose open-source AI framework for extracting high-level semantic information from thermal sensor payloads onboard satellites. The framework will support multiple application scenarios such as nighttime cloud detection and thermal event or anomaly monitoring on land and sea.\n\nThe project focuses on building a reusable pipeline covering dataset creation and augmentation from real and synthetic thermal imagery, model training and benchmarking, and advanced analysis tools such as uncertainty quantification and explainability. The goal is to provide a practical and reproducible platform for thermal remote sensing applications in Earth observation and small satellite programs.\n\n#### Expected Results[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=17) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=17)]\n\nModular AI pipeline for thermal satellite data processing\n\nDataset extraction, preprocessing and labeling workflows\n\nBaseline and benchmarked ML/DL models\n\nUncertainty quantification methods\n\nExplainability tools\n\nPublic open-source releases with documentation\n\n#### Duration of the Project[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=18) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=18)]\n\nLarge Project – 350 hrs\n\n#### Related Repositories[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=19) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=19)]\n\n[https://github.com/Orion-AI-Lab](https://github.com/Orion-AI-Lab)\n\n[https://github.com/Orion-AI-Lab/TIRAuxCloud](https://github.com/Orion-AI-Lab/TIRAuxCloud)\n\n#### Knowledge Prerequisites[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=20) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=20)]\n\nPython\n\nMachine Learning / Deep Learning (PyTorch or similar)\n\nImage processing fundamentals\n\nGeospatial / satellite imagery familiarity\n\nInterest in remote sensing and explainable AI\n\n#### Mentors[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=21) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=21)]\n\nChristos Chronis\n\nAlexis Apostolakis\n\nSimon Vellas\n\n**Command & Data Handling Software for Open-Source CubeSat FlatSat Testbed**[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=22) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=22)]\n\n#### Brief Explanation[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=23) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=23)]\n\nThe CubeSat FlatSat testbed is a ground-based platform for deploying and testing onboard AI algorithms, end-to-end processing pipelines, and avionics software/hardware. It supports onboard processing validation and serves as a development platform for university student projects and future open-source CubeSat missions.\n\n#### Expected Results[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=24) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=24)]\n\nC&DH flight software on STM32 with FreeRTOS\n\nInter-subsystem communication using CSP over CAN\n\nNASA cFS-inspired modular architecture\n\nZenoh middleware for high-bandwidth payload data\n\nUnit tests and integration tests\n\nArchitecture documentation and developer guides\n\nPublic open-source release on GitHub\n\n#### Duration of the Project[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=25) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=25)]\n\nLarge Project – 350 hrs\n\n#### Related Repositories[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=26) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=26)]\n\n[https://github.com/omega-space-group](https://github.com/omega-space-group)\n\n[https://github.com/omega-space-group/orion-cubesat-testbed](https://github.com/omega-space-group/orion-cubesat-testbed)\n\n#### Knowledge Prerequisites[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=27) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=27)]\n\nPython and C\n\nEmbedded systems development\n\nFreeRTOS\n\nCAN bus & networking protocols\n\nSTM32 toolchain familiarity\n\nInterest in satellite systems and flight software\n\n#### Mentors[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=28) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=28)]\n\nChristos Chronis\n\nSimon Vellas\n\n\n\n**Fine-tuning AI transcription models for Greek Municipal Councils**[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=29) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=29)]\n\n#### Brief Explanation[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=30) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=30)]\n\nOpenCouncil has accumulated hundreds of hours of Greek municipal council recordings with human-corrected transcriptions and utterance-level timestamps. Greek municipal speech presents unique challenges: regional accents, domain-specific legal and administrative terminology, multiple speakers, and varying audio quality. This project will fine-tune Whisper (or similar open-source speech recognition models) on our dataset to significantly improve transcription accuracy for Greek municipal contexts. The contributor will preprocess training data, experiment with fine-tuning approaches, evaluate model performance against our current pipeline, and deploy the improved model to production. Success means measurably better transcription quality — especially for technical terms and speaker identification.\n\nOpenCouncil is a civic tech platform that makes Greek municipal council proceedings accessible to citizens through AI-powered transcription, summarization, and search. We have established partnerships with 10+ municipalities across Greece, providing both real-world data and direct validation channels for this project. Our existing dataset of human-corrected transcriptions is a unique resource that makes this fine-tuning project feasible and impactful. The resulting model will be open-sourced and can benefit the entire Greek-speaking NLP community.\n\n#### Expected Results[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=31) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=31)]\n\nA preprocessed, validated training dataset of Greek municipal speech with utterance-level alignments, ready for model fine-tuning and future research use. A fine-tuned Whisper model that demonstrates measurable improvement in Word Error Rate (WER) over the baseline, particularly on domain-specific terminology (legal, administrative), regional accents, and multi-speaker segments. An evaluation framework with benchmarks and test sets for ongoing quality measurement of Greek municipal transcription. Production integration of the fine-tuned model into OpenCouncil's transcription pipeline, validated on real council meetings from our 10+ municipal partners. Documentation of the fine-tuning methodology, dataset preparation process, and results — contributing to the broader Greek NLP and open-source speech recognition community.\n\n#### Duration of the Project[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=32) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=32)]\n\nLarge Project – 350 hrs\n\n#### Related Repositories[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=33) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=33)]\n\n[https://github.com/schemalabz/opencouncil](https://github.com/schemalabz/opencouncil)\n\n#### Knowledge Prerequisites[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=34) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=34)]\n\nPython, Machine Learning, PyTorch/TensorFlow, Speech Recognition, Greek language required\n\n#### Mentors[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=35) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=35)]\n\nAndreas Kouloumos (andreas@opencouncil.gr), Christos Porios (christos@opencouncil.gr)\n\n\n\n\n\n**Municipal Budget and Technical Program Visualization Tool**[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=36) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=36)]\n\n#### Brief Explanation[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=37) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=37)]\n\nAll 332 Greek municipalities publish annual budgets (προϋπολογισμοί) and technical programs (τεχνικά προγράμματα) as PDFs — hundreds of pages of financial data and infrastructure projects that citizens struggle to understand. This project will build a standalone tool that processes these PDFs, extracts structured data, and presents it through an accessible interface. Users will be able to search projects, track spending over time, compare municipalities, and visualize budget allocations. The tool will handle the varied PDF formats used across municipalities and be deployable for all 332 Greek municipalities with minimal configuration.\n\nThis tool addresses a fundamental transparency gap in Greek local government. While budget data is technically public, it is practically inaccessible to citizens due to its format and complexity. OpenCouncil's network of 10+ municipal partners provides immediate access to real budget documents for development and testing, and a clear path to adoption across Greece. The tool will be fully open-source and designed for reuse by other civic tech initiatives. This project complements OpenCouncil's core mission of making municipal governance transparent and accessible.\n\n#### Expected Results[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=38) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=38)]\n\n1. PDF processing pipeline: Build robust extraction system that handles various PDF formats and structures, validate data quality 2.Data model and API: Design database schema, create API endpoints, implement search and comparison features 3. User interface and deployment: Build accessible frontend for exploring budgets and projects, deploy for multiple municipalities, write documentation\n\n#### Duration of the Project[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=39) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=39)]\n\nLarge Project – 350 hrs\n\n#### Related Repositories[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=40) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=40)]\n\n[https://github.com/schemalabz/opencouncil](https://github.com/schemalabz/opencouncil)\n\n#### Knowledge Prerequisites[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=41) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=41)]\n\nPython, PDF processing, Data extraction, PostgreSQL, Next.js/React, Data visualization, greek language required\n\n#### Mentors[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=42) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=42)]\n\nAndreas Kouloumos (andreas@opencouncil.gr), Christos Porios (christos@opencouncil.gr)\n\n\n\n**GlossAPI: Needs-Driven Evolution of the Dataset Production Pipeline for Greek Language Data**[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=43) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=43)]\n\n#### Brief Explanation[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=44) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=44)]\n\nThis project focuses on improving the GlossAPI dataset production pipeline by addressing practical limitations and gaps that emerge as new datasets are processed and published.\n\nAs the scope and volume of Greek-language datasets handled by GlossAPI continue to grow, the pipeline must evolve to remain maintainable, reliable, and adaptable to new use cases. The contributor will work on the reconstruction and evolution of parts of the pipeline, guided by operational needs encountered during dataset ingestion, processing, and publication.\n\nThe work will emphasize improvements to the pipeline’s maintainability and usability, while enabling richer interaction and input scenarios that better reflect how Greek-language data is accessed and processed in practice. This includes exploring enhancements related to workflow execution, interaction mechanisms, data acquisition paths, and challenges specific to Greek-language and OCR-derived content.\n\n#### Expected Results[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=45) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=45)]\n\n- Improved maintainability of the GlossAPI pipeline codebase\n- Targeted improvements addressing real usage issues in dataset ingestion and processing\n- Enhanced support for diverse data sources and interaction patterns\n- Incremental improvements tailored to the characteristics of Greek-language data\n- Documentation and usage notes supporting long-term sustainability and onboarding\n\n#### Duration of the Project[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=46) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=46)]\n\nLarge Project - 350 hrs\n\n#### Related Repositories[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=47) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=47)]\n\n[glossAPI](https://github.com/eellak/glossAPI)[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=48) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=48)]\n\n#### Knowledge Prerequisites[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=49) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=49)]\n\nApplicants should have good knowledge of Python, Git/GitHub, experience with data processing pipelines\n\n#### Mentors[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=50) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=50)]\n\nDimitrios Athanasopoulos, Nikos Tsekos\n\n**GlossAPI: ML-assisted Anonymization Layer and Targeted Pipeline Improvements for Greek Datasets**[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=51) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=51)]\n\n#### Brief Explanation[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=52) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=52)]\n\nThis project focuses on extending GlossAPI with a production-ready anonymization layer for Greek text datasets, addressing a critical need for privacy-preserving dataset publication, while also contributing targeted updates to the existing pipeline based on requirements that emerge during its evolution.\n\nThe core of the project is the design and implementation of an ML-assisted anonymization module that detects and masks sensitive personal information (such as names, emails, phone numbers, and organizations) in Greek text. Due to the linguistic characteristics of Greek and the presence of OCR noise in many datasets, the anonymization layer will explore and evaluate multiple approaches, including rule-based techniques and ML-based methods such as Named Entity Recognition, potentially using transformer-based or other state-of-the-art models depending on empirical results.\n\n#### Expected Results[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=53) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=53)]\n\n- Integrated anonymization module for Greek text datasets within GlossAPI\n- Detection and masking of common personal identifiers (names, emails, phone numbers, organizations)\n- Targeted updates to specific parts of the GlossAPI pipeline, limited to what is necessary to support anonymization\n- Documentation and usage examples for maintainers and future contributors\n\n#### Duration of the Project[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=54) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=54)]\n\nLarge Project - 350 hrs\n\n#### Related Repositories[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=55) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=55)]\n\n[glossAPI](https://github.com/eellak/glossAPI)[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=56) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=56)]\n\n#### Knowledge Prerequisites[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=57) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=57)]\n\nApplicants should have good knowledge of Python, Git/GitHub, Basic NLP/ML concepts, and Regular expressions.\n\n#### Mentors[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=58) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=58)]\n\nMyrsini Ioannou, Nikos Tsekos, Dimitrios Athanasopoulos\n\n** FOSSBot Platform: Simulation Enhancements and AI Integration **[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=59) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=59)]\n\n#### Brief Explanation[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=60) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=60)]\n\nThe FOSSBot Platform aims to enhance robotic simulation environments by integrating AI-driven capabilities and improving simulation realism. The project focuses on extending existing open-source robotic simulation tools with advanced features that support experimentation, education, and research in autonomous systems. Emphasis is placed on modularity, extensibility, and reproducibility within open-source ecosystems.\n\n#### Expected Results[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=61) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=61)]\n\nThe expected outcomes include enhanced simulation modules, AI-assisted decision-making components, improved documentation, and example use cases. The project will deliver code contributions upstream, along with benchmarks and demonstrations showcasing the improvements in robotic simulation fidelity and usability.\n\n#### Duration of the Project[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=62) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=62)]\n\nLarge Project - 350 hrs\n\n#### Related Repositories[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=63) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=63)]\n\n[https://github.com/eellak/fossbot-platform](https://github.com/eellak/fossbot-platform)\n[https://github.com/eellak/fossbot](https://github.com/eellak/fossbot)\n[https://fossbot.gr](https://fossbot.gr)\n\n#### Knowledge Prerequisites[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=64) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=64)]\n\nApplicants should have good knowledge of JavaScript, Python, robotics simulation environments, and basic AI/ML concepts. Familiarity with open-source workflows and collaborative development is required.\n\n#### Mentors[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=65) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=65)]\n\nChristos Chronis, Eleftheria Papageorgiou, Irida Ntinou\n\n** AI assisted KMC **[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=66) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=66)]\n\n#### Brief Explanation[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=67) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=67)]\n\nThis project explores the integration of machine learning techniques into Kinetic Monte Carlo (KMC) simulations. The goal is to accelerate simulations and improve predictive accuracy by leveraging AI models trained on simulation data. The project targets scientific computing and materials science applications.\n\n#### Expected Results[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=68) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=68)]\n\nDeliverables include AI-augmented KMC algorithms, performance evaluations against traditional methods, and a reproducible pipeline for training and inference. Documentation and example experiments will accompany the final implementation.\n\n#### Duration of the Project[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=69) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=69)]\n\nLarge Project - 350 hrs\n\n#### Related Repositories[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=70) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=70)]\n\n[https://github.com/nixeimar/Apothesis](https://github.com/nixeimar/Apothesis)\n\n#### Knowledge Prerequisites[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=71) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=71)]\n\nC++, working knowledge of machine learning techniques, numerical methods, and statistical modeling. Prior experience with scientific simulations is a plus.\n\n#### Mentors[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=72) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=72)]\n\nCheimarios Nikolaos, Vissarion Fysikopoulos\n\n\n\n**Unified SBOM Management via RDF Database Abstraction**[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=73) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=73)]\n\n#### Brief Explanation[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=74) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=74)]\n\nSoftware Bill of Materials (SBOM) documents, specifically in the ISO standard SPDX format, are becoming the cornerstone of software supply chain security. As the volume of SBOM data grows, simple file-based storage is no longer sufficient for complex analysis and cross-referencing. This project aims to develop a suite of tools to ingest, store, and extract SPDX documents using RDF databases (Triplestores). By utilizing the triplestore Python library, these tools will remain database-agnostic, allowing users to seamlessly switch between backends like Apache Jena, AllegroGraph, Blazegraph, GraphDB, and Oxigraph without changing the codebase.\n\n#### Background information[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=75) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=75)]\n\nTriplestores are a type of database specialized in storing triples, a data structure for representing information in a subject-predicate-object format. They are crucial in semantic web technologies, such as RDF, SPARQL, and OWL. However, there are numerous triplestore alternatives available, each with its own strengths and weaknesses. For GSoC 2025, a Python library abstracting some commonly used databases was developed.\n\nSBOM data in SPDX format can be serialized in RDF, and therefore can be stored in such databases.\n\n#### Project Description[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=76) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=76)]\n\nThe current SPDX ecosystem relies heavily on flat files (JSON, RDF/XML, or even Tag-Value for SPDXv2). While effective for transport, these files are difficult to query at scale—for example, when looking for a specific vulnerable component across thousands of SBOMs. Since SPDXv3 is natively based on an knowledge graph model, storing it in a RDF Triplestore is the most logical and powerful way to handle this data. However, different RDF databases have varying APIs and connection protocols.\n\nThis project will leverage the triplestore library (which provides a high-level Python abstraction) to build tools that:\n\n- *Ingest:* Parse SPDX documents (multi-format support) and map them to the unified RDF store.\n\n- *Extract:* Reconstruct valid SPDX documents from the database based on specific queries (e.g., \"Export the SBOM for Project X version 1.2\").\n\n- *Manage:* Provide basic management functions like listing stored SBOMs, deleting old versions, and validating data integrity.\n\n#### Expected Outcome[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=77) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=77)]\n\nBy the end of the project, we expect to have a number of well-documented tools that can operate on SBOM data. These will allow users to seemlessly move between SPDX documents and RDF databases.\n\nAn indicative list of tools and deliverables is:\n\n- *SBOM-to-Store Ingestor:* A CLI tool to upload SPDX documents (v2 and v3) into any supported triplestore.\n\n- *Store-to-SBOM Exporter:* A tool to query the database and output a standard-compliant SPDX file.\n\n- *Database Management Utilities:* Tools for basic CRUD operations on the stored SBOM data.\n\n- *Test Suite:* A comprehensive set of tests to verify the abstraction works.\n\n- *Documentation:* User guide for the CLI tools and developer documentation for the API.\n\n#### Duration of the Project[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=78) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=78)]\n\nLong (350 hours)\n\n#### Related Resources and Repositories[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=79) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=79)]\n\n- [https://github.com/eellak/triplestore](https://github.com/eellak/triplestore)\n\n- [https://github.com/spdx/tools-python](https://github.com/spdx/tools-python)\n\n- [https://github.com/RDFLib/rdflib](https://github.com/RDFLib/rdflib)\n\n- [https://spdx.github.io/spdx-spec](https://spdx.github.io/spdx-spec)\n\n#### Knowledge Areas[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=80) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=80)]\n\nPython3, RDF, SPARQL, SPDX specifications.\n\n*Tip for your application:* Study SPDX v3 (and v2): SPDX is heavily RDF-centric. Demonstrating knowledge of how 3.0 maps to triples will make your proposal stand out.\n\n#### Mentors[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=81) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=81)]\n\nAlexios Zavras, TBD\n\n\n\n**Using SWHID to Identify Software Components**[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=82) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=82)]\n\n#### Brief Explanation[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=83) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=83)]\n\nThis project addresses a critical gap in software supply chain security and reproducibility: the connection between package-level identifiers (like package-name@version) and content-level identifiers (SWHIDs).\n\n#### Background information[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=84) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=84)]\n\nSoftware Hash IDentifiers (SWHID) are a standardized way to identify software artifacts, based on content. The definition is officially adopted as ISO/IEC 18670:2025 and is available at [https://swhid.org](https://swhid.org).\n\nHowever, most developers interact with software through package managers like Cargo (Rust), PyPI (Python), Maven (Java), or APT (Debian/Ubuntu). There is currently a \"semantic gap\" between the package version (e.g., requests 2.31.0) and its corresponding SWHID, which depends on its contents.\n\n#### Project Description[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=85) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=85)]\n\nThe goal of this project is to develop tooling that automatically computes, verifies, and publishes the SWHIDs for components across major package registries. By creating a verifiable mapping between package releases and SWHIDs, we can enable better SBOM integration, improved vulnerability tracking, and long-term reproducibility of the global software supply chain.\n\nThis project will involve three main phases:\n\n- *Computation and Archival:* Build a pipeline to fetch packages from registries (like Crates.io, PyPI, Maven Central, etc.) and compute their SWHIDs locally to ensure integrity.\n\n- *Mapping & Verification:* Generate a high-quality dataset that maps registry data (URL and version) to SWHID. This will require handling the specific packaging quirks of each ecosystem.\n\n- *Publication:* Publish these identifiers in a way that makes them useful to the community. This could include: contributing to a public lookup service or API; exporting mappings to SPDX format; or proposing metadata additions to the package registries themselves.\n\n#### Expected Outcome[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=86) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=86)]\n\n- *CLI Tool:* A reusable utility that takes a package name/version and returns a verified SWHID.\n\n- *Public Dataset:* A comprehensive mapping of the most popular packages across ecosystems to their SWHIDs.\n\n- *Documentation:* A guide on how package maintainers can include SWHIDs in their own release workflows.\n\n- *Upstream Contributions:* (Stretch goal) Integration with tools like cargo-swhid or pyproject.toml plugins.\n\n#### Duration of the Project[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=87) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=87)]\n\nShort or Regular or Long, depending on breadth and depth.\n\n#### Related Resources and Repositories[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=88) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=88)]\n\n#### Knowledge Areas[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=89) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=89)]\n\nPython and bash scripting (for the solution), knowledge of other ecosystems (Rust, Java, etc.) is required to understand their packaging.\n\n*Tip for your application:* Study SWHID and the different ecosystems. Demonstrating understanding of ecosystem specific challenges will make your proposal stand out.\n\n#### Mentors[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=90) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=90)]\n\nAlexios Zavras, TBD\n\n**Who is who: Alexandria3k entity disambiguation extentions**[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=91) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=91)]\n\n#### Brief Explanation[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=92) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=92)]\n\nThe alexandria3k Python package supplies a command-line tool and an API providing fast and space-efficient relational query access to several large scientific publication open data sets. Data are decompressed on the fly, thus allowing the package's use even on storage-restricted laptops. This project will enhance Alexandria3k by integrating a scalable, high-precision author and affiliation disambiguation pipeline over Crossref metadata that does not rely on ORCID or ROR, using probabilistic clustering optimized for large-scale bibliometrics. We will implement aggressive normalization and blocking to control candidate growth, represent authors as paper-level mentions, and fuse lightweight, interpretable signals—name similarity, affiliation token overlap, co-author graph structure, venue/topic coherence, and temporal constraints—into conservative merge decisions that favor precision over recall. Disambiguation will be incremental and auditable, with stable cluster IDs, merge provenance, confidence scores, and an explicit “unknown” class to avoid over-merging common names. In parallel, we will cluster affiliation strings into canonical organization buckets using country-aware token blocking and city/org matching, enabling robust institution-level analyses even with noisy or missing data. Together, these additions will materially improve the reliability of author- and organization-centric metrics in Alexandria3k while remaining scalable, reproducible, and resilient to incomplete identifiers.\n\n#### Expected Results[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=93) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=93)]\n\nNew Alexandria3k actions to dissambiguate authors and organizations by adding corresponding fields in the populated database.\n\n#### Duration of the Project[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=94) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=94)]\n\nLarge Project – 350 hrs\n\n#### Related Repositories[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=95) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=95)]\n\n[https://github.com/dspinellis/alexandria3k](https://github.com/dspinellis/alexandria3k)\n\n#### Knowledge Prerequisites[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=96) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=96)]\n\nPython; machine learning; SQL\n\n#### Mentors[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=97) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=97)]\n\nDiomidis Spinellis\n\n**Python bindings for Apothesis**[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=98) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=98)]\n\n#### Brief Explanation[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=99) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=99)]\n\nThis project focuses on creating modern Python bindings for Apothesis to seamlessly connect its high-performance C++ core with Python-based AI workflows. While the existing C++ implementation delivers speed and efficiency for large-scale computation, the lack of native Python integration limits accessibility for researchers and machine learning practitioners who primarily work within Python ecosystems such as NumPy, PyTorch, and TensorFlow. The bindings will expose Apothesis’ core functionality through a clean, Pythonic API, preserving performance while ensuring memory safety and ease of installation. By bridging efficient C++ algorithms with Python’s flexibility and extensive AI tooling, this work enables rapid experimentation, smoother integration into machine learning pipelines, and broader adoption within the research community.\n\n#### Expected Results[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=100) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=100)]\n\nThe expected results of the project are the delivery of fully functional Python bindings for Apothesis that provide seamless access to its C++ core from Python. The bindings will expose the main computational components through a clean and intuitive API, while preserving the performance and efficiency of the underlying C++ implementation.The project will also include comprehensive documentation, usage examples, and unit tests to ensure reliability, maintainability, and ease of adoption. Overall, the outcome will be a stable, extensible interface that lowers the barrier to entry for researchers and developers, enabling faster experimentation, improved interoperability with machine learning pipelines, and broader community engagement.\n\n#### Duration of the Project[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=101) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=101)]\n\nLarge Project – 350 hrs\n\n#### Related Repositories[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=102) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=102)]\n\n[https://github.com/nixeimar/Apothesis](https://github.com/nixeimar/Apothesis)\n\n#### Knowledge Prerequisites[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=103) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=103)]\n\nC++, python\n\n#### Mentors[[επεξεργασία](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&veaction=edit§ion=104) | [επεξεργασία κώδικα](https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2026_proposed_ideas&action=edit§ion=104)]\n\nCheimarios Nikolaos, Vissarion Fysikopoulos"
  },
  {
    "name": "Open Genome Informatics",
    "slug": "open-genome-informatics",
    "tagline": "Open access genomics and bioinformatics projects",
    "description": "The Open Genome Informatics group represents an umbrella organization consisting of several open source and open access genomics and bioinformatics projects worldwide. Our goals are to develop and maintain a collection of sustainable software tools for managing, analyzing, visualizing, storing, and disseminating genomic data.",
    "ideas_url": "https://gmod.org/wiki/GSOC_Project_Ideas_2026",
    "website_url": "http://gmod.org/wiki/GSoC",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "react",
      "r-project",
      "graph",
      "angular"
    ],
    "topic_tags": [
      "genomics",
      "bioinformatics",
      "biology",
      "data discovery"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/open-genome-informatics",
    "ideas_content": "*Got an idea for GSOC 2026?’*\n\nThen please post it. You can either\n\n- Add it here, by directly editing this page. Just copy, paste and\nupdate the\n[template](https://gmod.org#Template)below. This requires that you create a fork of this repo and then make a pull request with the changes.\n\nProjects can use a broad set of skills, technologies, and domains, such as GUIs, database integration and algorithms.\n\nStudents are also encouraged to propose their own ideas related to our projects. If you have strong computer skills and have an interest in biology or bioinformatics, you should definitely apply! Do not hesitate to propose your own project idea: some of the best applications we see are by students who go this route. As long as it is relevant to one of our projects, we will give it serious consideration. Creativity and self-motivation are great traits for open-source programmers.\n\n*Brief explanation:*MP-BioPath is a computational tool designed to predict the effects of perturbations on biological pathways. Utilizing Reactome’s pathway models, MP-BioPath employs an optimization model. Our objective is to develop pipelines and tools that integrate MP-BioPath results with genomic data.*Expected results:*As a result of this project, we aim to develop tools and pipelines capable of handling diverse genomic datasets. Additionally, we anticipate the generation of novel biologically significant insights.*Project Home Page URL:*[Reactome](https://reactome.org)[MP-BioPath](https://github.com/OICR/mp-biopath)*Project paper reference and URL:*[“Evaluating the predictive accuracy of curated biological pathways in a public knowledgebase”](https://doi.org/10.1093%2Fdatabase%2Fbaac009)*Knowledge prerequisites:*Python, R, Julia*Skill level:*Medium*Project Time:*175-hour approximately 10 weeks*Mentors:*Adam Wright <adam.wright@oicr.on.ca>\n\n*Brief explanation:*Cancer patients are often left on their own to find clinical trials of cutting-edge therapies. This project seeks to develop an LLM-driven chatbot and interactive map that lets patients describe their situation and find nearby clinical trial sites that they may be eligible for.*Expected results:*As a result of this project, patients will be able to more effectively discover clinical trials, learn more about them, and contact the study doctors to seek enrollment.*Project Home Page URL:*There is no project web page at the moment, but you can get an idea of the type of underlying database we will be using at[the Cancer Trials Canada](https://www.cancertrialscanada.ca/)website.*Knowledge prerequisites:*SQL, Python, React (TypeScript), familiarity with Chainlit (LLM) and Mapbox (Geomapping) APIs*Skill level:*Medium*Project Time:*175-hour approximately 10 weeks*Mentors:*Lincoln Stein <lincoln.stein@gmail.com>, Shraddha Pai <spai@oicr.on.ca>.\n\n*Brief explanation:*Reactome houses a meticulously curated repository of human biological pathways. Our current initiative focuses on crafting a RAG chat application optimized for intuitive interaction with the Reactome web portal. Our primary aim is to empower the application to interpret user queries and leverage the LLM (Language Model) to delve deep into pathway structures, enabling the generation of comprehensive and insightful responses for users.*Expected results:*expected outcomes include the application’s ability to effectively handle a diverse range of user queries and to expand its capabilities to accommodate an increased number of use cases. Furthermore, the application is expected to leverage advanced reasoning capabilities powered by the LLM, thereby providing more insightful and comprehensive responses tailored to each user’s inquiry*Project Home Page URL:*[Reactome](https://reactome.org)*Project paper reference and URL:**Knowledge prerequisites:*Python, RAG*Skill level:*Medium*Project Time:*175-hour approximately 10 weeks*Mentors:*Adam Wright <adam.wright@oicr.on.ca>\n\n*Brief explanation:*Reactome provides users with various computational interfaces for computationally accessing the curated biological pathways, including analysis tools and a chat interface React-to-Me. A Reactome MCP would make the website more computationally accessible by providing access to the tools through React-to-Me and other LLM based chat interfaces.*Expected results:*expected outcomes include the application’s ability to run Reactome analysis tools through the React-to-Me chat interface. Other features of Reactome, including our REST APIs, should be made accessible to LLMs through the MCP.*Project Home Page URL:*[React-to-Me](https://reactome.org/chat)*Project paper reference and URL:**Knowledge prerequisites:*Python, RAG, MCP*Skill level:*Medium*Project Time:*175-hour approximately 10 weeks*Mentors:*Adam Wright <adam.wright@oicr.on.ca>\n\n*Brief explanation:*This project will develop and validate a real-time artificial intelligence (AI) application that continuously monitors major social media platforms (TikTok, YouTube, Instagram, X, and Reddit) to identify emerging health-related trends involving ear, nose, and throat (ENT) issues among children and adolescents. The system will classify and rank viral behaviors based on engagement metrics and notify pediatric otolaryngologists about potentially harmful trends or misinformation. The goal is to explore how automated social media surveillance can support early awareness and clinical decision-making in pediatric otolaryngology.*Expected results:*expected outcomes include:- A working prototype of a real-time social media monitoring pipeline.\n- Automated collection of public data via platform APIs.\n- NLP/LLM-based classification and ranking of pediatric ENT-related trends.\n- A reporting dashboard visualizing trends, engagement metrics, and risk flags for clinicians. Evaluation of model performance (precision, recall, accuracy) and preliminary assessment of clinical usefulness with pediatric otolaryngologists. Documentation and open-source code suitable for further research and extension.\n\n*Project Home Page URL:*[Host lab webpage, no specific project page yet](https://courtotlab.genomeinformatics.org/)*Project paper reference and URL: No existing paper yet; this project will contribute to future publications on AI-driven social media surveillance in pediatric otolaryngology.**Knowledge prerequisites:*Programming languages: Python (for AI/NLP and data pipelines), JavaScript/TypeScript (for frontend) Experience with:- REST APIs and social media data extraction\n- NLP and/or LLM integration\n- Basic machine learning workflows\n- Full-stack development (backend services + frontend dashboards)\n\n*Skill level:*Advanced*Project Time:*350-hour approximately 12 weeks*Mentors:*Melanie Courtot, OICR and UoT <mcourtot@oicr.on.ca>; Jochen Weile, OICR, <jweile@oicr.on.ca>\n\n*Brief explanation:*Brief description of the idea, including any relevant links, etc.*Expected results:*describe the outcome of the project idea.*Project Home Page URL:*if there is one.*Project paper reference and URL:*Is there a paper about the project this effort will be a part of?*Knowledge prerequisites:*programming language(s) to be used, plus any other particular computer science skills needed.*Skill level:*Basic, Medium or Advanced.*Project Time:*90-hour, 90, 175 or 350 hours that are a standard 10 weeks long and no longer than 12 weeks.*Mentors:*name + contact details of the lead mentor, name + contact details of 1 or 2 backup mentors."
  },
  {
    "name": "AOSSIE",
    "slug": "aossie",
    "tagline": "Australian Umbrella Org for Open-Source Projects",
    "description": "We are an Australian not-for-profit charity, founded in 2016, that serves as an umbrella organization for open-source projects. We believe the open-source philosophy is a resource-efficient approach to transfer knowledge, educate and innovate. \n\nWe have almost 200 repositories in 3 GitHub spaces:\n* https://github.com/orgs/AOSSIE-Org (our main space)\n* https://github.com/StabilityNexus (for our blockchain projects)\n* https://github.com/DjedAlliance (for our stablecoin projects)\n\nOur projects span a wide range of topics and themes, including: financial stability, environmental sustainability, governance, trust, decentralized communication, artificial intelligence. The common ground under all our projects is our passion for making the world a better place, by empowering people with free software than can be run with minimal dependencies.\n\nWe have a diverse group of mentors, including GSoC students from previous years who decided to become long-term contributors as well as academics with extensive experience in supervising undergraduate, M.Sc. and PhD students on theses and projects, whose results are often published and presented in the most prestigious conferences of our research fields.",
    "ideas_url": "https://github.com/AOSSIE-Org/Info/blob/main/GSoC-Ideas/2026/index.md",
    "website_url": "https://www.aossie.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "flutter",
      "Blockchain",
      "Solidity"
    ],
    "topic_tags": [
      "web",
      "artificial intelligence",
      "communication",
      "mobile",
      "blockchain"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/aossie",
    "ideas_content": "# AOSSIE's Idea List for Google Summer of Code 2026\n\nAs an umbrella organization since its inception 10 years ago, AOSSIE's projects have evolved mostly independently from each other. More recently, we have started a deliberate effort to group these projects by theme and skillset and to ensure that knowledge and mentorship propagates efficiently across projects of the same themes and with the same skillset. This year we are taking another step in this direction with the introduction of org-wide ideas.\n\n\n* [Project-Specific Ideas, Grouped by Theme](index.md#project-specific-ideas-grouped-by-theme)\n* [Organization-Wide Ideas](index.md#organization-wide-ideas)\n\n\n## Project-Specific Ideas, Grouped by Theme and Tagged by Skillset\n\nProject-specific ideas are ideas where the contributor is expected to focus on a single project, while taking care of all aspects of the project. These ideas are suitable for contributors who are generalists and interested in using all technical competence areas required by the project.\n\nThe skillset needed in each idea is shown in brackets.\n\n### Theme: Open Money\n\n**Theme goal:** research and develop open source money. \n\n**Ideas:**\n  - [Gluon](Gluon.md) _{Blockchain}_ _{Web}_\n  - [Djed](Djed.md) _{Blockchain}_ _{Web}_\n  - [StablePay](StablePay.md) _{Blockchain}_ _{Web}_\n  - [Zplit](Zplit.md) _{Blockchain}_ _{Mobile}_\n  - [MiniChain](MiniChain.md) _{Blockchain}_\n\n### Theme: Decentralized Economic and Financial Stability\n\n**Theme goal:** improve economic and financial stability in DeFi.\n\n**Ideas:**\n  - [Fate](Fate.md) _{Blockchain}_ _{Web}_\n  - [Karma](Karma.md) _{Blockchain}_ _{Web}_\n  - [Orb](Orb.md) _{Blockchain}_ _{Web}_\n  - [Porting our Projects from EVM to Ergo](Ergo.md) _{Blockchain}_ _{Web}_\n  - [An Order-Book Variation of the Maelstrom Auction-Based Decentralized Exchange](OrderBookAuctionExchange.md) _{Blockchain}_ _{Web}_\n\n\n### Theme: User-Empowering \"Sunny\" Tools\n\n**Theme goal:** empower users to do localy, in their own devices, what would normally require them to depend on cloud-based services.\n\n**Ideas:**\n  - [PictoPy](PictoPy.md) _{AI}_ _{Desktop}_\n  - [DocPilot](DocPilot.md) _{Mobile}_ _{AI}_\n  - [Smart Notes](SmartNotes.md) _{AI}_ _{Desktop}_\n  - [Neurotrack](Neurotrack.md) _{Mobile}_ _{AI}_\n\n### Theme: Trust\n\n**Theme goal:** enable us to trust the people and sources of knowledge that we rely on.\n\n**Ideas:**\n  - [End-to-End Open Verifiable LLM](LLM.md) _{AI}_ \n  - [Decentralized Identity Tokens](DIT.md) _{Blockchain}_ _{Web}_\n\n\n### Theme: Education\n\n**Theme goal:** help people learn.\n\n**Ideas*:* \n  - [Interactive Quizz Experience for EduAid](EduAid.md) _{AI}_ _{Web}_\n  - [Novel AI-Powered Education-Focused Apps](EduAI.md) _{AI}_ _{Mobile}_\n\n\n### Theme: Sustainability\n\n**Theme goal:** protect the environment and increase awareness about our planet's nature.\n  \n**Ideas:**   \n  - AOSSIE has many projects related to carbon footprint awareness. These projects have become inactive recently, but sustainability remains a strong focus theme for AOSSIE. Therefore, although we do not have specific ideas within this theme this year so far, our sustainability projects are in scope for our org-wide ideas above and we are open to novel sustainability-related project ideas.\n\n### Theme: Communication\n\n**Theme goal:** build open, free and censorship-resistant communication infra-structure. \n  - [Resonate](Resonate.md) _{Mobile}_\n  - [Rein](Rein.md) _{Networks}_\n\n\n### Theme: Governance and Management\n\n**Theme goal:** ease community and team work.\n  - [Org Explorer](OrgExplorer.md)  _{Web}_\n  - [Discord/Github Bot](Bot.md) _{Bots}_\n  - [Ellena](Ellena.md) _{Web}_ _{AI}_\n  - [Agora Voting on Chain](AgoraOnChain.md) _{Web}_ _{Blockchain}_\n\nWe are open to proposals that fit into our general themes, even if they don't fit exactly the ideas that are currently listed above. However, if you have such a proposal, discuss it with mentors and other contributors publicly in Discord firstly.\n\n\n## Organization-Wide Ideas\n\nOrg-wide ideas are ideas where a single contributor will contribute to many of our projects, but focusing on a single aspect in every project. These ideas are particularly suitable for contributors who prefer to specialize in a single technical competence area and who have the soft skills to interact effectively with contributors and mentors from many projects.\n\n- [DevOps](DevOps.md)\n- [Fundraising and Monetization](FundraisingMonetization.md)\n- [Redundancy and Choice for External Dependencies](Choice.md)\n- [Making our Projects Independent from Cloud Services](LessCloud.md)\n- [Better UI/UX for our Projects](UI.md)\n- [Design and Implement Great-Looking Landing Pages for our Projects](LandingPages.md)\n- [SEO, Social Sharing and Marketing](SEO.md)\n- [Operation Phoenix](Phoenix.md)\n\n\n---\n\n\nIf you are mentor, propose your idea by using our [Idea Template](../Template.md)\nto [this folder](https://github.com/AOSSIE-Org/Info/tree/main/GSoC-Ideas/2026)\nand then add a link to your file in the list above. Inform the admins in Discord.\nAdmins may modify or remove your ideas."
  },
  {
    "name": "GNU Project",
    "slug": "gnu-project-av",
    "tagline": "Development of the GNU Operating System",
    "description": "GNU is an operating system consisting entirely of free software, meaning it respects users’ freedom. The GNU operating system consists of GNU packages, which are programs released by the GNU Project, as well as free software released by third parties. The development of GNU made it possible to use a computer without relying on software that restricts or undermines user freedom. The GNU Project is the collective organization of maintainers and developers, webmasters, translators, and other contributors who develop and maintain more than 400 programs that together form the GNU operating system.",
    "ideas_url": "https://www.gnu.org/s/soc-projects/ideas.html",
    "website_url": "https://www.gnu.org",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "c++",
      "gcc",
      "autotools",
      "GNU"
    ],
    "topic_tags": [
      "compilers",
      "operating system",
      "toolchain",
      "command line",
      "OS"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/gnu-project-av",
    "ideas_content": "# Summer of Code projects for GNU\n\nThis page has the project suggestions for GNU's participation in\n[Google Summer of Code 2026](https://developers.google.com/open-source/gsoc/).\n\n**STUDENTS - BEFORE YOU SUBMIT YOUR PROJECT PROPOSAL**:\n\nPlease read the [GNU Project's guidelines\nfor Summer of Code projects](https://www.gnu.org/guidelines.html).\n\nMost importantly, please make sure you include all the information\nrequested. If you have questions, please ask [summer-of-code@gnu.org](mailto:summer-of-code@gnu.org) (list\ninfo [here](http://lists.gnu.org/mailman/listinfo/summer-of-code/)).\n\n**Please note that you are not bound to use these ideas, you can\npropose a new project. It is a good idea to find a mentor and\ndiscuss the idea before submit it.**\n\n## Projects and Ideas\n\nGNU is a large and complex project, and thus is subdivided into packages, which are relatively independent projetcts. In Summer of Code, GNU acts as an umbrella organization for its packages. The ideas here are grouped by package. Many packages have more than one suggestion, or even their own ideas page.\n\n[GnuCOBOL](https://www.gnu.org/software/gnucobol)\n\nGnuCOBOL is a free, modern COBOL compiler. It implements a substantial part of the COBOL 85, X/Open COBOL and newer ISO COBOL standards (2002, 2014, 2023), as well as many extensions included in other COBOL compilers (IBM COBOL, MicroFocus COBOL, ACUCOBOL-GT and others).\n\nGnuCOBOL translates COBOL into C and internally compiles the translated code using a native C compiler, therefore works on nearly every platform.\n\nGnuCOBOL maintains a list of ideas here:\n[https://gnucobol.sourceforge.io/gsoc.html](https://gnucobol.sourceforge.io/gsoc.html)\n\n**Project site:**[https://www.gnu.org/s/gnucobol](https://www.gnu.org/s/gnucobol)**Contact:**[gnucobol-dev@gnu.org](https://www.gnu.org/gnucobol-dev@gnu.org).\n\n[GNU Aris](https://www.gnu.org/software/aris)\n\nGNU Aris is a logical proof program that supports propositional and predicate logic, as well as Boolean algebra and arithmetical logic, in the form of abstract sequences.\n\nA logical proof program can prove mathematical statements by using strict reasoning steps, based on axioms and rewrite rules. GNU Aris supports manual creation of such proofs and it can verify if a proof is correct according to the axioms and rewrite rules. Therefore, it can give good support for undergraduate math courses like logic or abstract algebra.\n\n**Project site:**[https://www.gnu.org/s/aris](https://www.gnu.org/s/aris)**Contact:**[bug-aris@gnu.org](https://www.gnu.org/bug-aris@gnu.org).\n\n#### UI and Feature Enhancements\n\nGNU Aris is a logical proof program that helps students write exact mathematical proofs in propositional and quantified logic. It has been successfully applied in education at university level. Adressing the requests given by university students may significantly improve its user-friendliness:\n\n- More comprehensible and detailed error messages,\n- a feature to zoom for smaller device displays,\n- an option to change the user language,\n- an option to highlight, copy and paste inputs,\n- an option to change the type of input between premise and conclusion after inserting a new line,\n- an operator for exclusive disjunction,\n- an option to use the rule of inference for a proof by contrapositive,\n- eventually, automatic updates on the feedback for the correctness of statements after changing faulty inputs,\n- a fix for\n[https://github.com/kovzol/aris/issues/24](https://github.com/kovzol/aris/issues/24). - Expected outcomes: A new version of GNU Aris that implements most of the improvements, being available on all major platforms and HTML/WebAssembly.\n- Skills required/preferred: Good knowledge in C/C++, Qt, QML, cmake, preferable knowledge of building/debugging HTML/WebAssembly applications via Qt in C++\n- Project size: 175 hours\n**Reference links:**[https://matek.hu/zoltan/thedu24/](https://matek.hu/zoltan/thedu24/)\n\n[GNU XaoS](https://github.com/xaos-project)\n\nXaoS (pronounced chaos) is a realtime interactive fractal zoomer.\n\n#### Develop a mobile phone user interface for GNU XaoS\n\nGNU XaoS is a technology leader, free fractal zoomer and morpher program, written in C++. It is available on all major platforms, and HTML/WebAssembly. We, the XaoS Contributors, would like to extend its user interface to offer better user experience on mobile phones.\n\n- Some planned new features include:\n- stable, bug-free working on Android and iPhones,\n- option to join the user community and share the own created fractals and download other users' contributions inside the application, via an own developed protocol.\n\n- Expected outcomes: A new version of XaoS that implements the above mentioned features.\n**Skills required/preferred:**Good knowledge in C/C++, Qt, QML, cmake, preferable knowledge of building/debugging HTML/WebAssembly applications via Qt in C++, preferable knowledge of creating/building/deploying mobile applications (via Qt)- Project size: 350 hours\n**Contact:**[https://github.com/xaos-project](https://github.com/xaos-project).**Reference links:**\n\n[Libcdio](https://github.com/libcdio)\n\nThe libcdio package contains a library for CD-ROM and CD image access. Applications wishing to be oblivious of the OS- and device-dependent properties of a CD-ROM or of the specific details of various CD-image formats may benefit from using this library.\n\nA library for working with ISO-9660 filesystems, libiso9660, is included. A generic interface for issuing MMC (multimedia commands) is also part of the libcdio library.\n\nAlso included is a library for working with ISO-9660 filesystems.\n\nThe CD-DA error/jitter correction library from cdparanoia is included as a separate library licensed under GPL v2.\n\n#### Port the library to Rust\n\n**Project idea:**Port one or more parts of this code to Rust. A part could be*libiso9660*, ISO-9660 file reading, or*cd-paranoia*CD error/jitter correction.**Project site:**[https://github.com/libcdio](https://github.com/libcdio)**Contact:**[libcdio-devel@gnu.org](mailto:libcdio-devel@gnu.org).\n\n### Other links:\n\n[Google SoC Page](https://summerofcode.withgoogle.com)."
  },
  {
    "name": "The JPF team",
    "slug": "the-jpf-team-hg",
    "tagline": "JPF is a Java VM used to verify and debug software",
    "description": "The Java Pathfinder (JPF) project was initially conceived and developed at NASA Ames Research Center in 1999. JPF was open sourced in April 2005 as one of the first ongoing NASA development projects to date, and it is now released under the Apache license, 2.0. JPF is an extensible Java virtual machine written in Java itself. It is used to create a variety of verification and debugging tools, ranging from software model checkers to test case generators using symbolic execution. JPF is a research platform and a production tool at the same time. Although JPF has major contributions from companies and government agencies, our main user community is academic - there are ongoing collaborations with more than 20 universities worldwide. The JPF team for GSoC 2024 includes researchers from NASA Ames Research Center, KTH Royal Institute of Technology - Sweden, Carnegie Mellon University, Boise State University, University of Minnesota, Charles University - Czech Republic, and Singapore University of Technology and Design.\n\nJPF is designed to be highly extensible. There are well-defined extension mechanisms, directory structures and build procedures, which keep the core relatively stable and provide suitable, well-separated testbeds for new ideas and alternative implementations. As a consequence, we host a number of such extension projects on our own, public JPF server, together with a Wiki that provides a central location for learning about, obtaining, and contributing to JPF.\n\nJPF has been used for a variety of application domains and research topics such as verification of multi-threaded applications, graphical user interfaces, networking, and distributed applications. In addition to its continued presence in academia, JPF has matured enough to support verification of production code and frameworks such as Android. JPF is constantly being extended with support for verification of new types of correctness properties and for new types of application domains.",
    "ideas_url": "https://github.com/javapathfinder/jpf-core/wiki/GSoC-2026-Project-Ideas",
    "website_url": "https://github.com/javapathfinder/jpf-core/wiki",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "android",
      "java",
      "distributed systems",
      "jvm"
    ],
    "topic_tags": [
      "model checking",
      "symbolic execution",
      "verification of concurrent systems",
      "program analysis",
      "test input generation"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/the-jpf-team-hg",
    "ideas_content": "# Project Ideas\n\nPlease note that this list is not exclusive. If you have other ideas and topics related to JPF, please get in touch with us via our Discord server: https://discord.gg/sX4YZUVHK7.\nA possible proposal template can be found at the bottom of our GSoC page: [[JPF Google Summer of Code 2026]].\n\n### JPF Infrastructure\n\n* ![#f03c15](https://placehold.co/15x15/f03c15/f03c15.png) [Support Java 11/17 for JPF extensions](#support-java-11) <Cyrille>\n\n*  ![#FFD700](https://placehold.co/15x15/FFD700/FFD700.png) [Support Java 17 for jpf-core](#support-java-17) <Cyrille> \n\n<!-- ### JPF Application Domains -->\n\n<!-- * [Model Checking Distributed Java Applications](#model-checking-distributed-java-applications) <Cyrille> -->\n\n<!-- * [Verification of Multi Agent Systems](#verification-of-multi-agent-systems) <Franco><Eric><CheckWithNeha> -->\n\n<!--* [Verification of Actor-based Systems](#verification-of-actor-based-systems) <Nastaran> -->\n\n<!--* [Verification of Event-Driven Applications](#verification-of-event-driven-applications) <Oksana>-->\n\n<!-- * [Verification of epistemic properties of Java programs](#verification-of-epistemic-properties-of-java-programs) <Franco><Nikos> -->\n\n<!-- ### Separation Logic\n\n* [Verification of unbounded heap-manipulating programs via learning](#verification-of-unbounded-heap-manipulating-programs-via-learning) <Loc><Sang> -->\n\n<!-- ### Automatic Program Repair -->\n\n<!-- * [Automatic program repair using annotations](#automatic-program-repair-using-annotations) <Bach><Vaibhav><Eric><Corina> -->\n\n<!-- ### Symbolic Pathfinder (SPF) -->\n\n<!-- * ![#f03c15](https://placehold.co/15x15/f03c15/f03c15.png) [Support Java 11+ for SPF](#support-java-11-for-spf) <Yannic><Corina> -->\n\n<!-- * [Support gradle for SPF](#support-gradle-for-spf) <Yannic><Corina> -->\n\n<!-- * ![#f03c15](https://placehold.co/15x15/f03c15/f03c15.png) [String Constraint Solver Integration in SPF](#improving-string-analysis-in-spf) <Yannic><Corina><Elena><Soha> -->\n\n<!-- * ![#FFD700](https://placehold.co/15x15/FFD700/FFD700.png) [Support runtime exceptions in SPF](#runtime-exception-in-spf) <Soha> -->\n\n<!-- * ![#f03c15](https://placehold.co/15x15/f03c15/f03c15.png) [Support a portfolio of solvers in SPF](#solvers-portfolio-in-spf) <Soha> -->\n\n<!-- * ![#f03c15](https://placehold.co/15x15/f03c15/f03c15.png) [Use LLM to generate sound reduction rules in SPF](#llm-reduction-rules-in-spf) <Soha> -->\n\n<!-- * [Support Bit-Vector Floating Point in SPF](#bvfloating-point-in-spf) <Soha> -->\n\n<!-- * [Refactoring SPF constraint library](#refactoring-spf-constraint-library) <Elena> -->\n\n<!-- * [Handling Native Calls in the Context of Symbolic Execution](#handling-native-calls-in-the-context-of-symbolic-execution) <Corina><Nastaran> -->\n\n<!-- * [Comparison between concolic execution and classical symbolic execution](#comparison-between-concolic-and-classical-symbolic-execution) -->\n\n<!-- * [Generic GREEN](#generic-green) <Willem> -->\n\n<!-- * [Improving Symbolic PathFinder](#improving-symbolic-pathfinder) <Kasper><Corina> -->\n\n<!-- * [Improving Sampling of Symbolic Paths](#improving-sampling-of-symbolic-paths) <Kasper> -->\n\n<!-- * [Hash-consing for SPF](#hash-consing-for-spf) <Vaibhav> -->\n\n<!-- * [Visualizing ChoiceGenerator tree for SPF](#visualizing-choicegenerator-tree-for-spf) <Vaibhav> -->\n\n<!-- * [Combinatorial testing of configuration options for SPF](#combinatorial-testing-of-configuration-options-for-SPF) <Vaibhav> -->\n\n<!-- * [Beneficial path-merging for SPF](#beneficial-path-merging-for-SPF) <Vaibhav> -->\n\n<!--### Hybrid Fuzzing-->\n\n<!-- * [Whitebox Fuzzer and Grammar Learner](#whitebox-fuzzer-and-grammar-learner)  -->\n\n<!-- * [Fuzzing and Symbolic Execution](#fuzzing-and-symbolic-execution) <Corina><Yannic> -->\n\n\n<!-- ### Smart Contract -->\n\n<!-- * [Smart Contract Analysis](#smart-contract-analysis) <Cyrille> -->\n\n\n\n<!-- ### Android -->\n\n<!-- * [Analysis of Android Applications](#analysis-of-android-applications) -->\n\n\n\n<!-- ### Concolic Execution -->\n\n<!-- * [JDart maintenance and scalability](#jdart-maintenance-and-scalability) <Falk> -->\n\n<!--\n* [New Features for JDart](#new-features-for-jdart) <Kasper>\n\n* [Concolic Execution for Android Apps](#concolic-execution-for-android-apps) <Kasper>\n\n* [Support for parallel or distributed exploration in JDart](#support-for-parallel-or-distributed-exploration-in-jdart-and-regression-tests-for-jdart)\n\n* [Regression tests for JDart](#support-for-parallel-or-distributed-exploration-in-jdart-and-regression-tests-for-jdart)-->\n\n\n\n<!-- ### Environment and Test Case Generation -->\n\n<!-- * [Environment and Test Case Generation for Specific Domains](#environment-and-test-case-generation-for-specific-domains) <Oksana> -->\n\n<!-- * ![#FFD700](https://placehold.co/15x15/FFD700/FFD700.png) [Model-based Testing with Modbat for JPF](#mbt-modbat) <Cyrille> -->\n\n<!-- * [Minimizing test-cases for branch coverage of Path-Merged Regions](#minimize-testcases-path-merging) <Soha> -->\n\n<!-- * [Method summaries, extended](#method-summaries)<Cyrille><Pavel> -->\n\n<!-- * [Environment and Test Case Generation for Symbolic Execution](#environment-and-test-case-generation-for-symbolic-execution) <Oksana>\n\n<!-- * [Test Case Generation for Evolving Applications](#test-case-generation-for-evolving-applications) <Oksana> -->\n\n\n\n<!-- ### JPF Extensions and External Systems Interfacing -->\n\n<!-- * [Evaluating jpf-psyco](#evaluating-jpf-psyco) <Kasper><CheckWithFalk> -->\n\n\n\n<!-- ### Symbolic Data-race Detection -->\n\n<!-- * [Symbolic data-race detection for Habanero Java](#symbolic-data-race-detection-for-habanero-java) <Eric> -->\n\n\n ### Java Ranger (JR) \n\n * ![#f03c15](https://placehold.co/15x15/f03c15/f03c15.png) [Support Floating Point in JR](#fp-path-merging) <Soha>\n\n\n### Project Description\n\n<a name=\"support-java-11\"></a>\n#### ![#f03c15](https://placehold.co/15x15/f03c15/f03c15.png) Support Java 11/17 for JPF extensions\n\n**Description:**\njpf-core is essentially a JVM that currently fully supports only Java 8 and Java 11 (with limitations on bootstrap methods). Bootstrap methods are currently interpreted, which works for common usage but may not work for advanced cases. The goal of this project is to generate the call site code on the fly so bootstrap methods work as on the host JVM. \n\n**Difficulty:** Hard  \n**Scope:** 350 hours  \n**Required skills:** Knowledge of Java bytecode  \n**Preferred skills:** Knowledge of private Java APIs \n**Possible Mentors:** Cyrille\n\n<a name=\"support-java-17\"></a>\n#### ![#FFD700](https://placehold.co/15x15/FFD700/FFD700.png) Support for Java 17 for jpf-core\n\nRelated to the project above, there are also some new features in Java 17 that are not yet supported by JPF. We have work in progress on branch `java-17`. Currently unsupported Java features include language features that are not supported at run time (e.g., records) and Java language features that are not fully analyzed (e.g., sealed classes). In this project, you would identify such unsupported features and extend JPF (jpf-core) to support them.\n\n**Difficulty:** Medium  \n**Scope:** 175 hours  \n**Required skills:** Knowledge of Java internals  \n**Possible Mentors:** Cyrille\n\n<!--\n<a name=\"mbt-modbat\"></a>\n#### ![#FFD700](https://placehold.co/15x15/FFD700/FFD700.png) Test Case Generation/Model-based Testing with Modbat for JPF\n\n**Description:**\nJPF requires test cases as a starting point to explore a system. It is therefore suitable to use\ntest case generation to create test cases automatically. [Modbat](https://github.com/cyrille-artho/modbat/) is an open-source tool for test case generation. For testing concurrent software,\nan obvious choice would be to combine Modbat (to generate tests) with JPF (to execute tests and\nfind concurrency problems). This has been done once as a [proof of concept](https://people.kth.se/~artho/papers/ase-2013-preprint.pdf) but is not supported in the current version of Modbat.\nThe main reason for this is that Modbat's reporting has to read and parse bytecode, which requires\naccess to some native code that JPF does not support.\nThe goal is to find all problems where Modbat requires native access, and to use jpf-nhandler\nto resolve as many of these cases as possible. Remaining cases can be handled with custom model/peer classes, perhaps not with the full feature set, but at least to avoid JPF aborting due to an unsupported feature.\n\n**Difficulty:** Medium  \n**Scope:** 350 hours  \n**Required skills:** Knowledge of Java Pathfinder  \n**Preferred skills:** Knowledge of test generation  \n**Possible Mentors:** Cyrille\n-->\n\n<!--\n<a name=\"support-gradle-for-spf\"></a>\n#### Support for gradle for SPF\n\n**Description:**\nThe goal of this project is to (1) implement gradle support for Symbolic Pathfinder, (2) to update the extension template, including gradle support and updated documentation.\n\n**Difficulty:** Easy  \n**Scope:** 175 hours  \n**Required skills:** Knowledge of Java Pathfinder and Gradle build automation  \n**Preferred skills:** Knowledge of Symbolic Pathfinder  \n**Possible Mentors:** Yannic, Corina\n-->\n\n<!-- \n<a name=\"support-java-11-for-spf\"></a>\n#### ![#f03c15](https://placehold.co/15x15/f03c15/f03c15.png) Support for Java v11 for SPF\n\n**Description:**\nThe goal of this project is to upgrade SPF to work with Java 11.\n\n**Difficulty:** Hard  \n**Scope:** 350 hours  \n**Required skills:** Knowledge of Symbolic Pathfinder   \n**Preferred skills:** Knowledge of Java v11  \n**Possible Mentors:** Yannic, Corina\n\n-->\n\n<!-- \n<a name=\"improving-string-analysis-in-spf\"></a>\n#### ![#f03c15](https://placehold.co/15x15/f03c15/f03c15.png) Robustify String solving for SPF\n\n**Description:**\nThe goal of this project is to test SPF integration with Z3 string constraint solving; adding support cvc5 is a plus. This project will extend SPF branch `sv-comp`.\n\n\n**Difficulty:** Hard  \n**Scope:** 350 hours  \n**Required skills:** Knowledge of Symbolic Pathfinder   \n**Preferred skills:** Knowledge of String constraint solving.  \n**Possible Mentors:** Corina, Elena, Soha\n\n\n<a name=\"runtime-exception-in-spf\"></a>\n#### ![#FFD700](https://placehold.co/15x15/FFD700/FFD700.png) Support runtime exception in SPF\n\n**Description:**\nThe main goal of this project is to support throwing a runtime exception for some of the summarized functions such as `String.substring`. Also, this project should build on [SPF](https://github.com/SymbolicPathFinder/jpf-symbc) Java 11 Gradle support, which implies fixing existing issues. This project will extend SPF branch `sv-comp`.\n\n\n**Difficulty:** Medium\n**Scope:** 350 hours    \n**Required skills:** Knowledge of Symbolic Pathfinder   \n**Possible Mentors:** Soha\n\n\n<a name=\"solvers-portfolio-in-spf\"></a>\n#### ![#f03c15](https://placehold.co/15x15/f03c15/f03c15.png) Support portfolio of solvers in SPF\n\n**Description:**\nThe main goal of this project is to enable the simultaneous invocation of multiple solvers, terminating the wait as soon as any solver returns a satisfiable result. This approach is expected to enhance [SPF's](https://github.com/SymbolicPathFinder/jpf-symbc) ability to handle a broader range of constraints. This project will extend SPF branch `sv-comp`. \n\n\n**Difficulty:** Hard  \n**Scope:** 350 hours  \n**Required skills:** Knowledge of Symbolic Pathfinder   \n**Preferred skills:** Expeirence with various solvers   \n**Possible Mentors:** Soha\n\n\n<a name=\"llm-reduction-rules-in-spf\"></a>\n#### ![#f03c15](https://placehold.co/15x15/f03c15/f03c15.png) Use LLM to generate sound reduction rules in SPF\n\n**Description:**\nSolver constraints can become very complex, and very large. In this project, we will use LLM in [SPF](https://github.com/SymbolicPathFinder/jpf-symbc) to identify sound reduction rules that can be applied to the constraints before sending them to the solver, ideally improving its performance. See [this paper](https://link.springer.com/chapter/10.1007/978-3-642-39176-7_19) for reference. This project will extend SPF branch `sv-comp`.\n\n**Difficulty:** Hard  \n**Scope:** 350 hours  \n**Required skills:** Knowledge of Symbolic Pathfinder     \n**Preferred skills:** LLM  \n**Possible Mentors:** Soha\n\n-->\n\n\n<a name=\"fp-path-merging\"></a>\n#### ![#f03c15](https://placehold.co/15x15/f03c15/f03c15.png) Support Floating Point Constraints for Path-Merged Regions\n\n**Description:**\nJava Ranger is a path-merging symbolic execution that is built on top of SPF, which is in turn built on top JPF. Instead of dynamically executing all execution paths, Java Ranger can collapse multiple paths into a single dynamic path, that has a disjunctive constraint describing the behaviour of the merged region. \nIn this project, we want to allow Java Ranger to summarize regions with floating point contraints. This means that we might first add some floating point support to the baseline symbolic execution, then, after that allow JR to include summarizes of these operation. \n\n**Difficulty:** Hard  \n**Scope:** 350 hours  \n**Required skills:** Knowledge of Symbolic PathFinder.  \n**Preferred skills:** Knowledge of Java Ranger."
  },
  {
    "name": "Wikimedia Foundation",
    "slug": "wikimedia-foundation-nd",
    "tagline": "Bringing free educational content to the world",
    "description": "Wikimedia strives to bring about a world in which every single human being can freely share in the sum of all knowledge; through various projects, chapters, and the support structure of the non-profit Wikimedia Foundation. Wikimedia officially supports 13 projects, including Wikipedia, the seventh most popular site on the internet. Wikipedia receives over 20 billion global page views every month and is available in over 300 languages. The tech behind it ensures that our projects are fast, reliable, and open to all. We design and build the open-source technology that powers Wikimedia projects from hosting Wikipedia to creating edit-checking artificial intelligence (AI). Community volunteers and Foundation technologists collaborate on MediaWiki, which makes sharing free knowledge possible. Read more about Wikimedia on our homepage: https://wikimediafoundation.org/",
    "ideas_url": "https://www.mediawiki.org/wiki/Google_Summer_of_Code/2026#Projects",
    "website_url": "http://wikimediafoundation.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "javascript",
      "html",
      "php",
      "css",
      "Phyton"
    ],
    "topic_tags": [
      "semantic web",
      "wikipedia",
      "wikimedia",
      "mediawiki",
      "i18n"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/wikimedia-foundation-nd",
    "ideas_content": "# Google Summer of Code/2026\n\n## Program timeline\n\n[[edit](https://www.mediawiki.org/w/index.php?title=Google_Summer_of_Code/2026&action=edit§ion=1)]\n\n|\n|---|\n\nApplicants = Wikimedia mentors and/or GSoC contributors; Contributors = interns, junior developers\n\n## Projects\n\n[[edit](https://www.mediawiki.org/w/index.php?title=Google_Summer_of_Code/2026&action=edit§ion=2)]\n\nProject proposals were submitted and tracked via [this Phabricator task](https://phabricator.wikimedia.org/T414121). Proposal submissions closed on January 26 2026.\n\n*Please see the individual Phabricator link under each project for further details.*\n\n### Bulk OCR Improvements\n\n[[edit](https://www.mediawiki.org/w/index.php?title=Google_Summer_of_Code/2026&action=edit§ion=3)]\n\nWikisource is an online wiki-based digital library of free-content textual sources operated by the Wikimedia Foundation. The Bulk OCR feature aims to provide an easy way for volunteers to OCR multiple pages or, say, an entire book on Wikisource. However, the ability to perform bulk OCR on any work should be restricted only to certain groups of users. To this end, there is a need to add features to the Wikisource extension to allow authorized users to OCR multiple pages at once and insert the OCRed text back into the relevant text layer of the corresponding pages of the book on Wikisource.\n\n- Phabricator:\n[T415145](https://phabricator.wikimedia.org/T415145) - Skills required: Javascript, HTML, CSS, familiarity with object oriented programming, experience with PHP and Mediawiki are bonuses, familiarity with the\n[Wikimedia OCR](https://phabricator.wikimedia.org/tag/wikimedia_ocr/)project - Mentors: Parthiv Menon (\n[theprotonade](https://phabricator.wikimedia.org/p/theprotonade/)), Satdeep Gill ([SGill](https://phabricator.wikimedia.org/p/SGill/)) - Size: 350 hours\n- Difficulty: Medium\n\n### CampWiz NxT Redesign\n\n[[edit](https://www.mediawiki.org/w/index.php?title=Google_Summer_of_Code/2026&action=edit§ion=4)]\n\nCampWiz NXT is a comprehensive tool designed to facilitate the evaluation of media files such as images, audios, and videos uploaded to Wikimedia Commons during Wiki Loves contests. CampWiz NXT streamlines the jury process by offering a structured and efficient platform for media assessment. In the past, when it was developed, we took dual server approach with nextjs as frontend server and golang as backend server. But, now we need to migrate our frontend from nextjs to pure react with minimal functionality change.\n\n- Phabricator:\n[T414269](https://phabricator.wikimedia.org/T414269) - Skills required: Proficiency in React for building modular, maintainable user interfaces. Experience with Next.js for modern frontend development and static site generation. Familiarity with the Material UI component library for implementing accessible, consistent, and responsive designs.\n- Mentors:\n[Nokib_Sarkar](https://phabricator.wikimedia.org/p/Nokib_Sarkar/),[Tiven2240](https://phabricator.wikimedia.org/p/Tiven2240/) - Size: around 90 hours\n- Difficulty: Medium\n\n### Gamifying constraint violation fixes on Wikidata\n\n[[edit](https://www.mediawiki.org/w/index.php?title=Google_Summer_of_Code/2026&action=edit§ion=5)]\n\nDevelop a game to make edits to Wikidata to fix constraint violations. The requirements for being a game here is not only that the tool is easy to use but also that there are methods that keep users engaged, such as scores, leaderboards, collaborations, and challenges. There may be aspects of community collaboration in some games.\n\n- Phabricator:\n[T387248](https://phabricator.wikimedia.org/T387248) - Skills required: Understanding of Wikidata. Game Design. SPARQL proficiency. Proficiency in Python or another scripting language.\n- Mentors:\n[Peter F. Patel Schneider](https://phabricator.wikimedia.org/p/Pfps/),[David Martin](https://phabricator.wikimedia.org/p/DMartin-WMF/) - Size: 350 hours\n- Difficulty: Medium\n\n### Implement lossless JPG transformations in the Commons Android App\n\n[[edit](https://www.mediawiki.org/w/index.php?title=Google_Summer_of_Code/2026&action=edit§ion=6)]\n\nThe project aims to add picture editing capabilities with lossless transformations to the app:\n\n- Lossless crop.\n- Lossless blur: JPG images are made of many 8x8 pixel blocks. The idea here is to blur only the JPG blocks showing what the users wants to blur, without recompressing the other blocks.\n- Option to automatically blur people faces and car number plates.\n\n- Phabricator:\n[T415446](https://phabricator.wikimedia.org/T415446) - Skills required: Strong Android fundamentals, Kotlin. No prior knowledge of JPG format required.\n- Mentors:\n[Nicolas_Raoul](https://phabricator.wikimedia.org/p/Nicolas_Raoul/)(past maintainer),[RitikaPahwa4444](https://phabricator.wikimedia.org/p/RitikaPahwa4444/)(current maintainer) - Size: 350 hours\n- Difficulty: Medium\n\n### Integration testing for extensions in Canasta\n\n[[edit](https://www.mediawiki.org/w/index.php?title=Google_Summer_of_Code/2026&action=edit§ion=7)]\n\n[Canasta](https://canasta.wiki/) is a fairly large MediaWiki distribution that includes, besides MediaWiki itself, over 150 extensions, 10 skins, a full LAMP stack, and a variety of other applications and libraries, like Elasticsearch. This amount of software makes Canasta a full-featured solution, but it also means that many things can go wrong. An upgrade to some component could result in that component breaking - or could even result in the entire system breaking. There is already a plan to add testing of core MediaWiki, via [this](https://github.com/CanastaWiki/CanastaBase/pull/46) pending pull request. That leaves MediaWiki extensions (and, to a much lesser extent, skins). This project would add testing of these to the Canasta continuous integration (CI) pipeline, so that testing is done of every patch, helping to ensure that no change is destructive.\n\n- Phabricator:\n[T414617](https://phabricator.wikimedia.org/T414617) - Skills required: Familiarity with integration testing required, knowledge of GitHub Actions, Docker and the PHPUnit, Jest and SonarQube testing frameworks preferred\n- Mentors:\n[Yaron_Koren](https://phabricator.wikimedia.org/p/Yaron_Koren/),[cicalese](https://phabricator.wikimedia.org/p/cicalese/) - Size: 350 hours\n- Difficulty: Medium\n\n### Modularization + Jetpack Compose in Android Commons App\n\n[[edit](https://www.mediawiki.org/w/index.php?title=Google_Summer_of_Code/2026&action=edit§ion=8)]\n\nThe project aims to revamp the app architecture using Jetpack Compose.\n\n- Phabricator:\n[T415272](https://phabricator.wikimedia.org/T415272) - Skills required: Strong Android fundamentals, Kotlin, Jetpack Compose\n- Mentors:\n[Kaartic](https://phabricator.wikimedia.org/p/Kaartic/)(past maintainer),[Neeldoshii](https://phabricator.wikimedia.org/p/Neeldoshii/) - Size: 350 hours\n- Difficulty: Medium\n\n### Montage improvements\n\n[[edit](https://www.mediawiki.org/w/index.php?title=Google_Summer_of_Code/2026&action=edit§ion=9)]\n\nMontage is a photo evaluation tool for and by Wiki Loves competitions. It offers a flexible round-based workflow that is configurable to contests of all sizes, and is suited for evaluation of 10-1000s images. For the scope of GSoC, the proposal is to make multiple improvements to improve the workflows, solve existing bugs, and overall improve the experience of users (campaign organizers and jury) using the tool. Source code: [https://github.com/hatnote/montage](https://github.com/hatnote/montage)\n\n- Phabricator:\n[T415578](https://phabricator.wikimedia.org/T415578) - Skills required: Frontend: HTML, CSS, Javascript and Vue.js. Backend: Python, Clastic (\n[https://python-clastic.readthedocs.io/en/latest/](https://python-clastic.readthedocs.io/en/latest/)) - Mentors:\n[KCVelaga](https://phabricator.wikimedia.org/p/KCVelaga/),[Jayprakash12345](https://phabricator.wikimedia.org/p/Jayprakash12345/) - Size: 350 hours\n- Difficulty: Medium\n\n### Programs & Events Dashboard system-wide metrics and data downloads\n\n[[edit](https://www.mediawiki.org/w/index.php?title=Google_Summer_of_Code/2026&action=edit§ion=10)]\n\nDevelop efficient system-wide metrics and key data download options for Programs & Events Dashboard\n\n- Phabricator:\n[T415608](https://phabricator.wikimedia.org/T415608) - Skills required: Ruby (required), JavaScript (helpful)\n- Mentors:\n[Ragesoss](https://phabricator.wikimedia.org/p/Ragesoss/),[Abishekdascs](https://phabricator.wikimedia.org/p/Abishekdascs/) - Size: 350 hours\n- Difficulty: Medium\n\n### Scribe Conjugation Application Development\n\n[[edit](https://www.mediawiki.org/w/index.php?title=Google_Summer_of_Code/2026&action=edit§ion=11)]\n\nThe [Scribe](https://github.com/scribe-org) community makes [Wikidata](https://wikidata.org/) based mobile keyboard applications to help second language learners communicate in the languages they're learning. Till now the Scribe community has been working on keyboard applications, namely [Scribe-iOS](https://github.com/scribe-org/Scribe-iOS) and [Scribe-Android](https://github.com/scribe-org/Scribe-Android), along with the infrastructure projects that support them ([Scribe-Data](https://github.com/scribe-org/Scribe-Data) and [Scribe-Server](https://github.com/scribe-org/Scribe-Server)). We'd now like to expand the end user applications that we have on offer to include [Wikidata](https://wikidata.org/) based, multilingual verb conjugation applications. Scribe-Conjugate (see [designs on Figma](https://www.figma.com/design/c8945w2iyoPYVhsqW7vRn6/scribe_public_designs?node-id=1667-2132&t=YSEnQ9eiId51kS9h-1)) for both iOS and Android would provide users with an open-source, open-data and highly performative experience in a new version of a low barrier application that is used by language learners all over the world.\n\n- Phabricator:\n[T414862](https://phabricator.wikimedia.org/T414862) - Skills required:\n[Kotlin](https://kotlinlang.org/)for Android development,[Swift](https://www.swift.org/)for iOS development - Mentors:\n[AndrewTavis](https://phabricator.wikimedia.org/p/AndrewTavis/),[Henrikt93](https://phabricator.wikimedia.org/p/Henrikt93/),[DeleMike](https://phabricator.wikimedia.org/p/DeleMike/) - Size: 350 hours\n- Difficulty: Hard\n\n### Wikifile-Transfer Enhancement\n\n[[edit](https://www.mediawiki.org/w/index.php?title=Google_Summer_of_Code/2026&action=edit§ion=12)]\n\nWikifile-Transfer is a Toolforge web application that helps Wikimedia contributors transfer media files (especially non-free/fair-use images) between different wiki projects. This project aims to enhance the tool by adding batch upload capability, implementing an upload history system, improving metadata extraction with category localization, and adding comprehensive test coverage to ensure code quality and reliability.\n\n- Phabricator:\n[T415562](https://phabricator.wikimedia.org/T415562) - Skills required: Python (Flask, SQLAlchemy, Celery), JavaScript/React (functional components, hooks), SQL basics (MySQL), Git version control, Docker, Redis\n- Mentors:\n[ParasharSarthak](https://phabricator.wikimedia.org/p/ParasharSarthak/),[Jnanaranjan_sahu](https://phabricator.wikimedia.org/p/Jnanaranjan_sahu/) - Size: 350 hours\n- Difficulty: Medium\n\n## Recommended steps for accepted candidates\n\n[[edit](https://www.mediawiki.org/w/index.php?title=Google_Summer_of_Code/2026&action=edit§ion=13)]\n\nSee [Google Summer of Code/Participants#Accepted participants](https://www.mediawiki.org/wiki/Google_Summer_of_Code/Participants#Accepted_participants).\n\n## Contact\n\n[[edit](https://www.mediawiki.org/w/index.php?title=Google_Summer_of_Code/2026&action=edit§ion=14)]\n\n- Support forum:\n[https://wikimedia.zulipchat.com/#narrow/channel/561533-GSoC2026](https://wikimedia.zulipchat.com/#narrow/channel/561533-GSoC2026) - Organization administrators for this round are:\n[Lani Goto](https://meta.wikimedia.org/wiki/User:LGoto_(WMF)),[Gopa Vasanth](https://www.mediawiki.org/wiki/User:Gopavasanth),[Mahfuza Mohona](https://www.mediawiki.org/wiki/User:Mhmohona) - Read how to\n[communicate effectively](https://www.mediawiki.org/wiki/New_Developers/Communication_tips)and[get help on technical questions](https://developer.wikimedia.org/get-help/).We encourage applicants to communicate in the public streams and refrain from sending private emails/messages whenever possible. Open communication allows fellow applicants to learn from your questions. It also gives all community members a chance to answer your queries. This way, queries get answered sooner and the administrators do not become a bottleneck. Also see our[communication tips](https://www.mediawiki.org/wiki/New_Developers/Communication_tips).\n\n## External links\n\n[[edit](https://www.mediawiki.org/w/index.php?title=Google_Summer_of_Code/2026&action=edit§ion=15)]\n\n[GSoC timeline](https://developers.google.com/open-source/gsoc/timeline)- Google Open Source blog\n[update](https://opensource.googleblog.com/2025/12/shape-future-with-google-summer-of-code.html)"
  },
  {
    "name": "Neuroinformatics Unit",
    "slug": "neuroinformatics-unit",
    "tagline": "Open-source tools for neuroscience and ML",
    "description": "The Neuroinformatics Unit is dedicated to the development of high quality, accurate, robust, easy to use and maintainable open-source software for neuroscience and machine learning. We collaborate with researchers and other software engineers to advance neuroscience research and make new algorithms and tools available to the global community.",
    "ideas_url": "https://neuroinformatics.dev/get-involved/gsoc/2026",
    "website_url": "https://neuroinformatics.dev",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "numpy",
      "pytorch",
      "Scipy",
      "napari"
    ],
    "topic_tags": [
      "visualization",
      "neuroscience",
      "data-science",
      "Computer-Vision",
      "neuroanatomy"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/neuroinformatics-unit",
    "ideas_content": "# Google Summer of Code 2026[#](https://neuroinformatics.dev#google-summer-of-code-2026)\n\n## GSoC NIU Projects 2026[#](https://neuroinformatics.dev#gsoc-niu-projects-2026)\n\nNIU is offering a variety of projects for GSoC 2026, organized under different software tools. Click on a project below learn more about the scope and requirements for each one.\n\nA project can be one of three sizes: small (90 h), medium (175 h) or large (350 h). The standard coding period is 12 weeks for medium and large projects, and 8 weeks for small projects.\n\nHowever, GSoC contributors can request in their proposal up to a 22-week coding period, if they know they may have other commitments or certain weeks when they will not be able to work full time on their GSoC project. During the project preparation period (called “community bonding period”), both the GSoC contributor and the mentors will agree on a schedule and sign off on it.\nFor more details please see our [main GSoC page](https://neuroinformatics.dev/index.html). Please also see our [application guidelines](https://neuroinformatics.dev/guidelines.html) and our [policy on the use of AI](https://neuroinformatics.dev/ai_policy.html).\n\nOur GSoC ideas are based within specific, larger open source packages we develop. Some of these have specific project ideas associated with them.\nOthers do not yet have specific project ideas, but all on this list welcome ideas developed by GSoC participants. Please reach out to us via our [GSoc Zulip channel](https://neuroinformatics.zulipchat.com/#narrow/channel/487898-Google-Summer-of-Code) to discuss.\n\nOther projects\n\nThe list below are just project “ideas”, we are very keen to hear about other potential projects from applicants. In 2026 we are particularly interested in:\n\nMaking our software more maintainable and reducing technical debt.\n\nMaking our tools more accessible to scientists. We are keen to help practicing scientists make their first contributions to open source.\n\n\nIf you have any ideas within these themes, please reach out via our [GSoc Zulip channel](https://neuroinformatics.zulipchat.com/#narrow/channel/487898-Google-Summer-of-Code).\n\n## BrainGlobe[#](https://neuroinformatics.dev#brainglobe)\n\n[BrainGlobe](https://brainglobe.info/) is a community-driven suite of open-source Python tools. The BrainGlobe tools are widely used to process, analyse and visualise images of brains (and other related data) in neuroscientific research.\n\nOur working language is English, but our mentors for these projects also speak Italian, French, and German.\n\nThree BrainGlobe repositories ([morphapi](https://github.com/brainglobe/morphapi), [brainrender](https://github.com/brainglobe/brainrender), [brainreg](https://github.com/brainglobe/brainreg)) are in pure maintenance mode, and therefore excluded from any GSoC project proposals. All other BrainGlobe repositories welcome alternative project ideas!\n\n##\nRefactor `brainglobe-heatmap`\n\nto use atlas annotations rather than mesh slices for visualisation\n\n`brainglobe-heatmap`\n\nis BrainGlobe’s tool to generate heatmap plots of atlases in 2 and 3D. It relies heavily on BrainGlobe’s meshes, which can cause small imprecisions in visualising data. In 2D it also can fail to slice the meshes along a plane correctly. This could be improved by moving the heatmap functions to relies on the atlas annotations instead of the meshes. There are a number of additional refactoring improvements that could be done to `brainglobe-heatmap`\n\n.\n\n**Deliverables**\n\nRefactor 2D plotting functionality to use atlas annotations instead of meshes\n\nTests for new functionality\n\nEnsure any refactored functionality has docstrings\n\nA blog on the\n\n[BrainGlobe website](https://brainglobe.info/blog/)about the work done(Stretch goal) - further improvements to\n\n`brainglobe-heatmaps`\n\n\n**Duration**\nSmall (~90 hours)\n\n**Difficulty**\n\nThis project is well suited for an intermediate contributor to open source.\n\n**Required skills**\n\nFluency with Python\n\n**Nice-to-haves**\n\nExperience with\n\n[pytest](https://docs.pytest.org/en/stable/).Experience with visualisation libraries, in particular\n\n[matplotlib](https://matplotlib.org/)and/or[vedo](https://vedo.embl.es/)Experience with neuroanatomy\n\n\n**Potential mentors**\n\n**Further reading**\n`brainglobe-heatmap`\n\nissue [#103](https://github.com/brainglobe/brainglobe-heatmap/issues/103) nicely demonstrates the problem and a potential solution approach.\n\n##\nImproving the user experience in `brainrender-napari`\n\n\n`brainrender-napari`\n\nallows BrainGlobe users to download and visualise a variety of neuroanatomical atlases through a graphical user interface. As BrainGlobe supports more and more atlases, we’d like to make it more convenient for users to find the atlas they are interested in, and visualise it in more custom ways.\n\n**Deliverables**\n\nAdd sorting functionality to\n\n`brainrender-napari`\n\ntablesAllow users to filter atlas tables by species\n\nAdd functionality to visualise the atlas annotation with preset colours\n\nAny added functionality will require extensive tests and documentation\n\nA blog on the\n\n[BrainGlobe website](https://brainglobe.info/blog/)about the work done(Stretch) add functionality to allow users to set the colours of meshes\n\n\n**Duration**\nLarge (~350 hours)\n\n**Difficulty**\n\nThis project is well suited for an intermediate contributor to open source.\n\n**Required skills**\n\nFluency with Python\n\n**Nice-to-haves**\n\nExperience with\n\n[pytest](https://docs.pytest.org/en/stable/).Experience with graphical user face libraries, in particular\n\n[napari](https://napari.org/stable/)and/or[Qt](https://www.qt.io/)\n\n**Potential mentors**\n\n**Further reading**\n\nFurther details can be found in\n\n`brainrender-napari`\n\nissues[#22](https://github.com/brainglobe/brainrender-napari/issues/22),[#46](https://github.com/brainglobe/brainrender-napari/issues/46),[#154](https://github.com/brainglobe/brainrender-napari/issues/154), and[#218](https://github.com/brainglobe/brainrender-napari/issues/218)Initial familiarisation with\n\n`brainrender-napari`\n\n’s current features may happen by working through the[atlas downloading tutorial](https://brainglobe.info/tutorials/manage-atlases-in-GUI.html)and the[atlas visualisation tutorial](https://brainglobe.info/tutorials/visualise-atlas-napari.html)\n\n##\nExpand `cellfinder`\n\nto accept different types of input data (several or single channels, 2.5 dimensions)\n\nBrainGlobe’s `cellfinder`\n\ntool allows researchers to detect fluorescent cells in whole-brain microscopy images. It requires whole-brain images of both a signal and a background channels as input, which not many researchers have. We’d like to expand the types of inputs `cellfinder`\n\nsupport to include brain slices (essentially 2D data) and single channel inputs (no background channel).\n\n**Deliverables**\n\nAdd functionality supporting 2.5-dimensional data\n\nAdd functionality to support single-channel data\n\nAny added functionality will require extensive tests and documentation\n\nA blog on the\n\n[BrainGlobe website](https://brainglobe.info/blog/)about the work done\n\n**Duration**\nLarge (~350 hours)\n\n**Difficulty**\n\nThis project is well suited for an intermediate contributor to open source.\n\n**Required skills**\n\nFluency with Python and [NumPy](https://numpy.org/)\n\n**Nice-to-haves**\n\nExperience with\n\n[pytest](https://docs.pytest.org/en/stable/).Experience working with image data\n\nExperience working with large data, e.g. using\n\nand/or`pytorch`\n\n`dask`\n\n\n**Potential mentors**\n\n**Further reading**\n\nFurther details can be found in\n\n`cellfinder`\n\nissues[#298](https://github.com/brainglobe/cellfinder/issues/298)and[#352](https://github.com/brainglobe/cellfinder/issues/352)The current\n\n`cellfinder`\n\nfunctionality can be explored by working through the[3D cell detection tutorial](https://brainglobe.info/tutorials/cellfinder-detection.html)\n\n## Movement[#](https://neuroinformatics.dev#movement)\n\nMarkerless pose estimation tools based on deep learning, such as [DeepLabCut](https://www.mackenziemathislab.org/deeplabcut) and [SLEAP](https://sleap.ai/), have revolutionised the study of animal behaviour. However, there is currently no user-friendly, general-purpose approach for processing and analysing the trajectories generated by these popular tools. To fill this gap, we’re developing [ movement](https://movement.neuroinformatics.dev/latest/), an open-source Python package that provides a unified data analysis interface across pose estimation frameworks.\n\nOur working language is English, but our mentors for these projects also speak Spanish and Mandarin.\n\n## Adding I/O support for formats used in human motion tracking\n\nThe `movement`\n\npackage currently supports a variety of pose estimation formats commonly used in animal behaviour research. With this project, we would like to expand our support to file formats more commonly used in human pose estimation, such as:\n\n**Deliverables**\n\nFunctionality to load at least 3 popular file formats for human motion tracking, such as MMPose output files, COCO keypoint data, motion capture formats or motionBIDS.\n\nTests to cover any added functionality.\n\nDocumentation for the new functionality.\n\nExample use-cases in the\n\n`movement`\n\n[gallery](https://movement.neuroinformatics.dev/latest/examples/index.html).\n\n**Duration**\n\nLarge (~350 hours)\n\n**Difficulty**\n\nThis project is well suited for an intermediate contributor to open source.\n\n**Required skills**\n\nFluency with Python, [NumPy](https://numpy.org/) and/or [pandas](https://pandas.pydata.org/docs/index.html).\n\n**Nice-to-haves**\n\nFamiliarity with pose estimation frameworks and their usual workflow.\n\nFamiliarity with any of the human pose estimation formats mentioned above.\n\n\n**Potential mentors**\n\n**Further reading**\n\n## Adding I/O support for popular animal tracking software\n\nThe `movement`\n\npackage currently supports a variety of pose estimation formats commonly used in animal behaviour research. With this project, we would like to expand our support to other file formats used in the field, such as:\n\npoint trackers, such as\n\n[cotracker3](https://github.com/facebookresearch/co-tracker)[Bonsai’s](https://bonsai-rx.org/docs/index.html)centroid tracker[TRex’s](https://trex.run/docs/)pose and bounding box outputs\n\n**Deliverables**\n\nFunctionality to load 2-3 of the file formats mentioned above.\n\nTests to cover any added functionality.\n\nDocumentation for the new functionality.\n\nExample use-cases in the\n\n`movement`\n\n[gallery](https://movement.neuroinformatics.dev/latest/examples/index.html).\n\n**Duration**\n\nLarge (~350 hours)\n\n**Difficulty**\n\nThis project is well suited for an intermediate contributor to open source.\n\n**Required skills**\n\nFluency with Python, [NumPy](https://numpy.org/) and/or [pandas](https://pandas.pydata.org/docs/index.html).\n\n**Nice-to-haves**\n\nFamiliarity with pose estimation frameworks and their usual workflow.\n\nFamiliarity with any of the software packages mentioned above.\n\n\n**Potential mentors**\n\n**Further reading**\n\nFurther details are available in the following `movement`\n\nissues: [#348](https://github.com/neuroinformatics-unit/movement/issues/348), [#599](https://github.com/neuroinformatics-unit/movement/issues/599)\n\n## Adding support for tracked segmentation masks\n\n`movement`\n\nhas initially focused on pose estimation data, but the [long term goal](https://movement.neuroinformatics.dev/latest/community/mission-scope.html) of the package is to support all animal tracking data formats that are relevant to animal behaviour research. With tools like [SAM](https://github.com/facebookresearch/sam2) or [OCTRON](https://octron-tracking.github.io/OCTRON-docs/) that track segmentation masks in videos, adding support for such data would be a valuable extension of `movement`\n\n’s input capabilities. In this project, we would like to explore how segmentation‑based tracking data can be integrated into the `movement`\n\nframework and design a user-friendly workflow for doing so.\n\n**Deliverables**\n\nSupport for at least one of the file formats output by a popular segmentation and tracking software package.\n\nTests to cover any added functionality.\n\nDocumentation for the new functionality.\n\nExample use-cases in the\n\n`movement`\n\n[gallery](https://movement.neuroinformatics.dev/latest/examples/index.html).\n\n**Duration**\n\nLarge (~350 hours)\n\n**Difficulty**\n\nThis project is well suited for an intermediate contributor to open source.\n\n**Required skills**\n\nFluency with Python, [NumPy](https://numpy.org/) and/or [pandas](https://pandas.pydata.org/docs/index.html).\n\n**Nice-to-haves**\n\nFamiliarity with segmentation models (such as\n\n[SAM2](https://github.com/facebookresearch/sam2),[SAM3](https://github.com/facebookresearch/sam3)or[Ultralytics Instance segmentation with YOLO](https://docs.ultralytics.com/tasks/segment/)) and their usual workflow.Familiarity with software packages for instance segmentation applied to biology or animal behaviour research, such as\n\n[OCTRON](https://octron-tracking.github.io/OCTRON-docs/)or[convpaint](https://guiwitz.github.io/napari-convpaint/book/Landing.html)\n\n**Potential mentors**\n\n**Further reading**\n\nFurther details are available in the following\n\n`movement`\n\nissue:[#301](https://github.com/neuroinformatics-unit/movement/issues/301)\n\n## Adding a module for trajectory complexity metrics\n\nQuantitative characterisation of the trajectories of moving animals is an important component of many behavioural and ecological studies, and also falls within scope for `movement`\n\n. We would like to enable our users to perform statistical characterisation of trajectories through a variety of well-defined metrics such as straightness index, tortuosity, and sinuosity. Functions for computing these metrics could be implemented in a standalone module under [ movement.kinematics](https://github.com/neuroinformatics-unit/movement/tree/main/movement/kinematics).\n\n**Deliverables**\n\nFunctions for computing at least 3 metrics of trajectory complexity\n\nTests to cover any added functionality.\n\nDocumentation for the new functionality.\n\nExample use-cases in the\n\n`movement`\n\n[gallery](https://movement.neuroinformatics.dev/latest/examples/index.html).\n\n**Duration**\n\nMedium (~175 hours)\n\n**Difficulty**\n\nThis project is well suited for an intermediate contributor to open source, with a background in research.\n\n**Required skills**\n\n**Nice-to-haves**\n\nResearch experience in a relevant field: e.g. ethology, neuroscience, behavioural ecology, conservation.\n\n\n**Potential mentors**\n\n**Further reading**\n\nThe\n\nand its associated`trajr`\n\nR package[paper](https://onlinelibrary.wiley.com/doi/full/10.1111/eth.12739)\n\n## Adding a module for metrics of collective behaviour\n\nUnderstanding how individuals coordinate their movements within a group is a central question in behavioural ecology, ethology, and neuroscience. Since `movement`\n\nalready supports multi-individual tracking data, it is well positioned to enable users to quantify collective behaviour through established metrics such as group polarisation (alignment of heading directions), and nearest-neighbour distances. We would like to implement functions for computing collective behaviour metrics in a dedicated module.\n\n**Deliverables**\n\nA detailed GitHub issue describing suitable metrics to add.\n\nFunctions for computing at least 2 metrics of collective behaviour\n\nTests to cover any added functionality.\n\nDocumentation for the new functionality.\n\nExample use-cases in the\n\n`movement`\n\n[gallery](https://movement.neuroinformatics.dev/latest/examples/index.html).\n\n**Duration**\n\nMedium (~175 hours)\n\n**Difficulty**\n\nThis project is well suited for an intermediate contributor to open source, with a background in research.\n\n**Required skills**\n\n**Nice-to-haves**\n\nResearch experience in a relevant field: e.g. ethology, neuroscience, behavioural ecology, conservation.\n\n\n**Potential mentors**\n\n**Further reading**\n\nThe\n\nand its associated`swaRm`\n\nR package[paper](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.14460)An\n\n[example script](https://github.com/neuroinformatics-unit/zebras-stitching/blob/main/notebooks/03_notebook_compute_behaviour_metrics.py)for computing behaviour metrics for a herd of zebras. See also the corresponding[preprint](https://arxiv.org/abs/2505.16882).\n\n## Ethology[#](https://neuroinformatics.dev#ethology)\n\nThe main goal of [ ethology](https://github.com/neuroinformatics-unit/ethology) is to facilitate the application of a wide range of computer vision tasks to animal behaviour research, by providing a unified data analysis interface across these tasks.\n\nOur working language is English, but our mentors for these projects also speak Spanish.\n\n##\nExpanding annotations support in `ethology`\n\n\n`ethology`\n\nis a package in early development, whose goal is to make it very easy to mix and match computer vision tools to analyse animal behaviour data. Currently, `ethology`\n\nsupports loading and curating bounding box annotation datasets.We would like to expand the set of supported annotation types to include mask annotations, and add a UI interface for defining different annotation types in `napari`\n\n.\n\n**Deliverables**\n\nSupport for mask annotation datasets in\n\n`ethology`\n\n(following the current bounding box annotations dataset).Support for defining bounding box annotations in\n\n`napari`\n\n: drawing, exporting to file (e.g. JSON COCO format and as`ethology`\n\ndataset netCDF) and loading from file.Support for defining mask annotations in\n\n`napari`\n\n: drawing, exporting to file (e.g. JSON COCO format and as`ethology`\n\ndataset netCDF) and loading from file.Example use-cases in the\n\n`ethology`\n\n[gallery](https://ethology.neuroinformatics.dev/latest/examples/index.html).(Optional) Support for defining keypoint annotations in\n\n`napari`\n\n\n**Duration**\n\nLarge (~350 hours)\n\n**Difficulty**\n\nThis project is well suited for an intermediate contributor to open source.\n\n**Required skills**\n\nFluency with Python, experience working with multi-dimensional arrays libraries such as [xarray](https://docs.xarray.dev/en/stable/index.html), and experience with [pytest](https://docs.pytest.org/en/stable/).\n\n**Nice-to-haves**\n\nExperience with [napari](https://napari.org/stable/) plugins.\n\n**Potential mentors**\n\n**Further reading**\n\n, to get familiar with the structure of the annotations dataset.`ethology`\n\nexamples\n\n## Team[#](https://neuroinformatics.dev#team)\n\nThe NIU GSoC team for 2026 is composed of the following members. To read more about the different roles involved in GSoC, see [GSoC Participant Roles](https://google.github.io/gsocguides/mentor/#participant-roles).\n\nOur working languages are Python and English ;) - but we also speak other languages! We listed any additional languages spoken by the mentors in the projects list."
  },
  {
    "name": "QC-Devs",
    "slug": "qc-devs",
    "tagline": "Sustainable software for quantum chemistry & more",
    "description": "QC-Devs develops free, open-source, and cross-platform libraries for the computational sciences, focusing on theoretical and computational chemistry. Our goal is to make programming accessible to students and researchers, to catalyze scientific collaborations, and to promote precepts of sustainable software development. We're adapting some of the same principles to develop free and open-source educational materials (qc-edu.org) to modernize scientific education by integrating hands-on computation and computer programming.",
    "ideas_url": "https://qcdevs.org/join/qcdevs_gsoc/",
    "website_url": "https://qcdevs.org/",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "github",
      "c++",
      "julia",
      "jupyter"
    ],
    "topic_tags": [
      "data science",
      "scientific visualization",
      "quantum chemistry",
      "Computational Science",
      "numerical algorithms"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/qc-devs",
    "ideas_content": "#\n[Google Summer of Code 2026\n](https://qcdevs.org//join/qcdevs_gsoc/)\n\nThis document provides guidance for individuals interested in participating in the [Google Summer of Code (GSoC)](https://summerofcode.withgoogle.com/) program with QC-Devs. We are looking forward to your contributions.\n\n## Project Ideas\n\nWe store project ideas as GitHub issues. The below links refer to these issues, where you can find more information\nabout the package, the project, the task, and the expected outcomes. While QC-Devs supports quite a few packages (we released 9 in the last\n18 months!), each year we select a few to focus on, as this makes it easier for mentors to engage with\nparticipants. In keeping with this year’s GSoC emphasis on AI, we also included a [project related to AI/ML](https://github.com/theochem/Selector/issues/285).\n\n## Contributor Guidance\n\n[QC-Devs GSoC Contributor Guidance (for Proposals)](https://github.com/theochem/guidelines/blob/main/GSoC.md)[QC-Devs Contributor Guidelines (for Code)](https://github.com/theochem/guidelines/blob/main/CONTRIBUTING.md)[QC-Devs community health files, including our code-of-conduct](https://github.com/theochem/.github)\n\n## Previous Projects\n\n- A web interface for the\npackage. See the`Selector`\n\n[result](https://huggingface.co/spaces/QCDevs/Selector_GSoC)and the[original issue](https://github.com/theochem/Selector/issues/191). The software release note is published in[J. Chem. Inf. Model., 2026](https://pubs.acs.org/doi/10.1021/acs.jcim.5c01499)(2024) - A new API and additional functionality for the\npackage. See the`ModelHamiltonian`\n\n[original issue](https://github.com/theochem/ModelHamiltonian/issues/67). This led to a[software release publication](https://doi.org/10.1063/5.0219015).(2024) - Development and testing of an analytic solver for the chemical master equation in the\npackage. See the`NICE.jl`\n\n[original issue](https://github.com/theochem/NICE.jl/issues/8). A software release publication is in preparation. (2025) - Building interfaces to external packages for\n. See the`ModelHamiltonian`\n\n[original issue](https://github.com/theochem/ModelHamiltonian/issues/148). A scientific publication is in preparation. (2025) - Improve performance of\nby implementing screening techniques. See the`GBasis`\n\n[original issue](https://github.com/theochem/gbasis/issues/207). (2025) - Implementation of transformed grids and adaptive molecular quadrature in the\npackage. See the`Grid`\n\n[original](https://github.com/theochem/grid/issues/264)[issues](https://github.com/theochem/grid/issues/262). (2025) - Refactoring the database structure of the\npackage. See the`AtomDB`\n\n[original issue](https://github.com/theochem/AtomDB/issues/141). (2025) - Implementation of a new algorithm for the calculation of two-electron integrals in the\npackage. See the`GBasis`\n\n[original issue](https://github.com/theochem/gbasis/issues/221). ([Winter of Code](https://winter-of-code-5.devfolio.co/schedule)2026) - Arbitrary-order overlap integrals in the\npackage. See the`GBasis`\n\n[original issue](https://github.com/theochem/gbasis/issues/220)([Winter of Code](https://winter-of-code-5.devfolio.co/schedule)2026) - A full list of past projects can be found in the\n[QC-Devs Archive](https://qcdevs.org/internships/)."
  },
  {
    "name": "Open Food Facts",
    "slug": "open-food-facts",
    "tagline": "Better food choices for your health & the planet",
    "description": "Open Food Facts is the \"Wikipedia of food\". Our community collects information about all the food products in the world, using mobile phones to help people make better choices for themselves and the planet, and to transform the whole food system along the way.\nWe do so using mobile crowdsourcing, community involvement and machine learning,",
    "ideas_url": "https://wiki.openfoodfacts.org/GSOC/2026_ideas_list",
    "website_url": "https://world.openfoodfacts.org/discover",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "machine learning",
      "perl",
      "flutter"
    ],
    "topic_tags": [
      "open data",
      "health",
      "environment",
      "mobile",
      "food"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/open-food-facts",
    "ideas_content": "# Making sure you're not a bot!\n\nLoading...\n\nYou are seeing this because the administrator of this website has set up Anubis to protect the server against the scourge of AI companies aggressively scraping websites. This can and does cause downtime for the websites, which makes their resources inaccessible for everyone.\n\nAnubis is a compromise. Anubis uses a Proof-of-Work scheme in the vein of Hashcash, a proposed proof-of-work scheme for reducing email spam. The idea is that at individual scales the additional load is ignorable, but at mass scraper levels it adds up and makes scraping much more expensive.\n\nUltimately, this is a placeholder solution so that more time can be spent on fingerprinting and identifying headless browsers (EG: via how they do font rendering) so that the challenge proof of work page doesn't need to be presented to users that are much more likely to be legitimate.\n\nPlease note that Anubis requires the use of modern JavaScript features that plugins like JShelter will disable. Please disable JShelter or other such plugins for this domain."
  },
  {
    "name": "Metasploit",
    "slug": "metasploit",
    "tagline": "World’s most used penetration testing framework",
    "description": "The Metasploit Framework is both a penetration testing system and a development platform for creating security tools and exploits. The framework is used by network security professionals to perform penetration tests, system administrators to verify patch installations, product vendors to perform regression testing, and security researchers world-wide. The framework is written in the Ruby programming language and includes components written in C, many flavors of Assembly, Python, Powershell, PHP, and other languages.\n\nThe framework consists of tools, libraries, modules, and user interfaces. The basic function of the framework is a module launcher, allowing the user to configure an exploit module and launch it at a target system. If the exploit succeeds, the payload is executed on the target and the user is provided with a shell to interact with the payload. Hundreds of exploits and dozens of payload options are available.",
    "ideas_url": "https://github.com/rapid7/metasploit-framework/blob/master/docs/metasploit-framework.wiki/GSoC-2026-Project-Ideas.md",
    "website_url": "https://metasploit.com",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "c",
      "python",
      "postgresql",
      "ruby",
      "assembly"
    ],
    "topic_tags": [
      "security",
      "penetration testing",
      "offensive security",
      "exploitation"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/metasploit",
    "ideas_content": "GSoC Project Ideas in no particular order. When you've picked one, take a look at [[How-to-Apply-to-GSoC]] for how to make a proposal.\n\nMentors: [@jheysel-r7](https://github.com/jheysel-r7)\nCo-mentors: [@zeroSteiner](https://github.com/zeroSteiner) [@h00die](https://github.com/h00die)\n\nSlack Contacts: @jheysel, @zeroSteiner and @h00die on [Metasploit Slack](https://metasploit.slack.com/)\n\n\nFor any questions about these projects reach out on the Metasploit Slack in the `#gsoc` channel or DM one of the mentors\nusing the Slack contacts listed above. Note that mentors may be busy so please don't expect an immediate response,\nhowever we will endeavor to respond as soon as possible. If you'd prefer not to join Slack, you can also email\n`msfdev [@] metasploit [dot] com` and we will respond to your questions there if email is preferable.\n\n## Enhance Metasploit Framework\n### CertificateTrace and KerberosTicketTrace Support\n\nKerberos and certificate-based authentication mechanisms are becoming increasingly prevalent across modern environments,\nparticularly in Active Directory and enterprise deployments. As a result, Metasploit modules that interact with these\nauthentication flows often require operators and developers to inspect Kerberos tickets or certificate material in order\nto understand behavior, troubleshoot failures, or validate exploitation techniques. Today, this inspection typically\nrequires switching to separate auxiliary modules or exporting artifacts (such as .pfx files) for analysis with external\ntooling, which interrupts the normal workflow.\n\nThis project would introduce CertificateTrace and KerberosTicketTrace functionality to Metasploit, allowing relevant\nauthentication artifacts to be captured and inspected as part of module execution. Similar in concept to the existing\nHttpTrace capability, these traces would focus specifically on certificate and Kerberos-based authentication, decoding\nand presenting useful metadata in a consistent, operator-friendly format. Similar to HttpTrace and HttpTraceHeadersOnly,\nwe would expect there to be support for different levels of logging, ex: print only the Certificate Signing Request (CSR).\n\n\nMentors: @jheysel-r7, @zeroSteiner\n\nSize: 175 hrs\n\nDifficulty: Medium\n\nRequired Skills: Understanding of how Kerberos and certificate-based authentication work; ability to write and deliver Ruby code.\n\nPreferred Skills: Experience working with or using Kerberos and/or certificate-based authentication.\n\n\n### Automated Vulnerable Environment Provisioning (build_vuln)\n\nMany Metasploit modules—particularly those targeting web applications or open source software—include documentation\ndescribing how to build a vulnerable test environment, and some provide vulnerable container images to simplify this\nprocess. However, this information is typically maintained in module documentation and requires users to manually build\nand start the environment outside of Metasploit, making module verification more time-consuming and inconsistent.\n\nThis project proposes a new Metasploit command (for example, build_vuln) that automates launching a vulnerable\nenvironment for a given exploit module. Vulnerable environments would be defined using Open Container Initiative\n(OCI)–compliant configurations and designed to work with both Podman and Docker, with rootless execution.\n\nThe goal of this project is to automate setup steps that are already documented today, making it easier for users to\ntest exploits locally and for contributors and Rapid7 engineers to verify module behavior in a repeatable,\nwell-defined environment. This project would include refactoring existing modules to leverage the new functionality\nwhere possible (docker-compose files already exist), as well as creating new vulnerable environment definitions for\npopular modules that lack them today.\n\n\nMentors: @jheysel-r7, @h00die\n\nSize: 360 hrs\n\nDifficulty: Medium\n\nRequired Skills: Understanding of how containers work in the context of the Open Container Initiative; ability to write and deliver Ruby code.\n\nPreferred Skills: Experience using containers; understanding of container definitions and best practices.\n\n\n## Submit your own\n\nIf you want to suggest your own idea, please discuss it with us first on [Slack](https://metasploit.com/slack) in the\n`#gsoc` channel to make sure it is a reasonable amount of work for a summer and that it fits the goals of the project."
  },
  {
    "name": "Uramaki LAB",
    "slug": "uramaki-lab",
    "tagline": "The User Experience LAB based on IA",
    "description": "The RUXAILAB is an open-source organization dedicated to democratizing usability and accessibility evaluation through the use of Artificial Intelligence. We provide a suite of AI-powered tools that enable remote usability and accessibility testing, ensuring that professionals and researchers can analyze user experience through different methodologies.\n\nOur platform supports multiple methods such as User Testing, Heuristic Evaluation, Eye-Tracking system, Sentimental Analysis, a semi-automated tool for prototyping virtual reality environments in 2D, and heatmap analysis for advanced data extraction. \n\nOur mission is to eliminate financial and technological barriers to usability and accessibility research, making it possible for anyone, anywhere to set up their own usability lab at zero cost.\n\nWe invite developers, designers, and researchers to join us in expanding our toolkit, refining our existing solutions, and fostering a more accessible digital world. 🚀🌍",
    "ideas_url": "https://ruxailab.github.io/gsoc/",
    "website_url": "https://github.com/ruxailab",
    "irc_channel": "",
    "contact_email": "",
    "mailing_list": "",
    "tech_tags": [
      "python",
      "javascript",
      "html",
      "css",
      "Firebase"
    ],
    "topic_tags": [
      "artificial intelligence",
      "user experience",
      "Usability",
      "Eye Tracking"
    ],
    "category": "",
    "gsoc_page": "https://summerofcode.withgoogle.com/programs/2026/organizations/uramaki-lab",
    "ideas_content": "Google Summer of Code 2026\nExplore all our GSoC 2026 project ideas\nProject Size:\nAll Sizes\nBig (~350h)\nMedium (~175h)\nSmall (~90h)\nDifficulty:\nAll Levels\nHard\nMedium\nEasy\nSearch:\nReset Filters\nTitle\nSize\nHours\nDifficulty\nMentor\nKeywords\nSkills\nDescription\n×"
  }
]